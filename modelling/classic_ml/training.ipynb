{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e23aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.fft import fft\n",
    "# import polars as pl\n",
    "# import kaggle_evaluation.cmi_inference_server\n",
    "\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e4cc107",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0ea3b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>orientation</th>\n",
       "      <th>behavior</th>\n",
       "      <th>phase</th>\n",
       "      <th>gesture</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>thm_1</th>\n",
       "      <th>thm_2</th>\n",
       "      <th>thm_3</th>\n",
       "      <th>thm_4</th>\n",
       "      <th>thm_5</th>\n",
       "      <th>tof_1_v0</th>\n",
       "      <th>tof_1_v1</th>\n",
       "      <th>tof_1_v2</th>\n",
       "      <th>tof_1_v3</th>\n",
       "      <th>tof_1_v4</th>\n",
       "      <th>tof_1_v5</th>\n",
       "      <th>tof_1_v6</th>\n",
       "      <th>tof_1_v7</th>\n",
       "      <th>tof_1_v8</th>\n",
       "      <th>tof_1_v9</th>\n",
       "      <th>tof_1_v10</th>\n",
       "      <th>tof_1_v11</th>\n",
       "      <th>tof_1_v12</th>\n",
       "      <th>tof_1_v13</th>\n",
       "      <th>tof_1_v14</th>\n",
       "      <th>tof_1_v15</th>\n",
       "      <th>tof_1_v16</th>\n",
       "      <th>tof_1_v17</th>\n",
       "      <th>tof_1_v18</th>\n",
       "      <th>tof_1_v19</th>\n",
       "      <th>tof_1_v20</th>\n",
       "      <th>tof_1_v21</th>\n",
       "      <th>tof_1_v22</th>\n",
       "      <th>tof_1_v23</th>\n",
       "      <th>tof_1_v24</th>\n",
       "      <th>tof_1_v25</th>\n",
       "      <th>tof_1_v26</th>\n",
       "      <th>tof_1_v27</th>\n",
       "      <th>tof_1_v28</th>\n",
       "      <th>tof_1_v29</th>\n",
       "      <th>tof_1_v30</th>\n",
       "      <th>tof_1_v31</th>\n",
       "      <th>tof_1_v32</th>\n",
       "      <th>tof_1_v33</th>\n",
       "      <th>tof_1_v34</th>\n",
       "      <th>tof_1_v35</th>\n",
       "      <th>tof_1_v36</th>\n",
       "      <th>tof_1_v37</th>\n",
       "      <th>tof_1_v38</th>\n",
       "      <th>tof_1_v39</th>\n",
       "      <th>tof_1_v40</th>\n",
       "      <th>tof_1_v41</th>\n",
       "      <th>tof_1_v42</th>\n",
       "      <th>tof_1_v43</th>\n",
       "      <th>tof_1_v44</th>\n",
       "      <th>tof_1_v45</th>\n",
       "      <th>tof_1_v46</th>\n",
       "      <th>tof_1_v47</th>\n",
       "      <th>tof_1_v48</th>\n",
       "      <th>tof_1_v49</th>\n",
       "      <th>tof_1_v50</th>\n",
       "      <th>tof_1_v51</th>\n",
       "      <th>tof_1_v52</th>\n",
       "      <th>tof_1_v53</th>\n",
       "      <th>tof_1_v54</th>\n",
       "      <th>tof_1_v55</th>\n",
       "      <th>tof_1_v56</th>\n",
       "      <th>tof_1_v57</th>\n",
       "      <th>tof_1_v58</th>\n",
       "      <th>tof_1_v59</th>\n",
       "      <th>tof_1_v60</th>\n",
       "      <th>tof_1_v61</th>\n",
       "      <th>tof_1_v62</th>\n",
       "      <th>tof_1_v63</th>\n",
       "      <th>tof_2_v0</th>\n",
       "      <th>tof_2_v1</th>\n",
       "      <th>tof_2_v2</th>\n",
       "      <th>tof_2_v3</th>\n",
       "      <th>tof_2_v4</th>\n",
       "      <th>tof_2_v5</th>\n",
       "      <th>tof_2_v6</th>\n",
       "      <th>tof_2_v7</th>\n",
       "      <th>tof_2_v8</th>\n",
       "      <th>tof_2_v9</th>\n",
       "      <th>tof_2_v10</th>\n",
       "      <th>tof_2_v11</th>\n",
       "      <th>tof_2_v12</th>\n",
       "      <th>tof_2_v13</th>\n",
       "      <th>tof_2_v14</th>\n",
       "      <th>tof_2_v15</th>\n",
       "      <th>tof_2_v16</th>\n",
       "      <th>tof_2_v17</th>\n",
       "      <th>tof_2_v18</th>\n",
       "      <th>tof_2_v19</th>\n",
       "      <th>tof_2_v20</th>\n",
       "      <th>tof_2_v21</th>\n",
       "      <th>tof_2_v22</th>\n",
       "      <th>tof_2_v23</th>\n",
       "      <th>tof_2_v24</th>\n",
       "      <th>tof_2_v25</th>\n",
       "      <th>tof_2_v26</th>\n",
       "      <th>tof_2_v27</th>\n",
       "      <th>tof_2_v28</th>\n",
       "      <th>tof_2_v29</th>\n",
       "      <th>tof_2_v30</th>\n",
       "      <th>tof_2_v31</th>\n",
       "      <th>tof_2_v32</th>\n",
       "      <th>tof_2_v33</th>\n",
       "      <th>tof_2_v34</th>\n",
       "      <th>tof_2_v35</th>\n",
       "      <th>tof_2_v36</th>\n",
       "      <th>tof_2_v37</th>\n",
       "      <th>tof_2_v38</th>\n",
       "      <th>tof_2_v39</th>\n",
       "      <th>tof_2_v40</th>\n",
       "      <th>tof_2_v41</th>\n",
       "      <th>tof_2_v42</th>\n",
       "      <th>tof_2_v43</th>\n",
       "      <th>tof_2_v44</th>\n",
       "      <th>tof_2_v45</th>\n",
       "      <th>tof_2_v46</th>\n",
       "      <th>tof_2_v47</th>\n",
       "      <th>tof_2_v48</th>\n",
       "      <th>tof_2_v49</th>\n",
       "      <th>tof_2_v50</th>\n",
       "      <th>tof_2_v51</th>\n",
       "      <th>tof_2_v52</th>\n",
       "      <th>tof_2_v53</th>\n",
       "      <th>tof_2_v54</th>\n",
       "      <th>tof_2_v55</th>\n",
       "      <th>tof_2_v56</th>\n",
       "      <th>tof_2_v57</th>\n",
       "      <th>tof_2_v58</th>\n",
       "      <th>tof_2_v59</th>\n",
       "      <th>tof_2_v60</th>\n",
       "      <th>tof_2_v61</th>\n",
       "      <th>tof_2_v62</th>\n",
       "      <th>tof_2_v63</th>\n",
       "      <th>tof_3_v0</th>\n",
       "      <th>tof_3_v1</th>\n",
       "      <th>tof_3_v2</th>\n",
       "      <th>tof_3_v3</th>\n",
       "      <th>tof_3_v4</th>\n",
       "      <th>tof_3_v5</th>\n",
       "      <th>tof_3_v6</th>\n",
       "      <th>tof_3_v7</th>\n",
       "      <th>tof_3_v8</th>\n",
       "      <th>tof_3_v9</th>\n",
       "      <th>tof_3_v10</th>\n",
       "      <th>tof_3_v11</th>\n",
       "      <th>tof_3_v12</th>\n",
       "      <th>tof_3_v13</th>\n",
       "      <th>tof_3_v14</th>\n",
       "      <th>tof_3_v15</th>\n",
       "      <th>tof_3_v16</th>\n",
       "      <th>tof_3_v17</th>\n",
       "      <th>tof_3_v18</th>\n",
       "      <th>tof_3_v19</th>\n",
       "      <th>tof_3_v20</th>\n",
       "      <th>tof_3_v21</th>\n",
       "      <th>tof_3_v22</th>\n",
       "      <th>tof_3_v23</th>\n",
       "      <th>tof_3_v24</th>\n",
       "      <th>tof_3_v25</th>\n",
       "      <th>tof_3_v26</th>\n",
       "      <th>tof_3_v27</th>\n",
       "      <th>tof_3_v28</th>\n",
       "      <th>tof_3_v29</th>\n",
       "      <th>tof_3_v30</th>\n",
       "      <th>tof_3_v31</th>\n",
       "      <th>tof_3_v32</th>\n",
       "      <th>tof_3_v33</th>\n",
       "      <th>tof_3_v34</th>\n",
       "      <th>tof_3_v35</th>\n",
       "      <th>tof_3_v36</th>\n",
       "      <th>tof_3_v37</th>\n",
       "      <th>tof_3_v38</th>\n",
       "      <th>tof_3_v39</th>\n",
       "      <th>tof_3_v40</th>\n",
       "      <th>tof_3_v41</th>\n",
       "      <th>tof_3_v42</th>\n",
       "      <th>tof_3_v43</th>\n",
       "      <th>tof_3_v44</th>\n",
       "      <th>tof_3_v45</th>\n",
       "      <th>tof_3_v46</th>\n",
       "      <th>tof_3_v47</th>\n",
       "      <th>tof_3_v48</th>\n",
       "      <th>tof_3_v49</th>\n",
       "      <th>tof_3_v50</th>\n",
       "      <th>tof_3_v51</th>\n",
       "      <th>tof_3_v52</th>\n",
       "      <th>tof_3_v53</th>\n",
       "      <th>tof_3_v54</th>\n",
       "      <th>tof_3_v55</th>\n",
       "      <th>tof_3_v56</th>\n",
       "      <th>tof_3_v57</th>\n",
       "      <th>tof_3_v58</th>\n",
       "      <th>tof_3_v59</th>\n",
       "      <th>tof_3_v60</th>\n",
       "      <th>tof_3_v61</th>\n",
       "      <th>tof_3_v62</th>\n",
       "      <th>tof_3_v63</th>\n",
       "      <th>tof_4_v0</th>\n",
       "      <th>tof_4_v1</th>\n",
       "      <th>tof_4_v2</th>\n",
       "      <th>tof_4_v3</th>\n",
       "      <th>tof_4_v4</th>\n",
       "      <th>tof_4_v5</th>\n",
       "      <th>tof_4_v6</th>\n",
       "      <th>tof_4_v7</th>\n",
       "      <th>tof_4_v8</th>\n",
       "      <th>tof_4_v9</th>\n",
       "      <th>tof_4_v10</th>\n",
       "      <th>tof_4_v11</th>\n",
       "      <th>tof_4_v12</th>\n",
       "      <th>tof_4_v13</th>\n",
       "      <th>tof_4_v14</th>\n",
       "      <th>tof_4_v15</th>\n",
       "      <th>tof_4_v16</th>\n",
       "      <th>tof_4_v17</th>\n",
       "      <th>tof_4_v18</th>\n",
       "      <th>tof_4_v19</th>\n",
       "      <th>tof_4_v20</th>\n",
       "      <th>tof_4_v21</th>\n",
       "      <th>tof_4_v22</th>\n",
       "      <th>tof_4_v23</th>\n",
       "      <th>tof_4_v24</th>\n",
       "      <th>tof_4_v25</th>\n",
       "      <th>tof_4_v26</th>\n",
       "      <th>tof_4_v27</th>\n",
       "      <th>tof_4_v28</th>\n",
       "      <th>tof_4_v29</th>\n",
       "      <th>tof_4_v30</th>\n",
       "      <th>tof_4_v31</th>\n",
       "      <th>tof_4_v32</th>\n",
       "      <th>tof_4_v33</th>\n",
       "      <th>tof_4_v34</th>\n",
       "      <th>tof_4_v35</th>\n",
       "      <th>tof_4_v36</th>\n",
       "      <th>tof_4_v37</th>\n",
       "      <th>tof_4_v38</th>\n",
       "      <th>tof_4_v39</th>\n",
       "      <th>tof_4_v40</th>\n",
       "      <th>tof_4_v41</th>\n",
       "      <th>tof_4_v42</th>\n",
       "      <th>tof_4_v43</th>\n",
       "      <th>tof_4_v44</th>\n",
       "      <th>tof_4_v45</th>\n",
       "      <th>tof_4_v46</th>\n",
       "      <th>tof_4_v47</th>\n",
       "      <th>tof_4_v48</th>\n",
       "      <th>tof_4_v49</th>\n",
       "      <th>tof_4_v50</th>\n",
       "      <th>tof_4_v51</th>\n",
       "      <th>tof_4_v52</th>\n",
       "      <th>tof_4_v53</th>\n",
       "      <th>tof_4_v54</th>\n",
       "      <th>tof_4_v55</th>\n",
       "      <th>tof_4_v56</th>\n",
       "      <th>tof_4_v57</th>\n",
       "      <th>tof_4_v58</th>\n",
       "      <th>tof_4_v59</th>\n",
       "      <th>tof_4_v60</th>\n",
       "      <th>tof_4_v61</th>\n",
       "      <th>tof_4_v62</th>\n",
       "      <th>tof_4_v63</th>\n",
       "      <th>tof_5_v0</th>\n",
       "      <th>tof_5_v1</th>\n",
       "      <th>tof_5_v2</th>\n",
       "      <th>tof_5_v3</th>\n",
       "      <th>tof_5_v4</th>\n",
       "      <th>tof_5_v5</th>\n",
       "      <th>tof_5_v6</th>\n",
       "      <th>tof_5_v7</th>\n",
       "      <th>tof_5_v8</th>\n",
       "      <th>tof_5_v9</th>\n",
       "      <th>tof_5_v10</th>\n",
       "      <th>tof_5_v11</th>\n",
       "      <th>tof_5_v12</th>\n",
       "      <th>tof_5_v13</th>\n",
       "      <th>tof_5_v14</th>\n",
       "      <th>tof_5_v15</th>\n",
       "      <th>tof_5_v16</th>\n",
       "      <th>tof_5_v17</th>\n",
       "      <th>tof_5_v18</th>\n",
       "      <th>tof_5_v19</th>\n",
       "      <th>tof_5_v20</th>\n",
       "      <th>tof_5_v21</th>\n",
       "      <th>tof_5_v22</th>\n",
       "      <th>tof_5_v23</th>\n",
       "      <th>tof_5_v24</th>\n",
       "      <th>tof_5_v25</th>\n",
       "      <th>tof_5_v26</th>\n",
       "      <th>tof_5_v27</th>\n",
       "      <th>tof_5_v28</th>\n",
       "      <th>tof_5_v29</th>\n",
       "      <th>tof_5_v30</th>\n",
       "      <th>tof_5_v31</th>\n",
       "      <th>tof_5_v32</th>\n",
       "      <th>tof_5_v33</th>\n",
       "      <th>tof_5_v34</th>\n",
       "      <th>tof_5_v35</th>\n",
       "      <th>tof_5_v36</th>\n",
       "      <th>tof_5_v37</th>\n",
       "      <th>tof_5_v38</th>\n",
       "      <th>tof_5_v39</th>\n",
       "      <th>tof_5_v40</th>\n",
       "      <th>tof_5_v41</th>\n",
       "      <th>tof_5_v42</th>\n",
       "      <th>tof_5_v43</th>\n",
       "      <th>tof_5_v44</th>\n",
       "      <th>tof_5_v45</th>\n",
       "      <th>tof_5_v46</th>\n",
       "      <th>tof_5_v47</th>\n",
       "      <th>tof_5_v48</th>\n",
       "      <th>tof_5_v49</th>\n",
       "      <th>tof_5_v50</th>\n",
       "      <th>tof_5_v51</th>\n",
       "      <th>tof_5_v52</th>\n",
       "      <th>tof_5_v53</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000007_000000</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>0</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.683594</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.355469</td>\n",
       "      <td>0.134399</td>\n",
       "      <td>-0.355164</td>\n",
       "      <td>-0.447327</td>\n",
       "      <td>-0.809753</td>\n",
       "      <td>28.943842</td>\n",
       "      <td>31.822186</td>\n",
       "      <td>29.553024</td>\n",
       "      <td>28.592863</td>\n",
       "      <td>28.310535</td>\n",
       "      <td>131.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000007_000001</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>1</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.949219</td>\n",
       "      <td>6.214844</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>0.143494</td>\n",
       "      <td>-0.340271</td>\n",
       "      <td>-0.428650</td>\n",
       "      <td>-0.824524</td>\n",
       "      <td>29.340816</td>\n",
       "      <td>31.874645</td>\n",
       "      <td>29.791740</td>\n",
       "      <td>28.663383</td>\n",
       "      <td>28.406172</td>\n",
       "      <td>130.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000007_000002</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>2</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>5.722656</td>\n",
       "      <td>5.410156</td>\n",
       "      <td>5.421875</td>\n",
       "      <td>0.219055</td>\n",
       "      <td>-0.274231</td>\n",
       "      <td>-0.356934</td>\n",
       "      <td>-0.865662</td>\n",
       "      <td>30.339359</td>\n",
       "      <td>30.935045</td>\n",
       "      <td>30.090014</td>\n",
       "      <td>28.796087</td>\n",
       "      <td>28.529778</td>\n",
       "      <td>137.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000007_000003</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>3</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>6.601562</td>\n",
       "      <td>3.531250</td>\n",
       "      <td>6.457031</td>\n",
       "      <td>0.297546</td>\n",
       "      <td>-0.264160</td>\n",
       "      <td>-0.238159</td>\n",
       "      <td>-0.885986</td>\n",
       "      <td>30.543730</td>\n",
       "      <td>27.044001</td>\n",
       "      <td>29.310717</td>\n",
       "      <td>29.018711</td>\n",
       "      <td>27.402010</td>\n",
       "      <td>143.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000007_000004</td>\n",
       "      <td>Target</td>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>4</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Seated Lean Non Dom - FACE DOWN</td>\n",
       "      <td>Relaxes and moves hand to target location</td>\n",
       "      <td>Transition</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>5.566406</td>\n",
       "      <td>0.277344</td>\n",
       "      <td>9.632812</td>\n",
       "      <td>0.333557</td>\n",
       "      <td>-0.218628</td>\n",
       "      <td>-0.063538</td>\n",
       "      <td>-0.914856</td>\n",
       "      <td>29.317265</td>\n",
       "      <td>25.270855</td>\n",
       "      <td>26.808746</td>\n",
       "      <td>29.408604</td>\n",
       "      <td>27.357603</td>\n",
       "      <td>178.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              row_id sequence_type sequence_id  sequence_counter      subject  \\\n",
       "0  SEQ_000007_000000        Target  SEQ_000007                 0  SUBJ_059520   \n",
       "1  SEQ_000007_000001        Target  SEQ_000007                 1  SUBJ_059520   \n",
       "2  SEQ_000007_000002        Target  SEQ_000007                 2  SUBJ_059520   \n",
       "3  SEQ_000007_000003        Target  SEQ_000007                 3  SUBJ_059520   \n",
       "4  SEQ_000007_000004        Target  SEQ_000007                 4  SUBJ_059520   \n",
       "\n",
       "                       orientation                                   behavior  \\\n",
       "0  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "1  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "2  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "3  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "4  Seated Lean Non Dom - FACE DOWN  Relaxes and moves hand to target location   \n",
       "\n",
       "        phase             gesture     acc_x     acc_y     acc_z     rot_w  \\\n",
       "0  Transition  Cheek - pinch skin  6.683594  6.214844  3.355469  0.134399   \n",
       "1  Transition  Cheek - pinch skin  6.949219  6.214844  3.125000  0.143494   \n",
       "2  Transition  Cheek - pinch skin  5.722656  5.410156  5.421875  0.219055   \n",
       "3  Transition  Cheek - pinch skin  6.601562  3.531250  6.457031  0.297546   \n",
       "4  Transition  Cheek - pinch skin  5.566406  0.277344  9.632812  0.333557   \n",
       "\n",
       "      rot_x     rot_y     rot_z      thm_1      thm_2      thm_3      thm_4  \\\n",
       "0 -0.355164 -0.447327 -0.809753  28.943842  31.822186  29.553024  28.592863   \n",
       "1 -0.340271 -0.428650 -0.824524  29.340816  31.874645  29.791740  28.663383   \n",
       "2 -0.274231 -0.356934 -0.865662  30.339359  30.935045  30.090014  28.796087   \n",
       "3 -0.264160 -0.238159 -0.885986  30.543730  27.044001  29.310717  29.018711   \n",
       "4 -0.218628 -0.063538 -0.914856  29.317265  25.270855  26.808746  29.408604   \n",
       "\n",
       "       thm_5  tof_1_v0  tof_1_v1  tof_1_v2  tof_1_v3  tof_1_v4  tof_1_v5  \\\n",
       "0  28.310535     131.0     134.0     132.0     135.0      98.0      74.0   \n",
       "1  28.406172     130.0     138.0     131.0     135.0     101.0      76.0   \n",
       "2  28.529778     137.0     136.0     147.0     109.0      90.0      81.0   \n",
       "3  27.402010     143.0     147.0     170.0     127.0     109.0      98.0   \n",
       "4  27.357603     178.0     191.0     183.0     157.0     146.0     139.0   \n",
       "\n",
       "   tof_1_v6  tof_1_v7  tof_1_v8  tof_1_v9  tof_1_v10  tof_1_v11  tof_1_v12  \\\n",
       "0      64.0      60.0      -1.0      -1.0      152.0      153.0      141.0   \n",
       "1      66.0      61.0      -1.0      -1.0      156.0      155.0      141.0   \n",
       "2      74.0      74.0      -1.0     164.0      165.0      146.0      106.0   \n",
       "3      95.0      95.0      -1.0     177.0      189.0      177.0      136.0   \n",
       "4     143.0     148.0      -1.0      -1.0      236.0      238.0      208.0   \n",
       "\n",
       "   tof_1_v13  tof_1_v14  tof_1_v15  tof_1_v16  tof_1_v17  tof_1_v18  \\\n",
       "0       89.0       68.0       63.0       -1.0       -1.0       -1.0   \n",
       "1       93.0       74.0       64.0       -1.0       -1.0       -1.0   \n",
       "2       94.0       77.0       77.0       -1.0       -1.0       -1.0   \n",
       "3      121.0      107.0      104.0       -1.0       -1.0       -1.0   \n",
       "4      200.0      185.0      190.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_1_v19  tof_1_v20  tof_1_v21  tof_1_v22  tof_1_v23  tof_1_v24  \\\n",
       "0       -1.0      169.0      118.0       86.0       73.0       -1.0   \n",
       "1       -1.0      165.0      116.0       86.0       75.0      130.0   \n",
       "2      180.0      140.0      118.0      103.0       92.0       -1.0   \n",
       "3      202.0      171.0      160.0      141.0      135.0       -1.0   \n",
       "4      210.0      246.0      225.0      228.0      202.0      149.0   \n",
       "\n",
       "   tof_1_v25  tof_1_v26  tof_1_v27  tof_1_v28  tof_1_v29  tof_1_v30  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0      147.0      110.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0      142.0      114.0   \n",
       "2       -1.0       -1.0       -1.0       -1.0      155.0      119.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0      197.0      168.0   \n",
       "4      206.0      219.0      219.0      225.0      218.0      214.0   \n",
       "\n",
       "   tof_1_v31  tof_1_v32  tof_1_v33  tof_1_v34  tof_1_v35  tof_1_v36  \\\n",
       "0       87.0      126.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1       91.0      127.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2      122.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "3      150.0      131.0       -1.0       -1.0       -1.0      170.0   \n",
       "4       -1.0      162.0      177.0      206.0      219.0      207.0   \n",
       "\n",
       "   tof_1_v37  tof_1_v38  tof_1_v39  tof_1_v40  tof_1_v41  tof_1_v42  \\\n",
       "0       -1.0      137.0      108.0      115.0       -1.0       -1.0   \n",
       "1       -1.0      145.0      114.0      114.0       -1.0       -1.0   \n",
       "2       -1.0      148.0      130.0      123.0      158.0       -1.0   \n",
       "3      179.0      174.0      164.0      125.0      140.0      161.0   \n",
       "4      182.0      225.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_1_v43  tof_1_v44  tof_1_v45  tof_1_v46  tof_1_v47  tof_1_v48  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0      128.0      110.0   \n",
       "1       -1.0      135.0       -1.0       -1.0      132.0      110.0   \n",
       "2      141.0      147.0       -1.0      157.0      141.0      113.0   \n",
       "3      175.0      154.0      174.0      160.0      159.0       -1.0   \n",
       "4      233.0      195.0      204.0      190.0       -1.0       -1.0   \n",
       "\n",
       "   tof_1_v49  tof_1_v50  tof_1_v51  tof_1_v52  tof_1_v53  tof_1_v54  \\\n",
       "0      129.0      140.0       -1.0      126.0      131.0       -1.0   \n",
       "1      121.0      138.0      142.0      123.0      131.0       -1.0   \n",
       "2      131.0      152.0      147.0      146.0      157.0      144.0   \n",
       "3      126.0      143.0      167.0      149.0      137.0      130.0   \n",
       "4       -1.0       -1.0       -1.0      209.0      210.0       -1.0   \n",
       "\n",
       "   tof_1_v55  tof_1_v56  tof_1_v57  tof_1_v58  tof_1_v59  tof_1_v60  \\\n",
       "0       -1.0       -1.0      108.0      122.0      139.0      113.0   \n",
       "1       -1.0       -1.0      106.0      120.0      139.0      119.0   \n",
       "2      127.0       -1.0      115.0      127.0      129.0      119.0   \n",
       "3      131.0       -1.0       -1.0       -1.0      141.0      137.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_1_v61  tof_1_v62  tof_1_v63  tof_2_v0  tof_2_v1  tof_2_v2  tof_2_v3  \\\n",
       "0      121.0       -1.0      118.0      96.0      -1.0      -1.0      -1.0   \n",
       "1      124.0      131.0      117.0     109.0      -1.0      -1.0      -1.0   \n",
       "2      112.0      117.0      120.0     119.0      -1.0      -1.0     125.0   \n",
       "3      129.0      115.0      124.0     108.0     123.0     146.0     166.0   \n",
       "4       -1.0       -1.0       -1.0     138.0     155.0     173.0     188.0   \n",
       "\n",
       "   tof_2_v4  tof_2_v5  tof_2_v6  tof_2_v7  tof_2_v8  tof_2_v9  tof_2_v10  \\\n",
       "0      -1.0     165.0     124.0     100.0     102.0     119.0       -1.0   \n",
       "1      -1.0     165.0     134.0     108.0     106.0     123.0       -1.0   \n",
       "2     154.0     165.0     145.0     122.0     111.0     126.0      143.0   \n",
       "3     152.0     168.0     158.0     161.0     123.0     133.0      138.0   \n",
       "4     180.0     176.0     211.0     235.0      -1.0      -1.0       -1.0   \n",
       "\n",
       "   tof_2_v11  tof_2_v12  tof_2_v13  tof_2_v14  tof_2_v15  tof_2_v16  \\\n",
       "0       -1.0      115.0      130.0       -1.0      124.0      107.0   \n",
       "1       -1.0      121.0      147.0       -1.0      131.0      114.0   \n",
       "2      157.0      143.0      166.0      149.0      137.0      116.0   \n",
       "3      155.0      163.0      151.0      132.0      151.0       -1.0   \n",
       "4       -1.0      210.0      210.0      223.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v17  tof_2_v18  tof_2_v19  tof_2_v20  tof_2_v21  tof_2_v22  \\\n",
       "0      117.0      132.0      136.0      116.0      120.0       -1.0   \n",
       "1      114.0      138.0      145.0      121.0      141.0      144.0   \n",
       "2      123.0      149.0      148.0      136.0      141.0      143.0   \n",
       "3      216.0       -1.0       -1.0      175.0      157.0      146.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v23  tof_2_v24  tof_2_v25  tof_2_v26  tof_2_v27  tof_2_v28  \\\n",
       "0      141.0      118.0      115.0      122.0      145.0      128.0   \n",
       "1      138.0       -1.0      120.0      124.0      147.0      115.0   \n",
       "2      139.0       -1.0      134.0      133.0      142.0      123.0   \n",
       "3      140.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v29  tof_2_v30  tof_2_v31  tof_2_v32  tof_2_v33  tof_2_v34  \\\n",
       "0      130.0      137.0      131.0       -1.0      116.0      117.0   \n",
       "1      141.0      135.0      125.0       -1.0       -1.0      122.0   \n",
       "2      118.0      116.0      128.0       -1.0       -1.0       -1.0   \n",
       "3      173.0      153.0      164.0       -1.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v35  tof_2_v36  tof_2_v37  tof_2_v38  tof_2_v39  tof_2_v40  \\\n",
       "0      130.0      115.0      116.0      117.0      108.0       -1.0   \n",
       "1      122.0      117.0      103.0      108.0      108.0       -1.0   \n",
       "2      143.0      123.0      109.0      112.0      117.0       -1.0   \n",
       "3       -1.0      246.0      189.0       -1.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v41  tof_2_v42  tof_2_v43  tof_2_v44  tof_2_v45  tof_2_v46  \\\n",
       "0       -1.0      119.0      118.0      110.0       93.0       90.0   \n",
       "1       -1.0       -1.0      129.0      108.0      100.0       92.0   \n",
       "2       -1.0       -1.0       -1.0      119.0      127.0      114.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v47  tof_2_v48  tof_2_v49  tof_2_v50  tof_2_v51  tof_2_v52  \\\n",
       "0       90.0       -1.0       -1.0       -1.0      116.0      103.0   \n",
       "1       93.0       -1.0       -1.0       -1.0      116.0       99.0   \n",
       "2      128.0       -1.0       -1.0       -1.0      138.0      136.0   \n",
       "3      225.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v53  tof_2_v54  tof_2_v55  tof_2_v56  tof_2_v57  tof_2_v58  \\\n",
       "0       87.0       82.0       81.0       -1.0       -1.0       -1.0   \n",
       "1       93.0       90.0       91.0       -1.0       -1.0       -1.0   \n",
       "2      129.0      125.0      132.0       -1.0       -1.0       -1.0   \n",
       "3      243.0       -1.0      220.0       -1.0       -1.0       -1.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_2_v59  tof_2_v60  tof_2_v61  tof_2_v62  tof_2_v63  tof_3_v0  tof_3_v1  \\\n",
       "0      115.0       91.0       84.0       80.0       85.0      58.0      55.0   \n",
       "1      113.0      101.0       94.0       88.0       95.0      75.0      67.0   \n",
       "2       -1.0       -1.0      159.0      150.0       -1.0      73.0      94.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0       -1.0     119.0     132.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0      -1.0      -1.0   \n",
       "\n",
       "   tof_3_v2  tof_3_v3  tof_3_v4  tof_3_v5  tof_3_v6  tof_3_v7  tof_3_v8  \\\n",
       "0      59.0      59.0      63.0      96.0      93.0      -1.0      57.0   \n",
       "1      68.0      71.0      74.0     102.0      99.0      -1.0      64.0   \n",
       "2     109.0     117.0     126.0      -1.0      -1.0      -1.0      94.0   \n",
       "3     164.0      -1.0      -1.0      -1.0      -1.0      -1.0     117.0   \n",
       "4      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0     161.0   \n",
       "\n",
       "   tof_3_v9  tof_3_v10  tof_3_v11  tof_3_v12  tof_3_v13  tof_3_v14  tof_3_v15  \\\n",
       "0      59.0       58.0       64.0       72.0      103.0       98.0       -1.0   \n",
       "1      68.0       67.0       72.0       88.0      112.0      103.0       -1.0   \n",
       "2     119.0      101.0      123.0      139.0       -1.0       -1.0       -1.0   \n",
       "3     156.0      176.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "4      -1.0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_3_v16  tof_3_v17  tof_3_v18  tof_3_v19  tof_3_v20  tof_3_v21  \\\n",
       "0       55.0       57.0       62.0       63.0       88.0      103.0   \n",
       "1       65.0       68.0       69.0       75.0      105.0      111.0   \n",
       "2       98.0       97.0      101.0      128.0      144.0       -1.0   \n",
       "3      144.0      151.0      187.0       -1.0       -1.0       -1.0   \n",
       "4      165.0      207.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_3_v22  tof_3_v23  tof_3_v24  tof_3_v25  tof_3_v26  tof_3_v27  \\\n",
       "0      105.0      108.0       56.0       59.0       58.0       77.0   \n",
       "1      109.0       -1.0       66.0       71.0       72.0       81.0   \n",
       "2       -1.0       -1.0       88.0      107.0      101.0      154.0   \n",
       "3       -1.0       -1.0      126.0      162.0      184.0       -1.0   \n",
       "4       -1.0       -1.0      178.0      221.0       -1.0       -1.0   \n",
       "\n",
       "   tof_3_v28  tof_3_v29  tof_3_v30  tof_3_v31  tof_3_v32  tof_3_v33  \\\n",
       "0       94.0      106.0       -1.0      113.0       57.0       58.0   \n",
       "1      109.0      116.0      121.0      118.0       61.0       67.0   \n",
       "2      141.0       -1.0       -1.0       -1.0       84.0       89.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0      128.0      158.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0      184.0      216.0   \n",
       "\n",
       "   tof_3_v34  tof_3_v35  tof_3_v36  tof_3_v37  tof_3_v38  tof_3_v39  \\\n",
       "0       66.0       78.0       93.0       -1.0       -1.0       -1.0   \n",
       "1       75.0       93.0      116.0      128.0      130.0      121.0   \n",
       "2      107.0      140.0      146.0      149.0      147.0      131.0   \n",
       "3      180.0      189.0      202.0      171.0      168.0      164.0   \n",
       "4       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_3_v40  tof_3_v41  tof_3_v42  tof_3_v43  tof_3_v44  tof_3_v45  \\\n",
       "0       59.0       67.0       69.0       82.0      104.0       -1.0   \n",
       "1       62.0       72.0       80.0       92.0      115.0       -1.0   \n",
       "2       76.0      100.0      108.0      141.0       -1.0      158.0   \n",
       "3      117.0      153.0      183.0      197.0      192.0      164.0   \n",
       "4      162.0      212.0      237.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_3_v46  tof_3_v47  tof_3_v48  tof_3_v49  tof_3_v50  tof_3_v51  \\\n",
       "0       -1.0       -1.0       63.0       70.0       79.0       96.0   \n",
       "1       -1.0       -1.0       67.0       73.0       82.0       98.0   \n",
       "2      143.0      117.0       77.0       89.0      105.0      133.0   \n",
       "3      156.0      160.0      113.0      142.0      192.0      197.0   \n",
       "4       -1.0       -1.0      152.0      198.0      221.0      213.0   \n",
       "\n",
       "   tof_3_v52  tof_3_v53  tof_3_v54  tof_3_v55  tof_3_v56  tof_3_v57  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       79.0       83.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0       77.0       82.0   \n",
       "2       -1.0       -1.0      141.0      108.0       79.0       99.0   \n",
       "3      192.0      157.0      149.0      146.0      114.0      158.0   \n",
       "4      204.0      211.0      235.0       -1.0      143.0      205.0   \n",
       "\n",
       "   tof_3_v58  tof_3_v59  tof_3_v60  tof_3_v61  tof_3_v62  tof_3_v63  tof_4_v0  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0      102.0      100.0      -1.0   \n",
       "1      110.0       -1.0       -1.0       -1.0      112.0      105.0     134.0   \n",
       "2      114.0       -1.0       -1.0       -1.0      130.0      118.0     139.0   \n",
       "3       -1.0      173.0      159.0      156.0      147.0       -1.0     139.0   \n",
       "4      213.0      189.0      191.0      194.0      198.0       -1.0     139.0   \n",
       "\n",
       "   tof_4_v1  tof_4_v2  tof_4_v3  tof_4_v4  tof_4_v5  tof_4_v6  tof_4_v7  \\\n",
       "0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      74.0   \n",
       "1      -1.0      -1.0      -1.0      -1.0      -1.0      91.0      82.0   \n",
       "2     149.0     167.0     162.0      -1.0     107.0      92.0      81.0   \n",
       "3     146.0     153.0     181.0     161.0     113.0     112.0     100.0   \n",
       "4     138.0     159.0     145.0     120.0     121.0     118.0     116.0   \n",
       "\n",
       "   tof_4_v8  tof_4_v9  tof_4_v10  tof_4_v11  tof_4_v12  tof_4_v13  tof_4_v14  \\\n",
       "0     130.0      -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1     132.0     145.0      148.0      157.0      143.0       -1.0      117.0   \n",
       "2     135.0     140.0      148.0      151.0      155.0      111.0       82.0   \n",
       "3     131.0     153.0      148.0      162.0      138.0      120.0      106.0   \n",
       "4     149.0     143.0      152.0      136.0      127.0      138.0      125.0   \n",
       "\n",
       "   tof_4_v15  tof_4_v16  tof_4_v17  tof_4_v18  tof_4_v19  tof_4_v20  \\\n",
       "0       69.0      134.0      137.0      136.0      145.0      131.0   \n",
       "1       66.0      142.0      142.0      149.0      147.0      136.0   \n",
       "2       94.0      132.0      139.0      147.0      138.0      120.0   \n",
       "3      116.0      141.0      157.0      159.0      153.0      128.0   \n",
       "4      125.0      163.0      161.0      148.0      135.0      127.0   \n",
       "\n",
       "   tof_4_v21  tof_4_v22  tof_4_v23  tof_4_v24  tof_4_v25  tof_4_v26  \\\n",
       "0      126.0       83.0       60.0       -1.0      138.0      135.0   \n",
       "1      109.0       80.0       60.0      142.0      142.0      143.0   \n",
       "2       97.0       78.0       85.0      140.0      146.0      136.0   \n",
       "3      111.0      111.0      115.0      149.0      173.0      162.0   \n",
       "4      137.0      153.0      129.0      184.0      197.0      155.0   \n",
       "\n",
       "   tof_4_v27  tof_4_v28  tof_4_v29  tof_4_v30  tof_4_v31  tof_4_v32  \\\n",
       "0      148.0      121.0      109.0       69.0       51.0       -1.0   \n",
       "1      135.0      126.0       92.0       73.0       61.0       -1.0   \n",
       "2      131.0       98.0       86.0       75.0       80.0      149.0   \n",
       "3      141.0      120.0      117.0      108.0      120.0      181.0   \n",
       "4      146.0      140.0      149.0      154.0      164.0       -1.0   \n",
       "\n",
       "   tof_4_v33  tof_4_v34  tof_4_v35  tof_4_v36  tof_4_v37  tof_4_v38  \\\n",
       "0      143.0      139.0      148.0      113.0       91.0       67.0   \n",
       "1      147.0      148.0      137.0      109.0       82.0       71.0   \n",
       "2      156.0      147.0      113.0       97.0       84.0       81.0   \n",
       "3      178.0      210.0      137.0      143.0      112.0      126.0   \n",
       "4      229.0      200.0      176.0      169.0      166.0      169.0   \n",
       "\n",
       "   tof_4_v39  tof_4_v40  tof_4_v41  tof_4_v42  tof_4_v43  tof_4_v44  \\\n",
       "0       52.0       -1.0       -1.0       -1.0       -1.0      101.0   \n",
       "1       60.0       -1.0       -1.0       -1.0       -1.0      101.0   \n",
       "2       71.0       -1.0       -1.0      174.0      117.0       96.0   \n",
       "3      112.0       -1.0       -1.0      209.0      202.0      144.0   \n",
       "4      171.0       -1.0       -1.0       -1.0       -1.0      219.0   \n",
       "\n",
       "   tof_4_v45  tof_4_v46  tof_4_v47  tof_4_v48  tof_4_v49  tof_4_v50  \\\n",
       "0       81.0       62.0       54.0       -1.0       -1.0       -1.0   \n",
       "1       83.0       69.0       62.0       -1.0       -1.0       -1.0   \n",
       "2       89.0       80.0       78.0       -1.0       -1.0       -1.0   \n",
       "3      163.0      133.0      155.0       -1.0       -1.0       -1.0   \n",
       "4      208.0      202.0       -1.0       -1.0       -1.0      202.0   \n",
       "\n",
       "   tof_4_v51  tof_4_v52  tof_4_v53  tof_4_v54  tof_4_v55  tof_4_v56  \\\n",
       "0       -1.0      124.0       78.0       68.0       55.0       -1.0   \n",
       "1       -1.0      109.0       84.0       76.0       64.0       -1.0   \n",
       "2      145.0      104.0       92.0       88.0       76.0       -1.0   \n",
       "3       -1.0       -1.0      168.0      179.0      155.0       -1.0   \n",
       "4       -1.0      224.0      211.0       -1.0       -1.0      146.0   \n",
       "\n",
       "   tof_4_v57  tof_4_v58  tof_4_v59  tof_4_v60  tof_4_v61  tof_4_v62  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       66.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0       93.0       72.0   \n",
       "2       -1.0       -1.0       -1.0       -1.0      117.0       98.0   \n",
       "3       -1.0       -1.0       -1.0       -1.0       -1.0      164.0   \n",
       "4      179.0       -1.0      191.0      192.0      194.0       -1.0   \n",
       "\n",
       "   tof_4_v63  tof_5_v0  tof_5_v1  tof_5_v2  tof_5_v3  tof_5_v4  tof_5_v5  \\\n",
       "0       60.0     128.0     130.0     147.0     165.0      -1.0      -1.0   \n",
       "1       74.0     126.0     137.0     157.0     174.0      -1.0      -1.0   \n",
       "2      105.0      92.0     110.0     157.0     180.0      -1.0     128.0   \n",
       "3      175.0     105.0     132.0     171.0      -1.0     157.0     167.0   \n",
       "4       -1.0     127.0     185.0      -1.0     199.0     187.0     186.0   \n",
       "\n",
       "   tof_5_v6  tof_5_v7  tof_5_v8  tof_5_v9  tof_5_v10  tof_5_v11  tof_5_v12  \\\n",
       "0      -1.0     122.0     121.0     140.0      164.0       -1.0       -1.0   \n",
       "1     140.0     130.0     124.0     143.0      168.0       -1.0       -1.0   \n",
       "2     123.0     126.0     142.0     165.0      185.0       -1.0       -1.0   \n",
       "3     149.0     131.0     149.0     189.0      203.0       -1.0       -1.0   \n",
       "4      -1.0      -1.0     143.0      -1.0       -1.0      216.0      205.0   \n",
       "\n",
       "   tof_5_v13  tof_5_v14  tof_5_v15  tof_5_v16  tof_5_v17  tof_5_v18  \\\n",
       "0       -1.0      140.0      119.0      135.0      156.0      166.0   \n",
       "1       -1.0      142.0      122.0      138.0      157.0       -1.0   \n",
       "2       -1.0      145.0      139.0      138.0      164.0       -1.0   \n",
       "3      164.0      133.0       -1.0      162.0      181.0       -1.0   \n",
       "4       -1.0       -1.0       -1.0      197.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v19  tof_5_v20  tof_5_v21  tof_5_v22  tof_5_v23  tof_5_v24  \\\n",
       "0       -1.0       -1.0      155.0      137.0      112.0      148.0   \n",
       "1       -1.0       -1.0      155.0      133.0      117.0      145.0   \n",
       "2       -1.0       -1.0       -1.0      145.0      120.0      151.0   \n",
       "3       -1.0       -1.0      152.0      134.0       -1.0      148.0   \n",
       "4      219.0      192.0       -1.0       -1.0       -1.0      204.0   \n",
       "\n",
       "   tof_5_v25  tof_5_v26  tof_5_v27  tof_5_v28  tof_5_v29  tof_5_v30  \\\n",
       "0      163.0      164.0      153.0      133.0      131.0      121.0   \n",
       "1      170.0      163.0      157.0      139.0      127.0      126.0   \n",
       "2      165.0       -1.0       -1.0       -1.0      151.0      138.0   \n",
       "3      187.0       -1.0       -1.0      149.0      142.0      135.0   \n",
       "4       -1.0       -1.0      212.0      181.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v31  tof_5_v32  tof_5_v33  tof_5_v34  tof_5_v35  tof_5_v36  \\\n",
       "0      118.0      134.0      134.0      128.0      121.0      119.0   \n",
       "1      121.0      136.0      142.0      133.0      127.0      123.0   \n",
       "2      127.0      151.0      187.0       -1.0      156.0      136.0   \n",
       "3       -1.0      159.0      181.0      150.0      135.0      129.0   \n",
       "4       -1.0      184.0       -1.0      179.0      162.0       -1.0   \n",
       "\n",
       "   tof_5_v37  tof_5_v38  tof_5_v39  tof_5_v40  tof_5_v41  tof_5_v42  \\\n",
       "0      121.0      129.0       -1.0      113.0      124.0      122.0   \n",
       "1      127.0      134.0       -1.0      116.0      122.0      123.0   \n",
       "2      135.0      134.0       -1.0      133.0      142.0      131.0   \n",
       "3      139.0       -1.0       -1.0      141.0      136.0      120.0   \n",
       "4       -1.0       -1.0       -1.0      169.0      171.0      145.0   \n",
       "\n",
       "   tof_5_v43  tof_5_v44  tof_5_v45  tof_5_v46  tof_5_v47  tof_5_v48  \\\n",
       "0      131.0       -1.0       -1.0       -1.0       -1.0      120.0   \n",
       "1      126.0       -1.0       -1.0       -1.0       -1.0      122.0   \n",
       "2      130.0      132.0      136.0       -1.0       -1.0      112.0   \n",
       "3      122.0      132.0       -1.0       -1.0       -1.0      107.0   \n",
       "4      140.0       -1.0       -1.0       -1.0       -1.0      132.0   \n",
       "\n",
       "   tof_5_v49  tof_5_v50  tof_5_v51  tof_5_v52  tof_5_v53  tof_5_v54  \\\n",
       "0      127.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1      129.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2      121.0      123.0      125.0       -1.0       -1.0       -1.0   \n",
       "3      112.0      115.0      140.0       -1.0       -1.0       -1.0   \n",
       "4      125.0      131.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v55  tof_5_v56  tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  \\\n",
       "0       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "1       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "2       -1.0      112.0      119.0       -1.0       -1.0       -1.0   \n",
       "3       -1.0      101.0      111.0       -1.0       -1.0       -1.0   \n",
       "4       -1.0      101.0      109.0      125.0       -1.0       -1.0   \n",
       "\n",
       "   tof_5_v61  tof_5_v62  tof_5_v63  \n",
       "0       -1.0       -1.0       -1.0  \n",
       "1       -1.0       -1.0       -1.0  \n",
       "2       -1.0       -1.0       -1.0  \n",
       "3       -1.0       -1.0       -1.0  \n",
       "4       -1.0       -1.0       -1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99846dff",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "her sequnce iin bir satr veri olmal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "904f768c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>gesture</th>\n",
       "      <th>subject</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>max_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Target</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000008</td>\n",
       "      <td>Forehead - pull hairline</td>\n",
       "      <td>SUBJ_020948</td>\n",
       "      <td>Target</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000013</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>SUBJ_040282</td>\n",
       "      <td>Target</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000016</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>SUBJ_052342</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000018</td>\n",
       "      <td>Forehead - pull hairline</td>\n",
       "      <td>SUBJ_032165</td>\n",
       "      <td>Target</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id                   gesture      subject sequence_type  n_steps  \\\n",
       "0  SEQ_000007        Cheek - pinch skin  SUBJ_059520        Target       57   \n",
       "1  SEQ_000008  Forehead - pull hairline  SUBJ_020948        Target       68   \n",
       "2  SEQ_000013        Cheek - pinch skin  SUBJ_040282        Target       53   \n",
       "3  SEQ_000016         Write name on leg  SUBJ_052342    Non-Target       61   \n",
       "4  SEQ_000018  Forehead - pull hairline  SUBJ_032165        Target       54   \n",
       "\n",
       "   max_counter  \n",
       "0           56  \n",
       "1           67  \n",
       "2           52  \n",
       "3           60  \n",
       "4           53  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence-level metadata\n",
    "features_df = train[['sequence_id', 'gesture', 'subject', 'sequence_type']].drop_duplicates('sequence_id')\n",
    "\n",
    "# sequence_counter : Hareketin ne kadar sre devam ettii (max(sequence_counter)) gibi karmlar iin kullanlabilir.\n",
    "df_len = train.groupby(\"sequence_id\")[\"sequence_counter\"].agg([\"count\", \"max\"]).rename(columns={\"count\": \"n_steps\", \"max\": \"max_counter\"})\n",
    "features_df = features_df.merge(df_len, on='sequence_id', how='left')\n",
    "\n",
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76bcd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>max_counter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id      subject  n_steps  max_counter\n",
       "0  SEQ_000001  SUBJ_055840       56           55\n",
       "1  SEQ_000011  SUBJ_016452       51           50"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequence-level metadata\n",
    "features_test_df = test[['sequence_id', 'subject']].drop_duplicates('sequence_id')\n",
    "\n",
    "# sequence_counter : Hareketin ne kadar sre devam ettii (max(sequence_counter)) gibi karmlar iin kullanlabilir.\n",
    "df_len = test.groupby(\"sequence_id\")[\"sequence_counter\"].agg([\"count\", \"max\"]).rename(columns={\"count\": \"n_steps\", \"max\": \"max_counter\"})\n",
    "features_test_df = features_test_df.merge(df_len, on='sequence_id', how='left')\n",
    "\n",
    "features_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e034bf79",
   "metadata": {},
   "source": [
    "## acc_x, acc_y, acc_z\n",
    "#### Yn Bamsz zellikler\n",
    "\n",
    "* acc_mag - magnitude : ivme vektr normu (MUTLAK BYKLK) <br>\n",
    "Kol farkl alarda durduunda x/y/z bileenleri deiir ama norm sabit kalr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128cbc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['acc_mag'] = np.sqrt(train['acc_x'] ** 2 + train['acc_y'] ** 2 + train['acc_z'] ** 2)\n",
    "train['jerk'] = train['acc_mag'].diff().fillna(0)\n",
    "\n",
    "test['acc_mag'] = np.sqrt(test['acc_x'] ** 2 + test['acc_y'] ** 2 + test['acc_z'] ** 2)\n",
    "test['jerk'] = test['acc_mag'].diff().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ecb3d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 338)\n",
      "(574945, 343)\n",
      "----------------\n",
      "(8151, 6)\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(train.shape)\n",
    "print('----------------')\n",
    "print(features_df.shape)\n",
    "print(features_test_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bace8ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 8151/8151 [00:08<00:00, 1010.36it/s]\n",
      "100%|| 2/2 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_acc_features(df):\n",
    "    features = {}\n",
    "    for axis in ['x', 'y', 'z']:\n",
    "        col = f'acc_{axis}'\n",
    "        features[f'acc_{axis}_mean'] = df[col].mean()\n",
    "        features[f'acc_{axis}_std'] = df[col].std()\n",
    "        features[f'acc_{axis}_max'] = df[col].max()\n",
    "        features[f'acc_{axis}_min'] = df[col].min()\n",
    "        features[f'acc_{axis}_range'] = df[col].max() - df[col].min()\n",
    "        features[f'acc_{axis}_skew'] = df[col].skew()\n",
    "        features[f'acc_{axis}_kurt'] = df[col].kurt()\n",
    "\n",
    "        # jerk (trevi)\n",
    "        jerk = np.gradient(df[col])\n",
    "        features[f'acc_{axis}_jerk_mean'] = jerk.mean()\n",
    "        features[f'acc_{axis}_jerk_std'] = jerk.std()\n",
    "        features[f'acc_{axis}_jerk_max'] = jerk.max()\n",
    "        features[f'acc_{axis}_jerk_min'] = jerk.min()\n",
    "\n",
    "        # enerji\n",
    "        features[f'acc_{axis}_energy'] = np.sum(df[col] ** 2)\n",
    "\n",
    "    # Eksenler aras korelasyon\n",
    "    features['corr_acc_x_y'] = df['acc_x'].corr(df['acc_y'])\n",
    "    features['corr_acc_x_z'] = df['acc_x'].corr(df['acc_z'])\n",
    "    features['corr_acc_y_z'] = df['acc_y'].corr(df['acc_z'])\n",
    "\n",
    "    # Directional momentum\n",
    "    features['acc_z_momentum_x_range'] = df['acc_z'].mean() * (df['acc_x'].max() - df['acc_x'].min())\n",
    "\n",
    "    # Roll tahmini\n",
    "    roll_angle = np.arctan2(df['acc_y'], df['acc_x'])\n",
    "    features['roll_angle_mean'] = np.nanmean(roll_angle)\n",
    "    features['roll_angle_std'] = np.nanstd(roll_angle)\n",
    "    features['roll_angle_max'] = np.nanmax(roll_angle)\n",
    "    features['roll_angle_min'] = np.nanmin(roll_angle)\n",
    "\n",
    "    return features\n",
    "\n",
    "# sequence_id bazl zellik karm\n",
    "def build_acc_feature_dataframe(df):\n",
    "    feature_list = []\n",
    "\n",
    "    for seq_id, seq_df in tqdm(df.groupby(\"sequence_id\")):\n",
    "        feats = extract_acc_features(seq_df)\n",
    "        feats[\"sequence_id\"] = seq_id\n",
    "        feature_list.append(feats)\n",
    "\n",
    "    features_df = pd.DataFrame(feature_list)\n",
    "    return features_df\n",
    "features = build_acc_feature_dataframe(train)  #\n",
    "features_test = build_acc_feature_dataframe(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ba58581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sequence_id                   gesture      subject sequence_type  n_steps  \\\n",
      "0  SEQ_000007        Cheek - pinch skin  SUBJ_059520        Target       57   \n",
      "1  SEQ_000008  Forehead - pull hairline  SUBJ_020948        Target       68   \n",
      "2  SEQ_000013        Cheek - pinch skin  SUBJ_040282        Target       53   \n",
      "3  SEQ_000016         Write name on leg  SUBJ_052342    Non-Target       61   \n",
      "4  SEQ_000018  Forehead - pull hairline  SUBJ_032165        Target       54   \n",
      "\n",
      "   max_counter  acc_x_mean  acc_x_std  acc_x_max  acc_x_min  acc_x_range  \\\n",
      "0           56    6.153098   1.334155   9.015625   3.613281     5.402344   \n",
      "1           67    3.400506   1.087142   5.906250   1.734375     4.171875   \n",
      "2           52   -7.058962   1.295184  -3.347656  -9.250000     5.902344   \n",
      "3           60    5.524654   1.074108   9.378906   3.437500     5.941406   \n",
      "4           53    5.363715   1.627637   6.832031   1.964844     4.867188   \n",
      "\n",
      "   acc_x_skew  acc_x_kurt  acc_x_jerk_mean  acc_x_jerk_std  acc_x_jerk_max  \\\n",
      "0   -0.545319   -0.391295         0.020285        0.455492        1.339844   \n",
      "1    0.146452   -1.069663        -0.028148        0.519107        1.742188   \n",
      "2    0.518519    0.291585         0.034677        0.761798        2.527344   \n",
      "3    0.747648    1.524114        -0.043161        0.672640        2.703125   \n",
      "4   -1.397824    0.163483         0.040039        0.456681        2.031250   \n",
      "\n",
      "   acc_x_jerk_min  acc_x_energy  acc_y_mean  acc_y_std  acc_y_max  acc_y_min  \\\n",
      "0       -1.302734   2257.733032    3.915570   3.048287   6.519531  -2.019531   \n",
      "1       -1.839844    865.499603    5.311179   3.268073   8.667969  -0.222656   \n",
      "2       -1.726562   2728.164307    2.346182   2.564639   4.683594  -3.273438   \n",
      "3       -3.375000   1931.052567   -4.408491   0.598318  -2.960938  -5.718750   \n",
      "4       -1.265625   1693.957520    4.109737   3.525304   6.718750  -3.164062   \n",
      "\n",
      "   acc_y_range  acc_y_skew  acc_y_kurt  acc_y_jerk_mean  acc_y_jerk_std  \\\n",
      "0     8.539062   -1.184870   -0.391547        -0.001028        0.780156   \n",
      "1     8.890625   -0.830467   -1.170949         0.053740        0.672863   \n",
      "2     7.957031   -1.445762    0.544205         0.024838        0.732187   \n",
      "3     2.757812    0.505319   -0.017645        -0.002561        0.335250   \n",
      "4     9.882812   -1.347944    0.033611         0.025933        0.793187   \n",
      "\n",
      "   acc_y_jerk_max  acc_y_jerk_min  acc_y_energy  acc_z_mean  acc_z_std  \\\n",
      "0        3.542969       -2.566406   1394.261383    5.577782   2.337517   \n",
      "1        2.375000       -2.574219   2633.766251    6.581629   2.475402   \n",
      "2        2.701172       -2.394531    633.765793   -6.068544   1.330784   \n",
      "3        1.109375       -1.343750   1207.001572   -3.162077   6.139752   \n",
      "4        2.585938       -2.105469   1570.728409    5.937066   2.104544   \n",
      "\n",
      "   acc_z_max  acc_z_min  acc_z_range  acc_z_skew  acc_z_kurt  acc_z_jerk_mean  \\\n",
      "0   9.792969   1.093750     8.699219    0.586111   -0.897976         0.002981   \n",
      "1  11.074219   1.722656     9.351562    0.186346   -1.306469        -0.065545   \n",
      "2  -3.515625 -10.945312     7.429688   -1.039566    2.722204         0.026570   \n",
      "3   8.355469  -8.078125    16.433594    0.964846   -1.033536         0.083600   \n",
      "4   9.933594   4.148438     5.785156    1.040372   -0.718802        -0.001736   \n",
      "\n",
      "   acc_z_jerk_std  acc_z_jerk_max  acc_z_jerk_min  acc_z_energy  corr_acc_x_y  \\\n",
      "0        0.762233        2.105469       -2.357422   2079.347610      0.854289   \n",
      "1        1.072456        2.833984       -2.986328   3356.163620      0.678886   \n",
      "2        0.640019        2.316406       -1.863281   2043.934021     -0.500159   \n",
      "3        1.951462       11.531250       -6.037109   2871.715958      0.553929   \n",
      "4        0.522210        1.992188       -2.031250   2138.175323      0.934984   \n",
      "\n",
      "   corr_acc_x_z  corr_acc_y_z  acc_z_momentum_x_range  roll_angle_mean  \\\n",
      "0     -0.887190     -0.902468               30.133098         0.445496   \n",
      "1     -0.594269     -0.889196               27.457734         0.817318   \n",
      "2     -0.638358      0.695687              -35.818631         1.676461   \n",
      "3      0.639362      0.704613              -18.787186        -0.682500   \n",
      "4     -0.900993     -0.956922               28.896813         0.438831   \n",
      "\n",
      "   roll_angle_std  roll_angle_max  roll_angle_min  \n",
      "0        0.443626        0.799987       -0.464035  \n",
      "1        0.438181        1.307932       -0.084997  \n",
      "2        2.113786        2.954490       -2.899302  \n",
      "3        0.136990       -0.374288       -0.956637  \n",
      "4        0.638793        0.819412       -1.004394  \n",
      "  sequence_id      subject  n_steps  max_counter  acc_x_mean  acc_x_std  \\\n",
      "0  SEQ_000001  SUBJ_055840       56           55    7.750837   1.050640   \n",
      "1  SEQ_000011  SUBJ_016452       51           50   -2.423790   3.534764   \n",
      "\n",
      "   acc_x_max  acc_x_min  acc_x_range  acc_x_skew  acc_x_kurt  acc_x_jerk_mean  \\\n",
      "0  10.160156   6.132812     4.027344    0.730955   -0.756832        -0.041399   \n",
      "1   9.609375  -4.523438    14.132812    1.986602    2.661071         0.001417   \n",
      "\n",
      "   acc_x_jerk_std  acc_x_jerk_max  acc_x_jerk_min  acc_x_energy  acc_y_mean  \\\n",
      "0        0.466181        1.380859       -2.035156   3424.937988    5.393694   \n",
      "1        1.358934        4.136719       -6.701172    924.340561    6.621477   \n",
      "\n",
      "   acc_y_std  acc_y_max  acc_y_min  acc_y_range  acc_y_skew  acc_y_kurt  \\\n",
      "0   2.353345   7.214844   0.781250     6.433594   -1.222971   -0.319466   \n",
      "1   4.377906   8.957031  -5.257812    14.214844   -2.030169    2.552805   \n",
      "\n",
      "   acc_y_jerk_mean  acc_y_jerk_std  acc_y_jerk_max  acc_y_jerk_min  \\\n",
      "0         0.003453        0.524735        1.666016       -1.800781   \n",
      "1        -0.019072        1.340108        4.884766       -3.732422   \n",
      "\n",
      "   acc_y_energy  acc_z_mean  acc_z_std  acc_z_max  acc_z_min  acc_z_range  \\\n",
      "0   1933.751404   -0.093331   2.305147   4.093750  -4.792969     8.886719   \n",
      "1   3194.344513   -1.357996   4.619076  11.113281  -5.093750    16.207031   \n",
      "\n",
      "   acc_z_skew  acc_z_kurt  acc_z_jerk_mean  acc_z_jerk_std  acc_z_jerk_max  \\\n",
      "0   -0.837641   -0.385385        -0.003383        0.722215        2.433594   \n",
      "1    1.902655    1.943542        -0.006817        1.871495        8.025391   \n",
      "\n",
      "   acc_z_jerk_min  acc_z_energy  corr_acc_x_y  corr_acc_x_z  corr_acc_y_z  \\\n",
      "0       -2.335938    292.741547     -0.856616     -0.737114      0.905823   \n",
      "1       -6.166016   1160.845123     -0.935494      0.926198     -0.940147   \n",
      "\n",
      "   acc_z_momentum_x_range  roll_angle_mean  roll_angle_std  roll_angle_max  \\\n",
      "0               -0.375878         0.599637        0.265987        0.844646   \n",
      "1              -19.192307         1.605974        0.913583        2.152584   \n",
      "\n",
      "   roll_angle_min  \n",
      "0        0.086889  \n",
      "1       -0.839874  \n"
     ]
    }
   ],
   "source": [
    "features_df = features_df.merge(features, on='sequence_id', how='left')\n",
    "print(features_df.head())\n",
    "\n",
    "features_test_df = features_test_df.merge(features_test, on='sequence_id', how='left')\n",
    "print(features_test_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e4ad42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8151"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sequence_id'].value_counts().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53ce8636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8151, 50)\n",
      "(2, 48)\n"
     ]
    }
   ],
   "source": [
    "print(features_df.shape)\n",
    "print(features_test_df.shape)\n",
    "# sequence_type & gesture yok (TEST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba315f",
   "metadata": {},
   "source": [
    "## rotw, rotx, roty, rotz\n",
    "Rotation (rot_w, rot_x, rot_y, rot_z) deerleri quaternion biiminde olduundan dorudan yorumlanmas zordur.\n",
    "\n",
    "#### 1. Euler Dnm (Quaternion  Euler Angle)\n",
    "Quaternions'u yaw, pitch, roll alarna evirip bu alarn:\n",
    "\n",
    "- Ortalama\n",
    "- Maksimum / Minimum\n",
    "- Standart sapma\n",
    "- lk ve son frame fark gibi istatistiklerini karabiliriz.\n",
    "\n",
    "Bu dnm, elin baa gre ne kadar dndn (rnein yukar kaldrma, yana eme vb.) tespit etmemizi salar.\n",
    "\n",
    "#### 2. Orientation Dynamics  Hareket Yn ve Stabilite\n",
    "Belirli bir sequence iinde ynelim deiiminin iddeti:\n",
    "\n",
    "- Euler alar veya quaternionlar zerinden frame-to-frame farklarn toplam (orientation_change_magnitude)\n",
    "- En hzl dn yaplan yn (max_rotation_axis)\n",
    "- Balang ve biti yn arasndaki a fark\n",
    "\n",
    "#### 3. Orientation Stability\n",
    "BFRB-like hareketlerde el bata daha sabit durma eiliminde olabilir:\n",
    "\n",
    "- Euler alar veya quaternion'lar iin varyans  yaw_var, pitch_var, roll_var\n",
    "- BFRB olmayanlarda genelde daha fazla hareket olabilir.\n",
    "\n",
    "#### 4. Dnme Eksenlerinin Normalize Enerjisi\n",
    "Her eksen iin ortalama dn \"enerjisini\" hesaplayabiliriz:\n",
    "\n",
    "- rot_energy_x = mean(rot_x ** 2)\n",
    "- Dier eksenlerle birlikte karlatrma  elin hangi eksende daha aktif dnd karm\n",
    "\n",
    "#### 5. Hand Tilt Classification (Durumsal Binary Feature)\n",
    "Yarmadaki birok hareket iin elin baa gre eimi kritik. Euler dnm sonras:\n",
    "\n",
    "El \"yukarda m\" (pitch > threshold) gibi binary featurelar karlabilir.\n",
    "\n",
    "#### 6. Zamana Duyarl Pattern Extraction\n",
    "Eer el baa doru dnerken ve gesture srasnda sabitleniyorsa:\n",
    "\n",
    "- roll / pitch / yaw erileri iin low/high frequency sinyal ayrm \n",
    "- FFT ile dominant frekans karm (dk frekans: sabit el; yksek frekans: dalgalanmal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f6fd3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "def quaternion_to_euler(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    quats = df[['rot_x', 'rot_y', 'rot_z', 'rot_w']].to_numpy()\n",
    "    norms = np.linalg.norm(quats, axis=1)\n",
    "\n",
    "    valid = norms > 1e-6\n",
    "    euler = np.full((len(df), 3), np.nan)\n",
    "\n",
    "    if valid.any():\n",
    "        r = R.from_quat(quats[valid] / norms[valid, None])\n",
    "        euler[valid] = r.as_euler('zyx', degrees=True)\n",
    "\n",
    "    return pd.DataFrame(euler, columns=['yaw', 'pitch', 'roll'], index=df.index)\n",
    "\n",
    "\n",
    "# ----------------- Euler alarn ekle -----------------\n",
    "euler_df = quaternion_to_euler(train)\n",
    "train = pd.concat([train, euler_df], axis=1)\n",
    "\n",
    "# ----------------- Sequencelevel zet istatistikler ----\n",
    "rot_agg = (\n",
    "    train\n",
    "    .groupby('sequence_id')\n",
    "    .agg(\n",
    "        yaw_mean  = ('yaw',   'mean'),\n",
    "        yaw_std   = ('yaw',   'std'),\n",
    "        yaw_min   = ('yaw',   'min'),\n",
    "        yaw_max   = ('yaw',   'max'),\n",
    "        yaw_delta = ('yaw',   lambda x: x.iloc[-1]-x.iloc[0]),\n",
    "\n",
    "        pitch_mean  = ('pitch', 'mean'),\n",
    "        pitch_std   = ('pitch', 'std'),\n",
    "        pitch_min   = ('pitch', 'min'),\n",
    "        pitch_max   = ('pitch', 'max'),\n",
    "        pitch_delta = ('pitch', lambda x: x.iloc[-1]-x.iloc[0]),\n",
    "\n",
    "        roll_mean  = ('roll', 'mean'),\n",
    "        roll_std   = ('roll', 'std'),\n",
    "        roll_min   = ('roll', 'min'),\n",
    "        roll_max   = ('roll', 'max'),\n",
    "        roll_delta = ('roll', lambda x: x.iloc[-1]-x.iloc[0]),\n",
    "    )\n",
    ").reset_index()\n",
    "\n",
    "# ------------- zellik tablosuna birletir ----------------\n",
    "features_df = features_df.merge(rot_agg, on='sequence_id', how='left')\n",
    "\n",
    "#TEST\n",
    "# Euler dnmn hesapla ve ana DataFrame'e ekle\n",
    "euler_df = quaternion_to_euler(test)\n",
    "test = pd.concat([test, euler_df], axis=1)\n",
    "\n",
    "# Sequence bazl zet istatistikler\n",
    "rot_agg = test.groupby('sequence_id')[['yaw', 'pitch', 'roll']].agg(['mean', 'std', 'min', 'max', lambda x: x.iloc[-1] - x.iloc[0]])\n",
    "rot_agg.columns = ['_'.join([col[0], col[1] if isinstance(col[1], str) else 'delta']) for col in rot_agg.columns]\n",
    "rot_agg.reset_index(inplace=True)\n",
    "\n",
    "# zellik DataFrame'inize ekleyin\n",
    "features_test_df = features_test_df.merge(rot_agg, on='sequence_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f433f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8151, 65)\n",
      "(2, 63)\n"
     ]
    }
   ],
   "source": [
    "print(features_df.shape)\n",
    "print(features_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf6cf804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Sadece birinci DataFrame'de olan stunlar: {'orientation', 'behavior', 'gesture', 'phase', 'sequence_type'}\n",
      "---\n",
      "Sadece ikinci DataFrame'de olan stunlar: set()\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def differences(df1, df2):\n",
    "    # lk DataFrame'deki stunlar\n",
    "    sutunlar_df1 = set(df1.columns)\n",
    "\n",
    "    # kinci DataFrame'deki stunlar\n",
    "    sutunlar_df2 = set(df2.columns)\n",
    "\n",
    "    # Sadece df1'de olan stunlar\n",
    "    farkli_sutunlar_df1 = sutunlar_df1 - sutunlar_df2\n",
    "\n",
    "    # Sadece df2'de olan stunlar\n",
    "    farkli_sutunlar_df2 = sutunlar_df2 - sutunlar_df1\n",
    "\n",
    "    # Her iki DataFrame'de de farkl olan stunlar (birleim)\n",
    "    tum_farkli_sutunlar = sutunlar_df1.symmetric_difference(sutunlar_df2)\n",
    "\n",
    "    print(\"---\")\n",
    "    print(\"Sadece birinci DataFrame'de olan stunlar:\", farkli_sutunlar_df1)\n",
    "    print(\"---\")\n",
    "    print(\"Sadece ikinci DataFrame'de olan stunlar:\", farkli_sutunlar_df2)\n",
    "    print(\"---\")\n",
    "\n",
    "\n",
    "differences(train,test)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa83e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\1478193204.py:22: FutureWarning: The behavior of Series.idxmax with all-NA values, or any-NA and skipna=False, is deprecated. In a future version this will raise ValueError\n",
      "  row['max_rotation_axis'] = stds.idxmax()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def compute_orientation_dynamics(df):\n",
    "    angles = ['yaw', 'pitch', 'roll']\n",
    "    results = []\n",
    "\n",
    "    for seq_id, group in df.groupby('sequence_id'):\n",
    "        row = {'sequence_id': seq_id}\n",
    "\n",
    "        diffs = group[angles].diff().abs().sum()\n",
    "        row['orientation_change_magnitude'] = diffs.sum()\n",
    "\n",
    "        start = group[angles].iloc[0]\n",
    "        end = group[angles].iloc[-1]\n",
    "        delta = (end - start).abs()\n",
    "        row['orientation_delta_yaw'] = delta['yaw']\n",
    "        row['orientation_delta_pitch'] = delta['pitch']\n",
    "        row['orientation_delta_roll'] = delta['roll']\n",
    "\n",
    "        stds = group[angles].std()\n",
    "        row['max_rotation_axis'] = stds.idxmax()\n",
    "\n",
    "        results.append(row)\n",
    "\n",
    "    orient_df = pd.DataFrame(results)\n",
    "\n",
    "    # One-hot encoding iin tm olas eksenleri belirle\n",
    "    orient_df = pd.get_dummies(orient_df, columns=['max_rotation_axis'])\n",
    "\n",
    "    # Eksik olan stunlar manuel olarak ekle (tutarll salamak iin)\n",
    "    for axis in ['max_rotation_axis_pitch', 'max_rotation_axis_roll', 'max_rotation_axis_yaw']:\n",
    "        if axis not in orient_df.columns:\n",
    "            orient_df[axis] = False # YOKSA FALSE YAP !!!!!!!!!  SORUN OLABLR ?????\n",
    "\n",
    "    return orient_df\n",
    "\n",
    "\n",
    "# Kullanm\n",
    "# train zaten euler alarn ieriyor varsaymyla:\n",
    "orientation_features = compute_orientation_dynamics(train)\n",
    "orientation_features_test = compute_orientation_dynamics(test)\n",
    "\n",
    "\n",
    "# features_df ile birletir\n",
    "features_df = features_df.merge(orientation_features, on='sequence_id', how='left')\n",
    "features_test_df = features_test_df.merge(orientation_features_test, on='sequence_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce3bdd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8151, 72)\n",
      "(2, 70)\n"
     ]
    }
   ],
   "source": [
    "print(features_df.shape)\n",
    "print(features_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4787bae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Sadece birinci DataFrame'de olan stunlar: {'orientation', 'behavior', 'gesture', 'phase', 'sequence_type'}\n",
      "---\n",
      "Sadece ikinci DataFrame'de olan stunlar: set()\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "differences(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bef99757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>max_counter</th>\n",
       "      <th>acc_x_mean</th>\n",
       "      <th>acc_x_std</th>\n",
       "      <th>acc_x_max</th>\n",
       "      <th>acc_x_min</th>\n",
       "      <th>acc_x_range</th>\n",
       "      <th>acc_x_skew</th>\n",
       "      <th>acc_x_kurt</th>\n",
       "      <th>acc_x_jerk_mean</th>\n",
       "      <th>acc_x_jerk_std</th>\n",
       "      <th>acc_x_jerk_max</th>\n",
       "      <th>acc_x_jerk_min</th>\n",
       "      <th>acc_x_energy</th>\n",
       "      <th>acc_y_mean</th>\n",
       "      <th>acc_y_std</th>\n",
       "      <th>acc_y_max</th>\n",
       "      <th>acc_y_min</th>\n",
       "      <th>acc_y_range</th>\n",
       "      <th>acc_y_skew</th>\n",
       "      <th>acc_y_kurt</th>\n",
       "      <th>acc_y_jerk_mean</th>\n",
       "      <th>acc_y_jerk_std</th>\n",
       "      <th>acc_y_jerk_max</th>\n",
       "      <th>acc_y_jerk_min</th>\n",
       "      <th>acc_y_energy</th>\n",
       "      <th>acc_z_mean</th>\n",
       "      <th>acc_z_std</th>\n",
       "      <th>acc_z_max</th>\n",
       "      <th>acc_z_min</th>\n",
       "      <th>acc_z_range</th>\n",
       "      <th>acc_z_skew</th>\n",
       "      <th>acc_z_kurt</th>\n",
       "      <th>acc_z_jerk_mean</th>\n",
       "      <th>acc_z_jerk_std</th>\n",
       "      <th>acc_z_jerk_max</th>\n",
       "      <th>acc_z_jerk_min</th>\n",
       "      <th>acc_z_energy</th>\n",
       "      <th>corr_acc_x_y</th>\n",
       "      <th>corr_acc_x_z</th>\n",
       "      <th>corr_acc_y_z</th>\n",
       "      <th>acc_z_momentum_x_range</th>\n",
       "      <th>roll_angle_mean</th>\n",
       "      <th>roll_angle_std</th>\n",
       "      <th>roll_angle_max</th>\n",
       "      <th>roll_angle_min</th>\n",
       "      <th>yaw_mean</th>\n",
       "      <th>yaw_std</th>\n",
       "      <th>yaw_min</th>\n",
       "      <th>yaw_max</th>\n",
       "      <th>yaw_&lt;lambda_0&gt;</th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_&lt;lambda_0&gt;</th>\n",
       "      <th>roll_mean</th>\n",
       "      <th>roll_std</th>\n",
       "      <th>roll_min</th>\n",
       "      <th>roll_max</th>\n",
       "      <th>roll_&lt;lambda_0&gt;</th>\n",
       "      <th>orientation_change_magnitude</th>\n",
       "      <th>orientation_delta_yaw</th>\n",
       "      <th>orientation_delta_pitch</th>\n",
       "      <th>orientation_delta_roll</th>\n",
       "      <th>max_rotation_axis_yaw</th>\n",
       "      <th>max_rotation_axis_pitch</th>\n",
       "      <th>max_rotation_axis_roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>7.750837</td>\n",
       "      <td>1.050640</td>\n",
       "      <td>10.160156</td>\n",
       "      <td>6.132812</td>\n",
       "      <td>4.027344</td>\n",
       "      <td>0.730955</td>\n",
       "      <td>-0.756832</td>\n",
       "      <td>-0.041399</td>\n",
       "      <td>0.466181</td>\n",
       "      <td>1.380859</td>\n",
       "      <td>-2.035156</td>\n",
       "      <td>3424.937988</td>\n",
       "      <td>5.393694</td>\n",
       "      <td>2.353345</td>\n",
       "      <td>7.214844</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>6.433594</td>\n",
       "      <td>-1.222971</td>\n",
       "      <td>-0.319466</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.524735</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>-1.800781</td>\n",
       "      <td>1933.751404</td>\n",
       "      <td>-0.093331</td>\n",
       "      <td>2.305147</td>\n",
       "      <td>4.093750</td>\n",
       "      <td>-4.792969</td>\n",
       "      <td>8.886719</td>\n",
       "      <td>-0.837641</td>\n",
       "      <td>-0.385385</td>\n",
       "      <td>-0.003383</td>\n",
       "      <td>0.722215</td>\n",
       "      <td>2.433594</td>\n",
       "      <td>-2.335938</td>\n",
       "      <td>292.741547</td>\n",
       "      <td>-0.856616</td>\n",
       "      <td>-0.737114</td>\n",
       "      <td>0.905823</td>\n",
       "      <td>-0.375878</td>\n",
       "      <td>0.599637</td>\n",
       "      <td>0.265987</td>\n",
       "      <td>0.844646</td>\n",
       "      <td>0.086889</td>\n",
       "      <td>-124.452980</td>\n",
       "      <td>13.759787</td>\n",
       "      <td>-134.790098</td>\n",
       "      <td>-97.201198</td>\n",
       "      <td>-17.249719</td>\n",
       "      <td>-7.726119</td>\n",
       "      <td>4.687385</td>\n",
       "      <td>-17.477808</td>\n",
       "      <td>-0.217066</td>\n",
       "      <td>-11.477719</td>\n",
       "      <td>-89.877106</td>\n",
       "      <td>13.319235</td>\n",
       "      <td>-116.734228</td>\n",
       "      <td>-73.521057</td>\n",
       "      <td>16.508183</td>\n",
       "      <td>238.683552</td>\n",
       "      <td>17.249719</td>\n",
       "      <td>11.477719</td>\n",
       "      <td>16.508183</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>-2.423790</td>\n",
       "      <td>3.534764</td>\n",
       "      <td>9.609375</td>\n",
       "      <td>-4.523438</td>\n",
       "      <td>14.132812</td>\n",
       "      <td>1.986602</td>\n",
       "      <td>2.661071</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>1.358934</td>\n",
       "      <td>4.136719</td>\n",
       "      <td>-6.701172</td>\n",
       "      <td>924.340561</td>\n",
       "      <td>6.621477</td>\n",
       "      <td>4.377906</td>\n",
       "      <td>8.957031</td>\n",
       "      <td>-5.257812</td>\n",
       "      <td>14.214844</td>\n",
       "      <td>-2.030169</td>\n",
       "      <td>2.552805</td>\n",
       "      <td>-0.019072</td>\n",
       "      <td>1.340108</td>\n",
       "      <td>4.884766</td>\n",
       "      <td>-3.732422</td>\n",
       "      <td>3194.344513</td>\n",
       "      <td>-1.357996</td>\n",
       "      <td>4.619076</td>\n",
       "      <td>11.113281</td>\n",
       "      <td>-5.093750</td>\n",
       "      <td>16.207031</td>\n",
       "      <td>1.902655</td>\n",
       "      <td>1.943542</td>\n",
       "      <td>-0.006817</td>\n",
       "      <td>1.871495</td>\n",
       "      <td>8.025391</td>\n",
       "      <td>-6.166016</td>\n",
       "      <td>1160.845123</td>\n",
       "      <td>-0.935494</td>\n",
       "      <td>0.926198</td>\n",
       "      <td>-0.940147</td>\n",
       "      <td>-19.192307</td>\n",
       "      <td>1.605974</td>\n",
       "      <td>0.913583</td>\n",
       "      <td>2.152584</td>\n",
       "      <td>-0.839874</td>\n",
       "      <td>109.841953</td>\n",
       "      <td>128.224303</td>\n",
       "      <td>-175.741916</td>\n",
       "      <td>179.217338</td>\n",
       "      <td>-325.918929</td>\n",
       "      <td>40.400851</td>\n",
       "      <td>15.033985</td>\n",
       "      <td>-21.695485</td>\n",
       "      <td>51.545082</td>\n",
       "      <td>-67.459807</td>\n",
       "      <td>-101.762531</td>\n",
       "      <td>35.094755</td>\n",
       "      <td>-120.052248</td>\n",
       "      <td>-12.430743</td>\n",
       "      <td>47.338983</td>\n",
       "      <td>1694.018850</td>\n",
       "      <td>325.918929</td>\n",
       "      <td>67.459807</td>\n",
       "      <td>47.338983</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id      subject  n_steps  max_counter  acc_x_mean  acc_x_std  \\\n",
       "0  SEQ_000001  SUBJ_055840       56           55    7.750837   1.050640   \n",
       "1  SEQ_000011  SUBJ_016452       51           50   -2.423790   3.534764   \n",
       "\n",
       "   acc_x_max  acc_x_min  acc_x_range  acc_x_skew  acc_x_kurt  acc_x_jerk_mean  \\\n",
       "0  10.160156   6.132812     4.027344    0.730955   -0.756832        -0.041399   \n",
       "1   9.609375  -4.523438    14.132812    1.986602    2.661071         0.001417   \n",
       "\n",
       "   acc_x_jerk_std  acc_x_jerk_max  acc_x_jerk_min  acc_x_energy  acc_y_mean  \\\n",
       "0        0.466181        1.380859       -2.035156   3424.937988    5.393694   \n",
       "1        1.358934        4.136719       -6.701172    924.340561    6.621477   \n",
       "\n",
       "   acc_y_std  acc_y_max  acc_y_min  acc_y_range  acc_y_skew  acc_y_kurt  \\\n",
       "0   2.353345   7.214844   0.781250     6.433594   -1.222971   -0.319466   \n",
       "1   4.377906   8.957031  -5.257812    14.214844   -2.030169    2.552805   \n",
       "\n",
       "   acc_y_jerk_mean  acc_y_jerk_std  acc_y_jerk_max  acc_y_jerk_min  \\\n",
       "0         0.003453        0.524735        1.666016       -1.800781   \n",
       "1        -0.019072        1.340108        4.884766       -3.732422   \n",
       "\n",
       "   acc_y_energy  acc_z_mean  acc_z_std  acc_z_max  acc_z_min  acc_z_range  \\\n",
       "0   1933.751404   -0.093331   2.305147   4.093750  -4.792969     8.886719   \n",
       "1   3194.344513   -1.357996   4.619076  11.113281  -5.093750    16.207031   \n",
       "\n",
       "   acc_z_skew  acc_z_kurt  acc_z_jerk_mean  acc_z_jerk_std  acc_z_jerk_max  \\\n",
       "0   -0.837641   -0.385385        -0.003383        0.722215        2.433594   \n",
       "1    1.902655    1.943542        -0.006817        1.871495        8.025391   \n",
       "\n",
       "   acc_z_jerk_min  acc_z_energy  corr_acc_x_y  corr_acc_x_z  corr_acc_y_z  \\\n",
       "0       -2.335938    292.741547     -0.856616     -0.737114      0.905823   \n",
       "1       -6.166016   1160.845123     -0.935494      0.926198     -0.940147   \n",
       "\n",
       "   acc_z_momentum_x_range  roll_angle_mean  roll_angle_std  roll_angle_max  \\\n",
       "0               -0.375878         0.599637        0.265987        0.844646   \n",
       "1              -19.192307         1.605974        0.913583        2.152584   \n",
       "\n",
       "   roll_angle_min    yaw_mean     yaw_std     yaw_min     yaw_max  \\\n",
       "0        0.086889 -124.452980   13.759787 -134.790098  -97.201198   \n",
       "1       -0.839874  109.841953  128.224303 -175.741916  179.217338   \n",
       "\n",
       "   yaw_<lambda_0>  pitch_mean  pitch_std  pitch_min  pitch_max  \\\n",
       "0      -17.249719   -7.726119   4.687385 -17.477808  -0.217066   \n",
       "1     -325.918929   40.400851  15.033985 -21.695485  51.545082   \n",
       "\n",
       "   pitch_<lambda_0>   roll_mean   roll_std    roll_min   roll_max  \\\n",
       "0        -11.477719  -89.877106  13.319235 -116.734228 -73.521057   \n",
       "1        -67.459807 -101.762531  35.094755 -120.052248 -12.430743   \n",
       "\n",
       "   roll_<lambda_0>  orientation_change_magnitude  orientation_delta_yaw  \\\n",
       "0        16.508183                    238.683552              17.249719   \n",
       "1        47.338983                   1694.018850             325.918929   \n",
       "\n",
       "   orientation_delta_pitch  orientation_delta_roll  max_rotation_axis_yaw  \\\n",
       "0                11.477719               16.508183                   True   \n",
       "1                67.459807               47.338983                   True   \n",
       "\n",
       "   max_rotation_axis_pitch  max_rotation_axis_roll  \n",
       "0                    False                   False  \n",
       "1                    False                   False  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48203e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_id                 object\n",
      "gesture                     object\n",
      "subject                     object\n",
      "sequence_type               object\n",
      "n_steps                      int64\n",
      "                            ...   \n",
      "orientation_delta_pitch    float64\n",
      "orientation_delta_roll     float64\n",
      "max_rotation_axis_pitch       bool\n",
      "max_rotation_axis_roll        bool\n",
      "max_rotation_axis_yaw         bool\n",
      "Length: 72, dtype: object\n",
      "-----------------------------------\n",
      "sequence_id                 object\n",
      "subject                     object\n",
      "n_steps                      int64\n",
      "max_counter                  int64\n",
      "acc_x_mean                 float64\n",
      "                            ...   \n",
      "orientation_delta_pitch    float64\n",
      "orientation_delta_roll     float64\n",
      "max_rotation_axis_yaw         bool\n",
      "max_rotation_axis_pitch       bool\n",
      "max_rotation_axis_roll        bool\n",
      "Length: 70, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features_df.dtypes)\n",
    "print('-----------------------------------')\n",
    "print(features_test_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "615d98b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_orientation_stability_energy(df):\n",
    "    result = []\n",
    "\n",
    "    for seq_id, group in df.groupby('sequence_id'):\n",
    "        row = {'sequence_id': seq_id}\n",
    "\n",
    "        # Euler varyanslar (stabilite)\n",
    "        row['yaw_var'] = group['yaw'].var()\n",
    "        row['pitch_var'] = group['pitch'].var()\n",
    "        row['roll_var'] = group['roll'].var()\n",
    "\n",
    "        # Rotasyon enerjisi (eksensel dn iddeti)\n",
    "        row['rot_energy_x'] = np.mean(group['rot_x'] ** 2)\n",
    "        row['rot_energy_y'] = np.mean(group['rot_y'] ** 2)\n",
    "        row['rot_energy_z'] = np.mean(group['rot_z'] ** 2)\n",
    "\n",
    "        result.append(row)\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n",
    "# Train ve test iin ayr ayr hesapla\n",
    "orientation_stats_train = compute_orientation_stability_energy(train)\n",
    "orientation_stats_test = compute_orientation_stability_energy(test)\n",
    "\n",
    "# features_df ile birletir\n",
    "features_df = features_df.merge(orientation_stats_train, on='sequence_id', how='left')\n",
    "features_test_df = features_test_df.merge(orientation_stats_test, on='sequence_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f808f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8151, 78)\n",
      "(2, 76)\n"
     ]
    }
   ],
   "source": [
    "print(features_df.shape)\n",
    "print(features_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17771f17",
   "metadata": {},
   "source": [
    "## Thermopil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b698f100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3273308641.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features['thm_symmetry_side'] = grouped.apply(\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3273308641.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features['thm_center_edge_diff'] = grouped.apply(\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3273308641.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features['thm_symmetry_side'] = grouped.apply(\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3273308641.py:24: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  features['thm_center_edge_diff'] = grouped.apply(\n"
     ]
    }
   ],
   "source": [
    "def extract_thermopile_features(df):\n",
    "    thm_cols = ['thm_1', 'thm_2', 'thm_3', 'thm_4', 'thm_5']\n",
    "    grouped = df.groupby('sequence_id')\n",
    "    \n",
    "    features = pd.DataFrame(index=grouped.size().index)\n",
    "    \n",
    "    for col in thm_cols:\n",
    "        features[f'{col}_mean'] = grouped[col].mean()\n",
    "        features[f'{col}_std'] = grouped[col].std()\n",
    "        features[f'{col}_min'] = grouped[col].min()\n",
    "        features[f'{col}_max'] = grouped[col].max()\n",
    "        features[f'{col}_range'] = features[f'{col}_max'] - features[f'{col}_min']\n",
    "        features[f'{col}_delta'] = grouped[col].nth(-1).values - grouped[col].nth(0).values\n",
    "        features[f'{col}_activity'] = grouped[col].apply(lambda x: np.sum(np.abs(np.diff(x))))\n",
    "    \n",
    "    features['thm_mean_mean'] = features[[f'{col}_mean' for col in thm_cols]].mean(axis=1)\n",
    "    features['thm_std_mean'] = features[[f'{col}_std' for col in thm_cols]].mean(axis=1)\n",
    "    \n",
    "    mean_vals = features[[f'{col}_mean' for col in thm_cols]].values\n",
    "    features['thm_hotspot_index'] = np.argmax(mean_vals, axis=1)\n",
    "    \n",
    "    features['thm_symmetry_side'] = grouped.apply(\n",
    "        lambda x: ((x['thm_1'] + x['thm_5'])/2 - (x['thm_2'] + x['thm_4'])/2).mean())\n",
    "    features['thm_center_edge_diff'] = grouped.apply(\n",
    "        lambda x: np.abs(x['thm_3'] - ((x['thm_1'] + x['thm_5']) / 2)).mean())\n",
    "    \n",
    "    features.reset_index(inplace=True)\n",
    "    return features\n",
    "\n",
    "# Thermopile feature extraction\n",
    "features_df = features_df.merge(extract_thermopile_features(train), on='sequence_id', how='left')\n",
    "features_test_df = features_test_df.merge(extract_thermopile_features(test), on='sequence_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0463e028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>gesture</th>\n",
       "      <th>subject</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>max_counter</th>\n",
       "      <th>acc_x_mean</th>\n",
       "      <th>acc_x_std</th>\n",
       "      <th>acc_x_max</th>\n",
       "      <th>acc_x_min</th>\n",
       "      <th>acc_x_range</th>\n",
       "      <th>acc_x_skew</th>\n",
       "      <th>acc_x_kurt</th>\n",
       "      <th>acc_x_jerk_mean</th>\n",
       "      <th>acc_x_jerk_std</th>\n",
       "      <th>acc_x_jerk_max</th>\n",
       "      <th>acc_x_jerk_min</th>\n",
       "      <th>acc_x_energy</th>\n",
       "      <th>acc_y_mean</th>\n",
       "      <th>acc_y_std</th>\n",
       "      <th>acc_y_max</th>\n",
       "      <th>acc_y_min</th>\n",
       "      <th>acc_y_range</th>\n",
       "      <th>acc_y_skew</th>\n",
       "      <th>acc_y_kurt</th>\n",
       "      <th>acc_y_jerk_mean</th>\n",
       "      <th>acc_y_jerk_std</th>\n",
       "      <th>acc_y_jerk_max</th>\n",
       "      <th>acc_y_jerk_min</th>\n",
       "      <th>acc_y_energy</th>\n",
       "      <th>acc_z_mean</th>\n",
       "      <th>acc_z_std</th>\n",
       "      <th>acc_z_max</th>\n",
       "      <th>acc_z_min</th>\n",
       "      <th>acc_z_range</th>\n",
       "      <th>acc_z_skew</th>\n",
       "      <th>acc_z_kurt</th>\n",
       "      <th>acc_z_jerk_mean</th>\n",
       "      <th>acc_z_jerk_std</th>\n",
       "      <th>acc_z_jerk_max</th>\n",
       "      <th>acc_z_jerk_min</th>\n",
       "      <th>acc_z_energy</th>\n",
       "      <th>corr_acc_x_y</th>\n",
       "      <th>corr_acc_x_z</th>\n",
       "      <th>corr_acc_y_z</th>\n",
       "      <th>acc_z_momentum_x_range</th>\n",
       "      <th>roll_angle_mean</th>\n",
       "      <th>roll_angle_std</th>\n",
       "      <th>roll_angle_max</th>\n",
       "      <th>roll_angle_min</th>\n",
       "      <th>yaw_mean</th>\n",
       "      <th>yaw_std</th>\n",
       "      <th>yaw_min</th>\n",
       "      <th>yaw_max</th>\n",
       "      <th>yaw_delta</th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_delta</th>\n",
       "      <th>roll_mean</th>\n",
       "      <th>roll_std</th>\n",
       "      <th>roll_min</th>\n",
       "      <th>roll_max</th>\n",
       "      <th>roll_delta</th>\n",
       "      <th>orientation_change_magnitude</th>\n",
       "      <th>orientation_delta_yaw</th>\n",
       "      <th>orientation_delta_pitch</th>\n",
       "      <th>orientation_delta_roll</th>\n",
       "      <th>max_rotation_axis_pitch</th>\n",
       "      <th>max_rotation_axis_roll</th>\n",
       "      <th>max_rotation_axis_yaw</th>\n",
       "      <th>yaw_var</th>\n",
       "      <th>pitch_var</th>\n",
       "      <th>roll_var</th>\n",
       "      <th>rot_energy_x</th>\n",
       "      <th>rot_energy_y</th>\n",
       "      <th>rot_energy_z</th>\n",
       "      <th>thm_1_mean</th>\n",
       "      <th>thm_1_std</th>\n",
       "      <th>thm_1_min</th>\n",
       "      <th>thm_1_max</th>\n",
       "      <th>thm_1_range</th>\n",
       "      <th>thm_1_delta</th>\n",
       "      <th>thm_1_activity</th>\n",
       "      <th>thm_2_mean</th>\n",
       "      <th>thm_2_std</th>\n",
       "      <th>thm_2_min</th>\n",
       "      <th>thm_2_max</th>\n",
       "      <th>thm_2_range</th>\n",
       "      <th>thm_2_delta</th>\n",
       "      <th>thm_2_activity</th>\n",
       "      <th>thm_3_mean</th>\n",
       "      <th>thm_3_std</th>\n",
       "      <th>thm_3_min</th>\n",
       "      <th>thm_3_max</th>\n",
       "      <th>thm_3_range</th>\n",
       "      <th>thm_3_delta</th>\n",
       "      <th>thm_3_activity</th>\n",
       "      <th>thm_4_mean</th>\n",
       "      <th>thm_4_std</th>\n",
       "      <th>thm_4_min</th>\n",
       "      <th>thm_4_max</th>\n",
       "      <th>thm_4_range</th>\n",
       "      <th>thm_4_delta</th>\n",
       "      <th>thm_4_activity</th>\n",
       "      <th>thm_5_mean</th>\n",
       "      <th>thm_5_std</th>\n",
       "      <th>thm_5_min</th>\n",
       "      <th>thm_5_max</th>\n",
       "      <th>thm_5_range</th>\n",
       "      <th>thm_5_delta</th>\n",
       "      <th>thm_5_activity</th>\n",
       "      <th>thm_mean_mean</th>\n",
       "      <th>thm_std_mean</th>\n",
       "      <th>thm_hotspot_index</th>\n",
       "      <th>thm_symmetry_side</th>\n",
       "      <th>thm_center_edge_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Target</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>6.153098</td>\n",
       "      <td>1.334155</td>\n",
       "      <td>9.015625</td>\n",
       "      <td>3.613281</td>\n",
       "      <td>5.402344</td>\n",
       "      <td>-0.545319</td>\n",
       "      <td>-0.391295</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.455492</td>\n",
       "      <td>1.339844</td>\n",
       "      <td>-1.302734</td>\n",
       "      <td>2257.733032</td>\n",
       "      <td>3.915570</td>\n",
       "      <td>3.048287</td>\n",
       "      <td>6.519531</td>\n",
       "      <td>-2.019531</td>\n",
       "      <td>8.539062</td>\n",
       "      <td>-1.184870</td>\n",
       "      <td>-0.391547</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.780156</td>\n",
       "      <td>3.542969</td>\n",
       "      <td>-2.566406</td>\n",
       "      <td>1394.261383</td>\n",
       "      <td>5.577782</td>\n",
       "      <td>2.337517</td>\n",
       "      <td>9.792969</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>8.699219</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>-0.897976</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.762233</td>\n",
       "      <td>2.105469</td>\n",
       "      <td>-2.357422</td>\n",
       "      <td>2079.347610</td>\n",
       "      <td>0.854289</td>\n",
       "      <td>-0.887190</td>\n",
       "      <td>-0.902468</td>\n",
       "      <td>30.133098</td>\n",
       "      <td>0.445496</td>\n",
       "      <td>0.443626</td>\n",
       "      <td>0.799987</td>\n",
       "      <td>-0.464035</td>\n",
       "      <td>-136.782733</td>\n",
       "      <td>3.686740</td>\n",
       "      <td>-144.000190</td>\n",
       "      <td>-129.923292</td>\n",
       "      <td>3.191850</td>\n",
       "      <td>18.331457</td>\n",
       "      <td>5.661462</td>\n",
       "      <td>7.476183</td>\n",
       "      <td>31.224292</td>\n",
       "      <td>-13.083466</td>\n",
       "      <td>-50.211994</td>\n",
       "      <td>21.639925</td>\n",
       "      <td>-75.969314</td>\n",
       "      <td>-9.568449</td>\n",
       "      <td>9.286070</td>\n",
       "      <td>383.916977</td>\n",
       "      <td>3.191850</td>\n",
       "      <td>13.083466</td>\n",
       "      <td>9.286070</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13.592053</td>\n",
       "      <td>32.052153</td>\n",
       "      <td>468.286339</td>\n",
       "      <td>0.082005</td>\n",
       "      <td>0.139978</td>\n",
       "      <td>0.703864</td>\n",
       "      <td>28.630612</td>\n",
       "      <td>0.582076</td>\n",
       "      <td>27.696510</td>\n",
       "      <td>30.543730</td>\n",
       "      <td>2.847219</td>\n",
       "      <td>-0.150585</td>\n",
       "      <td>13.000359</td>\n",
       "      <td>29.571870</td>\n",
       "      <td>2.576799</td>\n",
       "      <td>24.558798</td>\n",
       "      <td>32.010178</td>\n",
       "      <td>7.451380</td>\n",
       "      <td>-1.006186</td>\n",
       "      <td>22.822474</td>\n",
       "      <td>28.576605</td>\n",
       "      <td>1.260533</td>\n",
       "      <td>25.907490</td>\n",
       "      <td>30.090014</td>\n",
       "      <td>4.182524</td>\n",
       "      <td>-0.156540</td>\n",
       "      <td>13.482555</td>\n",
       "      <td>29.177937</td>\n",
       "      <td>0.278147</td>\n",
       "      <td>28.592863</td>\n",
       "      <td>29.761480</td>\n",
       "      <td>1.168617</td>\n",
       "      <td>0.523323</td>\n",
       "      <td>5.657688</td>\n",
       "      <td>27.957446</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>26.047148</td>\n",
       "      <td>29.428299</td>\n",
       "      <td>3.381151</td>\n",
       "      <td>-0.324644</td>\n",
       "      <td>14.319735</td>\n",
       "      <td>28.782894</td>\n",
       "      <td>1.115080</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.080875</td>\n",
       "      <td>0.752568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000008</td>\n",
       "      <td>Forehead - pull hairline</td>\n",
       "      <td>SUBJ_020948</td>\n",
       "      <td>Target</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>3.400506</td>\n",
       "      <td>1.087142</td>\n",
       "      <td>5.906250</td>\n",
       "      <td>1.734375</td>\n",
       "      <td>4.171875</td>\n",
       "      <td>0.146452</td>\n",
       "      <td>-1.069663</td>\n",
       "      <td>-0.028148</td>\n",
       "      <td>0.519107</td>\n",
       "      <td>1.742188</td>\n",
       "      <td>-1.839844</td>\n",
       "      <td>865.499603</td>\n",
       "      <td>5.311179</td>\n",
       "      <td>3.268073</td>\n",
       "      <td>8.667969</td>\n",
       "      <td>-0.222656</td>\n",
       "      <td>8.890625</td>\n",
       "      <td>-0.830467</td>\n",
       "      <td>-1.170949</td>\n",
       "      <td>0.053740</td>\n",
       "      <td>0.672863</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-2.574219</td>\n",
       "      <td>2633.766251</td>\n",
       "      <td>6.581629</td>\n",
       "      <td>2.475402</td>\n",
       "      <td>11.074219</td>\n",
       "      <td>1.722656</td>\n",
       "      <td>9.351562</td>\n",
       "      <td>0.186346</td>\n",
       "      <td>-1.306469</td>\n",
       "      <td>-0.065545</td>\n",
       "      <td>1.072456</td>\n",
       "      <td>2.833984</td>\n",
       "      <td>-2.986328</td>\n",
       "      <td>3356.163620</td>\n",
       "      <td>0.678886</td>\n",
       "      <td>-0.594269</td>\n",
       "      <td>-0.889196</td>\n",
       "      <td>27.457734</td>\n",
       "      <td>0.817318</td>\n",
       "      <td>0.438181</td>\n",
       "      <td>1.307932</td>\n",
       "      <td>-0.084997</td>\n",
       "      <td>-148.403656</td>\n",
       "      <td>5.623907</td>\n",
       "      <td>-154.261658</td>\n",
       "      <td>-139.255923</td>\n",
       "      <td>-0.328373</td>\n",
       "      <td>3.416037</td>\n",
       "      <td>6.567778</td>\n",
       "      <td>-7.471505</td>\n",
       "      <td>17.183220</td>\n",
       "      <td>0.772071</td>\n",
       "      <td>-43.404627</td>\n",
       "      <td>22.413410</td>\n",
       "      <td>-67.011753</td>\n",
       "      <td>-8.412334</td>\n",
       "      <td>-7.846398</td>\n",
       "      <td>493.946555</td>\n",
       "      <td>0.328373</td>\n",
       "      <td>0.772071</td>\n",
       "      <td>7.846398</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>31.628330</td>\n",
       "      <td>43.135706</td>\n",
       "      <td>502.360935</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>0.152819</td>\n",
       "      <td>0.767665</td>\n",
       "      <td>30.464309</td>\n",
       "      <td>2.709212</td>\n",
       "      <td>25.985313</td>\n",
       "      <td>32.870808</td>\n",
       "      <td>6.885494</td>\n",
       "      <td>0.901049</td>\n",
       "      <td>19.042677</td>\n",
       "      <td>29.678206</td>\n",
       "      <td>3.885080</td>\n",
       "      <td>23.907709</td>\n",
       "      <td>33.100945</td>\n",
       "      <td>9.193235</td>\n",
       "      <td>0.056095</td>\n",
       "      <td>31.470016</td>\n",
       "      <td>29.179852</td>\n",
       "      <td>3.074828</td>\n",
       "      <td>24.414917</td>\n",
       "      <td>32.316135</td>\n",
       "      <td>7.901218</td>\n",
       "      <td>1.130726</td>\n",
       "      <td>42.520508</td>\n",
       "      <td>30.501325</td>\n",
       "      <td>0.976249</td>\n",
       "      <td>28.755495</td>\n",
       "      <td>31.613327</td>\n",
       "      <td>2.857832</td>\n",
       "      <td>0.866661</td>\n",
       "      <td>12.937668</td>\n",
       "      <td>25.824221</td>\n",
       "      <td>1.165940</td>\n",
       "      <td>24.181562</td>\n",
       "      <td>28.054575</td>\n",
       "      <td>3.873013</td>\n",
       "      <td>-0.130692</td>\n",
       "      <td>25.231140</td>\n",
       "      <td>29.129583</td>\n",
       "      <td>2.362262</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.945501</td>\n",
       "      <td>1.710534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000013</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>SUBJ_040282</td>\n",
       "      <td>Target</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>-7.058962</td>\n",
       "      <td>1.295184</td>\n",
       "      <td>-3.347656</td>\n",
       "      <td>-9.250000</td>\n",
       "      <td>5.902344</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.291585</td>\n",
       "      <td>0.034677</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>2.527344</td>\n",
       "      <td>-1.726562</td>\n",
       "      <td>2728.164307</td>\n",
       "      <td>2.346182</td>\n",
       "      <td>2.564639</td>\n",
       "      <td>4.683594</td>\n",
       "      <td>-3.273438</td>\n",
       "      <td>7.957031</td>\n",
       "      <td>-1.445762</td>\n",
       "      <td>0.544205</td>\n",
       "      <td>0.024838</td>\n",
       "      <td>0.732187</td>\n",
       "      <td>2.701172</td>\n",
       "      <td>-2.394531</td>\n",
       "      <td>633.765793</td>\n",
       "      <td>-6.068544</td>\n",
       "      <td>1.330784</td>\n",
       "      <td>-3.515625</td>\n",
       "      <td>-10.945312</td>\n",
       "      <td>7.429688</td>\n",
       "      <td>-1.039566</td>\n",
       "      <td>2.722204</td>\n",
       "      <td>0.026570</td>\n",
       "      <td>0.640019</td>\n",
       "      <td>2.316406</td>\n",
       "      <td>-1.863281</td>\n",
       "      <td>2043.934021</td>\n",
       "      <td>-0.500159</td>\n",
       "      <td>-0.638358</td>\n",
       "      <td>0.695687</td>\n",
       "      <td>-35.818631</td>\n",
       "      <td>1.676461</td>\n",
       "      <td>2.113786</td>\n",
       "      <td>2.954490</td>\n",
       "      <td>-2.899302</td>\n",
       "      <td>-131.321246</td>\n",
       "      <td>21.874304</td>\n",
       "      <td>-164.333444</td>\n",
       "      <td>-85.941112</td>\n",
       "      <td>-17.484747</td>\n",
       "      <td>40.867410</td>\n",
       "      <td>30.350971</td>\n",
       "      <td>-26.623562</td>\n",
       "      <td>66.133301</td>\n",
       "      <td>19.604578</td>\n",
       "      <td>137.968703</td>\n",
       "      <td>91.320949</td>\n",
       "      <td>-179.451926</td>\n",
       "      <td>179.724953</td>\n",
       "      <td>10.685674</td>\n",
       "      <td>1318.088253</td>\n",
       "      <td>17.484747</td>\n",
       "      <td>19.604578</td>\n",
       "      <td>10.685674</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>478.485194</td>\n",
       "      <td>921.181433</td>\n",
       "      <td>8339.515689</td>\n",
       "      <td>0.148647</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>24.522526</td>\n",
       "      <td>0.449773</td>\n",
       "      <td>24.181389</td>\n",
       "      <td>25.634346</td>\n",
       "      <td>1.452957</td>\n",
       "      <td>-0.013020</td>\n",
       "      <td>5.484901</td>\n",
       "      <td>24.367174</td>\n",
       "      <td>0.620555</td>\n",
       "      <td>23.933413</td>\n",
       "      <td>26.175961</td>\n",
       "      <td>2.242548</td>\n",
       "      <td>-0.110445</td>\n",
       "      <td>7.408587</td>\n",
       "      <td>24.892424</td>\n",
       "      <td>0.294962</td>\n",
       "      <td>24.406981</td>\n",
       "      <td>25.512794</td>\n",
       "      <td>1.105814</td>\n",
       "      <td>0.085846</td>\n",
       "      <td>6.074223</td>\n",
       "      <td>24.930840</td>\n",
       "      <td>0.572871</td>\n",
       "      <td>24.419798</td>\n",
       "      <td>26.452927</td>\n",
       "      <td>2.033129</td>\n",
       "      <td>-0.384151</td>\n",
       "      <td>5.965618</td>\n",
       "      <td>24.733322</td>\n",
       "      <td>0.475044</td>\n",
       "      <td>24.167980</td>\n",
       "      <td>26.051331</td>\n",
       "      <td>1.883350</td>\n",
       "      <td>0.257027</td>\n",
       "      <td>7.453289</td>\n",
       "      <td>24.689257</td>\n",
       "      <td>0.482641</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.021083</td>\n",
       "      <td>0.339090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000016</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>SUBJ_052342</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>5.524654</td>\n",
       "      <td>1.074108</td>\n",
       "      <td>9.378906</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>5.941406</td>\n",
       "      <td>0.747648</td>\n",
       "      <td>1.524114</td>\n",
       "      <td>-0.043161</td>\n",
       "      <td>0.672640</td>\n",
       "      <td>2.703125</td>\n",
       "      <td>-3.375000</td>\n",
       "      <td>1931.052567</td>\n",
       "      <td>-4.408491</td>\n",
       "      <td>0.598318</td>\n",
       "      <td>-2.960938</td>\n",
       "      <td>-5.718750</td>\n",
       "      <td>2.757812</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>-0.017645</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>0.335250</td>\n",
       "      <td>1.109375</td>\n",
       "      <td>-1.343750</td>\n",
       "      <td>1207.001572</td>\n",
       "      <td>-3.162077</td>\n",
       "      <td>6.139752</td>\n",
       "      <td>8.355469</td>\n",
       "      <td>-8.078125</td>\n",
       "      <td>16.433594</td>\n",
       "      <td>0.964846</td>\n",
       "      <td>-1.033536</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>1.951462</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>-6.037109</td>\n",
       "      <td>2871.715958</td>\n",
       "      <td>0.553929</td>\n",
       "      <td>0.639362</td>\n",
       "      <td>0.704613</td>\n",
       "      <td>-18.787186</td>\n",
       "      <td>-0.682500</td>\n",
       "      <td>0.136990</td>\n",
       "      <td>-0.374288</td>\n",
       "      <td>-0.956637</td>\n",
       "      <td>-65.105438</td>\n",
       "      <td>33.468126</td>\n",
       "      <td>-118.013318</td>\n",
       "      <td>-39.047014</td>\n",
       "      <td>-6.329272</td>\n",
       "      <td>15.967139</td>\n",
       "      <td>18.844155</td>\n",
       "      <td>-6.011835</td>\n",
       "      <td>44.952709</td>\n",
       "      <td>4.136208</td>\n",
       "      <td>-102.384014</td>\n",
       "      <td>50.621010</td>\n",
       "      <td>-143.251197</td>\n",
       "      <td>-21.145502</td>\n",
       "      <td>10.922323</td>\n",
       "      <td>622.312570</td>\n",
       "      <td>6.329272</td>\n",
       "      <td>4.136208</td>\n",
       "      <td>10.922323</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1120.115429</td>\n",
       "      <td>355.102188</td>\n",
       "      <td>2562.486694</td>\n",
       "      <td>0.572502</td>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.221416</td>\n",
       "      <td>31.651703</td>\n",
       "      <td>4.006846</td>\n",
       "      <td>25.413513</td>\n",
       "      <td>36.053188</td>\n",
       "      <td>10.639675</td>\n",
       "      <td>-0.282286</td>\n",
       "      <td>27.109056</td>\n",
       "      <td>31.601259</td>\n",
       "      <td>4.495657</td>\n",
       "      <td>25.018881</td>\n",
       "      <td>36.705894</td>\n",
       "      <td>11.687014</td>\n",
       "      <td>0.047785</td>\n",
       "      <td>31.485872</td>\n",
       "      <td>29.320353</td>\n",
       "      <td>3.274493</td>\n",
       "      <td>24.128819</td>\n",
       "      <td>33.617542</td>\n",
       "      <td>9.488724</td>\n",
       "      <td>-0.441620</td>\n",
       "      <td>23.481190</td>\n",
       "      <td>32.790761</td>\n",
       "      <td>3.253195</td>\n",
       "      <td>27.227589</td>\n",
       "      <td>35.665222</td>\n",
       "      <td>8.437634</td>\n",
       "      <td>1.619091</td>\n",
       "      <td>22.319618</td>\n",
       "      <td>30.860562</td>\n",
       "      <td>3.310154</td>\n",
       "      <td>26.312038</td>\n",
       "      <td>35.801083</td>\n",
       "      <td>9.489044</td>\n",
       "      <td>-0.020788</td>\n",
       "      <td>28.030943</td>\n",
       "      <td>31.244928</td>\n",
       "      <td>3.668069</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.939878</td>\n",
       "      <td>2.299691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000018</td>\n",
       "      <td>Forehead - pull hairline</td>\n",
       "      <td>SUBJ_032165</td>\n",
       "      <td>Target</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>5.363715</td>\n",
       "      <td>1.627637</td>\n",
       "      <td>6.832031</td>\n",
       "      <td>1.964844</td>\n",
       "      <td>4.867188</td>\n",
       "      <td>-1.397824</td>\n",
       "      <td>0.163483</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.456681</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>-1.265625</td>\n",
       "      <td>1693.957520</td>\n",
       "      <td>4.109737</td>\n",
       "      <td>3.525304</td>\n",
       "      <td>6.718750</td>\n",
       "      <td>-3.164062</td>\n",
       "      <td>9.882812</td>\n",
       "      <td>-1.347944</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>0.025933</td>\n",
       "      <td>0.793187</td>\n",
       "      <td>2.585938</td>\n",
       "      <td>-2.105469</td>\n",
       "      <td>1570.728409</td>\n",
       "      <td>5.937066</td>\n",
       "      <td>2.104544</td>\n",
       "      <td>9.933594</td>\n",
       "      <td>4.148438</td>\n",
       "      <td>5.785156</td>\n",
       "      <td>1.040372</td>\n",
       "      <td>-0.718802</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>0.522210</td>\n",
       "      <td>1.992188</td>\n",
       "      <td>-2.031250</td>\n",
       "      <td>2138.175323</td>\n",
       "      <td>0.934984</td>\n",
       "      <td>-0.900993</td>\n",
       "      <td>-0.956922</td>\n",
       "      <td>28.896813</td>\n",
       "      <td>0.438831</td>\n",
       "      <td>0.638793</td>\n",
       "      <td>0.819412</td>\n",
       "      <td>-1.004394</td>\n",
       "      <td>-14.657881</td>\n",
       "      <td>15.666985</td>\n",
       "      <td>-44.304886</td>\n",
       "      <td>0.046952</td>\n",
       "      <td>32.796140</td>\n",
       "      <td>-43.398718</td>\n",
       "      <td>22.229601</td>\n",
       "      <td>-58.711619</td>\n",
       "      <td>5.062855</td>\n",
       "      <td>-25.622874</td>\n",
       "      <td>20.653081</td>\n",
       "      <td>22.538566</td>\n",
       "      <td>-23.586628</td>\n",
       "      <td>40.365129</td>\n",
       "      <td>34.688647</td>\n",
       "      <td>331.830537</td>\n",
       "      <td>32.796140</td>\n",
       "      <td>25.622874</td>\n",
       "      <td>34.688647</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>245.454406</td>\n",
       "      <td>494.155175</td>\n",
       "      <td>507.986980</td>\n",
       "      <td>0.062624</td>\n",
       "      <td>0.145895</td>\n",
       "      <td>0.052185</td>\n",
       "      <td>28.903610</td>\n",
       "      <td>1.144503</td>\n",
       "      <td>26.533083</td>\n",
       "      <td>30.267483</td>\n",
       "      <td>3.734400</td>\n",
       "      <td>1.167833</td>\n",
       "      <td>10.336542</td>\n",
       "      <td>29.438643</td>\n",
       "      <td>1.658719</td>\n",
       "      <td>25.795074</td>\n",
       "      <td>31.035217</td>\n",
       "      <td>5.240143</td>\n",
       "      <td>0.690622</td>\n",
       "      <td>15.569307</td>\n",
       "      <td>27.058073</td>\n",
       "      <td>0.951421</td>\n",
       "      <td>25.127720</td>\n",
       "      <td>28.468761</td>\n",
       "      <td>3.341042</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>11.521690</td>\n",
       "      <td>27.841705</td>\n",
       "      <td>0.431424</td>\n",
       "      <td>26.827133</td>\n",
       "      <td>28.400864</td>\n",
       "      <td>1.573730</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>6.891409</td>\n",
       "      <td>31.014364</td>\n",
       "      <td>1.394629</td>\n",
       "      <td>28.282324</td>\n",
       "      <td>32.180752</td>\n",
       "      <td>3.898428</td>\n",
       "      <td>2.002932</td>\n",
       "      <td>8.149042</td>\n",
       "      <td>28.851279</td>\n",
       "      <td>1.116139</td>\n",
       "      <td>4</td>\n",
       "      <td>1.318813</td>\n",
       "      <td>2.900914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id                   gesture      subject sequence_type  n_steps  \\\n",
       "0  SEQ_000007        Cheek - pinch skin  SUBJ_059520        Target       57   \n",
       "1  SEQ_000008  Forehead - pull hairline  SUBJ_020948        Target       68   \n",
       "2  SEQ_000013        Cheek - pinch skin  SUBJ_040282        Target       53   \n",
       "3  SEQ_000016         Write name on leg  SUBJ_052342    Non-Target       61   \n",
       "4  SEQ_000018  Forehead - pull hairline  SUBJ_032165        Target       54   \n",
       "\n",
       "   max_counter  acc_x_mean  acc_x_std  acc_x_max  acc_x_min  acc_x_range  \\\n",
       "0           56    6.153098   1.334155   9.015625   3.613281     5.402344   \n",
       "1           67    3.400506   1.087142   5.906250   1.734375     4.171875   \n",
       "2           52   -7.058962   1.295184  -3.347656  -9.250000     5.902344   \n",
       "3           60    5.524654   1.074108   9.378906   3.437500     5.941406   \n",
       "4           53    5.363715   1.627637   6.832031   1.964844     4.867188   \n",
       "\n",
       "   acc_x_skew  acc_x_kurt  acc_x_jerk_mean  acc_x_jerk_std  acc_x_jerk_max  \\\n",
       "0   -0.545319   -0.391295         0.020285        0.455492        1.339844   \n",
       "1    0.146452   -1.069663        -0.028148        0.519107        1.742188   \n",
       "2    0.518519    0.291585         0.034677        0.761798        2.527344   \n",
       "3    0.747648    1.524114        -0.043161        0.672640        2.703125   \n",
       "4   -1.397824    0.163483         0.040039        0.456681        2.031250   \n",
       "\n",
       "   acc_x_jerk_min  acc_x_energy  acc_y_mean  acc_y_std  acc_y_max  acc_y_min  \\\n",
       "0       -1.302734   2257.733032    3.915570   3.048287   6.519531  -2.019531   \n",
       "1       -1.839844    865.499603    5.311179   3.268073   8.667969  -0.222656   \n",
       "2       -1.726562   2728.164307    2.346182   2.564639   4.683594  -3.273438   \n",
       "3       -3.375000   1931.052567   -4.408491   0.598318  -2.960938  -5.718750   \n",
       "4       -1.265625   1693.957520    4.109737   3.525304   6.718750  -3.164062   \n",
       "\n",
       "   acc_y_range  acc_y_skew  acc_y_kurt  acc_y_jerk_mean  acc_y_jerk_std  \\\n",
       "0     8.539062   -1.184870   -0.391547        -0.001028        0.780156   \n",
       "1     8.890625   -0.830467   -1.170949         0.053740        0.672863   \n",
       "2     7.957031   -1.445762    0.544205         0.024838        0.732187   \n",
       "3     2.757812    0.505319   -0.017645        -0.002561        0.335250   \n",
       "4     9.882812   -1.347944    0.033611         0.025933        0.793187   \n",
       "\n",
       "   acc_y_jerk_max  acc_y_jerk_min  acc_y_energy  acc_z_mean  acc_z_std  \\\n",
       "0        3.542969       -2.566406   1394.261383    5.577782   2.337517   \n",
       "1        2.375000       -2.574219   2633.766251    6.581629   2.475402   \n",
       "2        2.701172       -2.394531    633.765793   -6.068544   1.330784   \n",
       "3        1.109375       -1.343750   1207.001572   -3.162077   6.139752   \n",
       "4        2.585938       -2.105469   1570.728409    5.937066   2.104544   \n",
       "\n",
       "   acc_z_max  acc_z_min  acc_z_range  acc_z_skew  acc_z_kurt  acc_z_jerk_mean  \\\n",
       "0   9.792969   1.093750     8.699219    0.586111   -0.897976         0.002981   \n",
       "1  11.074219   1.722656     9.351562    0.186346   -1.306469        -0.065545   \n",
       "2  -3.515625 -10.945312     7.429688   -1.039566    2.722204         0.026570   \n",
       "3   8.355469  -8.078125    16.433594    0.964846   -1.033536         0.083600   \n",
       "4   9.933594   4.148438     5.785156    1.040372   -0.718802        -0.001736   \n",
       "\n",
       "   acc_z_jerk_std  acc_z_jerk_max  acc_z_jerk_min  acc_z_energy  corr_acc_x_y  \\\n",
       "0        0.762233        2.105469       -2.357422   2079.347610      0.854289   \n",
       "1        1.072456        2.833984       -2.986328   3356.163620      0.678886   \n",
       "2        0.640019        2.316406       -1.863281   2043.934021     -0.500159   \n",
       "3        1.951462       11.531250       -6.037109   2871.715958      0.553929   \n",
       "4        0.522210        1.992188       -2.031250   2138.175323      0.934984   \n",
       "\n",
       "   corr_acc_x_z  corr_acc_y_z  acc_z_momentum_x_range  roll_angle_mean  \\\n",
       "0     -0.887190     -0.902468               30.133098         0.445496   \n",
       "1     -0.594269     -0.889196               27.457734         0.817318   \n",
       "2     -0.638358      0.695687              -35.818631         1.676461   \n",
       "3      0.639362      0.704613              -18.787186        -0.682500   \n",
       "4     -0.900993     -0.956922               28.896813         0.438831   \n",
       "\n",
       "   roll_angle_std  roll_angle_max  roll_angle_min    yaw_mean    yaw_std  \\\n",
       "0        0.443626        0.799987       -0.464035 -136.782733   3.686740   \n",
       "1        0.438181        1.307932       -0.084997 -148.403656   5.623907   \n",
       "2        2.113786        2.954490       -2.899302 -131.321246  21.874304   \n",
       "3        0.136990       -0.374288       -0.956637  -65.105438  33.468126   \n",
       "4        0.638793        0.819412       -1.004394  -14.657881  15.666985   \n",
       "\n",
       "      yaw_min     yaw_max  yaw_delta  pitch_mean  pitch_std  pitch_min  \\\n",
       "0 -144.000190 -129.923292   3.191850   18.331457   5.661462   7.476183   \n",
       "1 -154.261658 -139.255923  -0.328373    3.416037   6.567778  -7.471505   \n",
       "2 -164.333444  -85.941112 -17.484747   40.867410  30.350971 -26.623562   \n",
       "3 -118.013318  -39.047014  -6.329272   15.967139  18.844155  -6.011835   \n",
       "4  -44.304886    0.046952  32.796140  -43.398718  22.229601 -58.711619   \n",
       "\n",
       "   pitch_max  pitch_delta   roll_mean   roll_std    roll_min    roll_max  \\\n",
       "0  31.224292   -13.083466  -50.211994  21.639925  -75.969314   -9.568449   \n",
       "1  17.183220     0.772071  -43.404627  22.413410  -67.011753   -8.412334   \n",
       "2  66.133301    19.604578  137.968703  91.320949 -179.451926  179.724953   \n",
       "3  44.952709     4.136208 -102.384014  50.621010 -143.251197  -21.145502   \n",
       "4   5.062855   -25.622874   20.653081  22.538566  -23.586628   40.365129   \n",
       "\n",
       "   roll_delta  orientation_change_magnitude  orientation_delta_yaw  \\\n",
       "0    9.286070                    383.916977               3.191850   \n",
       "1   -7.846398                    493.946555               0.328373   \n",
       "2   10.685674                   1318.088253              17.484747   \n",
       "3   10.922323                    622.312570               6.329272   \n",
       "4   34.688647                    331.830537              32.796140   \n",
       "\n",
       "   orientation_delta_pitch  orientation_delta_roll  max_rotation_axis_pitch  \\\n",
       "0                13.083466                9.286070                    False   \n",
       "1                 0.772071                7.846398                    False   \n",
       "2                19.604578               10.685674                    False   \n",
       "3                 4.136208               10.922323                    False   \n",
       "4                25.622874               34.688647                    False   \n",
       "\n",
       "   max_rotation_axis_roll  max_rotation_axis_yaw      yaw_var   pitch_var  \\\n",
       "0                    True                  False    13.592053   32.052153   \n",
       "1                    True                  False    31.628330   43.135706   \n",
       "2                    True                  False   478.485194  921.181433   \n",
       "3                    True                  False  1120.115429  355.102188   \n",
       "4                    True                  False   245.454406  494.155175   \n",
       "\n",
       "      roll_var  rot_energy_x  rot_energy_y  rot_energy_z  thm_1_mean  \\\n",
       "0   468.286339      0.082005      0.139978      0.703864   28.630612   \n",
       "1   502.360935      0.016126      0.152819      0.767665   30.464309   \n",
       "2  8339.515689      0.148647      0.648760      0.026494   24.522526   \n",
       "3  2562.486694      0.572502      0.074008      0.221416   31.651703   \n",
       "4   507.986980      0.062624      0.145895      0.052185   28.903610   \n",
       "\n",
       "   thm_1_std  thm_1_min  thm_1_max  thm_1_range  thm_1_delta  thm_1_activity  \\\n",
       "0   0.582076  27.696510  30.543730     2.847219    -0.150585       13.000359   \n",
       "1   2.709212  25.985313  32.870808     6.885494     0.901049       19.042677   \n",
       "2   0.449773  24.181389  25.634346     1.452957    -0.013020        5.484901   \n",
       "3   4.006846  25.413513  36.053188    10.639675    -0.282286       27.109056   \n",
       "4   1.144503  26.533083  30.267483     3.734400     1.167833       10.336542   \n",
       "\n",
       "   thm_2_mean  thm_2_std  thm_2_min  thm_2_max  thm_2_range  thm_2_delta  \\\n",
       "0   29.571870   2.576799  24.558798  32.010178     7.451380    -1.006186   \n",
       "1   29.678206   3.885080  23.907709  33.100945     9.193235     0.056095   \n",
       "2   24.367174   0.620555  23.933413  26.175961     2.242548    -0.110445   \n",
       "3   31.601259   4.495657  25.018881  36.705894    11.687014     0.047785   \n",
       "4   29.438643   1.658719  25.795074  31.035217     5.240143     0.690622   \n",
       "\n",
       "   thm_2_activity  thm_3_mean  thm_3_std  thm_3_min  thm_3_max  thm_3_range  \\\n",
       "0       22.822474   28.576605   1.260533  25.907490  30.090014     4.182524   \n",
       "1       31.470016   29.179852   3.074828  24.414917  32.316135     7.901218   \n",
       "2        7.408587   24.892424   0.294962  24.406981  25.512794     1.105814   \n",
       "3       31.485872   29.320353   3.274493  24.128819  33.617542     9.488724   \n",
       "4       15.569307   27.058073   0.951421  25.127720  28.468761     3.341042   \n",
       "\n",
       "   thm_3_delta  thm_3_activity  thm_4_mean  thm_4_std  thm_4_min  thm_4_max  \\\n",
       "0    -0.156540       13.482555   29.177937   0.278147  28.592863  29.761480   \n",
       "1     1.130726       42.520508   30.501325   0.976249  28.755495  31.613327   \n",
       "2     0.085846        6.074223   24.930840   0.572871  24.419798  26.452927   \n",
       "3    -0.441620       23.481190   32.790761   3.253195  27.227589  35.665222   \n",
       "4     0.760956       11.521690   27.841705   0.431424  26.827133  28.400864   \n",
       "\n",
       "   thm_4_range  thm_4_delta  thm_4_activity  thm_5_mean  thm_5_std  thm_5_min  \\\n",
       "0     1.168617     0.523323        5.657688   27.957446   0.877846  26.047148   \n",
       "1     2.857832     0.866661       12.937668   25.824221   1.165940  24.181562   \n",
       "2     2.033129    -0.384151        5.965618   24.733322   0.475044  24.167980   \n",
       "3     8.437634     1.619091       22.319618   30.860562   3.310154  26.312038   \n",
       "4     1.573730     0.005075        6.891409   31.014364   1.394629  28.282324   \n",
       "\n",
       "   thm_5_max  thm_5_range  thm_5_delta  thm_5_activity  thm_mean_mean  \\\n",
       "0  29.428299     3.381151    -0.324644       14.319735      28.782894   \n",
       "1  28.054575     3.873013    -0.130692       25.231140      29.129583   \n",
       "2  26.051331     1.883350     0.257027        7.453289      24.689257   \n",
       "3  35.801083     9.489044    -0.020788       28.030943      31.244928   \n",
       "4  32.180752     3.898428     2.002932        8.149042      28.851279   \n",
       "\n",
       "   thm_std_mean  thm_hotspot_index  thm_symmetry_side  thm_center_edge_diff  \n",
       "0      1.115080                  1          -1.080875              0.752568  \n",
       "1      2.362262                  3          -1.945501              1.710534  \n",
       "2      0.482641                  3          -0.021083              0.339090  \n",
       "3      3.668069                  3          -0.939878              2.299691  \n",
       "4      1.116139                  4           1.318813              2.900914  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9d22015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence_id              object\n",
      "gesture                  object\n",
      "subject                  object\n",
      "sequence_type            object\n",
      "n_steps                   int64\n",
      "                         ...   \n",
      "thm_mean_mean           float64\n",
      "thm_std_mean            float64\n",
      "thm_hotspot_index         int64\n",
      "thm_symmetry_side       float64\n",
      "thm_center_edge_diff    float64\n",
      "Length: 118, dtype: object\n",
      "---------------------------------------\n",
      "sequence_id              object\n",
      "subject                  object\n",
      "n_steps                   int64\n",
      "max_counter               int64\n",
      "acc_x_mean              float64\n",
      "                         ...   \n",
      "thm_mean_mean           float64\n",
      "thm_std_mean            float64\n",
      "thm_hotspot_index         int64\n",
      "thm_symmetry_side       float64\n",
      "thm_center_edge_diff    float64\n",
      "Length: 116, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(features_df.dtypes)\n",
    "print('---------------------------------------')\n",
    "print(features_test_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f6990",
   "metadata": {},
   "source": [
    "## ToF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc1f86af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # ToF sensr adlar\n",
    "tof_sensor_names = [f\"tof_{i}_v{j}\" for i in range(1, 6) for j in range(64)]\n",
    "\n",
    "# def extract_tof_features(df, prefix='tof'):\n",
    "#     tof_cols = [col for col in df.columns if col.startswith('tof_')]\n",
    "#     sensor_features = []\n",
    "\n",
    "#     for sensor_id in range(1, 6):\n",
    "#         sensor_cols = [f'tof_{sensor_id}_v{i}' for i in range(64)]\n",
    "\n",
    "#         # NaN ile geersiz deerleri iaretle\n",
    "#         df[sensor_cols] = df[sensor_cols].replace(-1, np.nan)\n",
    "\n",
    "#         # statistikler\n",
    "#         agg = df.groupby('sequence_id')[sensor_cols].agg(['mean', 'std', 'min', 'max', 'median'])\n",
    "#         agg.columns = [f'{prefix}_sensor{sensor_id}_' + '_'.join(col) for col in agg.columns]\n",
    "\n",
    "#         # Geerli piksel oran\n",
    "#         valid_ratio = df[sensor_cols].notna().groupby(df['sequence_id']).mean()\n",
    "#         valid_ratio.columns = [f'{prefix}_sensor{sensor_id}_valid_ratio_pix_{i}' for i in range(64)]\n",
    "\n",
    "#         # Sensr ii varyans skoru (her frame iin varyans, sonra sequence baznda ortalama)\n",
    "#         frame_var = df[sensor_cols].var(axis=1)\n",
    "#         frame_var_mean = frame_var.groupby(df['sequence_id']).mean().rename(f'{prefix}_sensor{sensor_id}_frame_variance_mean')\n",
    "\n",
    "#         sensor_feat = pd.concat([agg, valid_ratio, frame_var_mean], axis=1)\n",
    "#         sensor_features.append(sensor_feat)\n",
    "\n",
    "#     # Tm sensrler iin birletir\n",
    "#     all_features = pd.concat(sensor_features, axis=1)\n",
    "#     all_features.reset_index(inplace=True)\n",
    "\n",
    "#     return all_features\n",
    "\n",
    "# Geerli (valid) ToF deerleri zerinden zet karan fonksiyon\n",
    "def extract_reduced_tof_features(df):\n",
    "    features = []\n",
    "    for sensor_id in range(1, 6):\n",
    "        pixel_cols = [f\"tof_{sensor_id}_v{j}\" for j in range(64)]\n",
    "        pixels = df[pixel_cols].replace(-1, np.nan).to_numpy()\n",
    "\n",
    "        # statistiksel zetler (valid deerler zerinden)\n",
    "        mean_vals = np.nanmean(pixels, axis=1)\n",
    "        std_vals = np.nanstd(pixels, axis=1)\n",
    "        min_vals = np.nanmin(pixels, axis=1)\n",
    "        max_vals = np.nanmax(pixels, axis=1)\n",
    "        range_vals = max_vals - min_vals\n",
    "        valid_ratio = np.mean(~np.isnan(pixels), axis=1)\n",
    "\n",
    "        # Merkez ve u piksel bloklar\n",
    "        center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
    "        edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
    "        center_edge_ratio = center_mean / (edge_mean + 1e-6)\n",
    "\n",
    "        # Stun adlarn belirle\n",
    "        sensor_features = pd.DataFrame({\n",
    "            f'tof_{sensor_id}_mean': mean_vals,\n",
    "            f'tof_{sensor_id}_std': std_vals,\n",
    "            f'tof_{sensor_id}_min': min_vals,\n",
    "            f'tof_{sensor_id}_max': max_vals,\n",
    "            f'tof_{sensor_id}_range': range_vals,\n",
    "            f'tof_{sensor_id}_valid_ratio': valid_ratio,\n",
    "            f'tof_{sensor_id}_center_mean': center_mean,\n",
    "            f'tof_{sensor_id}_edge_mean': edge_mean,\n",
    "            f'tof_{sensor_id}_center_edge_ratio': center_edge_ratio,\n",
    "        })\n",
    "\n",
    "        features.append(sensor_features)\n",
    "\n",
    "    return pd.concat(features, axis=1)\n",
    "\n",
    "#Fonksiyonlar daha sonra train ve test dataframe'leri zerinde arabilirsiniz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50eab34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:43: RuntimeWarning: Mean of empty slice\n",
      "  mean_vals = np.nanmean(pixels, axis=1)\n",
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:45: RuntimeWarning: All-NaN slice encountered\n",
      "  min_vals = np.nanmin(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:46: RuntimeWarning: All-NaN slice encountered\n",
      "  max_vals = np.nanmax(pixels, axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:51: RuntimeWarning: Mean of empty slice\n",
      "  center_mean = np.nanmean(pixels[:, 24:40], axis=1)\n",
      "C:\\Users\\huseyin\\AppData\\Local\\Temp\\ipykernel_14544\\3855581350.py:52: RuntimeWarning: Mean of empty slice\n",
      "  edge_mean = np.nanmean(np.hstack([pixels[:, :16], pixels[:, 48:]]), axis=1)\n"
     ]
    }
   ],
   "source": [
    "# zellik karm\n",
    "train_tof_features = extract_reduced_tof_features(train)\n",
    "test_tof_features = extract_reduced_tof_features(test)\n",
    "\n",
    "# Sequence ID ile birletir\n",
    "train_tof_features['sequence_id'] = train['sequence_id'].values\n",
    "test_tof_features['sequence_id'] = test['sequence_id'].values\n",
    "\n",
    "# Sequence-level zet\n",
    "train_tof_summary = train_tof_features.groupby('sequence_id').mean().reset_index()\n",
    "test_tof_summary = test_tof_features.groupby('sequence_id').mean().reset_index()\n",
    "\n",
    "# features_df'ye ekleme\n",
    "features_df = features_df.merge(train_tof_summary, on='sequence_id', how='left')\n",
    "features_test_df = features_test_df.merge(test_tof_summary, on='sequence_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65a7e7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8151, 163)\n",
      "---------------------------------------\n",
      "(2, 161)\n"
     ]
    }
   ],
   "source": [
    "print(features_df.shape)\n",
    "print('---------------------------------------')\n",
    "print(features_test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6557b269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>gesture</th>\n",
       "      <th>subject</th>\n",
       "      <th>sequence_type</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>max_counter</th>\n",
       "      <th>acc_x_mean</th>\n",
       "      <th>acc_x_std</th>\n",
       "      <th>acc_x_max</th>\n",
       "      <th>acc_x_min</th>\n",
       "      <th>acc_x_range</th>\n",
       "      <th>acc_x_skew</th>\n",
       "      <th>acc_x_kurt</th>\n",
       "      <th>acc_x_jerk_mean</th>\n",
       "      <th>acc_x_jerk_std</th>\n",
       "      <th>acc_x_jerk_max</th>\n",
       "      <th>acc_x_jerk_min</th>\n",
       "      <th>acc_x_energy</th>\n",
       "      <th>acc_y_mean</th>\n",
       "      <th>acc_y_std</th>\n",
       "      <th>acc_y_max</th>\n",
       "      <th>acc_y_min</th>\n",
       "      <th>acc_y_range</th>\n",
       "      <th>acc_y_skew</th>\n",
       "      <th>acc_y_kurt</th>\n",
       "      <th>acc_y_jerk_mean</th>\n",
       "      <th>acc_y_jerk_std</th>\n",
       "      <th>acc_y_jerk_max</th>\n",
       "      <th>acc_y_jerk_min</th>\n",
       "      <th>acc_y_energy</th>\n",
       "      <th>acc_z_mean</th>\n",
       "      <th>acc_z_std</th>\n",
       "      <th>acc_z_max</th>\n",
       "      <th>acc_z_min</th>\n",
       "      <th>acc_z_range</th>\n",
       "      <th>acc_z_skew</th>\n",
       "      <th>acc_z_kurt</th>\n",
       "      <th>acc_z_jerk_mean</th>\n",
       "      <th>acc_z_jerk_std</th>\n",
       "      <th>acc_z_jerk_max</th>\n",
       "      <th>acc_z_jerk_min</th>\n",
       "      <th>acc_z_energy</th>\n",
       "      <th>corr_acc_x_y</th>\n",
       "      <th>corr_acc_x_z</th>\n",
       "      <th>corr_acc_y_z</th>\n",
       "      <th>acc_z_momentum_x_range</th>\n",
       "      <th>roll_angle_mean</th>\n",
       "      <th>roll_angle_std</th>\n",
       "      <th>roll_angle_max</th>\n",
       "      <th>roll_angle_min</th>\n",
       "      <th>yaw_mean</th>\n",
       "      <th>yaw_std</th>\n",
       "      <th>yaw_min</th>\n",
       "      <th>yaw_max</th>\n",
       "      <th>yaw_delta</th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_delta</th>\n",
       "      <th>roll_mean</th>\n",
       "      <th>roll_std</th>\n",
       "      <th>roll_min</th>\n",
       "      <th>roll_max</th>\n",
       "      <th>roll_delta</th>\n",
       "      <th>orientation_change_magnitude</th>\n",
       "      <th>orientation_delta_yaw</th>\n",
       "      <th>orientation_delta_pitch</th>\n",
       "      <th>orientation_delta_roll</th>\n",
       "      <th>max_rotation_axis_pitch</th>\n",
       "      <th>max_rotation_axis_roll</th>\n",
       "      <th>max_rotation_axis_yaw</th>\n",
       "      <th>yaw_var</th>\n",
       "      <th>pitch_var</th>\n",
       "      <th>roll_var</th>\n",
       "      <th>rot_energy_x</th>\n",
       "      <th>rot_energy_y</th>\n",
       "      <th>rot_energy_z</th>\n",
       "      <th>thm_1_mean</th>\n",
       "      <th>thm_1_std</th>\n",
       "      <th>thm_1_min</th>\n",
       "      <th>thm_1_max</th>\n",
       "      <th>thm_1_range</th>\n",
       "      <th>thm_1_delta</th>\n",
       "      <th>thm_1_activity</th>\n",
       "      <th>thm_2_mean</th>\n",
       "      <th>thm_2_std</th>\n",
       "      <th>thm_2_min</th>\n",
       "      <th>thm_2_max</th>\n",
       "      <th>thm_2_range</th>\n",
       "      <th>thm_2_delta</th>\n",
       "      <th>thm_2_activity</th>\n",
       "      <th>thm_3_mean</th>\n",
       "      <th>thm_3_std</th>\n",
       "      <th>thm_3_min</th>\n",
       "      <th>thm_3_max</th>\n",
       "      <th>thm_3_range</th>\n",
       "      <th>thm_3_delta</th>\n",
       "      <th>thm_3_activity</th>\n",
       "      <th>thm_4_mean</th>\n",
       "      <th>thm_4_std</th>\n",
       "      <th>thm_4_min</th>\n",
       "      <th>thm_4_max</th>\n",
       "      <th>thm_4_range</th>\n",
       "      <th>thm_4_delta</th>\n",
       "      <th>thm_4_activity</th>\n",
       "      <th>thm_5_mean</th>\n",
       "      <th>thm_5_std</th>\n",
       "      <th>thm_5_min</th>\n",
       "      <th>thm_5_max</th>\n",
       "      <th>thm_5_range</th>\n",
       "      <th>thm_5_delta</th>\n",
       "      <th>thm_5_activity</th>\n",
       "      <th>thm_mean_mean</th>\n",
       "      <th>thm_std_mean</th>\n",
       "      <th>thm_hotspot_index</th>\n",
       "      <th>thm_symmetry_side</th>\n",
       "      <th>thm_center_edge_diff</th>\n",
       "      <th>tof_1_mean</th>\n",
       "      <th>tof_1_std</th>\n",
       "      <th>tof_1_min</th>\n",
       "      <th>tof_1_max</th>\n",
       "      <th>tof_1_range</th>\n",
       "      <th>tof_1_valid_ratio</th>\n",
       "      <th>tof_1_center_mean</th>\n",
       "      <th>tof_1_edge_mean</th>\n",
       "      <th>tof_1_center_edge_ratio</th>\n",
       "      <th>tof_2_mean</th>\n",
       "      <th>tof_2_std</th>\n",
       "      <th>tof_2_min</th>\n",
       "      <th>tof_2_max</th>\n",
       "      <th>tof_2_range</th>\n",
       "      <th>tof_2_valid_ratio</th>\n",
       "      <th>tof_2_center_mean</th>\n",
       "      <th>tof_2_edge_mean</th>\n",
       "      <th>tof_2_center_edge_ratio</th>\n",
       "      <th>tof_3_mean</th>\n",
       "      <th>tof_3_std</th>\n",
       "      <th>tof_3_min</th>\n",
       "      <th>tof_3_max</th>\n",
       "      <th>tof_3_range</th>\n",
       "      <th>tof_3_valid_ratio</th>\n",
       "      <th>tof_3_center_mean</th>\n",
       "      <th>tof_3_edge_mean</th>\n",
       "      <th>tof_3_center_edge_ratio</th>\n",
       "      <th>tof_4_mean</th>\n",
       "      <th>tof_4_std</th>\n",
       "      <th>tof_4_min</th>\n",
       "      <th>tof_4_max</th>\n",
       "      <th>tof_4_range</th>\n",
       "      <th>tof_4_valid_ratio</th>\n",
       "      <th>tof_4_center_mean</th>\n",
       "      <th>tof_4_edge_mean</th>\n",
       "      <th>tof_4_center_edge_ratio</th>\n",
       "      <th>tof_5_mean</th>\n",
       "      <th>tof_5_std</th>\n",
       "      <th>tof_5_min</th>\n",
       "      <th>tof_5_max</th>\n",
       "      <th>tof_5_range</th>\n",
       "      <th>tof_5_valid_ratio</th>\n",
       "      <th>tof_5_center_mean</th>\n",
       "      <th>tof_5_edge_mean</th>\n",
       "      <th>tof_5_center_edge_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000007</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>SUBJ_059520</td>\n",
       "      <td>Target</td>\n",
       "      <td>57</td>\n",
       "      <td>56</td>\n",
       "      <td>6.153098</td>\n",
       "      <td>1.334155</td>\n",
       "      <td>9.015625</td>\n",
       "      <td>3.613281</td>\n",
       "      <td>5.402344</td>\n",
       "      <td>-0.545319</td>\n",
       "      <td>-0.391295</td>\n",
       "      <td>0.020285</td>\n",
       "      <td>0.455492</td>\n",
       "      <td>1.339844</td>\n",
       "      <td>-1.302734</td>\n",
       "      <td>2257.733032</td>\n",
       "      <td>3.915570</td>\n",
       "      <td>3.048287</td>\n",
       "      <td>6.519531</td>\n",
       "      <td>-2.019531</td>\n",
       "      <td>8.539062</td>\n",
       "      <td>-1.184870</td>\n",
       "      <td>-0.391547</td>\n",
       "      <td>-0.001028</td>\n",
       "      <td>0.780156</td>\n",
       "      <td>3.542969</td>\n",
       "      <td>-2.566406</td>\n",
       "      <td>1394.261383</td>\n",
       "      <td>5.577782</td>\n",
       "      <td>2.337517</td>\n",
       "      <td>9.792969</td>\n",
       "      <td>1.093750</td>\n",
       "      <td>8.699219</td>\n",
       "      <td>0.586111</td>\n",
       "      <td>-0.897976</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.762233</td>\n",
       "      <td>2.105469</td>\n",
       "      <td>-2.357422</td>\n",
       "      <td>2079.347610</td>\n",
       "      <td>0.854289</td>\n",
       "      <td>-0.887190</td>\n",
       "      <td>-0.902468</td>\n",
       "      <td>30.133098</td>\n",
       "      <td>0.445496</td>\n",
       "      <td>0.443626</td>\n",
       "      <td>0.799987</td>\n",
       "      <td>-0.464035</td>\n",
       "      <td>-136.782733</td>\n",
       "      <td>3.686740</td>\n",
       "      <td>-144.000190</td>\n",
       "      <td>-129.923292</td>\n",
       "      <td>3.191850</td>\n",
       "      <td>18.331457</td>\n",
       "      <td>5.661462</td>\n",
       "      <td>7.476183</td>\n",
       "      <td>31.224292</td>\n",
       "      <td>-13.083466</td>\n",
       "      <td>-50.211994</td>\n",
       "      <td>21.639925</td>\n",
       "      <td>-75.969314</td>\n",
       "      <td>-9.568449</td>\n",
       "      <td>9.286070</td>\n",
       "      <td>383.916977</td>\n",
       "      <td>3.191850</td>\n",
       "      <td>13.083466</td>\n",
       "      <td>9.286070</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>13.592053</td>\n",
       "      <td>32.052153</td>\n",
       "      <td>468.286339</td>\n",
       "      <td>0.082005</td>\n",
       "      <td>0.139978</td>\n",
       "      <td>0.703864</td>\n",
       "      <td>28.630612</td>\n",
       "      <td>0.582076</td>\n",
       "      <td>27.696510</td>\n",
       "      <td>30.543730</td>\n",
       "      <td>2.847219</td>\n",
       "      <td>-0.150585</td>\n",
       "      <td>13.000359</td>\n",
       "      <td>29.571870</td>\n",
       "      <td>2.576799</td>\n",
       "      <td>24.558798</td>\n",
       "      <td>32.010178</td>\n",
       "      <td>7.451380</td>\n",
       "      <td>-1.006186</td>\n",
       "      <td>22.822474</td>\n",
       "      <td>28.576605</td>\n",
       "      <td>1.260533</td>\n",
       "      <td>25.907490</td>\n",
       "      <td>30.090014</td>\n",
       "      <td>4.182524</td>\n",
       "      <td>-0.156540</td>\n",
       "      <td>13.482555</td>\n",
       "      <td>29.177937</td>\n",
       "      <td>0.278147</td>\n",
       "      <td>28.592863</td>\n",
       "      <td>29.761480</td>\n",
       "      <td>1.168617</td>\n",
       "      <td>0.523323</td>\n",
       "      <td>5.657688</td>\n",
       "      <td>27.957446</td>\n",
       "      <td>0.877846</td>\n",
       "      <td>26.047148</td>\n",
       "      <td>29.428299</td>\n",
       "      <td>3.381151</td>\n",
       "      <td>-0.324644</td>\n",
       "      <td>14.319735</td>\n",
       "      <td>28.782894</td>\n",
       "      <td>1.115080</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.080875</td>\n",
       "      <td>0.752568</td>\n",
       "      <td>101.462627</td>\n",
       "      <td>18.701970</td>\n",
       "      <td>64.122807</td>\n",
       "      <td>137.263158</td>\n",
       "      <td>73.140351</td>\n",
       "      <td>0.491776</td>\n",
       "      <td>105.167919</td>\n",
       "      <td>99.136456</td>\n",
       "      <td>1.084380</td>\n",
       "      <td>131.584300</td>\n",
       "      <td>18.873624</td>\n",
       "      <td>90.719298</td>\n",
       "      <td>163.614035</td>\n",
       "      <td>72.894737</td>\n",
       "      <td>0.516721</td>\n",
       "      <td>120.999208</td>\n",
       "      <td>124.970788</td>\n",
       "      <td>1.225540</td>\n",
       "      <td>88.811663</td>\n",
       "      <td>10.645399</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>113.631579</td>\n",
       "      <td>43.631579</td>\n",
       "      <td>0.659265</td>\n",
       "      <td>77.623725</td>\n",
       "      <td>88.133020</td>\n",
       "      <td>0.992352</td>\n",
       "      <td>88.479068</td>\n",
       "      <td>22.387650</td>\n",
       "      <td>56.771930</td>\n",
       "      <td>141.578947</td>\n",
       "      <td>84.807018</td>\n",
       "      <td>0.636513</td>\n",
       "      <td>98.636698</td>\n",
       "      <td>82.163070</td>\n",
       "      <td>1.142889</td>\n",
       "      <td>125.362645</td>\n",
       "      <td>23.611158</td>\n",
       "      <td>76.105263</td>\n",
       "      <td>165.087719</td>\n",
       "      <td>88.982456</td>\n",
       "      <td>0.600329</td>\n",
       "      <td>136.848416</td>\n",
       "      <td>118.542951</td>\n",
       "      <td>1.170684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000008</td>\n",
       "      <td>Forehead - pull hairline</td>\n",
       "      <td>SUBJ_020948</td>\n",
       "      <td>Target</td>\n",
       "      <td>68</td>\n",
       "      <td>67</td>\n",
       "      <td>3.400506</td>\n",
       "      <td>1.087142</td>\n",
       "      <td>5.906250</td>\n",
       "      <td>1.734375</td>\n",
       "      <td>4.171875</td>\n",
       "      <td>0.146452</td>\n",
       "      <td>-1.069663</td>\n",
       "      <td>-0.028148</td>\n",
       "      <td>0.519107</td>\n",
       "      <td>1.742188</td>\n",
       "      <td>-1.839844</td>\n",
       "      <td>865.499603</td>\n",
       "      <td>5.311179</td>\n",
       "      <td>3.268073</td>\n",
       "      <td>8.667969</td>\n",
       "      <td>-0.222656</td>\n",
       "      <td>8.890625</td>\n",
       "      <td>-0.830467</td>\n",
       "      <td>-1.170949</td>\n",
       "      <td>0.053740</td>\n",
       "      <td>0.672863</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>-2.574219</td>\n",
       "      <td>2633.766251</td>\n",
       "      <td>6.581629</td>\n",
       "      <td>2.475402</td>\n",
       "      <td>11.074219</td>\n",
       "      <td>1.722656</td>\n",
       "      <td>9.351562</td>\n",
       "      <td>0.186346</td>\n",
       "      <td>-1.306469</td>\n",
       "      <td>-0.065545</td>\n",
       "      <td>1.072456</td>\n",
       "      <td>2.833984</td>\n",
       "      <td>-2.986328</td>\n",
       "      <td>3356.163620</td>\n",
       "      <td>0.678886</td>\n",
       "      <td>-0.594269</td>\n",
       "      <td>-0.889196</td>\n",
       "      <td>27.457734</td>\n",
       "      <td>0.817318</td>\n",
       "      <td>0.438181</td>\n",
       "      <td>1.307932</td>\n",
       "      <td>-0.084997</td>\n",
       "      <td>-148.403656</td>\n",
       "      <td>5.623907</td>\n",
       "      <td>-154.261658</td>\n",
       "      <td>-139.255923</td>\n",
       "      <td>-0.328373</td>\n",
       "      <td>3.416037</td>\n",
       "      <td>6.567778</td>\n",
       "      <td>-7.471505</td>\n",
       "      <td>17.183220</td>\n",
       "      <td>0.772071</td>\n",
       "      <td>-43.404627</td>\n",
       "      <td>22.413410</td>\n",
       "      <td>-67.011753</td>\n",
       "      <td>-8.412334</td>\n",
       "      <td>-7.846398</td>\n",
       "      <td>493.946555</td>\n",
       "      <td>0.328373</td>\n",
       "      <td>0.772071</td>\n",
       "      <td>7.846398</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>31.628330</td>\n",
       "      <td>43.135706</td>\n",
       "      <td>502.360935</td>\n",
       "      <td>0.016126</td>\n",
       "      <td>0.152819</td>\n",
       "      <td>0.767665</td>\n",
       "      <td>30.464309</td>\n",
       "      <td>2.709212</td>\n",
       "      <td>25.985313</td>\n",
       "      <td>32.870808</td>\n",
       "      <td>6.885494</td>\n",
       "      <td>0.901049</td>\n",
       "      <td>19.042677</td>\n",
       "      <td>29.678206</td>\n",
       "      <td>3.885080</td>\n",
       "      <td>23.907709</td>\n",
       "      <td>33.100945</td>\n",
       "      <td>9.193235</td>\n",
       "      <td>0.056095</td>\n",
       "      <td>31.470016</td>\n",
       "      <td>29.179852</td>\n",
       "      <td>3.074828</td>\n",
       "      <td>24.414917</td>\n",
       "      <td>32.316135</td>\n",
       "      <td>7.901218</td>\n",
       "      <td>1.130726</td>\n",
       "      <td>42.520508</td>\n",
       "      <td>30.501325</td>\n",
       "      <td>0.976249</td>\n",
       "      <td>28.755495</td>\n",
       "      <td>31.613327</td>\n",
       "      <td>2.857832</td>\n",
       "      <td>0.866661</td>\n",
       "      <td>12.937668</td>\n",
       "      <td>25.824221</td>\n",
       "      <td>1.165940</td>\n",
       "      <td>24.181562</td>\n",
       "      <td>28.054575</td>\n",
       "      <td>3.873013</td>\n",
       "      <td>-0.130692</td>\n",
       "      <td>25.231140</td>\n",
       "      <td>29.129583</td>\n",
       "      <td>2.362262</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.945501</td>\n",
       "      <td>1.710534</td>\n",
       "      <td>147.262788</td>\n",
       "      <td>22.880775</td>\n",
       "      <td>114.029412</td>\n",
       "      <td>193.397059</td>\n",
       "      <td>79.367647</td>\n",
       "      <td>0.603171</td>\n",
       "      <td>123.860023</td>\n",
       "      <td>144.545448</td>\n",
       "      <td>1.077715</td>\n",
       "      <td>107.049142</td>\n",
       "      <td>13.899609</td>\n",
       "      <td>83.849057</td>\n",
       "      <td>154.339623</td>\n",
       "      <td>70.490566</td>\n",
       "      <td>0.542050</td>\n",
       "      <td>94.294453</td>\n",
       "      <td>107.176479</td>\n",
       "      <td>1.000236</td>\n",
       "      <td>162.770818</td>\n",
       "      <td>25.641174</td>\n",
       "      <td>116.970588</td>\n",
       "      <td>202.705882</td>\n",
       "      <td>85.735294</td>\n",
       "      <td>0.521829</td>\n",
       "      <td>152.341353</td>\n",
       "      <td>155.106973</td>\n",
       "      <td>1.207827</td>\n",
       "      <td>166.807100</td>\n",
       "      <td>30.497778</td>\n",
       "      <td>109.352941</td>\n",
       "      <td>215.779412</td>\n",
       "      <td>106.426471</td>\n",
       "      <td>0.727711</td>\n",
       "      <td>177.089265</td>\n",
       "      <td>159.717670</td>\n",
       "      <td>1.105589</td>\n",
       "      <td>141.004887</td>\n",
       "      <td>17.392831</td>\n",
       "      <td>114.338235</td>\n",
       "      <td>175.661765</td>\n",
       "      <td>61.323529</td>\n",
       "      <td>0.313189</td>\n",
       "      <td>148.581264</td>\n",
       "      <td>137.532246</td>\n",
       "      <td>1.140805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEQ_000013</td>\n",
       "      <td>Cheek - pinch skin</td>\n",
       "      <td>SUBJ_040282</td>\n",
       "      <td>Target</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>-7.058962</td>\n",
       "      <td>1.295184</td>\n",
       "      <td>-3.347656</td>\n",
       "      <td>-9.250000</td>\n",
       "      <td>5.902344</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.291585</td>\n",
       "      <td>0.034677</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>2.527344</td>\n",
       "      <td>-1.726562</td>\n",
       "      <td>2728.164307</td>\n",
       "      <td>2.346182</td>\n",
       "      <td>2.564639</td>\n",
       "      <td>4.683594</td>\n",
       "      <td>-3.273438</td>\n",
       "      <td>7.957031</td>\n",
       "      <td>-1.445762</td>\n",
       "      <td>0.544205</td>\n",
       "      <td>0.024838</td>\n",
       "      <td>0.732187</td>\n",
       "      <td>2.701172</td>\n",
       "      <td>-2.394531</td>\n",
       "      <td>633.765793</td>\n",
       "      <td>-6.068544</td>\n",
       "      <td>1.330784</td>\n",
       "      <td>-3.515625</td>\n",
       "      <td>-10.945312</td>\n",
       "      <td>7.429688</td>\n",
       "      <td>-1.039566</td>\n",
       "      <td>2.722204</td>\n",
       "      <td>0.026570</td>\n",
       "      <td>0.640019</td>\n",
       "      <td>2.316406</td>\n",
       "      <td>-1.863281</td>\n",
       "      <td>2043.934021</td>\n",
       "      <td>-0.500159</td>\n",
       "      <td>-0.638358</td>\n",
       "      <td>0.695687</td>\n",
       "      <td>-35.818631</td>\n",
       "      <td>1.676461</td>\n",
       "      <td>2.113786</td>\n",
       "      <td>2.954490</td>\n",
       "      <td>-2.899302</td>\n",
       "      <td>-131.321246</td>\n",
       "      <td>21.874304</td>\n",
       "      <td>-164.333444</td>\n",
       "      <td>-85.941112</td>\n",
       "      <td>-17.484747</td>\n",
       "      <td>40.867410</td>\n",
       "      <td>30.350971</td>\n",
       "      <td>-26.623562</td>\n",
       "      <td>66.133301</td>\n",
       "      <td>19.604578</td>\n",
       "      <td>137.968703</td>\n",
       "      <td>91.320949</td>\n",
       "      <td>-179.451926</td>\n",
       "      <td>179.724953</td>\n",
       "      <td>10.685674</td>\n",
       "      <td>1318.088253</td>\n",
       "      <td>17.484747</td>\n",
       "      <td>19.604578</td>\n",
       "      <td>10.685674</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>478.485194</td>\n",
       "      <td>921.181433</td>\n",
       "      <td>8339.515689</td>\n",
       "      <td>0.148647</td>\n",
       "      <td>0.648760</td>\n",
       "      <td>0.026494</td>\n",
       "      <td>24.522526</td>\n",
       "      <td>0.449773</td>\n",
       "      <td>24.181389</td>\n",
       "      <td>25.634346</td>\n",
       "      <td>1.452957</td>\n",
       "      <td>-0.013020</td>\n",
       "      <td>5.484901</td>\n",
       "      <td>24.367174</td>\n",
       "      <td>0.620555</td>\n",
       "      <td>23.933413</td>\n",
       "      <td>26.175961</td>\n",
       "      <td>2.242548</td>\n",
       "      <td>-0.110445</td>\n",
       "      <td>7.408587</td>\n",
       "      <td>24.892424</td>\n",
       "      <td>0.294962</td>\n",
       "      <td>24.406981</td>\n",
       "      <td>25.512794</td>\n",
       "      <td>1.105814</td>\n",
       "      <td>0.085846</td>\n",
       "      <td>6.074223</td>\n",
       "      <td>24.930840</td>\n",
       "      <td>0.572871</td>\n",
       "      <td>24.419798</td>\n",
       "      <td>26.452927</td>\n",
       "      <td>2.033129</td>\n",
       "      <td>-0.384151</td>\n",
       "      <td>5.965618</td>\n",
       "      <td>24.733322</td>\n",
       "      <td>0.475044</td>\n",
       "      <td>24.167980</td>\n",
       "      <td>26.051331</td>\n",
       "      <td>1.883350</td>\n",
       "      <td>0.257027</td>\n",
       "      <td>7.453289</td>\n",
       "      <td>24.689257</td>\n",
       "      <td>0.482641</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.021083</td>\n",
       "      <td>0.339090</td>\n",
       "      <td>202.243341</td>\n",
       "      <td>15.592535</td>\n",
       "      <td>181.638298</td>\n",
       "      <td>237.106383</td>\n",
       "      <td>55.468085</td>\n",
       "      <td>0.221108</td>\n",
       "      <td>180.602300</td>\n",
       "      <td>200.067111</td>\n",
       "      <td>1.021022</td>\n",
       "      <td>184.410453</td>\n",
       "      <td>14.396688</td>\n",
       "      <td>166.054054</td>\n",
       "      <td>208.054054</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.159493</td>\n",
       "      <td>111.969240</td>\n",
       "      <td>183.767872</td>\n",
       "      <td>1.046709</td>\n",
       "      <td>182.676496</td>\n",
       "      <td>32.916034</td>\n",
       "      <td>105.188679</td>\n",
       "      <td>217.698113</td>\n",
       "      <td>112.509434</td>\n",
       "      <td>0.456663</td>\n",
       "      <td>193.442163</td>\n",
       "      <td>172.626141</td>\n",
       "      <td>1.179970</td>\n",
       "      <td>210.052698</td>\n",
       "      <td>18.564589</td>\n",
       "      <td>171.547170</td>\n",
       "      <td>240.660377</td>\n",
       "      <td>69.113208</td>\n",
       "      <td>0.309257</td>\n",
       "      <td>205.891168</td>\n",
       "      <td>206.507863</td>\n",
       "      <td>1.065340</td>\n",
       "      <td>198.628079</td>\n",
       "      <td>29.101898</td>\n",
       "      <td>141.375000</td>\n",
       "      <td>242.750000</td>\n",
       "      <td>101.375000</td>\n",
       "      <td>0.145637</td>\n",
       "      <td>195.914295</td>\n",
       "      <td>185.557298</td>\n",
       "      <td>1.595708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000016</td>\n",
       "      <td>Write name on leg</td>\n",
       "      <td>SUBJ_052342</td>\n",
       "      <td>Non-Target</td>\n",
       "      <td>61</td>\n",
       "      <td>60</td>\n",
       "      <td>5.524654</td>\n",
       "      <td>1.074108</td>\n",
       "      <td>9.378906</td>\n",
       "      <td>3.437500</td>\n",
       "      <td>5.941406</td>\n",
       "      <td>0.747648</td>\n",
       "      <td>1.524114</td>\n",
       "      <td>-0.043161</td>\n",
       "      <td>0.672640</td>\n",
       "      <td>2.703125</td>\n",
       "      <td>-3.375000</td>\n",
       "      <td>1931.052567</td>\n",
       "      <td>-4.408491</td>\n",
       "      <td>0.598318</td>\n",
       "      <td>-2.960938</td>\n",
       "      <td>-5.718750</td>\n",
       "      <td>2.757812</td>\n",
       "      <td>0.505319</td>\n",
       "      <td>-0.017645</td>\n",
       "      <td>-0.002561</td>\n",
       "      <td>0.335250</td>\n",
       "      <td>1.109375</td>\n",
       "      <td>-1.343750</td>\n",
       "      <td>1207.001572</td>\n",
       "      <td>-3.162077</td>\n",
       "      <td>6.139752</td>\n",
       "      <td>8.355469</td>\n",
       "      <td>-8.078125</td>\n",
       "      <td>16.433594</td>\n",
       "      <td>0.964846</td>\n",
       "      <td>-1.033536</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>1.951462</td>\n",
       "      <td>11.531250</td>\n",
       "      <td>-6.037109</td>\n",
       "      <td>2871.715958</td>\n",
       "      <td>0.553929</td>\n",
       "      <td>0.639362</td>\n",
       "      <td>0.704613</td>\n",
       "      <td>-18.787186</td>\n",
       "      <td>-0.682500</td>\n",
       "      <td>0.136990</td>\n",
       "      <td>-0.374288</td>\n",
       "      <td>-0.956637</td>\n",
       "      <td>-65.105438</td>\n",
       "      <td>33.468126</td>\n",
       "      <td>-118.013318</td>\n",
       "      <td>-39.047014</td>\n",
       "      <td>-6.329272</td>\n",
       "      <td>15.967139</td>\n",
       "      <td>18.844155</td>\n",
       "      <td>-6.011835</td>\n",
       "      <td>44.952709</td>\n",
       "      <td>4.136208</td>\n",
       "      <td>-102.384014</td>\n",
       "      <td>50.621010</td>\n",
       "      <td>-143.251197</td>\n",
       "      <td>-21.145502</td>\n",
       "      <td>10.922323</td>\n",
       "      <td>622.312570</td>\n",
       "      <td>6.329272</td>\n",
       "      <td>4.136208</td>\n",
       "      <td>10.922323</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1120.115429</td>\n",
       "      <td>355.102188</td>\n",
       "      <td>2562.486694</td>\n",
       "      <td>0.572502</td>\n",
       "      <td>0.074008</td>\n",
       "      <td>0.221416</td>\n",
       "      <td>31.651703</td>\n",
       "      <td>4.006846</td>\n",
       "      <td>25.413513</td>\n",
       "      <td>36.053188</td>\n",
       "      <td>10.639675</td>\n",
       "      <td>-0.282286</td>\n",
       "      <td>27.109056</td>\n",
       "      <td>31.601259</td>\n",
       "      <td>4.495657</td>\n",
       "      <td>25.018881</td>\n",
       "      <td>36.705894</td>\n",
       "      <td>11.687014</td>\n",
       "      <td>0.047785</td>\n",
       "      <td>31.485872</td>\n",
       "      <td>29.320353</td>\n",
       "      <td>3.274493</td>\n",
       "      <td>24.128819</td>\n",
       "      <td>33.617542</td>\n",
       "      <td>9.488724</td>\n",
       "      <td>-0.441620</td>\n",
       "      <td>23.481190</td>\n",
       "      <td>32.790761</td>\n",
       "      <td>3.253195</td>\n",
       "      <td>27.227589</td>\n",
       "      <td>35.665222</td>\n",
       "      <td>8.437634</td>\n",
       "      <td>1.619091</td>\n",
       "      <td>22.319618</td>\n",
       "      <td>30.860562</td>\n",
       "      <td>3.310154</td>\n",
       "      <td>26.312038</td>\n",
       "      <td>35.801083</td>\n",
       "      <td>9.489044</td>\n",
       "      <td>-0.020788</td>\n",
       "      <td>28.030943</td>\n",
       "      <td>31.244928</td>\n",
       "      <td>3.668069</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.939878</td>\n",
       "      <td>2.299691</td>\n",
       "      <td>30.547978</td>\n",
       "      <td>3.582891</td>\n",
       "      <td>24.106383</td>\n",
       "      <td>37.510638</td>\n",
       "      <td>13.404255</td>\n",
       "      <td>0.636527</td>\n",
       "      <td>12.122747</td>\n",
       "      <td>30.563750</td>\n",
       "      <td>0.944166</td>\n",
       "      <td>75.149853</td>\n",
       "      <td>3.564886</td>\n",
       "      <td>69.852459</td>\n",
       "      <td>83.196721</td>\n",
       "      <td>13.344262</td>\n",
       "      <td>0.661629</td>\n",
       "      <td>6.117562</td>\n",
       "      <td>75.254783</td>\n",
       "      <td>1938.793473</td>\n",
       "      <td>32.401175</td>\n",
       "      <td>38.284690</td>\n",
       "      <td>9.627907</td>\n",
       "      <td>159.348837</td>\n",
       "      <td>149.720930</td>\n",
       "      <td>0.394980</td>\n",
       "      <td>17.313737</td>\n",
       "      <td>41.559451</td>\n",
       "      <td>0.612594</td>\n",
       "      <td>31.655589</td>\n",
       "      <td>20.205845</td>\n",
       "      <td>5.721311</td>\n",
       "      <td>72.967213</td>\n",
       "      <td>67.245902</td>\n",
       "      <td>0.801742</td>\n",
       "      <td>16.956148</td>\n",
       "      <td>36.058892</td>\n",
       "      <td>0.738948</td>\n",
       "      <td>26.369672</td>\n",
       "      <td>7.304523</td>\n",
       "      <td>16.489362</td>\n",
       "      <td>39.787234</td>\n",
       "      <td>23.297872</td>\n",
       "      <td>0.505891</td>\n",
       "      <td>24.796456</td>\n",
       "      <td>24.067193</td>\n",
       "      <td>0.857556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SEQ_000018</td>\n",
       "      <td>Forehead - pull hairline</td>\n",
       "      <td>SUBJ_032165</td>\n",
       "      <td>Target</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>5.363715</td>\n",
       "      <td>1.627637</td>\n",
       "      <td>6.832031</td>\n",
       "      <td>1.964844</td>\n",
       "      <td>4.867188</td>\n",
       "      <td>-1.397824</td>\n",
       "      <td>0.163483</td>\n",
       "      <td>0.040039</td>\n",
       "      <td>0.456681</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>-1.265625</td>\n",
       "      <td>1693.957520</td>\n",
       "      <td>4.109737</td>\n",
       "      <td>3.525304</td>\n",
       "      <td>6.718750</td>\n",
       "      <td>-3.164062</td>\n",
       "      <td>9.882812</td>\n",
       "      <td>-1.347944</td>\n",
       "      <td>0.033611</td>\n",
       "      <td>0.025933</td>\n",
       "      <td>0.793187</td>\n",
       "      <td>2.585938</td>\n",
       "      <td>-2.105469</td>\n",
       "      <td>1570.728409</td>\n",
       "      <td>5.937066</td>\n",
       "      <td>2.104544</td>\n",
       "      <td>9.933594</td>\n",
       "      <td>4.148438</td>\n",
       "      <td>5.785156</td>\n",
       "      <td>1.040372</td>\n",
       "      <td>-0.718802</td>\n",
       "      <td>-0.001736</td>\n",
       "      <td>0.522210</td>\n",
       "      <td>1.992188</td>\n",
       "      <td>-2.031250</td>\n",
       "      <td>2138.175323</td>\n",
       "      <td>0.934984</td>\n",
       "      <td>-0.900993</td>\n",
       "      <td>-0.956922</td>\n",
       "      <td>28.896813</td>\n",
       "      <td>0.438831</td>\n",
       "      <td>0.638793</td>\n",
       "      <td>0.819412</td>\n",
       "      <td>-1.004394</td>\n",
       "      <td>-14.657881</td>\n",
       "      <td>15.666985</td>\n",
       "      <td>-44.304886</td>\n",
       "      <td>0.046952</td>\n",
       "      <td>32.796140</td>\n",
       "      <td>-43.398718</td>\n",
       "      <td>22.229601</td>\n",
       "      <td>-58.711619</td>\n",
       "      <td>5.062855</td>\n",
       "      <td>-25.622874</td>\n",
       "      <td>20.653081</td>\n",
       "      <td>22.538566</td>\n",
       "      <td>-23.586628</td>\n",
       "      <td>40.365129</td>\n",
       "      <td>34.688647</td>\n",
       "      <td>331.830537</td>\n",
       "      <td>32.796140</td>\n",
       "      <td>25.622874</td>\n",
       "      <td>34.688647</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>245.454406</td>\n",
       "      <td>494.155175</td>\n",
       "      <td>507.986980</td>\n",
       "      <td>0.062624</td>\n",
       "      <td>0.145895</td>\n",
       "      <td>0.052185</td>\n",
       "      <td>28.903610</td>\n",
       "      <td>1.144503</td>\n",
       "      <td>26.533083</td>\n",
       "      <td>30.267483</td>\n",
       "      <td>3.734400</td>\n",
       "      <td>1.167833</td>\n",
       "      <td>10.336542</td>\n",
       "      <td>29.438643</td>\n",
       "      <td>1.658719</td>\n",
       "      <td>25.795074</td>\n",
       "      <td>31.035217</td>\n",
       "      <td>5.240143</td>\n",
       "      <td>0.690622</td>\n",
       "      <td>15.569307</td>\n",
       "      <td>27.058073</td>\n",
       "      <td>0.951421</td>\n",
       "      <td>25.127720</td>\n",
       "      <td>28.468761</td>\n",
       "      <td>3.341042</td>\n",
       "      <td>0.760956</td>\n",
       "      <td>11.521690</td>\n",
       "      <td>27.841705</td>\n",
       "      <td>0.431424</td>\n",
       "      <td>26.827133</td>\n",
       "      <td>28.400864</td>\n",
       "      <td>1.573730</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>6.891409</td>\n",
       "      <td>31.014364</td>\n",
       "      <td>1.394629</td>\n",
       "      <td>28.282324</td>\n",
       "      <td>32.180752</td>\n",
       "      <td>3.898428</td>\n",
       "      <td>2.002932</td>\n",
       "      <td>8.149042</td>\n",
       "      <td>28.851279</td>\n",
       "      <td>1.116139</td>\n",
       "      <td>4</td>\n",
       "      <td>1.318813</td>\n",
       "      <td>2.900914</td>\n",
       "      <td>139.359139</td>\n",
       "      <td>28.198077</td>\n",
       "      <td>85.462963</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>94.537037</td>\n",
       "      <td>0.669850</td>\n",
       "      <td>161.426370</td>\n",
       "      <td>130.793476</td>\n",
       "      <td>1.251414</td>\n",
       "      <td>122.274214</td>\n",
       "      <td>22.236042</td>\n",
       "      <td>93.425926</td>\n",
       "      <td>167.870370</td>\n",
       "      <td>74.444444</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>118.363216</td>\n",
       "      <td>125.265398</td>\n",
       "      <td>0.930803</td>\n",
       "      <td>143.509979</td>\n",
       "      <td>22.681284</td>\n",
       "      <td>104.481481</td>\n",
       "      <td>189.203704</td>\n",
       "      <td>84.722222</td>\n",
       "      <td>0.473380</td>\n",
       "      <td>138.594070</td>\n",
       "      <td>137.305816</td>\n",
       "      <td>1.143068</td>\n",
       "      <td>146.027234</td>\n",
       "      <td>26.971389</td>\n",
       "      <td>94.518519</td>\n",
       "      <td>195.611111</td>\n",
       "      <td>101.092593</td>\n",
       "      <td>0.780671</td>\n",
       "      <td>162.855939</td>\n",
       "      <td>134.551452</td>\n",
       "      <td>1.208594</td>\n",
       "      <td>138.873423</td>\n",
       "      <td>29.434685</td>\n",
       "      <td>87.796296</td>\n",
       "      <td>189.018519</td>\n",
       "      <td>101.222222</td>\n",
       "      <td>0.855035</td>\n",
       "      <td>151.110172</td>\n",
       "      <td>130.040274</td>\n",
       "      <td>1.162915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id                   gesture      subject sequence_type  n_steps  \\\n",
       "0  SEQ_000007        Cheek - pinch skin  SUBJ_059520        Target       57   \n",
       "1  SEQ_000008  Forehead - pull hairline  SUBJ_020948        Target       68   \n",
       "2  SEQ_000013        Cheek - pinch skin  SUBJ_040282        Target       53   \n",
       "3  SEQ_000016         Write name on leg  SUBJ_052342    Non-Target       61   \n",
       "4  SEQ_000018  Forehead - pull hairline  SUBJ_032165        Target       54   \n",
       "\n",
       "   max_counter  acc_x_mean  acc_x_std  acc_x_max  acc_x_min  acc_x_range  \\\n",
       "0           56    6.153098   1.334155   9.015625   3.613281     5.402344   \n",
       "1           67    3.400506   1.087142   5.906250   1.734375     4.171875   \n",
       "2           52   -7.058962   1.295184  -3.347656  -9.250000     5.902344   \n",
       "3           60    5.524654   1.074108   9.378906   3.437500     5.941406   \n",
       "4           53    5.363715   1.627637   6.832031   1.964844     4.867188   \n",
       "\n",
       "   acc_x_skew  acc_x_kurt  acc_x_jerk_mean  acc_x_jerk_std  acc_x_jerk_max  \\\n",
       "0   -0.545319   -0.391295         0.020285        0.455492        1.339844   \n",
       "1    0.146452   -1.069663        -0.028148        0.519107        1.742188   \n",
       "2    0.518519    0.291585         0.034677        0.761798        2.527344   \n",
       "3    0.747648    1.524114        -0.043161        0.672640        2.703125   \n",
       "4   -1.397824    0.163483         0.040039        0.456681        2.031250   \n",
       "\n",
       "   acc_x_jerk_min  acc_x_energy  acc_y_mean  acc_y_std  acc_y_max  acc_y_min  \\\n",
       "0       -1.302734   2257.733032    3.915570   3.048287   6.519531  -2.019531   \n",
       "1       -1.839844    865.499603    5.311179   3.268073   8.667969  -0.222656   \n",
       "2       -1.726562   2728.164307    2.346182   2.564639   4.683594  -3.273438   \n",
       "3       -3.375000   1931.052567   -4.408491   0.598318  -2.960938  -5.718750   \n",
       "4       -1.265625   1693.957520    4.109737   3.525304   6.718750  -3.164062   \n",
       "\n",
       "   acc_y_range  acc_y_skew  acc_y_kurt  acc_y_jerk_mean  acc_y_jerk_std  \\\n",
       "0     8.539062   -1.184870   -0.391547        -0.001028        0.780156   \n",
       "1     8.890625   -0.830467   -1.170949         0.053740        0.672863   \n",
       "2     7.957031   -1.445762    0.544205         0.024838        0.732187   \n",
       "3     2.757812    0.505319   -0.017645        -0.002561        0.335250   \n",
       "4     9.882812   -1.347944    0.033611         0.025933        0.793187   \n",
       "\n",
       "   acc_y_jerk_max  acc_y_jerk_min  acc_y_energy  acc_z_mean  acc_z_std  \\\n",
       "0        3.542969       -2.566406   1394.261383    5.577782   2.337517   \n",
       "1        2.375000       -2.574219   2633.766251    6.581629   2.475402   \n",
       "2        2.701172       -2.394531    633.765793   -6.068544   1.330784   \n",
       "3        1.109375       -1.343750   1207.001572   -3.162077   6.139752   \n",
       "4        2.585938       -2.105469   1570.728409    5.937066   2.104544   \n",
       "\n",
       "   acc_z_max  acc_z_min  acc_z_range  acc_z_skew  acc_z_kurt  acc_z_jerk_mean  \\\n",
       "0   9.792969   1.093750     8.699219    0.586111   -0.897976         0.002981   \n",
       "1  11.074219   1.722656     9.351562    0.186346   -1.306469        -0.065545   \n",
       "2  -3.515625 -10.945312     7.429688   -1.039566    2.722204         0.026570   \n",
       "3   8.355469  -8.078125    16.433594    0.964846   -1.033536         0.083600   \n",
       "4   9.933594   4.148438     5.785156    1.040372   -0.718802        -0.001736   \n",
       "\n",
       "   acc_z_jerk_std  acc_z_jerk_max  acc_z_jerk_min  acc_z_energy  corr_acc_x_y  \\\n",
       "0        0.762233        2.105469       -2.357422   2079.347610      0.854289   \n",
       "1        1.072456        2.833984       -2.986328   3356.163620      0.678886   \n",
       "2        0.640019        2.316406       -1.863281   2043.934021     -0.500159   \n",
       "3        1.951462       11.531250       -6.037109   2871.715958      0.553929   \n",
       "4        0.522210        1.992188       -2.031250   2138.175323      0.934984   \n",
       "\n",
       "   corr_acc_x_z  corr_acc_y_z  acc_z_momentum_x_range  roll_angle_mean  \\\n",
       "0     -0.887190     -0.902468               30.133098         0.445496   \n",
       "1     -0.594269     -0.889196               27.457734         0.817318   \n",
       "2     -0.638358      0.695687              -35.818631         1.676461   \n",
       "3      0.639362      0.704613              -18.787186        -0.682500   \n",
       "4     -0.900993     -0.956922               28.896813         0.438831   \n",
       "\n",
       "   roll_angle_std  roll_angle_max  roll_angle_min    yaw_mean    yaw_std  \\\n",
       "0        0.443626        0.799987       -0.464035 -136.782733   3.686740   \n",
       "1        0.438181        1.307932       -0.084997 -148.403656   5.623907   \n",
       "2        2.113786        2.954490       -2.899302 -131.321246  21.874304   \n",
       "3        0.136990       -0.374288       -0.956637  -65.105438  33.468126   \n",
       "4        0.638793        0.819412       -1.004394  -14.657881  15.666985   \n",
       "\n",
       "      yaw_min     yaw_max  yaw_delta  pitch_mean  pitch_std  pitch_min  \\\n",
       "0 -144.000190 -129.923292   3.191850   18.331457   5.661462   7.476183   \n",
       "1 -154.261658 -139.255923  -0.328373    3.416037   6.567778  -7.471505   \n",
       "2 -164.333444  -85.941112 -17.484747   40.867410  30.350971 -26.623562   \n",
       "3 -118.013318  -39.047014  -6.329272   15.967139  18.844155  -6.011835   \n",
       "4  -44.304886    0.046952  32.796140  -43.398718  22.229601 -58.711619   \n",
       "\n",
       "   pitch_max  pitch_delta   roll_mean   roll_std    roll_min    roll_max  \\\n",
       "0  31.224292   -13.083466  -50.211994  21.639925  -75.969314   -9.568449   \n",
       "1  17.183220     0.772071  -43.404627  22.413410  -67.011753   -8.412334   \n",
       "2  66.133301    19.604578  137.968703  91.320949 -179.451926  179.724953   \n",
       "3  44.952709     4.136208 -102.384014  50.621010 -143.251197  -21.145502   \n",
       "4   5.062855   -25.622874   20.653081  22.538566  -23.586628   40.365129   \n",
       "\n",
       "   roll_delta  orientation_change_magnitude  orientation_delta_yaw  \\\n",
       "0    9.286070                    383.916977               3.191850   \n",
       "1   -7.846398                    493.946555               0.328373   \n",
       "2   10.685674                   1318.088253              17.484747   \n",
       "3   10.922323                    622.312570               6.329272   \n",
       "4   34.688647                    331.830537              32.796140   \n",
       "\n",
       "   orientation_delta_pitch  orientation_delta_roll  max_rotation_axis_pitch  \\\n",
       "0                13.083466                9.286070                    False   \n",
       "1                 0.772071                7.846398                    False   \n",
       "2                19.604578               10.685674                    False   \n",
       "3                 4.136208               10.922323                    False   \n",
       "4                25.622874               34.688647                    False   \n",
       "\n",
       "   max_rotation_axis_roll  max_rotation_axis_yaw      yaw_var   pitch_var  \\\n",
       "0                    True                  False    13.592053   32.052153   \n",
       "1                    True                  False    31.628330   43.135706   \n",
       "2                    True                  False   478.485194  921.181433   \n",
       "3                    True                  False  1120.115429  355.102188   \n",
       "4                    True                  False   245.454406  494.155175   \n",
       "\n",
       "      roll_var  rot_energy_x  rot_energy_y  rot_energy_z  thm_1_mean  \\\n",
       "0   468.286339      0.082005      0.139978      0.703864   28.630612   \n",
       "1   502.360935      0.016126      0.152819      0.767665   30.464309   \n",
       "2  8339.515689      0.148647      0.648760      0.026494   24.522526   \n",
       "3  2562.486694      0.572502      0.074008      0.221416   31.651703   \n",
       "4   507.986980      0.062624      0.145895      0.052185   28.903610   \n",
       "\n",
       "   thm_1_std  thm_1_min  thm_1_max  thm_1_range  thm_1_delta  thm_1_activity  \\\n",
       "0   0.582076  27.696510  30.543730     2.847219    -0.150585       13.000359   \n",
       "1   2.709212  25.985313  32.870808     6.885494     0.901049       19.042677   \n",
       "2   0.449773  24.181389  25.634346     1.452957    -0.013020        5.484901   \n",
       "3   4.006846  25.413513  36.053188    10.639675    -0.282286       27.109056   \n",
       "4   1.144503  26.533083  30.267483     3.734400     1.167833       10.336542   \n",
       "\n",
       "   thm_2_mean  thm_2_std  thm_2_min  thm_2_max  thm_2_range  thm_2_delta  \\\n",
       "0   29.571870   2.576799  24.558798  32.010178     7.451380    -1.006186   \n",
       "1   29.678206   3.885080  23.907709  33.100945     9.193235     0.056095   \n",
       "2   24.367174   0.620555  23.933413  26.175961     2.242548    -0.110445   \n",
       "3   31.601259   4.495657  25.018881  36.705894    11.687014     0.047785   \n",
       "4   29.438643   1.658719  25.795074  31.035217     5.240143     0.690622   \n",
       "\n",
       "   thm_2_activity  thm_3_mean  thm_3_std  thm_3_min  thm_3_max  thm_3_range  \\\n",
       "0       22.822474   28.576605   1.260533  25.907490  30.090014     4.182524   \n",
       "1       31.470016   29.179852   3.074828  24.414917  32.316135     7.901218   \n",
       "2        7.408587   24.892424   0.294962  24.406981  25.512794     1.105814   \n",
       "3       31.485872   29.320353   3.274493  24.128819  33.617542     9.488724   \n",
       "4       15.569307   27.058073   0.951421  25.127720  28.468761     3.341042   \n",
       "\n",
       "   thm_3_delta  thm_3_activity  thm_4_mean  thm_4_std  thm_4_min  thm_4_max  \\\n",
       "0    -0.156540       13.482555   29.177937   0.278147  28.592863  29.761480   \n",
       "1     1.130726       42.520508   30.501325   0.976249  28.755495  31.613327   \n",
       "2     0.085846        6.074223   24.930840   0.572871  24.419798  26.452927   \n",
       "3    -0.441620       23.481190   32.790761   3.253195  27.227589  35.665222   \n",
       "4     0.760956       11.521690   27.841705   0.431424  26.827133  28.400864   \n",
       "\n",
       "   thm_4_range  thm_4_delta  thm_4_activity  thm_5_mean  thm_5_std  thm_5_min  \\\n",
       "0     1.168617     0.523323        5.657688   27.957446   0.877846  26.047148   \n",
       "1     2.857832     0.866661       12.937668   25.824221   1.165940  24.181562   \n",
       "2     2.033129    -0.384151        5.965618   24.733322   0.475044  24.167980   \n",
       "3     8.437634     1.619091       22.319618   30.860562   3.310154  26.312038   \n",
       "4     1.573730     0.005075        6.891409   31.014364   1.394629  28.282324   \n",
       "\n",
       "   thm_5_max  thm_5_range  thm_5_delta  thm_5_activity  thm_mean_mean  \\\n",
       "0  29.428299     3.381151    -0.324644       14.319735      28.782894   \n",
       "1  28.054575     3.873013    -0.130692       25.231140      29.129583   \n",
       "2  26.051331     1.883350     0.257027        7.453289      24.689257   \n",
       "3  35.801083     9.489044    -0.020788       28.030943      31.244928   \n",
       "4  32.180752     3.898428     2.002932        8.149042      28.851279   \n",
       "\n",
       "   thm_std_mean  thm_hotspot_index  thm_symmetry_side  thm_center_edge_diff  \\\n",
       "0      1.115080                  1          -1.080875              0.752568   \n",
       "1      2.362262                  3          -1.945501              1.710534   \n",
       "2      0.482641                  3          -0.021083              0.339090   \n",
       "3      3.668069                  3          -0.939878              2.299691   \n",
       "4      1.116139                  4           1.318813              2.900914   \n",
       "\n",
       "   tof_1_mean  tof_1_std   tof_1_min   tof_1_max  tof_1_range  \\\n",
       "0  101.462627  18.701970   64.122807  137.263158    73.140351   \n",
       "1  147.262788  22.880775  114.029412  193.397059    79.367647   \n",
       "2  202.243341  15.592535  181.638298  237.106383    55.468085   \n",
       "3   30.547978   3.582891   24.106383   37.510638    13.404255   \n",
       "4  139.359139  28.198077   85.462963  180.000000    94.537037   \n",
       "\n",
       "   tof_1_valid_ratio  tof_1_center_mean  tof_1_edge_mean  \\\n",
       "0           0.491776         105.167919        99.136456   \n",
       "1           0.603171         123.860023       144.545448   \n",
       "2           0.221108         180.602300       200.067111   \n",
       "3           0.636527          12.122747        30.563750   \n",
       "4           0.669850         161.426370       130.793476   \n",
       "\n",
       "   tof_1_center_edge_ratio  tof_2_mean  tof_2_std   tof_2_min   tof_2_max  \\\n",
       "0                 1.084380  131.584300  18.873624   90.719298  163.614035   \n",
       "1                 1.077715  107.049142  13.899609   83.849057  154.339623   \n",
       "2                 1.021022  184.410453  14.396688  166.054054  208.054054   \n",
       "3                 0.944166   75.149853   3.564886   69.852459   83.196721   \n",
       "4                 1.251414  122.274214  22.236042   93.425926  167.870370   \n",
       "\n",
       "   tof_2_range  tof_2_valid_ratio  tof_2_center_mean  tof_2_edge_mean  \\\n",
       "0    72.894737           0.516721         120.999208       124.970788   \n",
       "1    70.490566           0.542050          94.294453       107.176479   \n",
       "2    42.000000           0.159493         111.969240       183.767872   \n",
       "3    13.344262           0.661629           6.117562        75.254783   \n",
       "4    74.444444           0.739583         118.363216       125.265398   \n",
       "\n",
       "   tof_2_center_edge_ratio  tof_3_mean  tof_3_std   tof_3_min   tof_3_max  \\\n",
       "0                 1.225540   88.811663  10.645399   70.000000  113.631579   \n",
       "1                 1.000236  162.770818  25.641174  116.970588  202.705882   \n",
       "2                 1.046709  182.676496  32.916034  105.188679  217.698113   \n",
       "3              1938.793473   32.401175  38.284690    9.627907  159.348837   \n",
       "4                 0.930803  143.509979  22.681284  104.481481  189.203704   \n",
       "\n",
       "   tof_3_range  tof_3_valid_ratio  tof_3_center_mean  tof_3_edge_mean  \\\n",
       "0    43.631579           0.659265          77.623725        88.133020   \n",
       "1    85.735294           0.521829         152.341353       155.106973   \n",
       "2   112.509434           0.456663         193.442163       172.626141   \n",
       "3   149.720930           0.394980          17.313737        41.559451   \n",
       "4    84.722222           0.473380         138.594070       137.305816   \n",
       "\n",
       "   tof_3_center_edge_ratio  tof_4_mean  tof_4_std   tof_4_min   tof_4_max  \\\n",
       "0                 0.992352   88.479068  22.387650   56.771930  141.578947   \n",
       "1                 1.207827  166.807100  30.497778  109.352941  215.779412   \n",
       "2                 1.179970  210.052698  18.564589  171.547170  240.660377   \n",
       "3                 0.612594   31.655589  20.205845    5.721311   72.967213   \n",
       "4                 1.143068  146.027234  26.971389   94.518519  195.611111   \n",
       "\n",
       "   tof_4_range  tof_4_valid_ratio  tof_4_center_mean  tof_4_edge_mean  \\\n",
       "0    84.807018           0.636513          98.636698        82.163070   \n",
       "1   106.426471           0.727711         177.089265       159.717670   \n",
       "2    69.113208           0.309257         205.891168       206.507863   \n",
       "3    67.245902           0.801742          16.956148        36.058892   \n",
       "4   101.092593           0.780671         162.855939       134.551452   \n",
       "\n",
       "   tof_4_center_edge_ratio  tof_5_mean  tof_5_std   tof_5_min   tof_5_max  \\\n",
       "0                 1.142889  125.362645  23.611158   76.105263  165.087719   \n",
       "1                 1.105589  141.004887  17.392831  114.338235  175.661765   \n",
       "2                 1.065340  198.628079  29.101898  141.375000  242.750000   \n",
       "3                 0.738948   26.369672   7.304523   16.489362   39.787234   \n",
       "4                 1.208594  138.873423  29.434685   87.796296  189.018519   \n",
       "\n",
       "   tof_5_range  tof_5_valid_ratio  tof_5_center_mean  tof_5_edge_mean  \\\n",
       "0    88.982456           0.600329         136.848416       118.542951   \n",
       "1    61.323529           0.313189         148.581264       137.532246   \n",
       "2   101.375000           0.145637         195.914295       185.557298   \n",
       "3    23.297872           0.505891          24.796456        24.067193   \n",
       "4   101.222222           0.855035         151.110172       130.040274   \n",
       "\n",
       "   tof_5_center_edge_ratio  \n",
       "0                 1.170684  \n",
       "1                 1.140805  \n",
       "2                 1.595708  \n",
       "3                 0.857556  \n",
       "4                 1.162915  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>subject</th>\n",
       "      <th>n_steps</th>\n",
       "      <th>max_counter</th>\n",
       "      <th>acc_x_mean</th>\n",
       "      <th>acc_x_std</th>\n",
       "      <th>acc_x_max</th>\n",
       "      <th>acc_x_min</th>\n",
       "      <th>acc_x_range</th>\n",
       "      <th>acc_x_skew</th>\n",
       "      <th>acc_x_kurt</th>\n",
       "      <th>acc_x_jerk_mean</th>\n",
       "      <th>acc_x_jerk_std</th>\n",
       "      <th>acc_x_jerk_max</th>\n",
       "      <th>acc_x_jerk_min</th>\n",
       "      <th>acc_x_energy</th>\n",
       "      <th>acc_y_mean</th>\n",
       "      <th>acc_y_std</th>\n",
       "      <th>acc_y_max</th>\n",
       "      <th>acc_y_min</th>\n",
       "      <th>acc_y_range</th>\n",
       "      <th>acc_y_skew</th>\n",
       "      <th>acc_y_kurt</th>\n",
       "      <th>acc_y_jerk_mean</th>\n",
       "      <th>acc_y_jerk_std</th>\n",
       "      <th>acc_y_jerk_max</th>\n",
       "      <th>acc_y_jerk_min</th>\n",
       "      <th>acc_y_energy</th>\n",
       "      <th>acc_z_mean</th>\n",
       "      <th>acc_z_std</th>\n",
       "      <th>acc_z_max</th>\n",
       "      <th>acc_z_min</th>\n",
       "      <th>acc_z_range</th>\n",
       "      <th>acc_z_skew</th>\n",
       "      <th>acc_z_kurt</th>\n",
       "      <th>acc_z_jerk_mean</th>\n",
       "      <th>acc_z_jerk_std</th>\n",
       "      <th>acc_z_jerk_max</th>\n",
       "      <th>acc_z_jerk_min</th>\n",
       "      <th>acc_z_energy</th>\n",
       "      <th>corr_acc_x_y</th>\n",
       "      <th>corr_acc_x_z</th>\n",
       "      <th>corr_acc_y_z</th>\n",
       "      <th>acc_z_momentum_x_range</th>\n",
       "      <th>roll_angle_mean</th>\n",
       "      <th>roll_angle_std</th>\n",
       "      <th>roll_angle_max</th>\n",
       "      <th>roll_angle_min</th>\n",
       "      <th>yaw_mean</th>\n",
       "      <th>yaw_std</th>\n",
       "      <th>yaw_min</th>\n",
       "      <th>yaw_max</th>\n",
       "      <th>yaw_&lt;lambda_0&gt;</th>\n",
       "      <th>pitch_mean</th>\n",
       "      <th>pitch_std</th>\n",
       "      <th>pitch_min</th>\n",
       "      <th>pitch_max</th>\n",
       "      <th>pitch_&lt;lambda_0&gt;</th>\n",
       "      <th>roll_mean</th>\n",
       "      <th>roll_std</th>\n",
       "      <th>roll_min</th>\n",
       "      <th>roll_max</th>\n",
       "      <th>roll_&lt;lambda_0&gt;</th>\n",
       "      <th>orientation_change_magnitude</th>\n",
       "      <th>orientation_delta_yaw</th>\n",
       "      <th>orientation_delta_pitch</th>\n",
       "      <th>orientation_delta_roll</th>\n",
       "      <th>max_rotation_axis_yaw</th>\n",
       "      <th>max_rotation_axis_pitch</th>\n",
       "      <th>max_rotation_axis_roll</th>\n",
       "      <th>yaw_var</th>\n",
       "      <th>pitch_var</th>\n",
       "      <th>roll_var</th>\n",
       "      <th>rot_energy_x</th>\n",
       "      <th>rot_energy_y</th>\n",
       "      <th>rot_energy_z</th>\n",
       "      <th>thm_1_mean</th>\n",
       "      <th>thm_1_std</th>\n",
       "      <th>thm_1_min</th>\n",
       "      <th>thm_1_max</th>\n",
       "      <th>thm_1_range</th>\n",
       "      <th>thm_1_delta</th>\n",
       "      <th>thm_1_activity</th>\n",
       "      <th>thm_2_mean</th>\n",
       "      <th>thm_2_std</th>\n",
       "      <th>thm_2_min</th>\n",
       "      <th>thm_2_max</th>\n",
       "      <th>thm_2_range</th>\n",
       "      <th>thm_2_delta</th>\n",
       "      <th>thm_2_activity</th>\n",
       "      <th>thm_3_mean</th>\n",
       "      <th>thm_3_std</th>\n",
       "      <th>thm_3_min</th>\n",
       "      <th>thm_3_max</th>\n",
       "      <th>thm_3_range</th>\n",
       "      <th>thm_3_delta</th>\n",
       "      <th>thm_3_activity</th>\n",
       "      <th>thm_4_mean</th>\n",
       "      <th>thm_4_std</th>\n",
       "      <th>thm_4_min</th>\n",
       "      <th>thm_4_max</th>\n",
       "      <th>thm_4_range</th>\n",
       "      <th>thm_4_delta</th>\n",
       "      <th>thm_4_activity</th>\n",
       "      <th>thm_5_mean</th>\n",
       "      <th>thm_5_std</th>\n",
       "      <th>thm_5_min</th>\n",
       "      <th>thm_5_max</th>\n",
       "      <th>thm_5_range</th>\n",
       "      <th>thm_5_delta</th>\n",
       "      <th>thm_5_activity</th>\n",
       "      <th>thm_mean_mean</th>\n",
       "      <th>thm_std_mean</th>\n",
       "      <th>thm_hotspot_index</th>\n",
       "      <th>thm_symmetry_side</th>\n",
       "      <th>thm_center_edge_diff</th>\n",
       "      <th>tof_1_mean</th>\n",
       "      <th>tof_1_std</th>\n",
       "      <th>tof_1_min</th>\n",
       "      <th>tof_1_max</th>\n",
       "      <th>tof_1_range</th>\n",
       "      <th>tof_1_valid_ratio</th>\n",
       "      <th>tof_1_center_mean</th>\n",
       "      <th>tof_1_edge_mean</th>\n",
       "      <th>tof_1_center_edge_ratio</th>\n",
       "      <th>tof_2_mean</th>\n",
       "      <th>tof_2_std</th>\n",
       "      <th>tof_2_min</th>\n",
       "      <th>tof_2_max</th>\n",
       "      <th>tof_2_range</th>\n",
       "      <th>tof_2_valid_ratio</th>\n",
       "      <th>tof_2_center_mean</th>\n",
       "      <th>tof_2_edge_mean</th>\n",
       "      <th>tof_2_center_edge_ratio</th>\n",
       "      <th>tof_3_mean</th>\n",
       "      <th>tof_3_std</th>\n",
       "      <th>tof_3_min</th>\n",
       "      <th>tof_3_max</th>\n",
       "      <th>tof_3_range</th>\n",
       "      <th>tof_3_valid_ratio</th>\n",
       "      <th>tof_3_center_mean</th>\n",
       "      <th>tof_3_edge_mean</th>\n",
       "      <th>tof_3_center_edge_ratio</th>\n",
       "      <th>tof_4_mean</th>\n",
       "      <th>tof_4_std</th>\n",
       "      <th>tof_4_min</th>\n",
       "      <th>tof_4_max</th>\n",
       "      <th>tof_4_range</th>\n",
       "      <th>tof_4_valid_ratio</th>\n",
       "      <th>tof_4_center_mean</th>\n",
       "      <th>tof_4_edge_mean</th>\n",
       "      <th>tof_4_center_edge_ratio</th>\n",
       "      <th>tof_5_mean</th>\n",
       "      <th>tof_5_std</th>\n",
       "      <th>tof_5_min</th>\n",
       "      <th>tof_5_max</th>\n",
       "      <th>tof_5_range</th>\n",
       "      <th>tof_5_valid_ratio</th>\n",
       "      <th>tof_5_center_mean</th>\n",
       "      <th>tof_5_edge_mean</th>\n",
       "      <th>tof_5_center_edge_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "      <td>7.750837</td>\n",
       "      <td>1.050640</td>\n",
       "      <td>10.160156</td>\n",
       "      <td>6.132812</td>\n",
       "      <td>4.027344</td>\n",
       "      <td>0.730955</td>\n",
       "      <td>-0.756832</td>\n",
       "      <td>-0.041399</td>\n",
       "      <td>0.466181</td>\n",
       "      <td>1.380859</td>\n",
       "      <td>-2.035156</td>\n",
       "      <td>3424.937988</td>\n",
       "      <td>5.393694</td>\n",
       "      <td>2.353345</td>\n",
       "      <td>7.214844</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>6.433594</td>\n",
       "      <td>-1.222971</td>\n",
       "      <td>-0.319466</td>\n",
       "      <td>0.003453</td>\n",
       "      <td>0.524735</td>\n",
       "      <td>1.666016</td>\n",
       "      <td>-1.800781</td>\n",
       "      <td>1933.751404</td>\n",
       "      <td>-0.093331</td>\n",
       "      <td>2.305147</td>\n",
       "      <td>4.093750</td>\n",
       "      <td>-4.792969</td>\n",
       "      <td>8.886719</td>\n",
       "      <td>-0.837641</td>\n",
       "      <td>-0.385385</td>\n",
       "      <td>-0.003383</td>\n",
       "      <td>0.722215</td>\n",
       "      <td>2.433594</td>\n",
       "      <td>-2.335938</td>\n",
       "      <td>292.741547</td>\n",
       "      <td>-0.856616</td>\n",
       "      <td>-0.737114</td>\n",
       "      <td>0.905823</td>\n",
       "      <td>-0.375878</td>\n",
       "      <td>0.599637</td>\n",
       "      <td>0.265987</td>\n",
       "      <td>0.844646</td>\n",
       "      <td>0.086889</td>\n",
       "      <td>-124.452980</td>\n",
       "      <td>13.759787</td>\n",
       "      <td>-134.790098</td>\n",
       "      <td>-97.201198</td>\n",
       "      <td>-17.249719</td>\n",
       "      <td>-7.726119</td>\n",
       "      <td>4.687385</td>\n",
       "      <td>-17.477808</td>\n",
       "      <td>-0.217066</td>\n",
       "      <td>-11.477719</td>\n",
       "      <td>-89.877106</td>\n",
       "      <td>13.319235</td>\n",
       "      <td>-116.734228</td>\n",
       "      <td>-73.521057</td>\n",
       "      <td>16.508183</td>\n",
       "      <td>238.683552</td>\n",
       "      <td>17.249719</td>\n",
       "      <td>11.477719</td>\n",
       "      <td>16.508183</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>189.331752</td>\n",
       "      <td>21.971576</td>\n",
       "      <td>177.402017</td>\n",
       "      <td>0.099826</td>\n",
       "      <td>0.399130</td>\n",
       "      <td>0.373045</td>\n",
       "      <td>30.344483</td>\n",
       "      <td>0.527554</td>\n",
       "      <td>29.404165</td>\n",
       "      <td>31.404631</td>\n",
       "      <td>2.000465</td>\n",
       "      <td>0.531841</td>\n",
       "      <td>7.977383</td>\n",
       "      <td>31.704738</td>\n",
       "      <td>0.869936</td>\n",
       "      <td>30.001017</td>\n",
       "      <td>33.143929</td>\n",
       "      <td>3.142912</td>\n",
       "      <td>-2.180260</td>\n",
       "      <td>19.702045</td>\n",
       "      <td>29.959844</td>\n",
       "      <td>0.744500</td>\n",
       "      <td>28.804676</td>\n",
       "      <td>32.595078</td>\n",
       "      <td>3.790401</td>\n",
       "      <td>1.608583</td>\n",
       "      <td>13.600054</td>\n",
       "      <td>33.351966</td>\n",
       "      <td>0.120876</td>\n",
       "      <td>33.141365</td>\n",
       "      <td>33.648617</td>\n",
       "      <td>0.507252</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>3.245098</td>\n",
       "      <td>30.091830</td>\n",
       "      <td>0.713068</td>\n",
       "      <td>28.103935</td>\n",
       "      <td>31.459490</td>\n",
       "      <td>3.355555</td>\n",
       "      <td>-0.439772</td>\n",
       "      <td>12.562983</td>\n",
       "      <td>31.090572</td>\n",
       "      <td>0.595187</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.310195</td>\n",
       "      <td>0.591100</td>\n",
       "      <td>47.112077</td>\n",
       "      <td>14.550525</td>\n",
       "      <td>16.500000</td>\n",
       "      <td>77.964286</td>\n",
       "      <td>61.464286</td>\n",
       "      <td>0.694754</td>\n",
       "      <td>52.090583</td>\n",
       "      <td>43.598407</td>\n",
       "      <td>1.061843</td>\n",
       "      <td>18.893912</td>\n",
       "      <td>7.256463</td>\n",
       "      <td>8.160714</td>\n",
       "      <td>36.321429</td>\n",
       "      <td>28.160714</td>\n",
       "      <td>0.481864</td>\n",
       "      <td>21.394630</td>\n",
       "      <td>17.984281</td>\n",
       "      <td>39754.34948</td>\n",
       "      <td>41.080951</td>\n",
       "      <td>9.350177</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>60.089286</td>\n",
       "      <td>39.089286</td>\n",
       "      <td>0.715681</td>\n",
       "      <td>40.959654</td>\n",
       "      <td>41.378338</td>\n",
       "      <td>0.470091</td>\n",
       "      <td>160.665970</td>\n",
       "      <td>40.281767</td>\n",
       "      <td>109.178571</td>\n",
       "      <td>245.642857</td>\n",
       "      <td>136.464286</td>\n",
       "      <td>0.797433</td>\n",
       "      <td>162.288566</td>\n",
       "      <td>156.776636</td>\n",
       "      <td>1.029469</td>\n",
       "      <td>138.955569</td>\n",
       "      <td>35.814128</td>\n",
       "      <td>70.553571</td>\n",
       "      <td>218.196429</td>\n",
       "      <td>147.642857</td>\n",
       "      <td>0.713449</td>\n",
       "      <td>158.621833</td>\n",
       "      <td>126.234063</td>\n",
       "      <td>1.205740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>51</td>\n",
       "      <td>50</td>\n",
       "      <td>-2.423790</td>\n",
       "      <td>3.534764</td>\n",
       "      <td>9.609375</td>\n",
       "      <td>-4.523438</td>\n",
       "      <td>14.132812</td>\n",
       "      <td>1.986602</td>\n",
       "      <td>2.661071</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>1.358934</td>\n",
       "      <td>4.136719</td>\n",
       "      <td>-6.701172</td>\n",
       "      <td>924.340561</td>\n",
       "      <td>6.621477</td>\n",
       "      <td>4.377906</td>\n",
       "      <td>8.957031</td>\n",
       "      <td>-5.257812</td>\n",
       "      <td>14.214844</td>\n",
       "      <td>-2.030169</td>\n",
       "      <td>2.552805</td>\n",
       "      <td>-0.019072</td>\n",
       "      <td>1.340108</td>\n",
       "      <td>4.884766</td>\n",
       "      <td>-3.732422</td>\n",
       "      <td>3194.344513</td>\n",
       "      <td>-1.357996</td>\n",
       "      <td>4.619076</td>\n",
       "      <td>11.113281</td>\n",
       "      <td>-5.093750</td>\n",
       "      <td>16.207031</td>\n",
       "      <td>1.902655</td>\n",
       "      <td>1.943542</td>\n",
       "      <td>-0.006817</td>\n",
       "      <td>1.871495</td>\n",
       "      <td>8.025391</td>\n",
       "      <td>-6.166016</td>\n",
       "      <td>1160.845123</td>\n",
       "      <td>-0.935494</td>\n",
       "      <td>0.926198</td>\n",
       "      <td>-0.940147</td>\n",
       "      <td>-19.192307</td>\n",
       "      <td>1.605974</td>\n",
       "      <td>0.913583</td>\n",
       "      <td>2.152584</td>\n",
       "      <td>-0.839874</td>\n",
       "      <td>109.841953</td>\n",
       "      <td>128.224303</td>\n",
       "      <td>-175.741916</td>\n",
       "      <td>179.217338</td>\n",
       "      <td>-325.918929</td>\n",
       "      <td>40.400851</td>\n",
       "      <td>15.033985</td>\n",
       "      <td>-21.695485</td>\n",
       "      <td>51.545082</td>\n",
       "      <td>-67.459807</td>\n",
       "      <td>-101.762531</td>\n",
       "      <td>35.094755</td>\n",
       "      <td>-120.052248</td>\n",
       "      <td>-12.430743</td>\n",
       "      <td>47.338983</td>\n",
       "      <td>1694.018850</td>\n",
       "      <td>325.918929</td>\n",
       "      <td>67.459807</td>\n",
       "      <td>47.338983</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>16441.471931</td>\n",
       "      <td>226.020700</td>\n",
       "      <td>1231.641845</td>\n",
       "      <td>0.039554</td>\n",
       "      <td>0.530911</td>\n",
       "      <td>0.299272</td>\n",
       "      <td>24.037935</td>\n",
       "      <td>0.744225</td>\n",
       "      <td>23.668732</td>\n",
       "      <td>28.038889</td>\n",
       "      <td>4.370157</td>\n",
       "      <td>4.227476</td>\n",
       "      <td>13.772425</td>\n",
       "      <td>24.337945</td>\n",
       "      <td>0.719458</td>\n",
       "      <td>23.831026</td>\n",
       "      <td>27.659178</td>\n",
       "      <td>3.828152</td>\n",
       "      <td>3.764561</td>\n",
       "      <td>14.427422</td>\n",
       "      <td>24.916696</td>\n",
       "      <td>0.861194</td>\n",
       "      <td>23.956018</td>\n",
       "      <td>27.454428</td>\n",
       "      <td>3.498409</td>\n",
       "      <td>2.766108</td>\n",
       "      <td>17.130732</td>\n",
       "      <td>24.325895</td>\n",
       "      <td>0.790553</td>\n",
       "      <td>23.922821</td>\n",
       "      <td>27.937756</td>\n",
       "      <td>4.014935</td>\n",
       "      <td>3.876791</td>\n",
       "      <td>15.689600</td>\n",
       "      <td>24.213695</td>\n",
       "      <td>0.274667</td>\n",
       "      <td>23.681103</td>\n",
       "      <td>24.870544</td>\n",
       "      <td>1.189442</td>\n",
       "      <td>0.569208</td>\n",
       "      <td>5.652426</td>\n",
       "      <td>24.366433</td>\n",
       "      <td>0.678020</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.206105</td>\n",
       "      <td>0.790881</td>\n",
       "      <td>212.842044</td>\n",
       "      <td>20.490726</td>\n",
       "      <td>179.833333</td>\n",
       "      <td>244.833333</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.027574</td>\n",
       "      <td>204.074074</td>\n",
       "      <td>207.150855</td>\n",
       "      <td>1.075229</td>\n",
       "      <td>118.397172</td>\n",
       "      <td>12.852974</td>\n",
       "      <td>104.232558</td>\n",
       "      <td>139.581395</td>\n",
       "      <td>35.348837</td>\n",
       "      <td>0.049939</td>\n",
       "      <td>178.733333</td>\n",
       "      <td>115.966381</td>\n",
       "      <td>1.25247</td>\n",
       "      <td>186.123590</td>\n",
       "      <td>31.198974</td>\n",
       "      <td>144.395349</td>\n",
       "      <td>242.767442</td>\n",
       "      <td>98.372093</td>\n",
       "      <td>0.242341</td>\n",
       "      <td>226.630417</td>\n",
       "      <td>178.629219</td>\n",
       "      <td>1.460772</td>\n",
       "      <td>211.514657</td>\n",
       "      <td>19.918354</td>\n",
       "      <td>183.428571</td>\n",
       "      <td>242.714286</td>\n",
       "      <td>59.285714</td>\n",
       "      <td>0.027267</td>\n",
       "      <td>213.440000</td>\n",
       "      <td>207.174248</td>\n",
       "      <td>1.098584</td>\n",
       "      <td>221.083333</td>\n",
       "      <td>13.890694</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>237.500000</td>\n",
       "      <td>44.500000</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>218.833333</td>\n",
       "      <td>1.143357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sequence_id      subject  n_steps  max_counter  acc_x_mean  acc_x_std  \\\n",
       "0  SEQ_000001  SUBJ_055840       56           55    7.750837   1.050640   \n",
       "1  SEQ_000011  SUBJ_016452       51           50   -2.423790   3.534764   \n",
       "\n",
       "   acc_x_max  acc_x_min  acc_x_range  acc_x_skew  acc_x_kurt  acc_x_jerk_mean  \\\n",
       "0  10.160156   6.132812     4.027344    0.730955   -0.756832        -0.041399   \n",
       "1   9.609375  -4.523438    14.132812    1.986602    2.661071         0.001417   \n",
       "\n",
       "   acc_x_jerk_std  acc_x_jerk_max  acc_x_jerk_min  acc_x_energy  acc_y_mean  \\\n",
       "0        0.466181        1.380859       -2.035156   3424.937988    5.393694   \n",
       "1        1.358934        4.136719       -6.701172    924.340561    6.621477   \n",
       "\n",
       "   acc_y_std  acc_y_max  acc_y_min  acc_y_range  acc_y_skew  acc_y_kurt  \\\n",
       "0   2.353345   7.214844   0.781250     6.433594   -1.222971   -0.319466   \n",
       "1   4.377906   8.957031  -5.257812    14.214844   -2.030169    2.552805   \n",
       "\n",
       "   acc_y_jerk_mean  acc_y_jerk_std  acc_y_jerk_max  acc_y_jerk_min  \\\n",
       "0         0.003453        0.524735        1.666016       -1.800781   \n",
       "1        -0.019072        1.340108        4.884766       -3.732422   \n",
       "\n",
       "   acc_y_energy  acc_z_mean  acc_z_std  acc_z_max  acc_z_min  acc_z_range  \\\n",
       "0   1933.751404   -0.093331   2.305147   4.093750  -4.792969     8.886719   \n",
       "1   3194.344513   -1.357996   4.619076  11.113281  -5.093750    16.207031   \n",
       "\n",
       "   acc_z_skew  acc_z_kurt  acc_z_jerk_mean  acc_z_jerk_std  acc_z_jerk_max  \\\n",
       "0   -0.837641   -0.385385        -0.003383        0.722215        2.433594   \n",
       "1    1.902655    1.943542        -0.006817        1.871495        8.025391   \n",
       "\n",
       "   acc_z_jerk_min  acc_z_energy  corr_acc_x_y  corr_acc_x_z  corr_acc_y_z  \\\n",
       "0       -2.335938    292.741547     -0.856616     -0.737114      0.905823   \n",
       "1       -6.166016   1160.845123     -0.935494      0.926198     -0.940147   \n",
       "\n",
       "   acc_z_momentum_x_range  roll_angle_mean  roll_angle_std  roll_angle_max  \\\n",
       "0               -0.375878         0.599637        0.265987        0.844646   \n",
       "1              -19.192307         1.605974        0.913583        2.152584   \n",
       "\n",
       "   roll_angle_min    yaw_mean     yaw_std     yaw_min     yaw_max  \\\n",
       "0        0.086889 -124.452980   13.759787 -134.790098  -97.201198   \n",
       "1       -0.839874  109.841953  128.224303 -175.741916  179.217338   \n",
       "\n",
       "   yaw_<lambda_0>  pitch_mean  pitch_std  pitch_min  pitch_max  \\\n",
       "0      -17.249719   -7.726119   4.687385 -17.477808  -0.217066   \n",
       "1     -325.918929   40.400851  15.033985 -21.695485  51.545082   \n",
       "\n",
       "   pitch_<lambda_0>   roll_mean   roll_std    roll_min   roll_max  \\\n",
       "0        -11.477719  -89.877106  13.319235 -116.734228 -73.521057   \n",
       "1        -67.459807 -101.762531  35.094755 -120.052248 -12.430743   \n",
       "\n",
       "   roll_<lambda_0>  orientation_change_magnitude  orientation_delta_yaw  \\\n",
       "0        16.508183                    238.683552              17.249719   \n",
       "1        47.338983                   1694.018850             325.918929   \n",
       "\n",
       "   orientation_delta_pitch  orientation_delta_roll  max_rotation_axis_yaw  \\\n",
       "0                11.477719               16.508183                   True   \n",
       "1                67.459807               47.338983                   True   \n",
       "\n",
       "   max_rotation_axis_pitch  max_rotation_axis_roll       yaw_var   pitch_var  \\\n",
       "0                    False                   False    189.331752   21.971576   \n",
       "1                    False                   False  16441.471931  226.020700   \n",
       "\n",
       "      roll_var  rot_energy_x  rot_energy_y  rot_energy_z  thm_1_mean  \\\n",
       "0   177.402017      0.099826      0.399130      0.373045   30.344483   \n",
       "1  1231.641845      0.039554      0.530911      0.299272   24.037935   \n",
       "\n",
       "   thm_1_std  thm_1_min  thm_1_max  thm_1_range  thm_1_delta  thm_1_activity  \\\n",
       "0   0.527554  29.404165  31.404631     2.000465     0.531841        7.977383   \n",
       "1   0.744225  23.668732  28.038889     4.370157     4.227476       13.772425   \n",
       "\n",
       "   thm_2_mean  thm_2_std  thm_2_min  thm_2_max  thm_2_range  thm_2_delta  \\\n",
       "0   31.704738   0.869936  30.001017  33.143929     3.142912    -2.180260   \n",
       "1   24.337945   0.719458  23.831026  27.659178     3.828152     3.764561   \n",
       "\n",
       "   thm_2_activity  thm_3_mean  thm_3_std  thm_3_min  thm_3_max  thm_3_range  \\\n",
       "0       19.702045   29.959844   0.744500  28.804676  32.595078     3.790401   \n",
       "1       14.427422   24.916696   0.861194  23.956018  27.454428     3.498409   \n",
       "\n",
       "   thm_3_delta  thm_3_activity  thm_4_mean  thm_4_std  thm_4_min  thm_4_max  \\\n",
       "0     1.608583       13.600054   33.351966   0.120876  33.141365  33.648617   \n",
       "1     2.766108       17.130732   24.325895   0.790553  23.922821  27.937756   \n",
       "\n",
       "   thm_4_range  thm_4_delta  thm_4_activity  thm_5_mean  thm_5_std  thm_5_min  \\\n",
       "0     0.507252     0.064503        3.245098   30.091830   0.713068  28.103935   \n",
       "1     4.014935     3.876791       15.689600   24.213695   0.274667  23.681103   \n",
       "\n",
       "   thm_5_max  thm_5_range  thm_5_delta  thm_5_activity  thm_mean_mean  \\\n",
       "0  31.459490     3.355555    -0.439772       12.562983      31.090572   \n",
       "1  24.870544     1.189442     0.569208        5.652426      24.366433   \n",
       "\n",
       "   thm_std_mean  thm_hotspot_index  thm_symmetry_side  thm_center_edge_diff  \\\n",
       "0      0.595187                  3          -2.310195              0.591100   \n",
       "1      0.678020                  2          -0.206105              0.790881   \n",
       "\n",
       "   tof_1_mean  tof_1_std   tof_1_min   tof_1_max  tof_1_range  \\\n",
       "0   47.112077  14.550525   16.500000   77.964286    61.464286   \n",
       "1  212.842044  20.490726  179.833333  244.833333    65.000000   \n",
       "\n",
       "   tof_1_valid_ratio  tof_1_center_mean  tof_1_edge_mean  \\\n",
       "0           0.694754          52.090583        43.598407   \n",
       "1           0.027574         204.074074       207.150855   \n",
       "\n",
       "   tof_1_center_edge_ratio  tof_2_mean  tof_2_std   tof_2_min   tof_2_max  \\\n",
       "0                 1.061843   18.893912   7.256463    8.160714   36.321429   \n",
       "1                 1.075229  118.397172  12.852974  104.232558  139.581395   \n",
       "\n",
       "   tof_2_range  tof_2_valid_ratio  tof_2_center_mean  tof_2_edge_mean  \\\n",
       "0    28.160714           0.481864          21.394630        17.984281   \n",
       "1    35.348837           0.049939         178.733333       115.966381   \n",
       "\n",
       "   tof_2_center_edge_ratio  tof_3_mean  tof_3_std   tof_3_min   tof_3_max  \\\n",
       "0              39754.34948   41.080951   9.350177   21.000000   60.089286   \n",
       "1                  1.25247  186.123590  31.198974  144.395349  242.767442   \n",
       "\n",
       "   tof_3_range  tof_3_valid_ratio  tof_3_center_mean  tof_3_edge_mean  \\\n",
       "0    39.089286           0.715681          40.959654        41.378338   \n",
       "1    98.372093           0.242341         226.630417       178.629219   \n",
       "\n",
       "   tof_3_center_edge_ratio  tof_4_mean  tof_4_std   tof_4_min   tof_4_max  \\\n",
       "0                 0.470091  160.665970  40.281767  109.178571  245.642857   \n",
       "1                 1.460772  211.514657  19.918354  183.428571  242.714286   \n",
       "\n",
       "   tof_4_range  tof_4_valid_ratio  tof_4_center_mean  tof_4_edge_mean  \\\n",
       "0   136.464286           0.797433         162.288566       156.776636   \n",
       "1    59.285714           0.027267         213.440000       207.174248   \n",
       "\n",
       "   tof_4_center_edge_ratio  tof_5_mean  tof_5_std   tof_5_min   tof_5_max  \\\n",
       "0                 1.029469  138.955569  35.814128   70.553571  218.196429   \n",
       "1                 1.098584  221.083333  13.890694  193.000000  237.500000   \n",
       "\n",
       "   tof_5_range  tof_5_valid_ratio  tof_5_center_mean  tof_5_edge_mean  \\\n",
       "0   147.642857           0.713449         158.621833       126.234063   \n",
       "1    44.500000           0.003983         218.000000       218.833333   \n",
       "\n",
       "   tof_5_center_edge_ratio  \n",
       "0                 1.205740  \n",
       "1                 1.143357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(features_df.head())\n",
    "display(features_test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b5401ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metric import score\n",
    "def hierarchical_macro_f1_score(y_true, y_pred,sequence_ids):\n",
    "    # y_true ve y_pred: pandas.Series veya numpy dizisi (gesture etiketleri)\n",
    "    \n",
    "    # DataFrame yapalm\n",
    "    df_true = pd.DataFrame({'sequence_id': sequence_ids, 'gesture': y_true,})\n",
    "    df_pred = pd.DataFrame({'sequence_id': sequence_ids, 'gesture': y_pred,})\n",
    "\n",
    "\n",
    "    return score(df_true, df_pred, row_id_column_name='sequence_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b74052ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"n_steps\",\"max_counter\",\"acc_x_mean\",\"acc_x_std\",\"acc_x_max\",\"acc_x_min\",\"acc_x_range\",\"acc_x_skew\",\"acc_x_kurt\",\"acc_x_jerk_mean\",\"acc_x_jerk_std\",\"acc_x_jerk_max\",\"acc_x_jerk_min\",\"acc_x_energy\",\"acc_y_mean\",\"acc_y_std\",\"acc_y_max\",\"acc_y_min\",\"acc_y_range\",\"acc_y_skew\",\"acc_y_kurt\",\"acc_y_jerk_mean\",\"acc_y_jerk_std\",\"acc_y_jerk_max\",\"acc_y_jerk_min\",\"acc_y_energy\",\"acc_z_mean\",\"acc_z_std\",\"acc_z_max\",\"acc_z_min\",\"acc_z_range\",\"acc_z_skew\",\"acc_z_kurt\",\"acc_z_jerk_mean\",\"acc_z_jerk_std\",\"acc_z_jerk_max\",\"acc_z_jerk_min\",\"acc_z_energy\",\"corr_acc_x_y\",\"corr_acc_x_z\",\"corr_acc_y_z\",\"acc_z_momentum_x_range\",\"roll_angle_mean\",\"roll_angle_std\",\"roll_angle_max\",\"roll_angle_min\",\"yaw_mean\",\"yaw_std\",\"yaw_min\",\"yaw_max\",\"yaw_delta\",\"pitch_mean\",\"pitch_std\",\"pitch_min\",\"pitch_max\",\"pitch_delta\",\"roll_mean\",\"roll_std\",\"roll_min\",\"roll_max\",\"roll_delta\",\"orientation_change_magnitude\",\"orientation_delta_yaw\",\"orientation_delta_pitch\",\"orientation_delta_roll\",\"max_rotation_axis_pitch\",\"max_rotation_axis_roll\",\"max_rotation_axis_yaw\",\"yaw_var\",\"pitch_var\",\"roll_var\",\"rot_energy_x\",\"rot_energy_y\",\"rot_energy_z\",\"thm_1_mean\",\"thm_1_std\",\"thm_1_min\",\"thm_1_max\",\"thm_1_range\",\"thm_1_delta\",\"thm_1_activity\",\"thm_2_mean\",\"thm_2_std\",\"thm_2_min\",\"thm_2_max\",\"thm_2_range\",\"thm_2_delta\",\"thm_2_activity\",\"thm_3_mean\",\"thm_3_std\",\"thm_3_min\",\"thm_3_max\",\"thm_3_range\",\"thm_3_delta\",\"thm_3_activity\",\"thm_4_mean\",\"thm_4_std\",\"thm_4_min\",\"thm_4_max\",\"thm_4_range\",\"thm_4_delta\",\"thm_4_activity\",\"thm_5_mean\",\"thm_5_std\",\"thm_5_min\",\"thm_5_max\",\"thm_5_range\",\"thm_5_delta\",\"thm_5_activity\",\"thm_mean_mean\",\"thm_std_mean\",\"thm_hotspot_index\",\"thm_symmetry_side\",\"thm_center_edge_diff\",\"tof_1_mean\",\"tof_1_std\",\"tof_1_min\",\"tof_1_max\",\"tof_1_range\",\"tof_1_valid_ratio\",\"tof_1_center_mean\",\"tof_1_edge_mean\",\"tof_1_center_edge_ratio\",\"tof_2_mean\",\"tof_2_std\",\"tof_2_min\",\"tof_2_max\",\"tof_2_range\",\"tof_2_valid_ratio\",\"tof_2_center_mean\",\"tof_2_edge_mean\",\"tof_2_center_edge_ratio\",\"tof_3_mean\",\"tof_3_std\",\"tof_3_min\",\"tof_3_max\",\"tof_3_range\",\"tof_3_valid_ratio\",\"tof_3_center_mean\",\"tof_3_edge_mean\",\"tof_3_center_edge_ratio\",\"tof_4_mean\",\"tof_4_std\",\"tof_4_min\",\"tof_4_max\",\"tof_4_range\",\"tof_4_valid_ratio\",\"tof_4_center_mean\",\"tof_4_edge_mean\",\"tof_4_center_edge_ratio\",\"tof_5_mean\",\"tof_5_std\",\"tof_5_min\",\"tof_5_max\",\"tof_5_range\",\"tof_5_valid_ratio\",\"tof_5_center_mean\",\"tof_5_edge_mean\",\"tof_5_center_edge_ratio\"\n"
     ]
    }
   ],
   "source": [
    "print(','.join(f'\"{col}\"' for col in features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type']).columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd2ed20",
   "metadata": {},
   "source": [
    "## HGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e7ffc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING IMU MODEL...\n",
      "val preds :  ['Forehead - pull hairline' 'Wave hello' 'Wave hello' ...\n",
      " 'Forehead - pull hairline' 'Text on phone' 'Cheek - pinch skin']\n",
      "Fold 0 hierarchical macro F1: 0.6780\n",
      "-----------------------------------------------------------------------\n",
      "val preds :  ['Above ear - pull hair' 'Write name on leg' 'Eyebrow - pull hair' ...\n",
      " 'Pull air toward your face' 'Above ear - pull hair'\n",
      " 'Forehead - pull hairline']\n",
      "Fold 1 hierarchical macro F1: 0.6697\n",
      "-----------------------------------------------------------------------\n",
      "val preds :  ['Eyebrow - pull hair' 'Neck - scratch' 'Forehead - pull hairline' ...\n",
      " 'Above ear - pull hair' 'Cheek - pinch skin' 'Eyelash - pull hair']\n",
      "Fold 2 hierarchical macro F1: 0.6654\n",
      "-----------------------------------------------------------------------\n",
      "val preds :  ['Text on phone' 'Pull air toward your face' 'Forehead - scratch' ...\n",
      " 'Eyebrow - pull hair' 'Neck - scratch' 'Pinch knee/leg skin']\n",
      "Fold 3 hierarchical macro F1: 0.6801\n",
      "-----------------------------------------------------------------------\n",
      "val preds :  ['Above ear - pull hair' 'Text on phone' 'Eyebrow - pull hair' ...\n",
      " 'Eyebrow - pull hair' 'Forehead - pull hairline' 'Above ear - pull hair']\n",
      "Fold 4 hierarchical macro F1: 0.6696\n",
      "-----------------------------------------------------------------------\n",
      "En iyi fold modeli kaydedildi: Metric score = 0.6801\n",
      "\n",
      "TRAINING FULL MODEL...\n",
      "val preds :  ['Forehead - pull hairline' 'Wave hello' 'Wave hello' ...\n",
      " 'Eyebrow - pull hair' 'Text on phone' 'Eyelash - pull hair']\n",
      "Fold 0 hierarchical macro F1: 0.7873\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 53\u001b[39m\n\u001b[32m     50\u001b[39m train_and_save_model(X_imu, y_imu, features_df[\u001b[33m'\u001b[39m\u001b[33msequence_id\u001b[39m\u001b[33m'\u001b[39m], model_path=\u001b[33m\"\u001b[39m\u001b[33mmodel_hgbm\u001b[39m\u001b[33m\"\u001b[39m, model_name=\u001b[33m\"\u001b[39m\u001b[33mimu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTRAINING FULL MODEL...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[43mtrain_and_save_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_full\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msequence_id\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel_hgbm\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfull\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 32\u001b[39m, in \u001b[36mtrain_and_save_model\u001b[39m\u001b[34m(X, y, sequence_ids, model_path, model_name)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     30\u001b[39m     model = HistGradientBoostingClassifier()\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m val_preds = model.predict(X_val)\n\u001b[32m     35\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mval preds : \u001b[39m\u001b[33m'\u001b[39m, val_preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/stabil/lib/python3.11/site-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:687\u001b[39m, in \u001b[36mBaseHistGradientBoosting.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.n_trees_per_iteration_):\n\u001b[32m    670\u001b[39m     grower = TreeGrower(\n\u001b[32m    671\u001b[39m         X_binned=X_binned_train,\n\u001b[32m    672\u001b[39m         gradients=g_view[:, k],\n\u001b[32m   (...)\u001b[39m\u001b[32m    685\u001b[39m         n_threads=n_threads,\n\u001b[32m    686\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m687\u001b[39m     \u001b[43mgrower\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m     acc_apply_split_time += grower.total_apply_split_time\n\u001b[32m    690\u001b[39m     acc_find_split_time += grower.total_find_split_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/stabil/lib/python3.11/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:364\u001b[39m, in \u001b[36mTreeGrower.grow\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Grow the tree, from root to leaves.\"\"\"\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m.splittable_nodes:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplit_next\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[38;5;28mself\u001b[39m._apply_shrinkage()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/stabil/lib/python3.11/site-packages/sklearn/ensemble/_hist_gradient_boosting/grower.py:468\u001b[39m, in \u001b[36mTreeGrower.split_next\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    461\u001b[39m node = heappop(\u001b[38;5;28mself\u001b[39m.splittable_nodes)\n\u001b[32m    463\u001b[39m tic = time()\n\u001b[32m    464\u001b[39m (\n\u001b[32m    465\u001b[39m     sample_indices_left,\n\u001b[32m    466\u001b[39m     sample_indices_right,\n\u001b[32m    467\u001b[39m     right_child_pos,\n\u001b[32m--> \u001b[39m\u001b[32m468\u001b[39m ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[38;5;28mself\u001b[39m.total_apply_split_time += time() - tic\n\u001b[32m    471\u001b[39m depth = node.depth + \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import joblib\n",
    "\n",
    "# IMU zellikleri ve dier zellikler\n",
    "imu_features = [col for col in features_df.columns if not col.startswith(('thm_','tof_'))]\n",
    "\n",
    "\n",
    "# IMU modeli iin X ve y (tm satrlar, sadece IMU zellikleri)\n",
    "X_imu = features_df[imu_features].drop(columns= ['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_imu = features_df['gesture']\n",
    "\n",
    "# Full modeli iin X ve y (tm satrlar, full zellikler)\n",
    "X_full = features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_full = features_df['gesture']\n",
    "\n",
    "\n",
    "# {'max_iter': 629, 'max_leaf_nodes': 37, 'learning_rate': 0.1345386179108374, 'min_samples_leaf': 43, 'max_bins': 254, 'l2_regularization': 0.40798224928170634}\n",
    "def train_and_save_model(X, y, sequence_ids, model_path, model_name=\"imu\"):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_score = 0\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        val_sequence_ids = sequence_ids.iloc[val_idx]\n",
    "        model = HistGradientBoostingClassifier()\n",
    "        if model_name == 'imu':\n",
    "            model = HistGradientBoostingClassifier(random_state=42, max_iter=720, max_leaf_nodes=48, learning_rate=0.04, min_samples_leaf=36, max_bins=128,n_iter_no_change=30, l2_regularization=0.36, early_stopping= True)\n",
    "        else:\n",
    "            model = HistGradientBoostingClassifier()\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        print('val preds : ', val_preds)\n",
    "        score = hierarchical_macro_f1_score(y_val, val_preds,  val_sequence_ids)\n",
    "\n",
    "        print(f\"Fold {fold} hierarchical macro F1: {score:.4f}\")\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "    \n",
    "    joblib.dump(best_model, f\"{model_path}_{model_name}_{best_score:.4f}.pkl\")\n",
    "    print(f\"En iyi fold modeli kaydedildi: Metric score = {best_score:.4f}\")\n",
    "\n",
    "# Eitim\n",
    "print(\"TRAINING IMU MODEL...\")\n",
    "train_and_save_model(X_imu, y_imu, features_df['sequence_id'], model_path=\"model_hgbm\", model_name=\"imu\")\n",
    "\n",
    "print(\"\\nTRAINING FULL MODEL...\")\n",
    "train_and_save_model(X_full, y_full,features_df['sequence_id'], model_path=\"model_hgbm\", model_name=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e3966b",
   "metadata": {},
   "source": [
    "### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95a4e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING IMU MODEL...\n",
      "Fold 0 hierarchical macro F1: 0.6828\n",
      "-----------------------------------------------------------------------\n",
      "Fold 1 hierarchical macro F1: 0.6720\n",
      "-----------------------------------------------------------------------\n",
      "Fold 2 hierarchical macro F1: 0.6679\n",
      "-----------------------------------------------------------------------\n",
      "Fold 3 hierarchical macro F1: 0.6769\n",
      "-----------------------------------------------------------------------\n",
      "Fold 4 hierarchical macro F1: 0.6807\n",
      "-----------------------------------------------------------------------\n",
      "En iyi fold modeli kaydedildi: Metric score = 0.6828\n",
      "\n",
      "TRAINING FULL MODEL...\n",
      "Fold 0 hierarchical macro F1: 0.7888\n",
      "-----------------------------------------------------------------------\n",
      "Fold 1 hierarchical macro F1: 0.7851\n",
      "-----------------------------------------------------------------------\n",
      "Fold 2 hierarchical macro F1: 0.7807\n",
      "-----------------------------------------------------------------------\n",
      "Fold 3 hierarchical macro F1: 0.7747\n",
      "-----------------------------------------------------------------------\n",
      "Fold 4 hierarchical macro F1: 0.7854\n",
      "-----------------------------------------------------------------------\n",
      "En iyi fold modeli kaydedildi: Metric score = 0.7888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n",
    "# IMU zellikleri ve dier zellikler\n",
    "imu_features = [col for col in features_df.columns if not col.startswith(('thm_','tof_'))]\n",
    "\n",
    "\n",
    "# IMU modeli iin X ve y (tm satrlar, sadece IMU zellikleri)\n",
    "X_imu = features_df[imu_features].drop(columns= ['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_imu = features_df['gesture']\n",
    "\n",
    "# Full modeli iin X ve y (tm satrlar, full zellikler)\n",
    "X_full = features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_full = features_df['gesture']\n",
    "\n",
    "\n",
    "# {'max_iter': 629, 'max_leaf_nodes': 37, 'learning_rate': 0.1345386179108374, 'min_samples_leaf': 43, 'max_bins': 254, 'l2_regularization': 0.40798224928170634}\n",
    "def train_and_save_model(X, y, sequence_ids, model_path, model_name=\"imu\"):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_score = 0\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        val_sequence_ids = sequence_ids.iloc[val_idx]\n",
    "\n",
    "        model = LGBMClassifier(verbose = -1)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        score = hierarchical_macro_f1_score(y_val, val_preds,  val_sequence_ids)\n",
    "\n",
    "        print(f\"Fold {fold} hierarchical macro F1: {score:.4f}\")\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "    \n",
    "    joblib.dump(best_model, f\"{model_path}_{model_name}_{best_score:.4f}.pkl\")\n",
    "    print(f\"En iyi fold modeli kaydedildi: Metric score = {best_score:.4f}\")\n",
    "\n",
    "# Eitim\n",
    "print(\"TRAINING IMU MODEL...\")\n",
    "train_and_save_model(X_imu, y_imu, features_df['sequence_id'], model_path=\"lgbm\", model_name=\"imu\")\n",
    "\n",
    "print(\"\\nTRAINING FULL MODEL...\")\n",
    "train_and_save_model(X_full, y_full,features_df['sequence_id'], model_path=\"lgbm\", model_name=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a70c252",
   "metadata": {},
   "source": [
    "## CATBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0630200e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING IMU MODEL...\n",
      "Fold 0 hierarchical macro F1: 0.6795\n",
      "-----------------------------------------------------------------------\n",
      "Fold 1 hierarchical macro F1: 0.6877\n",
      "-----------------------------------------------------------------------\n",
      "Fold 2 hierarchical macro F1: 0.6795\n",
      "-----------------------------------------------------------------------\n",
      "Fold 3 hierarchical macro F1: 0.6889\n",
      "-----------------------------------------------------------------------\n",
      "Fold 4 hierarchical macro F1: 0.6818\n",
      "-----------------------------------------------------------------------\n",
      "En iyi fold modeli kaydedildi: Metric score = 0.6889\n",
      "\n",
      "TRAINING FULL MODEL...\n",
      "Fold 0 hierarchical macro F1: 0.7920\n",
      "-----------------------------------------------------------------------\n",
      "Fold 1 hierarchical macro F1: 0.8019\n",
      "-----------------------------------------------------------------------\n",
      "Fold 2 hierarchical macro F1: 0.7891\n",
      "-----------------------------------------------------------------------\n",
      "Fold 3 hierarchical macro F1: 0.7798\n",
      "-----------------------------------------------------------------------\n",
      "Fold 4 hierarchical macro F1: 0.7853\n",
      "-----------------------------------------------------------------------\n",
      "En iyi fold modeli kaydedildi: Metric score = 0.8019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from catboost import CatBoostClassifier\n",
    "import joblib\n",
    "\n",
    "# IMU zellikleri ve dier zellikler\n",
    "imu_features = [col for col in features_df.columns if not col.startswith(('thm_','tof_'))]\n",
    "\n",
    "\n",
    "# IMU modeli iin X ve y (tm satrlar, sadece IMU zellikleri)\n",
    "X_imu = features_df[imu_features].drop(columns= ['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_imu = features_df['gesture']\n",
    "\n",
    "# Full modeli iin X ve y (tm satrlar, full zellikler)\n",
    "X_full = features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_full = features_df['gesture']\n",
    "\n",
    "\n",
    "# {'max_iter': 629, 'max_leaf_nodes': 37, 'learning_rate': 0.1345386179108374, 'min_samples_leaf': 43, 'max_bins': 254, 'l2_regularization': 0.40798224928170634}\n",
    "def train_and_save_model(X, y, sequence_ids, model_path, model_name=\"imu\"):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_score = 0\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        val_sequence_ids = sequence_ids.iloc[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier(verbose = 0)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_preds_flat = val_preds.flatten() if hasattr(val_preds, 'flatten') else val_preds\n",
    "        score = hierarchical_macro_f1_score(y_val, val_preds_flat,  val_sequence_ids)\n",
    "\n",
    "        print(f\"Fold {fold} hierarchical macro F1: {score:.4f}\")\n",
    "        print(\"-----------------------------------------------------------------------\")\n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "    \n",
    "    joblib.dump(best_model, f\"{model_path}_{model_name}_{best_score:.4f}.pkl\")\n",
    "    print(f\"En iyi fold modeli kaydedildi: Metric score = {best_score:.4f}\")\n",
    "\n",
    "# Eitim\n",
    "print(\"TRAINING IMU MODEL...\")\n",
    "train_and_save_model(X_imu, y_imu, features_df['sequence_id'], model_path=\"model_cb\", model_name=\"imu\")\n",
    "\n",
    "print(\"\\nTRAINING FULL MODEL...\")\n",
    "train_and_save_model(X_full, y_full,features_df['sequence_id'], model_path=\"model_cb\", model_name=\"full\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd429c3a",
   "metadata": {},
   "source": [
    "## XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "887d8f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING IMU MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:16:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU | Fold 0 F1: 0.6921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:16:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU | Fold 1 F1: 0.6717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:17:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU | Fold 2 F1: 0.6748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:17:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU | Fold 3 F1: 0.6856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:17:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMU | Fold 4 F1: 0.6814\n",
      "Saved best imu model F1=0.6921\n",
      "\n",
      "TRAINING FULL MODEL...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:18:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL | Fold 0 F1: 0.7858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:18:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL | Fold 1 F1: 0.7912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:19:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL | Fold 2 F1: 0.7866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:19:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL | Fold 3 F1: 0.7866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/xgboost/training.py:183: UserWarning: [16:20:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:738: \n",
      "Parameters: { \"verbose\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL | Fold 4 F1: 0.7820\n",
      "Saved best full model F1=0.7912\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# IMU zellikleri ve dier zellikler\n",
    "imu_features = [col for col in features_df.columns if not col.startswith(('thm_','tof_'))]\n",
    "\n",
    "\n",
    "# IMU modeli iin X ve y (tm satrlar, sadece IMU zellikleri)\n",
    "X_imu = features_df[imu_features].drop(columns= ['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_imu = features_df['gesture']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded_imu = le.fit_transform(y_imu)\n",
    "\n",
    "# Full modeli iin X ve y (tm satrlar, full zellikler)\n",
    "X_full = features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_full = features_df['gesture']\n",
    "y_encoded_full = le.fit_transform(y_full)\n",
    "\n",
    "\n",
    "# {'max_iter': 629, 'max_leaf_nodes': 37, 'learning_rate': 0.1345386179108374, 'min_samples_leaf': 43, 'max_bins': 254, 'l2_regularization': 0.40798224928170634}\n",
    "def train_and_save_model(X, y_np, sequence_ids, model_path, model_name=\"imu\"):\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    best_score, best_model = 0, None\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y_np)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val   = y_np[train_idx],   y_np[val_idx]      # < dz indeksleme\n",
    "\n",
    "        model = XGBClassifier(n_estimators=600, tree_method=\"hist\", verbose=0)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_preds_decoded = le.inverse_transform(val_preds)\n",
    "        # print('pred decoded: ',val_preds_decoded)\n",
    "        # print('pred y_val: ',y_val)\n",
    "        y_val_decoded = le.inverse_transform(y_val)\n",
    "\n",
    "        score = hierarchical_macro_f1_score(y_val_decoded, val_preds_decoded, sequence_ids.iloc[val_idx])\n",
    "\n",
    "        print(f\"{model_name.upper()} | Fold {fold} F1: {score:.4f}\")\n",
    "        if score > best_score:\n",
    "            best_score, best_model = score, model\n",
    "\n",
    "    joblib.dump(best_model, f\"{model_path}_{model_name}_{best_score:.4f}.pkl\")\n",
    "    print(f\"Saved best {model_name} model F1={best_score:.4f}\")\n",
    "\n",
    "\n",
    "# Eitim\n",
    "print(\"TRAINING IMU MODEL...\")\n",
    "joblib.dump(le, \"enc_imu.pkl\") \n",
    "train_and_save_model(X_imu, y_encoded_imu, features_df['sequence_id'], model_path=\"model_xgb\", model_name=\"imu\")\n",
    "\n",
    "\n",
    "print(\"\\nTRAINING FULL MODEL...\")\n",
    "train_and_save_model(X_full, y_encoded_full,features_df['sequence_id'], model_path=\"model_xgb\", model_name=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3cd048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>sequence_counter</th>\n",
       "      <th>subject</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>rot_w</th>\n",
       "      <th>rot_x</th>\n",
       "      <th>rot_y</th>\n",
       "      <th>rot_z</th>\n",
       "      <th>thm_1</th>\n",
       "      <th>thm_2</th>\n",
       "      <th>thm_3</th>\n",
       "      <th>thm_4</th>\n",
       "      <th>thm_5</th>\n",
       "      <th>tof_1_v0</th>\n",
       "      <th>tof_1_v1</th>\n",
       "      <th>tof_1_v2</th>\n",
       "      <th>tof_1_v3</th>\n",
       "      <th>tof_1_v4</th>\n",
       "      <th>tof_1_v5</th>\n",
       "      <th>tof_1_v6</th>\n",
       "      <th>tof_1_v7</th>\n",
       "      <th>tof_1_v8</th>\n",
       "      <th>tof_1_v9</th>\n",
       "      <th>tof_1_v10</th>\n",
       "      <th>tof_1_v11</th>\n",
       "      <th>tof_1_v12</th>\n",
       "      <th>tof_1_v13</th>\n",
       "      <th>tof_1_v14</th>\n",
       "      <th>tof_1_v15</th>\n",
       "      <th>tof_1_v16</th>\n",
       "      <th>tof_1_v17</th>\n",
       "      <th>tof_1_v18</th>\n",
       "      <th>tof_1_v19</th>\n",
       "      <th>tof_1_v20</th>\n",
       "      <th>tof_1_v21</th>\n",
       "      <th>tof_1_v22</th>\n",
       "      <th>tof_1_v23</th>\n",
       "      <th>tof_1_v24</th>\n",
       "      <th>tof_1_v25</th>\n",
       "      <th>tof_1_v26</th>\n",
       "      <th>tof_1_v27</th>\n",
       "      <th>tof_1_v28</th>\n",
       "      <th>tof_1_v29</th>\n",
       "      <th>tof_1_v30</th>\n",
       "      <th>tof_1_v31</th>\n",
       "      <th>tof_1_v32</th>\n",
       "      <th>tof_1_v33</th>\n",
       "      <th>tof_1_v34</th>\n",
       "      <th>tof_1_v35</th>\n",
       "      <th>tof_1_v36</th>\n",
       "      <th>tof_1_v37</th>\n",
       "      <th>tof_1_v38</th>\n",
       "      <th>tof_1_v39</th>\n",
       "      <th>tof_1_v40</th>\n",
       "      <th>tof_1_v41</th>\n",
       "      <th>tof_1_v42</th>\n",
       "      <th>tof_1_v43</th>\n",
       "      <th>tof_1_v44</th>\n",
       "      <th>tof_1_v45</th>\n",
       "      <th>tof_1_v46</th>\n",
       "      <th>tof_1_v47</th>\n",
       "      <th>tof_1_v48</th>\n",
       "      <th>tof_1_v49</th>\n",
       "      <th>tof_1_v50</th>\n",
       "      <th>tof_1_v51</th>\n",
       "      <th>tof_1_v52</th>\n",
       "      <th>tof_1_v53</th>\n",
       "      <th>tof_1_v54</th>\n",
       "      <th>tof_1_v55</th>\n",
       "      <th>tof_1_v56</th>\n",
       "      <th>tof_1_v57</th>\n",
       "      <th>tof_1_v58</th>\n",
       "      <th>tof_1_v59</th>\n",
       "      <th>tof_1_v60</th>\n",
       "      <th>tof_1_v61</th>\n",
       "      <th>tof_1_v62</th>\n",
       "      <th>tof_1_v63</th>\n",
       "      <th>tof_2_v0</th>\n",
       "      <th>tof_2_v1</th>\n",
       "      <th>tof_2_v2</th>\n",
       "      <th>tof_2_v3</th>\n",
       "      <th>tof_2_v4</th>\n",
       "      <th>tof_2_v5</th>\n",
       "      <th>tof_2_v6</th>\n",
       "      <th>tof_2_v7</th>\n",
       "      <th>tof_2_v8</th>\n",
       "      <th>tof_2_v9</th>\n",
       "      <th>tof_2_v10</th>\n",
       "      <th>tof_2_v11</th>\n",
       "      <th>tof_2_v12</th>\n",
       "      <th>tof_2_v13</th>\n",
       "      <th>tof_2_v14</th>\n",
       "      <th>tof_2_v15</th>\n",
       "      <th>tof_2_v16</th>\n",
       "      <th>tof_2_v17</th>\n",
       "      <th>tof_2_v18</th>\n",
       "      <th>tof_2_v19</th>\n",
       "      <th>tof_2_v20</th>\n",
       "      <th>tof_2_v21</th>\n",
       "      <th>tof_2_v22</th>\n",
       "      <th>tof_2_v23</th>\n",
       "      <th>tof_2_v24</th>\n",
       "      <th>tof_2_v25</th>\n",
       "      <th>tof_2_v26</th>\n",
       "      <th>tof_2_v27</th>\n",
       "      <th>tof_2_v28</th>\n",
       "      <th>tof_2_v29</th>\n",
       "      <th>tof_2_v30</th>\n",
       "      <th>tof_2_v31</th>\n",
       "      <th>tof_2_v32</th>\n",
       "      <th>tof_2_v33</th>\n",
       "      <th>tof_2_v34</th>\n",
       "      <th>tof_2_v35</th>\n",
       "      <th>tof_2_v36</th>\n",
       "      <th>tof_2_v37</th>\n",
       "      <th>tof_2_v38</th>\n",
       "      <th>tof_2_v39</th>\n",
       "      <th>tof_2_v40</th>\n",
       "      <th>tof_2_v41</th>\n",
       "      <th>tof_2_v42</th>\n",
       "      <th>tof_2_v43</th>\n",
       "      <th>tof_2_v44</th>\n",
       "      <th>tof_2_v45</th>\n",
       "      <th>tof_2_v46</th>\n",
       "      <th>tof_2_v47</th>\n",
       "      <th>tof_2_v48</th>\n",
       "      <th>tof_2_v49</th>\n",
       "      <th>tof_2_v50</th>\n",
       "      <th>tof_2_v51</th>\n",
       "      <th>tof_2_v52</th>\n",
       "      <th>tof_2_v53</th>\n",
       "      <th>tof_2_v54</th>\n",
       "      <th>tof_2_v55</th>\n",
       "      <th>tof_2_v56</th>\n",
       "      <th>tof_2_v57</th>\n",
       "      <th>tof_2_v58</th>\n",
       "      <th>tof_2_v59</th>\n",
       "      <th>tof_2_v60</th>\n",
       "      <th>tof_2_v61</th>\n",
       "      <th>tof_2_v62</th>\n",
       "      <th>tof_2_v63</th>\n",
       "      <th>tof_3_v0</th>\n",
       "      <th>tof_3_v1</th>\n",
       "      <th>tof_3_v2</th>\n",
       "      <th>tof_3_v3</th>\n",
       "      <th>tof_3_v4</th>\n",
       "      <th>tof_3_v5</th>\n",
       "      <th>tof_3_v6</th>\n",
       "      <th>tof_3_v7</th>\n",
       "      <th>tof_3_v8</th>\n",
       "      <th>tof_3_v9</th>\n",
       "      <th>tof_3_v10</th>\n",
       "      <th>tof_3_v11</th>\n",
       "      <th>tof_3_v12</th>\n",
       "      <th>tof_3_v13</th>\n",
       "      <th>tof_3_v14</th>\n",
       "      <th>tof_3_v15</th>\n",
       "      <th>tof_3_v16</th>\n",
       "      <th>tof_3_v17</th>\n",
       "      <th>tof_3_v18</th>\n",
       "      <th>tof_3_v19</th>\n",
       "      <th>tof_3_v20</th>\n",
       "      <th>tof_3_v21</th>\n",
       "      <th>tof_3_v22</th>\n",
       "      <th>tof_3_v23</th>\n",
       "      <th>tof_3_v24</th>\n",
       "      <th>tof_3_v25</th>\n",
       "      <th>tof_3_v26</th>\n",
       "      <th>tof_3_v27</th>\n",
       "      <th>tof_3_v28</th>\n",
       "      <th>tof_3_v29</th>\n",
       "      <th>tof_3_v30</th>\n",
       "      <th>tof_3_v31</th>\n",
       "      <th>tof_3_v32</th>\n",
       "      <th>tof_3_v33</th>\n",
       "      <th>tof_3_v34</th>\n",
       "      <th>tof_3_v35</th>\n",
       "      <th>tof_3_v36</th>\n",
       "      <th>tof_3_v37</th>\n",
       "      <th>tof_3_v38</th>\n",
       "      <th>tof_3_v39</th>\n",
       "      <th>tof_3_v40</th>\n",
       "      <th>tof_3_v41</th>\n",
       "      <th>tof_3_v42</th>\n",
       "      <th>tof_3_v43</th>\n",
       "      <th>tof_3_v44</th>\n",
       "      <th>tof_3_v45</th>\n",
       "      <th>tof_3_v46</th>\n",
       "      <th>tof_3_v47</th>\n",
       "      <th>tof_3_v48</th>\n",
       "      <th>tof_3_v49</th>\n",
       "      <th>tof_3_v50</th>\n",
       "      <th>tof_3_v51</th>\n",
       "      <th>tof_3_v52</th>\n",
       "      <th>tof_3_v53</th>\n",
       "      <th>tof_3_v54</th>\n",
       "      <th>tof_3_v55</th>\n",
       "      <th>tof_3_v56</th>\n",
       "      <th>tof_3_v57</th>\n",
       "      <th>tof_3_v58</th>\n",
       "      <th>tof_3_v59</th>\n",
       "      <th>tof_3_v60</th>\n",
       "      <th>tof_3_v61</th>\n",
       "      <th>tof_3_v62</th>\n",
       "      <th>tof_3_v63</th>\n",
       "      <th>tof_4_v0</th>\n",
       "      <th>tof_4_v1</th>\n",
       "      <th>tof_4_v2</th>\n",
       "      <th>tof_4_v3</th>\n",
       "      <th>tof_4_v4</th>\n",
       "      <th>tof_4_v5</th>\n",
       "      <th>tof_4_v6</th>\n",
       "      <th>tof_4_v7</th>\n",
       "      <th>tof_4_v8</th>\n",
       "      <th>tof_4_v9</th>\n",
       "      <th>tof_4_v10</th>\n",
       "      <th>tof_4_v11</th>\n",
       "      <th>tof_4_v12</th>\n",
       "      <th>tof_4_v13</th>\n",
       "      <th>tof_4_v14</th>\n",
       "      <th>tof_4_v15</th>\n",
       "      <th>tof_4_v16</th>\n",
       "      <th>tof_4_v17</th>\n",
       "      <th>tof_4_v18</th>\n",
       "      <th>tof_4_v19</th>\n",
       "      <th>tof_4_v20</th>\n",
       "      <th>tof_4_v21</th>\n",
       "      <th>tof_4_v22</th>\n",
       "      <th>tof_4_v23</th>\n",
       "      <th>tof_4_v24</th>\n",
       "      <th>tof_4_v25</th>\n",
       "      <th>tof_4_v26</th>\n",
       "      <th>tof_4_v27</th>\n",
       "      <th>tof_4_v28</th>\n",
       "      <th>tof_4_v29</th>\n",
       "      <th>tof_4_v30</th>\n",
       "      <th>tof_4_v31</th>\n",
       "      <th>tof_4_v32</th>\n",
       "      <th>tof_4_v33</th>\n",
       "      <th>tof_4_v34</th>\n",
       "      <th>tof_4_v35</th>\n",
       "      <th>tof_4_v36</th>\n",
       "      <th>tof_4_v37</th>\n",
       "      <th>tof_4_v38</th>\n",
       "      <th>tof_4_v39</th>\n",
       "      <th>tof_4_v40</th>\n",
       "      <th>tof_4_v41</th>\n",
       "      <th>tof_4_v42</th>\n",
       "      <th>tof_4_v43</th>\n",
       "      <th>tof_4_v44</th>\n",
       "      <th>tof_4_v45</th>\n",
       "      <th>tof_4_v46</th>\n",
       "      <th>tof_4_v47</th>\n",
       "      <th>tof_4_v48</th>\n",
       "      <th>tof_4_v49</th>\n",
       "      <th>tof_4_v50</th>\n",
       "      <th>tof_4_v51</th>\n",
       "      <th>tof_4_v52</th>\n",
       "      <th>tof_4_v53</th>\n",
       "      <th>tof_4_v54</th>\n",
       "      <th>tof_4_v55</th>\n",
       "      <th>tof_4_v56</th>\n",
       "      <th>tof_4_v57</th>\n",
       "      <th>tof_4_v58</th>\n",
       "      <th>tof_4_v59</th>\n",
       "      <th>tof_4_v60</th>\n",
       "      <th>tof_4_v61</th>\n",
       "      <th>tof_4_v62</th>\n",
       "      <th>tof_4_v63</th>\n",
       "      <th>tof_5_v0</th>\n",
       "      <th>tof_5_v1</th>\n",
       "      <th>tof_5_v2</th>\n",
       "      <th>tof_5_v3</th>\n",
       "      <th>tof_5_v4</th>\n",
       "      <th>tof_5_v5</th>\n",
       "      <th>tof_5_v6</th>\n",
       "      <th>tof_5_v7</th>\n",
       "      <th>tof_5_v8</th>\n",
       "      <th>tof_5_v9</th>\n",
       "      <th>tof_5_v10</th>\n",
       "      <th>tof_5_v11</th>\n",
       "      <th>tof_5_v12</th>\n",
       "      <th>tof_5_v13</th>\n",
       "      <th>tof_5_v14</th>\n",
       "      <th>tof_5_v15</th>\n",
       "      <th>tof_5_v16</th>\n",
       "      <th>tof_5_v17</th>\n",
       "      <th>tof_5_v18</th>\n",
       "      <th>tof_5_v19</th>\n",
       "      <th>tof_5_v20</th>\n",
       "      <th>tof_5_v21</th>\n",
       "      <th>tof_5_v22</th>\n",
       "      <th>tof_5_v23</th>\n",
       "      <th>tof_5_v24</th>\n",
       "      <th>tof_5_v25</th>\n",
       "      <th>tof_5_v26</th>\n",
       "      <th>tof_5_v27</th>\n",
       "      <th>tof_5_v28</th>\n",
       "      <th>tof_5_v29</th>\n",
       "      <th>tof_5_v30</th>\n",
       "      <th>tof_5_v31</th>\n",
       "      <th>tof_5_v32</th>\n",
       "      <th>tof_5_v33</th>\n",
       "      <th>tof_5_v34</th>\n",
       "      <th>tof_5_v35</th>\n",
       "      <th>tof_5_v36</th>\n",
       "      <th>tof_5_v37</th>\n",
       "      <th>tof_5_v38</th>\n",
       "      <th>tof_5_v39</th>\n",
       "      <th>tof_5_v40</th>\n",
       "      <th>tof_5_v41</th>\n",
       "      <th>tof_5_v42</th>\n",
       "      <th>tof_5_v43</th>\n",
       "      <th>tof_5_v44</th>\n",
       "      <th>tof_5_v45</th>\n",
       "      <th>tof_5_v46</th>\n",
       "      <th>tof_5_v47</th>\n",
       "      <th>tof_5_v48</th>\n",
       "      <th>tof_5_v49</th>\n",
       "      <th>tof_5_v50</th>\n",
       "      <th>tof_5_v51</th>\n",
       "      <th>tof_5_v52</th>\n",
       "      <th>tof_5_v53</th>\n",
       "      <th>tof_5_v54</th>\n",
       "      <th>tof_5_v55</th>\n",
       "      <th>tof_5_v56</th>\n",
       "      <th>tof_5_v57</th>\n",
       "      <th>tof_5_v58</th>\n",
       "      <th>tof_5_v59</th>\n",
       "      <th>tof_5_v60</th>\n",
       "      <th>tof_5_v61</th>\n",
       "      <th>tof_5_v62</th>\n",
       "      <th>tof_5_v63</th>\n",
       "      <th>acc_mag</th>\n",
       "      <th>jerk</th>\n",
       "      <th>yaw</th>\n",
       "      <th>pitch</th>\n",
       "      <th>roll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEQ_000001_000003</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>3</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.773438</td>\n",
       "      <td>1.355469</td>\n",
       "      <td>-4.371094</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>-0.531982</td>\n",
       "      <td>-0.634033</td>\n",
       "      <td>-0.405823</td>\n",
       "      <td>31.043678</td>\n",
       "      <td>32.963718</td>\n",
       "      <td>29.661499</td>\n",
       "      <td>33.603333</td>\n",
       "      <td>29.308136</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10.791841</td>\n",
       "      <td>-0.278344</td>\n",
       "      <td>-97.675542</td>\n",
       "      <td>-3.435027</td>\n",
       "      <td>-111.752839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SEQ_000001_000005</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>5</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.425781</td>\n",
       "      <td>1.011719</td>\n",
       "      <td>-3.835938</td>\n",
       "      <td>0.382141</td>\n",
       "      <td>-0.537170</td>\n",
       "      <td>-0.638733</td>\n",
       "      <td>-0.396729</td>\n",
       "      <td>31.216425</td>\n",
       "      <td>33.055676</td>\n",
       "      <td>29.672804</td>\n",
       "      <td>33.603333</td>\n",
       "      <td>29.169149</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>10.226600</td>\n",
       "      <td>0.430536</td>\n",
       "      <td>-97.530082</td>\n",
       "      <td>-3.551933</td>\n",
       "      <td>-113.196135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SEQ_000001_000006</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>6</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.156250</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>-3.679688</td>\n",
       "      <td>0.373657</td>\n",
       "      <td>-0.542725</td>\n",
       "      <td>-0.645569</td>\n",
       "      <td>-0.386047</td>\n",
       "      <td>31.193876</td>\n",
       "      <td>33.059315</td>\n",
       "      <td>29.543169</td>\n",
       "      <td>33.648617</td>\n",
       "      <td>28.887142</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>9.908441</td>\n",
       "      <td>-0.318159</td>\n",
       "      <td>-97.578966</td>\n",
       "      <td>-3.635597</td>\n",
       "      <td>-115.057367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SEQ_000001_000009</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>9</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>8.968750</td>\n",
       "      <td>0.894531</td>\n",
       "      <td>-3.910156</td>\n",
       "      <td>0.372620</td>\n",
       "      <td>-0.544495</td>\n",
       "      <td>-0.649536</td>\n",
       "      <td>-0.377869</td>\n",
       "      <td>31.343843</td>\n",
       "      <td>32.933079</td>\n",
       "      <td>29.456949</td>\n",
       "      <td>33.489895</td>\n",
       "      <td>28.403872</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>230.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>9.824866</td>\n",
       "      <td>-0.037605</td>\n",
       "      <td>-97.452478</td>\n",
       "      <td>-4.161314</td>\n",
       "      <td>-115.969661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SEQ_000001_000011</td>\n",
       "      <td>SEQ_000001</td>\n",
       "      <td>11</td>\n",
       "      <td>SUBJ_055840</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.816406</td>\n",
       "      <td>-4.410156</td>\n",
       "      <td>0.359436</td>\n",
       "      <td>-0.529907</td>\n",
       "      <td>-0.659973</td>\n",
       "      <td>-0.393005</td>\n",
       "      <td>31.397932</td>\n",
       "      <td>32.894608</td>\n",
       "      <td>29.326990</td>\n",
       "      <td>33.452057</td>\n",
       "      <td>28.103935</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>10.055645</td>\n",
       "      <td>0.172377</td>\n",
       "      <td>-100.388523</td>\n",
       "      <td>-3.320584</td>\n",
       "      <td>-115.686103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>SEQ_000011_000046</td>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>46</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>-4.062500</td>\n",
       "      <td>8.613281</td>\n",
       "      <td>-3.140625</td>\n",
       "      <td>0.362488</td>\n",
       "      <td>0.176758</td>\n",
       "      <td>0.793274</td>\n",
       "      <td>0.456177</td>\n",
       "      <td>23.794315</td>\n",
       "      <td>23.865911</td>\n",
       "      <td>24.450621</td>\n",
       "      <td>24.088888</td>\n",
       "      <td>24.363342</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.027764</td>\n",
       "      <td>0.079257</td>\n",
       "      <td>175.738140</td>\n",
       "      <td>47.421754</td>\n",
       "      <td>-118.324905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>SEQ_000011_000047</td>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>47</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>-4.140625</td>\n",
       "      <td>8.535156</td>\n",
       "      <td>-3.410156</td>\n",
       "      <td>0.340637</td>\n",
       "      <td>0.166565</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>0.465088</td>\n",
       "      <td>23.802591</td>\n",
       "      <td>24.013430</td>\n",
       "      <td>24.728827</td>\n",
       "      <td>24.068518</td>\n",
       "      <td>24.231316</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.080815</td>\n",
       "      <td>0.053051</td>\n",
       "      <td>175.955482</td>\n",
       "      <td>44.421172</td>\n",
       "      <td>-117.999460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>SEQ_000011_000048</td>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>48</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>-4.214844</td>\n",
       "      <td>8.414062</td>\n",
       "      <td>-3.371094</td>\n",
       "      <td>0.341675</td>\n",
       "      <td>0.169312</td>\n",
       "      <td>0.799316</td>\n",
       "      <td>0.464417</td>\n",
       "      <td>23.759735</td>\n",
       "      <td>24.021555</td>\n",
       "      <td>24.915707</td>\n",
       "      <td>24.056049</td>\n",
       "      <td>24.272644</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>203.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>217.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.996281</td>\n",
       "      <td>-0.084534</td>\n",
       "      <td>176.233133</td>\n",
       "      <td>44.706591</td>\n",
       "      <td>-118.135896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>SEQ_000011_000049</td>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>49</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>-4.406250</td>\n",
       "      <td>8.957031</td>\n",
       "      <td>-3.292969</td>\n",
       "      <td>0.241699</td>\n",
       "      <td>0.135437</td>\n",
       "      <td>0.827820</td>\n",
       "      <td>0.487793</td>\n",
       "      <td>23.937767</td>\n",
       "      <td>24.121841</td>\n",
       "      <td>25.461512</td>\n",
       "      <td>24.211035</td>\n",
       "      <td>24.115343</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>154.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>202.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>209.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>247.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>10.511284</td>\n",
       "      <td>0.515003</td>\n",
       "      <td>179.217338</td>\n",
       "      <td>32.161187</td>\n",
       "      <td>-118.756929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>SEQ_000011_000050</td>\n",
       "      <td>SEQ_000011</td>\n",
       "      <td>50</td>\n",
       "      <td>SUBJ_016452</td>\n",
       "      <td>-3.949219</td>\n",
       "      <td>8.457031</td>\n",
       "      <td>-3.371094</td>\n",
       "      <td>0.302368</td>\n",
       "      <td>0.015930</td>\n",
       "      <td>-0.571106</td>\n",
       "      <td>-0.763000</td>\n",
       "      <td>28.038889</td>\n",
       "      <td>27.659178</td>\n",
       "      <td>27.454428</td>\n",
       "      <td>27.937756</td>\n",
       "      <td>24.870544</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>189.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>249.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>211.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>226.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.923809</td>\n",
       "      <td>-0.587475</td>\n",
       "      <td>-151.510139</td>\n",
       "      <td>-21.695485</td>\n",
       "      <td>-68.059432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows  341 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                row_id sequence_id  sequence_counter      subject     acc_x  \\\n",
       "3    SEQ_000001_000003  SEQ_000001                 3  SUBJ_055840  9.773438   \n",
       "5    SEQ_000001_000005  SEQ_000001                 5  SUBJ_055840  9.425781   \n",
       "6    SEQ_000001_000006  SEQ_000001                 6  SUBJ_055840  9.156250   \n",
       "9    SEQ_000001_000009  SEQ_000001                 9  SUBJ_055840  8.968750   \n",
       "11   SEQ_000001_000011  SEQ_000001                11  SUBJ_055840  9.000000   \n",
       "..                 ...         ...               ...          ...       ...   \n",
       "102  SEQ_000011_000046  SEQ_000011                46  SUBJ_016452 -4.062500   \n",
       "103  SEQ_000011_000047  SEQ_000011                47  SUBJ_016452 -4.140625   \n",
       "104  SEQ_000011_000048  SEQ_000011                48  SUBJ_016452 -4.214844   \n",
       "105  SEQ_000011_000049  SEQ_000011                49  SUBJ_016452 -4.406250   \n",
       "106  SEQ_000011_000050  SEQ_000011                50  SUBJ_016452 -3.949219   \n",
       "\n",
       "        acc_y     acc_z     rot_w     rot_x     rot_y     rot_z      thm_1  \\\n",
       "3    1.355469 -4.371094  0.387756 -0.531982 -0.634033 -0.405823  31.043678   \n",
       "5    1.011719 -3.835938  0.382141 -0.537170 -0.638733 -0.396729  31.216425   \n",
       "6    0.894531 -3.679688  0.373657 -0.542725 -0.645569 -0.386047  31.193876   \n",
       "9    0.894531 -3.910156  0.372620 -0.544495 -0.649536 -0.377869  31.343843   \n",
       "11   0.816406 -4.410156  0.359436 -0.529907 -0.659973 -0.393005  31.397932   \n",
       "..        ...       ...       ...       ...       ...       ...        ...   \n",
       "102  8.613281 -3.140625  0.362488  0.176758  0.793274  0.456177  23.794315   \n",
       "103  8.535156 -3.410156  0.340637  0.166565  0.799927  0.465088  23.802591   \n",
       "104  8.414062 -3.371094  0.341675  0.169312  0.799316  0.464417  23.759735   \n",
       "105  8.957031 -3.292969  0.241699  0.135437  0.827820  0.487793  23.937767   \n",
       "106  8.457031 -3.371094  0.302368  0.015930 -0.571106 -0.763000  28.038889   \n",
       "\n",
       "         thm_2      thm_3      thm_4      thm_5  tof_1_v0  tof_1_v1  tof_1_v2  \\\n",
       "3    32.963718  29.661499  33.603333  29.308136      -1.0      -1.0      -1.0   \n",
       "5    33.055676  29.672804  33.603333  29.169149      -1.0      -1.0      -1.0   \n",
       "6    33.059315  29.543169  33.648617  28.887142      -1.0      -1.0      -1.0   \n",
       "9    32.933079  29.456949  33.489895  28.403872      -1.0      -1.0      -1.0   \n",
       "11   32.894608  29.326990  33.452057  28.103935      -1.0      -1.0      -1.0   \n",
       "..         ...        ...        ...        ...       ...       ...       ...   \n",
       "102  23.865911  24.450621  24.088888  24.363342      -1.0      -1.0      -1.0   \n",
       "103  24.013430  24.728827  24.068518  24.231316      -1.0      -1.0      -1.0   \n",
       "104  24.021555  24.915707  24.056049  24.272644      -1.0      -1.0      -1.0   \n",
       "105  24.121841  25.461512  24.211035  24.115343      -1.0      -1.0      -1.0   \n",
       "106  27.659178  27.454428  27.937756  24.870544      -1.0      -1.0      -1.0   \n",
       "\n",
       "     tof_1_v3  tof_1_v4  tof_1_v5  tof_1_v6  tof_1_v7  tof_1_v8  tof_1_v9  \\\n",
       "3       214.0     228.0     228.0     163.0     145.0      -1.0     200.0   \n",
       "5        -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "6       215.0     227.0     241.0     177.0     148.0     164.0      -1.0   \n",
       "9        -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "11       -1.0     243.0     237.0     208.0     159.0      -1.0      -1.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "102      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "103      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "104      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "105      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "106      -1.0     204.0     173.0     138.0     133.0      -1.0      -1.0   \n",
       "\n",
       "     tof_1_v10  tof_1_v11  tof_1_v12  tof_1_v13  tof_1_v14  tof_1_v15  \\\n",
       "3        193.0      197.0      215.0      224.0      180.0      149.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6        203.0      193.0      203.0      215.0      200.0      156.0   \n",
       "9         -1.0       -1.0       -1.0      211.0       -1.0       -1.0   \n",
       "11       200.0       -1.0      200.0      212.0      224.0      158.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0      244.0      244.0      179.0      169.0      129.0   \n",
       "\n",
       "     tof_1_v16  tof_1_v17  tof_1_v18  tof_1_v19  tof_1_v20  tof_1_v21  \\\n",
       "3         -1.0      183.0      175.0      176.0      201.0      211.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6         -1.0       -1.0      176.0      176.0      192.0      201.0   \n",
       "9         -1.0       -1.0       -1.0      179.0       -1.0       -1.0   \n",
       "11        -1.0       -1.0      193.0      181.0      181.0      200.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0      233.0      189.0   \n",
       "\n",
       "     tof_1_v22  tof_1_v23  tof_1_v24  tof_1_v25  tof_1_v26  tof_1_v27  \\\n",
       "3        202.0      161.0      182.0      165.0      166.0      181.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6        210.0      167.0       -1.0      162.0      164.0      176.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0      162.0      170.0   \n",
       "11       203.0      178.0       -1.0      181.0      161.0      166.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106      168.0      152.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_1_v28  tof_1_v29  tof_1_v30  tof_1_v31  tof_1_v32  tof_1_v33  \\\n",
       "3        187.0      207.0       -1.0      181.0      151.0      151.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0      148.0   \n",
       "6        176.0      196.0      206.0       -1.0      152.0      149.0   \n",
       "9        182.0       -1.0      197.0       -1.0       -1.0      147.0   \n",
       "11       176.0      188.0      195.0       -1.0       -1.0      150.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0      197.0      184.0      152.0       -1.0       -1.0   \n",
       "\n",
       "     tof_1_v34  tof_1_v35  tof_1_v36  tof_1_v37  tof_1_v38  tof_1_v39  \\\n",
       "3        162.0      171.0      185.0      189.0       -1.0       -1.0   \n",
       "5        158.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6        154.0      163.0      172.0      177.0      191.0       -1.0   \n",
       "9        146.0      163.0      174.0       -1.0       -1.0       -1.0   \n",
       "11       153.0      161.0      173.0      185.0      201.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0      234.0      173.0      152.0   \n",
       "\n",
       "     tof_1_v40  tof_1_v41  tof_1_v42  tof_1_v43  tof_1_v44  tof_1_v45  \\\n",
       "3        137.0      144.0      148.0      161.0      177.0      152.0   \n",
       "5        132.0      137.0      142.0       -1.0       -1.0       -1.0   \n",
       "6        129.0      134.0      143.0      154.0      169.0      177.0   \n",
       "9        128.0      134.0      140.0      149.0      159.0       -1.0   \n",
       "11       134.0      136.0      143.0      148.0      158.0      173.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0      236.0   \n",
       "\n",
       "     tof_1_v46  tof_1_v47  tof_1_v48  tof_1_v49  tof_1_v50  tof_1_v51  \\\n",
       "3         -1.0       -1.0      123.0      132.0      141.0      129.0   \n",
       "5         -1.0       -1.0      120.0      128.0      135.0       -1.0   \n",
       "6         -1.0       -1.0      121.0      127.0      130.0      140.0   \n",
       "9         -1.0       -1.0      123.0      122.0      135.0      139.0   \n",
       "11        -1.0       -1.0      124.0      127.0      134.0      143.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106      206.0      149.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_1_v52  tof_1_v53  tof_1_v54  tof_1_v55  tof_1_v56  tof_1_v57  \\\n",
       "3        120.0       93.0       77.0       68.0      113.0      109.0   \n",
       "5         -1.0       96.0       79.0       67.0      110.0      112.0   \n",
       "6        142.0      137.0       -1.0       76.0      111.0      117.0   \n",
       "9        159.0       -1.0       -1.0       -1.0      106.0      112.0   \n",
       "11       151.0      167.0       -1.0       -1.0      111.0      114.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0      249.0      186.0      143.0       -1.0       -1.0   \n",
       "\n",
       "     tof_1_v58  tof_1_v59  tof_1_v60  tof_1_v61  tof_1_v62  tof_1_v63  \\\n",
       "3         97.0       85.0       77.0       68.0       61.0       54.0   \n",
       "5         98.0       90.0       78.0       66.0       59.0       53.0   \n",
       "6        107.0       98.0       82.0       71.0       62.0       56.0   \n",
       "9        117.0      109.0       97.0       82.0       68.0       58.0   \n",
       "11       122.0      121.0      112.0      100.0       81.0       69.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0      145.0   \n",
       "\n",
       "     tof_2_v0  tof_2_v1  tof_2_v2  tof_2_v3  tof_2_v4  tof_2_v5  tof_2_v6  \\\n",
       "3        -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "5        -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "6        -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "9        -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "11       -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "102      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "103      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "104      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "105      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "106      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "\n",
       "     tof_2_v7  tof_2_v8  tof_2_v9  tof_2_v10  tof_2_v11  tof_2_v12  tof_2_v13  \\\n",
       "3        -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "5        -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6        -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "9        -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11       -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..        ...       ...       ...        ...        ...        ...        ...   \n",
       "102      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v14  tof_2_v15  tof_2_v16  tof_2_v17  tof_2_v18  tof_2_v19  \\\n",
       "3         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v20  tof_2_v21  tof_2_v22  tof_2_v23  tof_2_v24  tof_2_v25  \\\n",
       "3         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v26  tof_2_v27  tof_2_v28  tof_2_v29  tof_2_v30  tof_2_v31  \\\n",
       "3         -1.0       -1.0       -1.0       58.0       57.0       53.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       55.0       56.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0       57.0       57.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0       -1.0       59.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0       -1.0       62.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v32  tof_2_v33  tof_2_v34  tof_2_v35  tof_2_v36  tof_2_v37  \\\n",
       "3         -1.0       -1.0       -1.0       -1.0       -1.0       57.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0       59.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0       -1.0       61.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0       -1.0       60.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0       -1.0       61.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v38  tof_2_v39  tof_2_v40  tof_2_v41  tof_2_v42  tof_2_v43  \\\n",
       "3         52.0       50.0       -1.0       -1.0       -1.0       -1.0   \n",
       "5         57.0       53.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6         54.0       54.0       -1.0       -1.0       -1.0       -1.0   \n",
       "9         57.0       54.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11        57.0       55.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v44  tof_2_v45  tof_2_v46  tof_2_v47  tof_2_v48  tof_2_v49  \\\n",
       "3         57.0       59.0       54.0       54.0       24.0       25.0   \n",
       "5         -1.0       58.0       55.0       53.0       27.0       27.0   \n",
       "6         -1.0       58.0       55.0       54.0       29.0       28.0   \n",
       "9         -1.0       59.0       54.0       54.0       -1.0       34.0   \n",
       "11        61.0       58.0       55.0       53.0       -1.0       42.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v50  tof_2_v51  tof_2_v52  tof_2_v53  tof_2_v54  tof_2_v55  \\\n",
       "3         26.0       28.0       42.0       54.0       57.0       54.0   \n",
       "5         24.0       29.0       38.0       -1.0       55.0       55.0   \n",
       "6         25.0       28.0       33.0       -1.0       55.0       56.0   \n",
       "9         28.0       26.0       36.0       54.0       56.0       51.0   \n",
       "11        31.0       37.0       52.0       57.0       55.0       52.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v56  tof_2_v57  tof_2_v58  tof_2_v59  tof_2_v60  tof_2_v61  \\\n",
       "3         13.0       19.0       19.0       24.0       21.0       29.0   \n",
       "5         18.0       21.0       21.0       25.0       26.0       24.0   \n",
       "6         21.0       20.0       19.0       22.0       23.0       26.0   \n",
       "9         21.0       19.0       20.0       23.0       24.0       29.0   \n",
       "11        25.0       23.0       20.0       29.0       27.0       36.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_2_v62  tof_2_v63  tof_3_v0  tof_3_v1  tof_3_v2  tof_3_v3  tof_3_v4  \\\n",
       "3         -1.0       50.0     137.0     145.0     156.0     167.0     197.0   \n",
       "5         -1.0       -1.0     137.0     142.0     153.0     165.0     195.0   \n",
       "6         -1.0       50.0     134.0     139.0     147.0     170.0     187.0   \n",
       "9         45.0       49.0     133.0     135.0     144.0     167.0     184.0   \n",
       "11        51.0       49.0     128.0     128.0     138.0     155.0     174.0   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "102       -1.0      109.0     150.0     154.0     165.0     159.0     168.0   \n",
       "103       -1.0      111.0     151.0     160.0     163.0     163.0     174.0   \n",
       "104       -1.0      100.0     146.0     152.0     156.0     152.0     159.0   \n",
       "105       -1.0       95.0     135.0     146.0     154.0     147.0     134.0   \n",
       "106       -1.0       96.0     137.0     146.0     156.0     147.0     137.0   \n",
       "\n",
       "     tof_3_v5  tof_3_v6  tof_3_v7  tof_3_v8  tof_3_v9  tof_3_v10  tof_3_v11  \\\n",
       "3       195.0     142.0      67.0     135.0     148.0      161.0      185.0   \n",
       "5       189.0     162.0      66.0     134.0     143.0      162.0      179.0   \n",
       "6       178.0     171.0      79.0     132.0     142.0      161.0      176.0   \n",
       "9       173.0     169.0      92.0     131.0     141.0      153.0      179.0   \n",
       "11      178.0     162.0     164.0     131.0     138.0      152.0      172.0   \n",
       "..        ...       ...       ...       ...       ...        ...        ...   \n",
       "102     168.0     159.0     201.0     183.0     189.0      196.0      213.0   \n",
       "103     168.0     158.0     204.0     188.0     185.0      206.0      219.0   \n",
       "104     162.0     157.0     200.0     184.0     180.0      203.0      210.0   \n",
       "105     132.0     134.0     173.0     171.0     172.0      180.0      183.0   \n",
       "106     140.0     139.0     184.0     170.0     173.0      179.0      188.0   \n",
       "\n",
       "     tof_3_v12  tof_3_v13  tof_3_v14  tof_3_v15  tof_3_v16  tof_3_v17  \\\n",
       "3        193.0      181.0      174.0       70.0      139.0      156.0   \n",
       "5        187.0      179.0      172.0       70.0      138.0      154.0   \n",
       "6        190.0      176.0      174.0       95.0      140.0      155.0   \n",
       "9        178.0      168.0      177.0      108.0      140.0      156.0   \n",
       "11       180.0      167.0      170.0      154.0      137.0      147.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102      221.0      231.0      234.0       -1.0       -1.0       -1.0   \n",
       "103      223.0      229.0      233.0      219.0       -1.0       -1.0   \n",
       "104      210.0      217.0      240.0       -1.0      242.0      242.0   \n",
       "105      202.0      206.0      209.0       -1.0      220.0      218.0   \n",
       "106      206.0      211.0      218.0       -1.0      226.0      228.0   \n",
       "\n",
       "     tof_3_v18  tof_3_v19  tof_3_v20  tof_3_v21  tof_3_v22  tof_3_v23  \\\n",
       "3        174.0      182.0      191.0      176.0      172.0       75.0   \n",
       "5        173.0      184.0      177.0      171.0      172.0       73.0   \n",
       "6        171.0      179.0      172.0      178.0      182.0       98.0   \n",
       "9        170.0      174.0      172.0      179.0      202.0      113.0   \n",
       "11       163.0      172.0      170.0      173.0      209.0      154.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105      247.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106      243.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_3_v24  tof_3_v25  tof_3_v26  tof_3_v27  tof_3_v28  tof_3_v29  \\\n",
       "3        149.0      170.0      176.0      184.0      175.0      172.0   \n",
       "5        151.0      170.0      177.0      182.0      175.0      188.0   \n",
       "6        152.0      170.0      173.0      180.0      181.0       -1.0   \n",
       "9        156.0      168.0      172.0      168.0      184.0       -1.0   \n",
       "11       158.0      168.0      166.0      169.0      177.0      191.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_3_v30  tof_3_v31  tof_3_v32  tof_3_v33  tof_3_v34  tof_3_v35  \\\n",
       "3        166.0       77.0      163.0      174.0      181.0      182.0   \n",
       "5        171.0       77.0      160.0      169.0      174.0      179.0   \n",
       "6        192.0      109.0      156.0      166.0      172.0      181.0   \n",
       "9         -1.0      129.0      158.0      167.0      171.0      190.0   \n",
       "11        -1.0      152.0      158.0      164.0      166.0      178.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_3_v36  tof_3_v37  tof_3_v38  tof_3_v39  tof_3_v40  tof_3_v41  \\\n",
       "3        188.0       -1.0      166.0       81.0      156.0      167.0   \n",
       "5        198.0       -1.0      160.0       79.0      159.0      168.0   \n",
       "6         -1.0       -1.0       -1.0      105.0      169.0      184.0   \n",
       "9         -1.0       -1.0       -1.0      126.0      166.0      185.0   \n",
       "11       210.0       -1.0       -1.0      153.0      174.0      178.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_3_v42  tof_3_v43  tof_3_v44  tof_3_v45  tof_3_v46  tof_3_v47  \\\n",
       "3        171.0      199.0       -1.0       -1.0      157.0       79.0   \n",
       "5        183.0      205.0       -1.0       -1.0       -1.0       83.0   \n",
       "6        193.0       -1.0       -1.0       -1.0       -1.0      113.0   \n",
       "9        197.0      225.0       -1.0       -1.0       -1.0      135.0   \n",
       "11       188.0      217.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_3_v48  tof_3_v49  tof_3_v50  tof_3_v51  tof_3_v52  tof_3_v53  \\\n",
       "3        171.0      188.0      207.0       -1.0       -1.0       -1.0   \n",
       "5        184.0      193.0      213.0      224.0       -1.0       -1.0   \n",
       "6        208.0      221.0      212.0      223.0      205.0       -1.0   \n",
       "9        210.0      216.0      213.0      213.0      203.0       -1.0   \n",
       "11       209.0      214.0      217.0      216.0      210.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_3_v54  tof_3_v55  tof_3_v56  tof_3_v57  tof_3_v58  tof_3_v59  \\\n",
       "3         -1.0       77.0      222.0      211.0      193.0      197.0   \n",
       "5         -1.0       78.0      219.0      200.0      190.0      190.0   \n",
       "6         -1.0      105.0      217.0      194.0      185.0      182.0   \n",
       "9         -1.0      127.0      216.0      191.0      179.0      182.0   \n",
       "11        -1.0       -1.0      216.0      200.0      190.0      184.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_3_v60  tof_3_v61  tof_3_v62  tof_3_v63  tof_4_v0  tof_4_v1  tof_4_v2  \\\n",
       "3        199.0      197.0       -1.0       81.0     188.0     154.0     162.0   \n",
       "5        186.0      187.0       -1.0       87.0      -1.0     157.0     154.0   \n",
       "6        177.0      184.0      178.0      115.0     188.0     158.0     152.0   \n",
       "9        175.0      166.0      168.0      130.0      -1.0     156.0     150.0   \n",
       "11       180.0      181.0      172.0      161.0     185.0     152.0     151.0   \n",
       "..         ...        ...        ...        ...       ...       ...       ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0      -1.0      -1.0      -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0      -1.0      -1.0      -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0      -1.0      -1.0      -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0      -1.0      -1.0      -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0      -1.0      -1.0      -1.0   \n",
       "\n",
       "     tof_4_v3  tof_4_v4  tof_4_v5  tof_4_v6  tof_4_v7  tof_4_v8  tof_4_v9  \\\n",
       "3       173.0     190.0     209.0      -1.0      -1.0     180.0     204.0   \n",
       "5       169.0     178.0     188.0      -1.0      -1.0      -1.0     205.0   \n",
       "6       162.0     178.0     186.0      -1.0      -1.0      -1.0     206.0   \n",
       "9       157.0     174.0     179.0     230.0      -1.0     181.0      -1.0   \n",
       "11      161.0     172.0     178.0     218.0      -1.0     182.0     208.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "102      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "103      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "104      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "105      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "106      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "\n",
       "     tof_4_v10  tof_4_v11  tof_4_v12  tof_4_v13  tof_4_v14  tof_4_v15  \\\n",
       "3        194.0      204.0      211.0       -1.0       -1.0       -1.0   \n",
       "5        189.0      200.0      205.0      221.0       -1.0       -1.0   \n",
       "6        188.0      198.0      201.0      211.0       -1.0      248.0   \n",
       "9        188.0      184.0      199.0      208.0       -1.0      249.0   \n",
       "11       187.0      192.0      196.0      201.0      246.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v16  tof_4_v17  tof_4_v18  tof_4_v19  tof_4_v20  tof_4_v21  \\\n",
       "3         -1.0      218.0      233.0      232.0      244.0       -1.0   \n",
       "5         -1.0      211.0      214.0      232.0      240.0       -1.0   \n",
       "6         -1.0      210.0      215.0      226.0      220.0      243.0   \n",
       "9         -1.0      215.0      219.0      216.0      225.0      241.0   \n",
       "11        -1.0      215.0      227.0      213.0      225.0      232.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v22  tof_4_v23  tof_4_v24  tof_4_v25  tof_4_v26  tof_4_v27  \\\n",
       "3        247.0      217.0       -1.0       -1.0       -1.0       -1.0   \n",
       "5         -1.0      221.0       -1.0       -1.0      245.0       -1.0   \n",
       "6         -1.0      229.0       -1.0      224.0      238.0       -1.0   \n",
       "9         -1.0      227.0       -1.0       -1.0      235.0       -1.0   \n",
       "11        -1.0      235.0       -1.0      227.0      242.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v28  tof_4_v29  tof_4_v30  tof_4_v31  tof_4_v32  tof_4_v33  \\\n",
       "3         -1.0       -1.0      229.0      169.0       -1.0       -1.0   \n",
       "5         -1.0       -1.0      226.0      206.0       -1.0       -1.0   \n",
       "6         -1.0       -1.0      241.0      212.0       -1.0       -1.0   \n",
       "9         -1.0       -1.0      247.0      212.0       -1.0       -1.0   \n",
       "11        -1.0       -1.0      242.0      220.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v34  tof_4_v35  tof_4_v36  tof_4_v37  tof_4_v38  tof_4_v39  \\\n",
       "3         -1.0       -1.0       -1.0       -1.0      217.0      164.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0      231.0      174.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0      232.0      183.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0      242.0      191.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0      233.0      187.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v40  tof_4_v41  tof_4_v42  tof_4_v43  tof_4_v44  tof_4_v45  \\\n",
       "3         -1.0       -1.0      246.0      244.0       -1.0       -1.0   \n",
       "5        194.0       -1.0      240.0      243.0       -1.0       -1.0   \n",
       "6        178.0       -1.0      246.0       -1.0       -1.0       -1.0   \n",
       "9        182.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11       189.0       -1.0      249.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v46  tof_4_v47  tof_4_v48  tof_4_v49  tof_4_v50  tof_4_v51  \\\n",
       "3        189.0      161.0      186.0      199.0      209.0      207.0   \n",
       "5        197.0      165.0      173.0      196.0      210.0      204.0   \n",
       "6        215.0      169.0      163.0      210.0      208.0      209.0   \n",
       "9        231.0      166.0      160.0       -1.0      209.0      211.0   \n",
       "11       213.0      162.0      174.0      204.0      212.0      216.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v52  tof_4_v53  tof_4_v54  tof_4_v55  tof_4_v56  tof_4_v57  \\\n",
       "3        227.0      238.0      195.0      152.0      179.0      168.0   \n",
       "5        215.0      228.0      211.0      152.0      174.0      178.0   \n",
       "6        213.0      215.0      216.0      167.0      173.0      180.0   \n",
       "9        209.0      216.0      225.0      164.0      167.0      178.0   \n",
       "11       215.0      232.0      208.0      158.0      172.0      186.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_4_v58  tof_4_v59  tof_4_v60  tof_4_v61  tof_4_v62  tof_4_v63  \\\n",
       "3        167.0      177.0      196.0      198.0      207.0      160.0   \n",
       "5        171.0      178.0      188.0      192.0      214.0      174.0   \n",
       "6        175.0      166.0      176.0      192.0      199.0      186.0   \n",
       "9        183.0      170.0      182.0      184.0      192.0      184.0   \n",
       "11       180.0      184.0      190.0      193.0      201.0      161.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v0  tof_5_v1  tof_5_v2  tof_5_v3  tof_5_v4  tof_5_v5  tof_5_v6  \\\n",
       "3       189.0     171.0     164.0     158.0     152.0     146.0     140.0   \n",
       "5       192.0     170.0     161.0     155.0     147.0     139.0     134.0   \n",
       "6       193.0     164.0     158.0     153.0     142.0     136.0     132.0   \n",
       "9       198.0     164.0     154.0     143.0     135.0     128.0     130.0   \n",
       "11      217.0     169.0     163.0     152.0     142.0     135.0     126.0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "102      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "103      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "104      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "105      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "106      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0      -1.0   \n",
       "\n",
       "     tof_5_v7  tof_5_v8  tof_5_v9  tof_5_v10  tof_5_v11  tof_5_v12  tof_5_v13  \\\n",
       "3       103.0     208.0     186.0      174.0      167.0      157.0      145.0   \n",
       "5       112.0     208.0     192.0      172.0      164.0      152.0      138.0   \n",
       "6       122.0      -1.0     193.0      176.0      162.0      147.0      138.0   \n",
       "9       119.0      -1.0     188.0      180.0      155.0      146.0      134.0   \n",
       "11      128.0      -1.0     187.0      188.0      158.0      152.0      134.0   \n",
       "..        ...       ...       ...        ...        ...        ...        ...   \n",
       "102      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106      -1.0      -1.0      -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v14  tof_5_v15  tof_5_v16  tof_5_v17  tof_5_v18  tof_5_v19  \\\n",
       "3        141.0      118.0       -1.0      214.0      207.0      173.0   \n",
       "5        136.0      122.0       -1.0      201.0      198.0      169.0   \n",
       "6        129.0      128.0       -1.0       -1.0       -1.0      190.0   \n",
       "9        125.0      122.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11       129.0      120.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v20  tof_5_v21  tof_5_v22  tof_5_v23  tof_5_v24  tof_5_v25  \\\n",
       "3        165.0      152.0      142.0      129.0       -1.0       -1.0   \n",
       "5        163.0      147.0      138.0      125.0       -1.0       -1.0   \n",
       "6        157.0      150.0      136.0      122.0       -1.0       -1.0   \n",
       "9        165.0      140.0      129.0      120.0       -1.0       -1.0   \n",
       "11       163.0      144.0      135.0      124.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v26  tof_5_v27  tof_5_v28  tof_5_v29  tof_5_v30  tof_5_v31  \\\n",
       "3         -1.0       -1.0      171.0      160.0      141.0      135.0   \n",
       "5         -1.0       -1.0      170.0      155.0      142.0      128.0   \n",
       "6         -1.0       -1.0       -1.0      161.0      143.0      132.0   \n",
       "9         -1.0       -1.0       -1.0      162.0      142.0      132.0   \n",
       "11        -1.0       -1.0       -1.0      164.0      144.0      130.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v32  tof_5_v33  tof_5_v34  tof_5_v35  tof_5_v36  tof_5_v37  \\\n",
       "3         -1.0       -1.0       -1.0       -1.0       -1.0      169.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0      170.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v38  tof_5_v39  tof_5_v40  tof_5_v41  tof_5_v42  tof_5_v43  \\\n",
       "3        156.0      145.0       -1.0       -1.0       -1.0       -1.0   \n",
       "5        149.0      145.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6        158.0      142.0       -1.0       -1.0       -1.0       -1.0   \n",
       "9        156.0      141.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11       161.0      141.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v44  tof_5_v45  tof_5_v46  tof_5_v47  tof_5_v48  tof_5_v49  \\\n",
       "3         -1.0       -1.0      170.0      152.0       -1.0       -1.0   \n",
       "5         -1.0       -1.0      163.0      152.0       -1.0       -1.0   \n",
       "6         -1.0       -1.0       -1.0      156.0       -1.0       -1.0   \n",
       "9         -1.0       -1.0       -1.0      151.0       -1.0       -1.0   \n",
       "11        -1.0       -1.0       -1.0      153.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v50  tof_5_v51  tof_5_v52  tof_5_v53  tof_5_v54  tof_5_v55  \\\n",
       "3         -1.0       -1.0       -1.0       -1.0       -1.0      160.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0      159.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0       -1.0      164.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0       -1.0      170.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0       -1.0      168.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v56  tof_5_v57  tof_5_v58  tof_5_v59  tof_5_v60  tof_5_v61  \\\n",
       "3         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "5         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "6         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "9         -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "11        -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "102       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "103       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "104       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "105       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "106       -1.0       -1.0       -1.0       -1.0       -1.0       -1.0   \n",
       "\n",
       "     tof_5_v62  tof_5_v63    acc_mag      jerk         yaw      pitch  \\\n",
       "3        197.0      183.0  10.791841 -0.278344  -97.675542  -3.435027   \n",
       "5        197.0      175.0  10.226600  0.430536  -97.530082  -3.551933   \n",
       "6         -1.0      182.0   9.908441 -0.318159  -97.578966  -3.635597   \n",
       "9         -1.0      179.0   9.824866 -0.037605  -97.452478  -4.161314   \n",
       "11        -1.0      184.0  10.055645  0.172377 -100.388523  -3.320584   \n",
       "..         ...        ...        ...       ...         ...        ...   \n",
       "102       -1.0       -1.0  10.027764  0.079257  175.738140  47.421754   \n",
       "103       -1.0       -1.0  10.080815  0.053051  175.955482  44.421172   \n",
       "104       -1.0       -1.0   9.996281 -0.084534  176.233133  44.706591   \n",
       "105       -1.0       -1.0  10.511284  0.515003  179.217338  32.161187   \n",
       "106       -1.0       -1.0   9.923809 -0.587475 -151.510139 -21.695485   \n",
       "\n",
       "           roll  \n",
       "3   -111.752839  \n",
       "5   -113.196135  \n",
       "6   -115.057367  \n",
       "9   -115.969661  \n",
       "11  -115.686103  \n",
       "..          ...  \n",
       "102 -118.324905  \n",
       "103 -117.999460  \n",
       "104 -118.135896  \n",
       "105 -118.756929  \n",
       "106  -68.059432  \n",
       "\n",
       "[62 rows x 341 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test['tof_1_v0'] == -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65412bde",
   "metadata": {},
   "source": [
    "## XGB with OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b439ae46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teklif_bilisim/.pyenv/versions/stabil/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-13 20:12:52,861] A new study created in memory with name: no-name-77d7aa5f-01d3-42a0-b47a-7e5325dc7f1a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING IMU MODEL WITH OPTUNA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-13 20:15:36,355] Trial 0 finished with value: 0.6801031006131991 and parameters: {'max_depth': 9, 'min_child_weight': 3.709758215822068, 'gamma': 1.091490597134129, 'colsample_bytree': 0.7874834568406306, 'subsample': 0.7550573771466548, 'reg_lambda': 1.4143985697424324, 'reg_alpha': 1.0568475273442546, 'learning_rate': 0.028458398207429878, 'n_estimators': 1600, 'max_delta_step': 0}. Best is trial 0 with value: 0.6801031006131991.\n",
      "[I 2025-06-13 20:18:35,252] Trial 1 finished with value: 0.6792086888987721 and parameters: {'max_depth': 6, 'min_child_weight': 0.2518139952407489, 'gamma': 0.9177120332390445, 'colsample_bytree': 0.8528418409414399, 'subsample': 0.8043533952359618, 'reg_lambda': 0.6290724107863149, 'reg_alpha': 0.3905589445017583, 'learning_rate': 0.020386001295025127, 'n_estimators': 900, 'max_delta_step': 1}. Best is trial 0 with value: 0.6801031006131991.\n",
      "[I 2025-06-13 20:21:59,649] Trial 2 finished with value: 0.6784767726877511 and parameters: {'max_depth': 7, 'min_child_weight': 1.689181253573603, 'gamma': 0.8152308649114262, 'colsample_bytree': 0.8029047957230576, 'subsample': 0.8858806711615688, 'reg_lambda': 0.5269185002083432, 'reg_alpha': 1.6383153824299648, 'learning_rate': 0.0214931504343938, 'n_estimators': 1400, 'max_delta_step': 4}. Best is trial 0 with value: 0.6801031006131991.\n",
      "[I 2025-06-13 20:23:13,100] Trial 3 finished with value: 0.673986110517156 and parameters: {'max_depth': 11, 'min_child_weight': 0.24531767046991448, 'gamma': 1.782445906612618, 'colsample_bytree': 0.8434614152328751, 'subsample': 0.8605110118247943, 'reg_lambda': 0.5183748728523334, 'reg_alpha': 0.5149287508523737, 'learning_rate': 0.05879226798661669, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 0 with value: 0.6801031006131991.\n",
      "[I 2025-06-13 20:25:59,652] Trial 4 finished with value: 0.6793196139107259 and parameters: {'max_depth': 8, 'min_child_weight': 1.2313676287620074, 'gamma': 1.5143254926658276, 'colsample_bytree': 0.8917303537215576, 'subsample': 0.8887133427829732, 'reg_lambda': 1.7113461201595206, 'reg_alpha': 0.4199937887363616, 'learning_rate': 0.021800221305016233, 'n_estimators': 1300, 'max_delta_step': 4}. Best is trial 0 with value: 0.6801031006131991.\n",
      "[I 2025-06-13 20:28:58,470] Trial 5 finished with value: 0.6771858520865748 and parameters: {'max_depth': 7, 'min_child_weight': 0.10671175340095716, 'gamma': 1.601753353269776, 'colsample_bytree': 0.7822629554846342, 'subsample': 0.7538645932570252, 'reg_lambda': 1.713138581701792, 'reg_alpha': 1.5521809377392237, 'learning_rate': 0.022574640283538203, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 0 with value: 0.6801031006131991.\n",
      "[I 2025-06-13 20:31:55,024] Trial 6 finished with value: 0.6821501395584524 and parameters: {'max_depth': 6, 'min_child_weight': 0.3615955285213718, 'gamma': 0.34583740696094556, 'colsample_bytree': 0.6649471533325019, 'subsample': 0.850735538509039, 'reg_lambda': 2.9030526320592047, 'reg_alpha': 1.3988495292055174, 'learning_rate': 0.07389130622655438, 'n_estimators': 1400, 'max_delta_step': 3}. Best is trial 6 with value: 0.6821501395584524.\n",
      "[I 2025-06-13 20:34:39,549] Trial 7 finished with value: 0.676153320207419 and parameters: {'max_depth': 8, 'min_child_weight': 2.378946839153006, 'gamma': 1.5511384385471525, 'colsample_bytree': 0.7571032059039164, 'subsample': 0.7057373513319936, 'reg_lambda': 5.638744427348996, 'reg_alpha': 0.8550244727809002, 'learning_rate': 0.07882880650321279, 'n_estimators': 1600, 'max_delta_step': 1}. Best is trial 6 with value: 0.6821501395584524.\n",
      "[I 2025-06-13 20:37:08,762] Trial 8 finished with value: 0.67472797971627 and parameters: {'max_depth': 9, 'min_child_weight': 0.20833133101121445, 'gamma': 1.5539516544514473, 'colsample_bytree': 0.6794211600098186, 'subsample': 0.8100756163451774, 'reg_lambda': 0.14789915316189442, 'reg_alpha': 1.7568091680009894, 'learning_rate': 0.07129392682153284, 'n_estimators': 1500, 'max_delta_step': 3}. Best is trial 6 with value: 0.6821501395584524.\n",
      "[I 2025-06-13 20:40:26,183] Trial 9 finished with value: 0.6768712864936208 and parameters: {'max_depth': 10, 'min_child_weight': 0.16405345774096206, 'gamma': 1.6027313773197804, 'colsample_bytree': 0.7377049797588046, 'subsample': 0.7139186921994183, 'reg_lambda': 1.241239997998206, 'reg_alpha': 0.43739475517226145, 'learning_rate': 0.028722573131504545, 'n_estimators': 1000, 'max_delta_step': 2}. Best is trial 6 with value: 0.6821501395584524.\n",
      "[I 2025-06-13 20:44:34,305] Trial 10 finished with value: 0.6843125594693452 and parameters: {'max_depth': 6, 'min_child_weight': 0.5981225237027591, 'gamma': 0.08076345514683558, 'colsample_bytree': 0.6111368859276324, 'subsample': 0.8358732676716414, 'reg_lambda': 8.815901216969023, 'reg_alpha': 1.283988201893822, 'learning_rate': 0.04807187754027058, 'n_estimators': 600, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 20:49:02,517] Trial 11 finished with value: 0.6826657669820948 and parameters: {'max_depth': 6, 'min_child_weight': 0.5699344567628059, 'gamma': 0.06202610753700573, 'colsample_bytree': 0.6075509223750182, 'subsample': 0.8373883497619787, 'reg_lambda': 8.774837129325581, 'reg_alpha': 1.2884942582041323, 'learning_rate': 0.04759158729458525, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 20:53:03,067] Trial 12 finished with value: 0.6805056274843936 and parameters: {'max_depth': 6, 'min_child_weight': 0.6102330697435249, 'gamma': 0.034624981409257335, 'colsample_bytree': 0.6132247658739446, 'subsample': 0.8302315726566777, 'reg_lambda': 7.86999527903174, 'reg_alpha': 1.1351326252346787, 'learning_rate': 0.045108707637788056, 'n_estimators': 600, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 20:58:22,424] Trial 13 finished with value: 0.682184708241756 and parameters: {'max_depth': 7, 'min_child_weight': 0.6756481511937564, 'gamma': 0.10088790027406844, 'colsample_bytree': 0.6031549380992801, 'subsample': 0.7744633466476739, 'reg_lambda': 9.620072063135812, 'reg_alpha': 1.9674588140055504, 'learning_rate': 0.04489641953918838, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:00:51,389] Trial 14 finished with value: 0.6833256613745549 and parameters: {'max_depth': 6, 'min_child_weight': 0.4855917771564933, 'gamma': 0.467426984531481, 'colsample_bytree': 0.6515966264639947, 'subsample': 0.840238144413884, 'reg_lambda': 3.7607230840642956, 'reg_alpha': 1.284772259073473, 'learning_rate': 0.05483102142662002, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:03:05,222] Trial 15 finished with value: 0.6812471169254012 and parameters: {'max_depth': 8, 'min_child_weight': 1.0568686758370027, 'gamma': 0.5361597339515242, 'colsample_bytree': 0.6689319144912889, 'subsample': 0.8672329798767577, 'reg_lambda': 3.8089900625159316, 'reg_alpha': 0.8108435561751951, 'learning_rate': 0.056556539290492445, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:06:59,819] Trial 16 finished with value: 0.6806706238665788 and parameters: {'max_depth': 7, 'min_child_weight': 0.36093805788138933, 'gamma': 0.46750108885778974, 'colsample_bytree': 0.7081338157434606, 'subsample': 0.8240862410551674, 'reg_lambda': 3.1521820590647125, 'reg_alpha': 0.7931768760841299, 'learning_rate': 0.036692151732787295, 'n_estimators': 1000, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:09:39,564] Trial 17 finished with value: 0.6797200335258341 and parameters: {'max_depth': 6, 'min_child_weight': 1.0780948933598078, 'gamma': 0.6693094003521384, 'colsample_bytree': 0.6412348086801775, 'subsample': 0.7894904104743437, 'reg_lambda': 4.582478098889421, 'reg_alpha': 0.0232307899843478, 'learning_rate': 0.03584049588060969, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:12:04,641] Trial 18 finished with value: 0.6807636904307884 and parameters: {'max_depth': 7, 'min_child_weight': 0.42302162530044746, 'gamma': 0.29235231905912173, 'colsample_bytree': 0.706258801372947, 'subsample': 0.8743378465556565, 'reg_lambda': 0.22138397151957454, 'reg_alpha': 1.3194828108022474, 'learning_rate': 0.05621143334404735, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:14:09,557] Trial 19 finished with value: 0.6766489632364854 and parameters: {'max_depth': 11, 'min_child_weight': 0.958173668428475, 'gamma': 1.2073195053587664, 'colsample_bytree': 0.6450425151995445, 'subsample': 0.8454994834763597, 'reg_lambda': 2.5451231540324426, 'reg_alpha': 1.8902084196379194, 'learning_rate': 0.0638293791922946, 'n_estimators': 1100, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:18:08,715] Trial 20 finished with value: 0.679278067662022 and parameters: {'max_depth': 10, 'min_child_weight': 0.4783445571131684, 'gamma': 0.33492799097858905, 'colsample_bytree': 0.6377778366786803, 'subsample': 0.8194812796399175, 'reg_lambda': 5.9093803540974195, 'reg_alpha': 1.4648129239815741, 'learning_rate': 0.04926644724956486, 'n_estimators': 900, 'max_delta_step': 1}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:21:54,492] Trial 21 finished with value: 0.6826723996135116 and parameters: {'max_depth': 6, 'min_child_weight': 0.6223511983112479, 'gamma': 0.16938011334109418, 'colsample_bytree': 0.6021637802571375, 'subsample': 0.8404238582667101, 'reg_lambda': 9.678257903710293, 'reg_alpha': 1.249319190337688, 'learning_rate': 0.050251926951991224, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:25:39,037] Trial 22 finished with value: 0.6827581637837982 and parameters: {'max_depth': 6, 'min_child_weight': 0.8632343547786515, 'gamma': 0.24136508073424817, 'colsample_bytree': 0.6291348359784635, 'subsample': 0.7898799162612896, 'reg_lambda': 6.774049275371174, 'reg_alpha': 1.1682513857024346, 'learning_rate': 0.040063434126310624, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:28:49,164] Trial 23 finished with value: 0.6803083858654674 and parameters: {'max_depth': 7, 'min_child_weight': 1.7089314159961455, 'gamma': 0.5865666244496627, 'colsample_bytree': 0.6966156211473505, 'subsample': 0.781556768013719, 'reg_lambda': 5.823444926913556, 'reg_alpha': 1.0041660379340367, 'learning_rate': 0.04100846650802662, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:32:05,465] Trial 24 finished with value: 0.6825178635213988 and parameters: {'max_depth': 6, 'min_child_weight': 0.8993512666435369, 'gamma': 0.24678676295175284, 'colsample_bytree': 0.6436173686095054, 'subsample': 0.7624083880813047, 'reg_lambda': 2.1634065145406884, 'reg_alpha': 1.6655108274452366, 'learning_rate': 0.03350029954364293, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:34:51,902] Trial 25 finished with value: 0.6792954414301416 and parameters: {'max_depth': 6, 'min_child_weight': 0.3226191855262897, 'gamma': 0.7443295556368247, 'colsample_bytree': 0.6195699079719058, 'subsample': 0.7365719643265349, 'reg_lambda': 4.519762470548683, 'reg_alpha': 1.167759696076318, 'learning_rate': 0.038737833041433224, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:39:09,999] Trial 26 finished with value: 0.6807971932066624 and parameters: {'max_depth': 7, 'min_child_weight': 0.8128460177930321, 'gamma': 0.4451821032451727, 'colsample_bytree': 0.7331123054560128, 'subsample': 0.7953177769416218, 'reg_lambda': 6.382206215154537, 'reg_alpha': 0.6394324118951702, 'learning_rate': 0.031520636257170054, 'n_estimators': 900, 'max_delta_step': 2}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:42:42,010] Trial 27 finished with value: 0.6808617162168963 and parameters: {'max_depth': 8, 'min_child_weight': 1.458865788040949, 'gamma': 0.24632604395268, 'colsample_bytree': 0.6827451462078864, 'subsample': 0.8191518811046326, 'reg_lambda': 3.8163237679641515, 'reg_alpha': 0.9221142669307055, 'learning_rate': 0.042403598438961194, 'n_estimators': 600, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:45:17,326] Trial 28 finished with value: 0.6809166475168724 and parameters: {'max_depth': 6, 'min_child_weight': 2.2765539321586945, 'gamma': 0.44574697540408614, 'colsample_bytree': 0.662301019546453, 'subsample': 0.8101486692322527, 'reg_lambda': 0.8396966889764917, 'reg_alpha': 1.3936024748298184, 'learning_rate': 0.05164595287806578, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:46:49,135] Trial 29 finished with value: 0.6776682241044709 and parameters: {'max_depth': 9, 'min_child_weight': 4.83278603972934, 'gamma': 1.137506168508831, 'colsample_bytree': 0.6328509364400513, 'subsample': 0.8530706044755578, 'reg_lambda': 7.173265104459182, 'reg_alpha': 1.0483009937618648, 'learning_rate': 0.06544768191760829, 'n_estimators': 700, 'max_delta_step': 0}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:50:12,884] Trial 30 finished with value: 0.67825160125632 and parameters: {'max_depth': 7, 'min_child_weight': 0.49520334369542585, 'gamma': 0.9743467205541723, 'colsample_bytree': 0.6269878815313651, 'subsample': 0.7641358153562432, 'reg_lambda': 2.1902629846679185, 'reg_alpha': 1.1590572583643988, 'learning_rate': 0.027828090222985796, 'n_estimators': 1000, 'max_delta_step': 2}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:53:51,784] Trial 31 finished with value: 0.6814019485306945 and parameters: {'max_depth': 6, 'min_child_weight': 0.738960442205144, 'gamma': 0.1623836016301764, 'colsample_bytree': 0.6075467121508327, 'subsample': 0.837242932250603, 'reg_lambda': 9.362486646285364, 'reg_alpha': 1.2181898521176813, 'learning_rate': 0.052459029104543635, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 21:57:39,241] Trial 32 finished with value: 0.6842160297274708 and parameters: {'max_depth': 6, 'min_child_weight': 0.6111885841356738, 'gamma': 0.00096943444252931, 'colsample_bytree': 0.6515322916620486, 'subsample': 0.8040278067533905, 'reg_lambda': 4.848953579801835, 'reg_alpha': 1.5120956493115285, 'learning_rate': 0.06213207297302781, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 22:01:13,299] Trial 33 finished with value: 0.6828999772226723 and parameters: {'max_depth': 6, 'min_child_weight': 0.3028040559508655, 'gamma': 0.02112087069521432, 'colsample_bytree': 0.6492296513092777, 'subsample': 0.800894694224635, 'reg_lambda': 4.3272820811429025, 'reg_alpha': 1.597300325501226, 'learning_rate': 0.062387891867165354, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 22:05:56,285] Trial 34 finished with value: 0.6817182856649143 and parameters: {'max_depth': 6, 'min_child_weight': 0.26848079672317343, 'gamma': 0.001046420600147003, 'colsample_bytree': 0.6554522659746856, 'subsample': 0.8107154931486262, 'reg_lambda': 4.338722545218241, 'reg_alpha': 1.600235362082833, 'learning_rate': 0.0614158691273315, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 22:11:46,473] Trial 35 finished with value: 0.6812188460532047 and parameters: {'max_depth': 7, 'min_child_weight': 0.2025367224669848, 'gamma': 0.012678506355774163, 'colsample_bytree': 0.6897766865233387, 'subsample': 0.7989237139280313, 'reg_lambda': 3.2077192146753983, 'reg_alpha': 1.7741960196497497, 'learning_rate': 0.06750224500809121, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 10 with value: 0.6843125594693452.\n",
      "[I 2025-06-13 22:15:41,339] Trial 36 finished with value: 0.684574994762153 and parameters: {'max_depth': 7, 'min_child_weight': 0.29182831835995093, 'gamma': 0.13899439151039905, 'colsample_bytree': 0.7172941287036565, 'subsample': 0.8729274571858051, 'reg_lambda': 0.9223929219471895, 'reg_alpha': 1.5203210399430624, 'learning_rate': 0.05832107023769441, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:20:12,601] Trial 37 finished with value: 0.6818133182302131 and parameters: {'max_depth': 7, 'min_child_weight': 0.1528669349173422, 'gamma': 0.16112294895696927, 'colsample_bytree': 0.7922153738774734, 'subsample': 0.8963733265868692, 'reg_lambda': 0.7360542138188724, 'reg_alpha': 1.4970819266727688, 'learning_rate': 0.055098398903854415, 'n_estimators': 900, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:21:45,639] Trial 38 finished with value: 0.6739826574453558 and parameters: {'max_depth': 8, 'min_child_weight': 0.439320359380332, 'gamma': 1.9793243808861494, 'colsample_bytree': 0.723482172061443, 'subsample': 0.8774454306049123, 'reg_lambda': 0.41964687294104075, 'reg_alpha': 1.3691870892950546, 'learning_rate': 0.05846045860248511, 'n_estimators': 700, 'max_delta_step': 0}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:23:29,377] Trial 39 finished with value: 0.6802281137541863 and parameters: {'max_depth': 7, 'min_child_weight': 0.38440957936444536, 'gamma': 0.854768370522988, 'colsample_bytree': 0.7562320397464466, 'subsample': 0.8564210582448523, 'reg_lambda': 1.1523820226836723, 'reg_alpha': 1.7060531036173283, 'learning_rate': 0.07285382348774615, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:27:18,402] Trial 40 finished with value: 0.6825325619254513 and parameters: {'max_depth': 6, 'min_child_weight': 0.5310126205062826, 'gamma': 0.35714238417090377, 'colsample_bytree': 0.8399019976723252, 'subsample': 0.8610165777904266, 'reg_lambda': 1.5897385983508288, 'reg_alpha': 1.4846147632108568, 'learning_rate': 0.04687599817411506, 'n_estimators': 1300, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:30:12,960] Trial 41 finished with value: 0.6774864442574616 and parameters: {'max_depth': 6, 'min_child_weight': 0.28008386084952724, 'gamma': 0.11492337427770827, 'colsample_bytree': 0.6544644358229896, 'subsample': 0.8316013762205264, 'reg_lambda': 0.4852213993493328, 'reg_alpha': 1.8131619125494982, 'learning_rate': 0.061366095732894685, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:32:29,450] Trial 42 finished with value: 0.6798801289901161 and parameters: {'max_depth': 6, 'min_child_weight': 0.2206720025240874, 'gamma': 0.18792350975842026, 'colsample_bytree': 0.6678519327311936, 'subsample': 0.883000721292346, 'reg_lambda': 0.3517229370735616, 'reg_alpha': 1.5638378125456391, 'learning_rate': 0.07874721755501464, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:34:05,772] Trial 43 finished with value: 0.6806919957947698 and parameters: {'max_depth': 6, 'min_child_weight': 0.1690191330650242, 'gamma': 1.354219378110496, 'colsample_bytree': 0.6799953015426854, 'subsample': 0.8677539862882585, 'reg_lambda': 0.928781856748478, 'reg_alpha': 1.6124076763991302, 'learning_rate': 0.052956668289589094, 'n_estimators': 700, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:37:51,718] Trial 44 finished with value: 0.6790373458974788 and parameters: {'max_depth': 7, 'min_child_weight': 0.33313815569138105, 'gamma': 0.09132423877119696, 'colsample_bytree': 0.7047587111369251, 'subsample': 0.8073740394279927, 'reg_lambda': 2.0066271257246897, 'reg_alpha': 1.4274122442652215, 'learning_rate': 0.06044110980721239, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:40:03,154] Trial 45 finished with value: 0.6833026781124707 and parameters: {'max_depth': 6, 'min_child_weight': 0.1109481885333655, 'gamma': 0.36586708617862385, 'colsample_bytree': 0.7729818645152263, 'subsample': 0.8943465500664491, 'reg_lambda': 1.187249146456986, 'reg_alpha': 1.51644282501847, 'learning_rate': 0.06807918358586748, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:42:11,664] Trial 46 finished with value: 0.6820671036865902 and parameters: {'max_depth': 7, 'min_child_weight': 0.111362957912959, 'gamma': 0.5929618848352007, 'colsample_bytree': 0.7689826123877516, 'subsample': 0.8813542999326931, 'reg_lambda': 0.6714392177768187, 'reg_alpha': 1.348572067898048, 'learning_rate': 0.06886701102324412, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:44:26,610] Trial 47 finished with value: 0.6793511638427566 and parameters: {'max_depth': 8, 'min_child_weight': 0.11339278383186081, 'gamma': 0.4002535383115109, 'colsample_bytree': 0.8084319608233629, 'subsample': 0.8946462357113645, 'reg_lambda': 1.3062868388862843, 'reg_alpha': 1.2901165201916642, 'learning_rate': 0.07686120095250797, 'n_estimators': 600, 'max_delta_step': 1}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:46:58,552] Trial 48 finished with value: 0.6787683121085554 and parameters: {'max_depth': 6, 'min_child_weight': 0.13555035128447535, 'gamma': 0.6974169422967882, 'colsample_bytree': 0.7797803846698879, 'subsample': 0.890996349827753, 'reg_lambda': 0.3243631556445484, 'reg_alpha': 1.0753876458775942, 'learning_rate': 0.044292541452536485, 'n_estimators': 700, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:50:11,378] Trial 49 finished with value: 0.6794612441129011 and parameters: {'max_depth': 7, 'min_child_weight': 0.7392117219605154, 'gamma': 0.5256060829054805, 'colsample_bytree': 0.811273054344935, 'subsample': 0.869950927507732, 'reg_lambda': 1.026397725135755, 'reg_alpha': 1.830869817985028, 'learning_rate': 0.05453432400971043, 'n_estimators': 1200, 'max_delta_step': 3}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:52:28,530] Trial 50 finished with value: 0.6812892085372446 and parameters: {'max_depth': 6, 'min_child_weight': 0.5830816976657264, 'gamma': 0.29861438827783393, 'colsample_bytree': 0.7455603516518027, 'subsample': 0.8999718450438512, 'reg_lambda': 1.5998387354023584, 'reg_alpha': 1.518462210867434, 'learning_rate': 0.0698479574795774, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 22:56:00,531] Trial 51 finished with value: 0.683627184480178 and parameters: {'max_depth': 6, 'min_child_weight': 0.29535595330732656, 'gamma': 0.08945463031113247, 'colsample_bytree': 0.6197373512991222, 'subsample': 0.8220125997968076, 'reg_lambda': 8.004674103577072, 'reg_alpha': 1.6591125848913042, 'learning_rate': 0.06526296455507297, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:00:25,808] Trial 52 finished with value: 0.681671024038595 and parameters: {'max_depth': 6, 'min_child_weight': 0.22442433619098343, 'gamma': 0.08942560512405712, 'colsample_bytree': 0.8990620379895693, 'subsample': 0.826491535645884, 'reg_lambda': 7.110165588012162, 'reg_alpha': 1.7236789064627502, 'learning_rate': 0.058290335261669726, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:04:28,495] Trial 53 finished with value: 0.6814388916981298 and parameters: {'max_depth': 6, 'min_child_weight': 0.40147290238975125, 'gamma': 0.2491964306099263, 'colsample_bytree': 0.6230417874223733, 'subsample': 0.8426204236125745, 'reg_lambda': 5.159528894865707, 'reg_alpha': 1.4425625229298207, 'learning_rate': 0.0660394872466912, 'n_estimators': 1600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:06:52,207] Trial 54 finished with value: 0.6832027451574298 and parameters: {'max_depth': 6, 'min_child_weight': 0.18786506811665407, 'gamma': 0.3494745359871687, 'colsample_bytree': 0.7226084644404321, 'subsample': 0.8181906145904805, 'reg_lambda': 8.032787568666274, 'reg_alpha': 0.23165071629600975, 'learning_rate': 0.07321232882228998, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:10:58,573] Trial 55 finished with value: 0.6786292796101258 and parameters: {'max_depth': 10, 'min_child_weight': 0.48588119185888223, 'gamma': 0.16404095102041713, 'colsample_bytree': 0.6136463096972467, 'subsample': 0.8482292273661249, 'reg_lambda': 5.124205228474787, 'reg_alpha': 1.9303114661685912, 'learning_rate': 0.04891295224947179, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:15:24,162] Trial 56 finished with value: 0.6833199173703074 and parameters: {'max_depth': 7, 'min_child_weight': 0.6555690881619143, 'gamma': 0.07352296796361935, 'colsample_bytree': 0.7688693378298675, 'subsample': 0.8304992069412459, 'reg_lambda': 2.6901117779491197, 'reg_alpha': 1.6555669189913107, 'learning_rate': 0.05740031222974823, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:20:22,601] Trial 57 finished with value: 0.6803114937551091 and parameters: {'max_depth': 8, 'min_child_weight': 0.6642666647906762, 'gamma': 0.08079857289269526, 'colsample_bytree': 0.8192676205934448, 'subsample': 0.8309269030026423, 'reg_lambda': 2.9297668721669465, 'reg_alpha': 1.658747280861868, 'learning_rate': 0.05723847081143762, 'n_estimators': 800, 'max_delta_step': 2}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:25:19,328] Trial 58 finished with value: 0.6794238096329683 and parameters: {'max_depth': 7, 'min_child_weight': 1.2497118157997706, 'gamma': 0.21773084539963042, 'colsample_bytree': 0.6351720668838122, 'subsample': 0.8360771742980996, 'reg_lambda': 3.619492659656311, 'reg_alpha': 1.8773469000038001, 'learning_rate': 0.04705202068786565, 'n_estimators': 1500, 'max_delta_step': 3}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:29:50,401] Trial 59 finished with value: 0.6793487406494985 and parameters: {'max_depth': 7, 'min_child_weight': 0.25376402206455817, 'gamma': 0.12070706461511771, 'colsample_bytree': 0.6720902499098543, 'subsample': 0.8150207906371217, 'reg_lambda': 2.586971095817003, 'reg_alpha': 1.2715064694168614, 'learning_rate': 0.050804105054590945, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:33:45,823] Trial 60 finished with value: 0.6810977997497408 and parameters: {'max_depth': 11, 'min_child_weight': 0.4354615771165608, 'gamma': 0.2886886526983273, 'colsample_bytree': 0.6206563240475468, 'subsample': 0.8614479576448331, 'reg_lambda': 7.709996868225465, 'reg_alpha': 0.9288784740669902, 'learning_rate': 0.05493452633776306, 'n_estimators': 700, 'max_delta_step': 1}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:36:24,950] Trial 61 finished with value: 0.6834732131193599 and parameters: {'max_depth': 6, 'min_child_weight': 0.5594579867627358, 'gamma': 0.39340777444410885, 'colsample_bytree': 0.7571998767576463, 'subsample': 0.8255252903869622, 'reg_lambda': 5.451394353710194, 'reg_alpha': 1.5331589064673943, 'learning_rate': 0.06467649561502609, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:40:25,767] Trial 62 finished with value: 0.6833768312717221 and parameters: {'max_depth': 6, 'min_child_weight': 0.3598607849996899, 'gamma': 0.05112652913074867, 'colsample_bytree': 0.7906909174046409, 'subsample': 0.8284493671737997, 'reg_lambda': 5.434893879594815, 'reg_alpha': 1.6795850168663882, 'learning_rate': 0.06457446853311026, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:43:32,679] Trial 63 finished with value: 0.6813661062611509 and parameters: {'max_depth': 6, 'min_child_weight': 0.3548456338121364, 'gamma': 0.1910889054085916, 'colsample_bytree': 0.6017943477249337, 'subsample': 0.7911526094407135, 'reg_lambda': 6.020150065973144, 'reg_alpha': 1.733084786985275, 'learning_rate': 0.06414295741898524, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:46:12,076] Trial 64 finished with value: 0.6833637973658316 and parameters: {'max_depth': 6, 'min_child_weight': 0.5475773866051568, 'gamma': 0.5004637704916862, 'colsample_bytree': 0.8722896331741107, 'subsample': 0.8229808045793373, 'reg_lambda': 5.1547752653062044, 'reg_alpha': 1.428375848224581, 'learning_rate': 0.0643360814513706, 'n_estimators': 700, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:50:41,066] Trial 65 finished with value: 0.6842884848742157 and parameters: {'max_depth': 6, 'min_child_weight': 0.5486214107320773, 'gamma': 0.04415997629171011, 'colsample_bytree': 0.8652745707222576, 'subsample': 0.7839840786318735, 'reg_lambda': 8.623043145572392, 'reg_alpha': 1.5537779370225355, 'learning_rate': 0.0759037442431171, 'n_estimators': 700, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:55:23,999] Trial 66 finished with value: 0.6831598573954762 and parameters: {'max_depth': 6, 'min_child_weight': 0.7672772866827678, 'gamma': 0.016992476530731545, 'colsample_bytree': 0.8741727778376551, 'subsample': 0.7844753768670423, 'reg_lambda': 9.901906707165065, 'reg_alpha': 1.5528039753200273, 'learning_rate': 0.07449409775046968, 'n_estimators': 700, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-13 23:59:26,110] Trial 67 finished with value: 0.680904171033236 and parameters: {'max_depth': 6, 'min_child_weight': 0.3044734189084497, 'gamma': 0.12892029025504242, 'colsample_bytree': 0.829080826872058, 'subsample': 0.778854833042333, 'reg_lambda': 8.090796605261025, 'reg_alpha': 1.6741763782141612, 'learning_rate': 0.07161525336097943, 'n_estimators': 700, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-14 00:04:51,216] Trial 68 finished with value: 0.6814345000770481 and parameters: {'max_depth': 6, 'min_child_weight': 0.38583287717113596, 'gamma': 0.05574436231084019, 'colsample_bytree': 0.7947022238116555, 'subsample': 0.8001278926055331, 'reg_lambda': 8.822616531982693, 'reg_alpha': 1.7682414176875851, 'learning_rate': 0.06124760588663004, 'n_estimators': 900, 'max_delta_step': 3}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-14 00:07:32,328] Trial 69 finished with value: 0.6812521705645285 and parameters: {'max_depth': 6, 'min_child_weight': 0.5974747769417789, 'gamma': 0.28143659556335315, 'colsample_bytree': 0.7413775748425402, 'subsample': 0.7712417087214024, 'reg_lambda': 6.40372165830887, 'reg_alpha': 1.5626100916616912, 'learning_rate': 0.07739356071079585, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-14 00:11:21,742] Trial 70 finished with value: 0.683404783377121 and parameters: {'max_depth': 6, 'min_child_weight': 0.46636360788579706, 'gamma': 0.0005280630997086741, 'colsample_bytree': 0.8602604335966078, 'subsample': 0.8136704342117128, 'reg_lambda': 0.14641246442910635, 'reg_alpha': 1.376172936536725, 'learning_rate': 0.06646350957588192, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-14 00:14:41,099] Trial 71 finished with value: 0.6818559718578063 and parameters: {'max_depth': 6, 'min_child_weight': 0.4504952064672534, 'gamma': 0.048898647511875726, 'colsample_bytree': 0.8605388096165535, 'subsample': 0.8050258601311974, 'reg_lambda': 0.12313996772719472, 'reg_alpha': 1.3445850075074337, 'learning_rate': 0.06674290493999774, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-14 00:18:15,059] Trial 72 finished with value: 0.6809583145294835 and parameters: {'max_depth': 6, 'min_child_weight': 0.9601093670675938, 'gamma': 0.011629984706017407, 'colsample_bytree': 0.8402025786955507, 'subsample': 0.8136333542675724, 'reg_lambda': 0.23445856720174313, 'reg_alpha': 1.3860829122673346, 'learning_rate': 0.07054669645190091, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 36 with value: 0.684574994762153.\n",
      "[I 2025-06-14 00:21:36,396] Trial 73 finished with value: 0.6848073669319643 and parameters: {'max_depth': 6, 'min_child_weight': 0.5317377149836044, 'gamma': 0.1423566259801424, 'colsample_bytree': 0.8779908348339797, 'subsample': 0.8248012746289748, 'reg_lambda': 5.465529619795072, 'reg_alpha': 1.4782738380064977, 'learning_rate': 0.0751908813470053, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:25:12,506] Trial 74 finished with value: 0.6823361860312209 and parameters: {'max_depth': 6, 'min_child_weight': 0.5249910965124059, 'gamma': 0.14963893189078858, 'colsample_bytree': 0.8845130999434814, 'subsample': 0.7943869714804239, 'reg_lambda': 6.982409751671273, 'reg_alpha': 1.218043814309685, 'learning_rate': 0.07450443994354965, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:28:50,252] Trial 75 finished with value: 0.6808284823575214 and parameters: {'max_depth': 9, 'min_child_weight': 0.83738542671027, 'gamma': 0.20072827230486914, 'colsample_bytree': 0.8490861816813144, 'subsample': 0.8210515391296387, 'reg_lambda': 8.410440246820807, 'reg_alpha': 1.534577143789034, 'learning_rate': 0.07676517749015807, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:31:06,389] Trial 76 finished with value: 0.6796888443831739 and parameters: {'max_depth': 6, 'min_child_weight': 0.6647729119243522, 'gamma': 0.41289665519557195, 'colsample_bytree': 0.8579604108657289, 'subsample': 0.8036085402445967, 'reg_lambda': 0.19589781414942747, 'reg_alpha': 1.612849447088107, 'learning_rate': 0.06971355772621177, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:34:24,643] Trial 77 finished with value: 0.6811783656277266 and parameters: {'max_depth': 7, 'min_child_weight': 0.5845621768659636, 'gamma': 0.13110777936734153, 'colsample_bytree': 0.8829307800131329, 'subsample': 0.7224778905751166, 'reg_lambda': 0.10573578543785242, 'reg_alpha': 1.4443910245511102, 'learning_rate': 0.063588036276781, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:39:00,566] Trial 78 finished with value: 0.6819695533896553 and parameters: {'max_depth': 6, 'min_child_weight': 0.4844859514390569, 'gamma': 0.0008467250571634194, 'colsample_bytree': 0.8663497919057102, 'subsample': 0.7860832291341437, 'reg_lambda': 4.038852325800494, 'reg_alpha': 1.4642438964261415, 'learning_rate': 0.06070178358576181, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:42:19,184] Trial 79 finished with value: 0.6800949742176293 and parameters: {'max_depth': 6, 'min_child_weight': 0.28696717402703886, 'gamma': 0.225353051800297, 'colsample_bytree': 0.829154322703312, 'subsample': 0.8164620430157301, 'reg_lambda': 4.852967133709387, 'reg_alpha': 1.3927864351288917, 'learning_rate': 0.07956320692599045, 'n_estimators': 1100, 'max_delta_step': 1}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:45:09,701] Trial 80 finished with value: 0.6788655839871318 and parameters: {'max_depth': 7, 'min_child_weight': 1.0651569596499757, 'gamma': 0.32174531435823006, 'colsample_bytree': 0.6136617791385633, 'subsample': 0.80996021370131, 'reg_lambda': 6.026452113348499, 'reg_alpha': 1.0913000913097959, 'learning_rate': 0.05933886622558293, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:49:40,560] Trial 81 finished with value: 0.6825919683596492 and parameters: {'max_depth': 6, 'min_child_weight': 0.3405195506535163, 'gamma': 0.06290067666791233, 'colsample_bytree': 0.7235006968743751, 'subsample': 0.8342879372317162, 'reg_lambda': 5.597169124262453, 'reg_alpha': 1.5960852482005208, 'learning_rate': 0.02443162538022563, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:53:20,346] Trial 82 finished with value: 0.6834771022008843 and parameters: {'max_depth': 6, 'min_child_weight': 0.4010516349909782, 'gamma': 0.10379438073253433, 'colsample_bytree': 0.8845702122066689, 'subsample': 0.8421654879278769, 'reg_lambda': 7.3483784096718985, 'reg_alpha': 1.6972270369056068, 'learning_rate': 0.06775577471653459, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 00:57:22,274] Trial 83 finished with value: 0.6836545002293382 and parameters: {'max_depth': 6, 'min_child_weight': 0.4154828412456155, 'gamma': 0.11405164543926209, 'colsample_bytree': 0.8895679919049088, 'subsample': 0.8449345050624202, 'reg_lambda': 7.293609485199548, 'reg_alpha': 1.4944309341037554, 'learning_rate': 0.0683209462003584, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:00:19,080] Trial 84 finished with value: 0.6811068606111491 and parameters: {'max_depth': 6, 'min_child_weight': 0.42116567932503934, 'gamma': 0.2642805321535179, 'colsample_bytree': 0.8966981607261162, 'subsample': 0.8446319143545942, 'reg_lambda': 7.348700160407375, 'reg_alpha': 1.8302956563072477, 'learning_rate': 0.07404058399012389, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:03:55,481] Trial 85 finished with value: 0.6816219552061658 and parameters: {'max_depth': 6, 'min_child_weight': 0.24596836303470543, 'gamma': 0.1931093156011137, 'colsample_bytree': 0.8839353940470486, 'subsample': 0.8527215654970263, 'reg_lambda': 8.997317104859263, 'reg_alpha': 1.481185934430768, 'learning_rate': 0.07098385477741254, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:07:51,793] Trial 86 finished with value: 0.6819167345056648 and parameters: {'max_depth': 6, 'min_child_weight': 0.5292184493239753, 'gamma': 0.1030466800880683, 'colsample_bytree': 0.8926146527937676, 'subsample': 0.8406135565030711, 'reg_lambda': 6.636338542560861, 'reg_alpha': 0.690967772427831, 'learning_rate': 0.06775153943533482, 'n_estimators': 800, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:09:21,749] Trial 87 finished with value: 0.6788784909333142 and parameters: {'max_depth': 6, 'min_child_weight': 0.30977979106135073, 'gamma': 1.6983235954115872, 'colsample_bytree': 0.8804457407771312, 'subsample': 0.8248696949155155, 'reg_lambda': 9.676580351256083, 'reg_alpha': 1.314383541923697, 'learning_rate': 0.07592883946875893, 'n_estimators': 600, 'max_delta_step': 1}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:13:51,917] Trial 88 finished with value: 0.6827944516990614 and parameters: {'max_depth': 7, 'min_child_weight': 0.3923983135781745, 'gamma': 0.12325418320742398, 'colsample_bytree': 0.8895777007632069, 'subsample': 0.8456924354209633, 'reg_lambda': 3.3796085684367805, 'reg_alpha': 1.7763448323056172, 'learning_rate': 0.05326947118680608, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:15:30,036] Trial 89 finished with value: 0.6786646883367333 and parameters: {'max_depth': 6, 'min_child_weight': 0.7334184400762569, 'gamma': 1.300806625602797, 'colsample_bytree': 0.6953756310538097, 'subsample': 0.7466156110078774, 'reg_lambda': 4.2401996057049205, 'reg_alpha': 1.614214445271121, 'learning_rate': 0.06257381840619708, 'n_estimators': 600, 'max_delta_step': 3}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:18:18,339] Trial 90 finished with value: 0.6799484266782035 and parameters: {'max_depth': 6, 'min_child_weight': 0.6178214446001805, 'gamma': 0.3952571975787819, 'colsample_bytree': 0.8743265551863241, 'subsample': 0.8558744874573256, 'reg_lambda': 7.763782878226826, 'reg_alpha': 1.5324498630734298, 'learning_rate': 0.07182667375405515, 'n_estimators': 800, 'max_delta_step': 1}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:21:50,805] Trial 91 finished with value: 0.6804316855244783 and parameters: {'max_depth': 6, 'min_child_weight': 0.4530420451787223, 'gamma': 0.16693137169645392, 'colsample_bytree': 0.8650931703899212, 'subsample': 0.8265997263159137, 'reg_lambda': 6.538086961551466, 'reg_alpha': 1.4982160980361758, 'learning_rate': 0.06625703881469087, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:25:31,070] Trial 92 finished with value: 0.681955965099557 and parameters: {'max_depth': 6, 'min_child_weight': 0.5041693329263373, 'gamma': 0.08311399046518692, 'colsample_bytree': 0.8533376037511139, 'subsample': 0.8372965833100554, 'reg_lambda': 4.694840245751055, 'reg_alpha': 1.5693235776494971, 'learning_rate': 0.06832014005590568, 'n_estimators': 600, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:29:08,051] Trial 93 finished with value: 0.6839443104321437 and parameters: {'max_depth': 6, 'min_child_weight': 0.4009300447822687, 'gamma': 0.23850557962167532, 'colsample_bytree': 0.8461799761054218, 'subsample': 0.822687214092427, 'reg_lambda': 7.421920423950593, 'reg_alpha': 1.705635281591202, 'learning_rate': 0.05952414104595514, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:32:02,099] Trial 94 finished with value: 0.6815405719457415 and parameters: {'max_depth': 6, 'min_child_weight': 0.38310910643798973, 'gamma': 0.2465173289820798, 'colsample_bytree': 0.8767567801746369, 'subsample': 0.8496598022358025, 'reg_lambda': 0.8092395425595547, 'reg_alpha': 1.7046727790447391, 'learning_rate': 0.05961886743633568, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:36:13,029] Trial 95 finished with value: 0.6809163055777401 and parameters: {'max_depth': 6, 'min_child_weight': 0.33072052549689573, 'gamma': 0.2128055011962641, 'colsample_bytree': 0.6600788706629082, 'subsample': 0.8215253303243603, 'reg_lambda': 8.406749177741338, 'reg_alpha': 1.639928886231462, 'learning_rate': 0.05604456765578616, 'n_estimators': 1000, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:38:07,958] Trial 96 finished with value: 0.6821603683796631 and parameters: {'max_depth': 6, 'min_child_weight': 0.4239068703395389, 'gamma': 1.0200329386434024, 'colsample_bytree': 0.8489202166034358, 'subsample': 0.8326504141817748, 'reg_lambda': 0.5960964963116736, 'reg_alpha': 1.8778468759261457, 'learning_rate': 0.062212577124947606, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:40:56,831] Trial 97 finished with value: 0.6831886532611593 and parameters: {'max_depth': 7, 'min_child_weight': 0.272130117494516, 'gamma': 0.3186154659290605, 'colsample_bytree': 0.6442623536115974, 'subsample': 0.8400402707184941, 'reg_lambda': 5.886831124020681, 'reg_alpha': 1.7437644897970368, 'learning_rate': 0.0692048306615841, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:44:46,823] Trial 98 finished with value: 0.6822059545896656 and parameters: {'max_depth': 6, 'min_child_weight': 0.566453036190623, 'gamma': 0.14071535659343012, 'colsample_bytree': 0.8688092547102164, 'subsample': 0.865213193921986, 'reg_lambda': 9.987695511361883, 'reg_alpha': 1.9542922891396046, 'learning_rate': 0.07999695652874278, 'n_estimators': 900, 'max_delta_step': 3}. Best is trial 73 with value: 0.6848073669319643.\n",
      "[I 2025-06-14 01:50:19,742] Trial 99 finished with value: 0.68139510694122 and parameters: {'max_depth': 7, 'min_child_weight': 0.6976349817257376, 'gamma': 0.09471789634419236, 'colsample_bytree': 0.8910397528863808, 'subsample': 0.8084587411867215, 'reg_lambda': 7.08273843653328, 'reg_alpha': 1.9966753616741637, 'learning_rate': 0.041917569799273816, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 73 with value: 0.6848073669319643.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'max_depth': 6, 'min_child_weight': 0.5317377149836044, 'gamma': 0.1423566259801424, 'colsample_bytree': 0.8779908348339797, 'subsample': 0.8248012746289748, 'reg_lambda': 5.465529619795072, 'reg_alpha': 1.4782738380064977, 'learning_rate': 0.0751908813470053, 'n_estimators': 600, 'max_delta_step': 2}\n",
      "Best trial score: 0.6848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 01:51:04,914] A new study created in memory with name: no-name-a9645700-3824-4841-b4fc-839dd654aae6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En iyi model kaydedildi: Metric score = 0.6848\n",
      "\n",
      "TRAINING FULL MODEL WITH OPTUNA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 01:55:25,675] Trial 0 finished with value: 0.7743748806176114 and parameters: {'max_depth': 10, 'min_child_weight': 0.14182414211690095, 'gamma': 1.1456346169013396, 'colsample_bytree': 0.6160581643647094, 'subsample': 0.7059688617053544, 'reg_lambda': 0.3610686133893097, 'reg_alpha': 1.6936958711693948, 'learning_rate': 0.07647426479718301, 'n_estimators': 1500, 'max_delta_step': 0}. Best is trial 0 with value: 0.7743748806176114.\n",
      "[I 2025-06-14 02:00:59,854] Trial 1 finished with value: 0.7756155479992434 and parameters: {'max_depth': 9, 'min_child_weight': 2.312533472112632, 'gamma': 1.5963509167594456, 'colsample_bytree': 0.6123882446886946, 'subsample': 0.7623220363389281, 'reg_lambda': 6.385853053748329, 'reg_alpha': 0.15898941538652744, 'learning_rate': 0.0207460062698945, 'n_estimators': 600, 'max_delta_step': 0}. Best is trial 1 with value: 0.7756155479992434.\n",
      "[I 2025-06-14 02:05:53,441] Trial 2 finished with value: 0.7780453036014862 and parameters: {'max_depth': 9, 'min_child_weight': 0.9000582924901979, 'gamma': 0.9611808852945227, 'colsample_bytree': 0.7857600534853781, 'subsample': 0.7904917855016952, 'reg_lambda': 8.48697337478521, 'reg_alpha': 0.1301941133779474, 'learning_rate': 0.06049024874534548, 'n_estimators': 1100, 'max_delta_step': 0}. Best is trial 2 with value: 0.7780453036014862.\n",
      "[I 2025-06-14 02:10:21,964] Trial 3 finished with value: 0.7743421130401587 and parameters: {'max_depth': 9, 'min_child_weight': 2.056272735160388, 'gamma': 1.2865477715031655, 'colsample_bytree': 0.8792254510610479, 'subsample': 0.8216481145294728, 'reg_lambda': 2.5193478505709352, 'reg_alpha': 0.24797890142216494, 'learning_rate': 0.06102983384055521, 'n_estimators': 1100, 'max_delta_step': 1}. Best is trial 2 with value: 0.7780453036014862.\n",
      "[I 2025-06-14 02:14:10,638] Trial 4 finished with value: 0.7748839252769779 and parameters: {'max_depth': 8, 'min_child_weight': 1.6508641910653334, 'gamma': 1.5684530847391125, 'colsample_bytree': 0.6028108158854018, 'subsample': 0.7621493851994757, 'reg_lambda': 3.161156513765777, 'reg_alpha': 0.665844833399468, 'learning_rate': 0.06215442298611856, 'n_estimators': 1100, 'max_delta_step': 1}. Best is trial 2 with value: 0.7780453036014862.\n",
      "[I 2025-06-14 02:20:06,925] Trial 5 finished with value: 0.7820242230911847 and parameters: {'max_depth': 10, 'min_child_weight': 4.217557122290756, 'gamma': 0.46818159900390444, 'colsample_bytree': 0.624885838849109, 'subsample': 0.7930211207316132, 'reg_lambda': 0.2622743390989424, 'reg_alpha': 1.455891304742622, 'learning_rate': 0.03072515630420109, 'n_estimators': 600, 'max_delta_step': 3}. Best is trial 5 with value: 0.7820242230911847.\n",
      "[I 2025-06-14 02:26:27,651] Trial 6 finished with value: 0.7798489038372981 and parameters: {'max_depth': 7, 'min_child_weight': 0.10151448980371466, 'gamma': 0.58380247292247, 'colsample_bytree': 0.8080415860183591, 'subsample': 0.7441504695692159, 'reg_lambda': 2.7602686521897546, 'reg_alpha': 1.4716307085846372, 'learning_rate': 0.06998713518696437, 'n_estimators': 1600, 'max_delta_step': 4}. Best is trial 5 with value: 0.7820242230911847.\n",
      "[I 2025-06-14 02:29:14,257] Trial 7 finished with value: 0.7809311601980323 and parameters: {'max_depth': 6, 'min_child_weight': 4.86319725378253, 'gamma': 0.9189663383682494, 'colsample_bytree': 0.6176972993155709, 'subsample': 0.7926690837561656, 'reg_lambda': 0.338900507042158, 'reg_alpha': 1.6317999584125635, 'learning_rate': 0.06695109004847673, 'n_estimators': 600, 'max_delta_step': 1}. Best is trial 5 with value: 0.7820242230911847.\n",
      "[I 2025-06-14 02:37:46,142] Trial 8 finished with value: 0.7835072216070773 and parameters: {'max_depth': 11, 'min_child_weight': 0.3399986912734325, 'gamma': 0.019551500998815863, 'colsample_bytree': 0.731337986221083, 'subsample': 0.8487492907129077, 'reg_lambda': 0.620702231655152, 'reg_alpha': 0.871987807196988, 'learning_rate': 0.07476352449026928, 'n_estimators': 1100, 'max_delta_step': 1}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 02:44:04,492] Trial 9 finished with value: 0.7762443961432026 and parameters: {'max_depth': 11, 'min_child_weight': 0.390296028051607, 'gamma': 0.9671042991433327, 'colsample_bytree': 0.7885176453891849, 'subsample': 0.8166093421113199, 'reg_lambda': 0.1682494077424044, 'reg_alpha': 1.9263734263153582, 'learning_rate': 0.046498767763393394, 'n_estimators': 1500, 'max_delta_step': 4}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 02:53:45,181] Trial 10 finished with value: 0.7823410303614334 and parameters: {'max_depth': 11, 'min_child_weight': 0.27886394716275453, 'gamma': 0.11348005541890238, 'colsample_bytree': 0.7135083041420843, 'subsample': 0.8834014606891238, 'reg_lambda': 0.7098172217432154, 'reg_alpha': 0.9535163894526131, 'learning_rate': 0.040058770447503625, 'n_estimators': 900, 'max_delta_step': 2}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 03:06:02,276] Trial 11 finished with value: 0.781895787750335 and parameters: {'max_depth': 11, 'min_child_weight': 0.29054896428168664, 'gamma': 0.046940140297419476, 'colsample_bytree': 0.6972122592444053, 'subsample': 0.8875510519614919, 'reg_lambda': 0.9443260845492835, 'reg_alpha': 1.0126776962974666, 'learning_rate': 0.037057543390060746, 'n_estimators': 900, 'max_delta_step': 2}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 03:17:08,127] Trial 12 finished with value: 0.7827758243322906 and parameters: {'max_depth': 11, 'min_child_weight': 0.3145873296191731, 'gamma': 0.013068569914073618, 'colsample_bytree': 0.7067423645462299, 'subsample': 0.8808198871348565, 'reg_lambda': 0.7487966139894628, 'reg_alpha': 0.9415846406281698, 'learning_rate': 0.04555953437905858, 'n_estimators': 800, 'max_delta_step': 2}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 03:22:28,019] Trial 13 finished with value: 0.7772776407149024 and parameters: {'max_depth': 10, 'min_child_weight': 0.6119214137046106, 'gamma': 0.4373287122145833, 'colsample_bytree': 0.699653922521304, 'subsample': 0.852747474137663, 'reg_lambda': 0.10174904797696149, 'reg_alpha': 0.6860288786993582, 'learning_rate': 0.04930060469565306, 'n_estimators': 900, 'max_delta_step': 3}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 03:35:31,707] Trial 14 finished with value: 0.7798089800287011 and parameters: {'max_depth': 11, 'min_child_weight': 0.2018226481055349, 'gamma': 0.2598730017006523, 'colsample_bytree': 0.7442171070684925, 'subsample': 0.8565499202208924, 'reg_lambda': 0.6276857680145981, 'reg_alpha': 1.1325342025887986, 'learning_rate': 0.024206411626590933, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 03:38:54,068] Trial 15 finished with value: 0.7706946151946299 and parameters: {'max_depth': 10, 'min_child_weight': 0.5957801512411407, 'gamma': 1.925671685772257, 'colsample_bytree': 0.6647011900495622, 'subsample': 0.8497909362009411, 'reg_lambda': 1.6486796271505868, 'reg_alpha': 0.5831270541385023, 'learning_rate': 0.05040766404213835, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 03:46:42,142] Trial 16 finished with value: 0.7801691097909336 and parameters: {'max_depth': 8, 'min_child_weight': 0.9992741331352785, 'gamma': 0.7383258054033263, 'colsample_bytree': 0.7513460100365252, 'subsample': 0.8990402241049577, 'reg_lambda': 1.364146189079418, 'reg_alpha': 1.2026009501030983, 'learning_rate': 0.029987552128876143, 'n_estimators': 1300, 'max_delta_step': 1}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 03:55:35,204] Trial 17 finished with value: 0.7799607688996038 and parameters: {'max_depth': 11, 'min_child_weight': 0.39363261386686155, 'gamma': 0.2703082173113705, 'colsample_bytree': 0.8494114045562278, 'subsample': 0.8685809111522883, 'reg_lambda': 0.4870671267852432, 'reg_alpha': 0.8392907301252415, 'learning_rate': 0.039218796567680535, 'n_estimators': 800, 'max_delta_step': 1}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 04:05:06,315] Trial 18 finished with value: 0.7830068049898923 and parameters: {'max_depth': 10, 'min_child_weight': 0.18454111569434375, 'gamma': 0.05534266243261759, 'colsample_bytree': 0.6736725868139432, 'subsample': 0.8304030701948336, 'reg_lambda': 1.1593154806070272, 'reg_alpha': 0.37333222968471036, 'learning_rate': 0.05369174204818527, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 04:09:38,534] Trial 19 finished with value: 0.7765226454913469 and parameters: {'max_depth': 10, 'min_child_weight': 0.16991924973733383, 'gamma': 0.7293992549253948, 'colsample_bytree': 0.6621377510869466, 'subsample': 0.8281800757511137, 'reg_lambda': 1.3215700795362222, 'reg_alpha': 0.4195003059403304, 'learning_rate': 0.07991639138207711, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 04:15:46,092] Trial 20 finished with value: 0.7804844522420162 and parameters: {'max_depth': 9, 'min_child_weight': 0.11698271351631688, 'gamma': 0.2992832332720907, 'colsample_bytree': 0.6581131021462964, 'subsample': 0.8360285815895796, 'reg_lambda': 2.0227617382370946, 'reg_alpha': 0.47393708492075426, 'learning_rate': 0.05541016844423784, 'n_estimators': 1200, 'max_delta_step': 3}. Best is trial 8 with value: 0.7835072216070773.\n",
      "[I 2025-06-14 04:33:53,208] Trial 21 finished with value: 0.7840007478221135 and parameters: {'max_depth': 11, 'min_child_weight': 0.2303859191000524, 'gamma': 0.009855279419313412, 'colsample_bytree': 0.7333919684389925, 'subsample': 0.8675559079632117, 'reg_lambda': 0.8589305965761398, 'reg_alpha': 0.7848732739615626, 'learning_rate': 0.05493503193949558, 'n_estimators': 1400, 'max_delta_step': 2}. Best is trial 21 with value: 0.7840007478221135.\n",
      "[I 2025-06-14 04:50:45,642] Trial 22 finished with value: 0.784997778580232 and parameters: {'max_depth': 10, 'min_child_weight': 0.2059656120794023, 'gamma': 0.15277456377791004, 'colsample_bytree': 0.7392362306459709, 'subsample': 0.8404092838918736, 'reg_lambda': 4.145429980649105, 'reg_alpha': 0.3844484808622812, 'learning_rate': 0.0534621629786867, 'n_estimators': 1400, 'max_delta_step': 1}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:04:08,593] Trial 23 finished with value: 0.7832727425447187 and parameters: {'max_depth': 11, 'min_child_weight': 0.23064711590937084, 'gamma': 0.21774071816713506, 'colsample_bytree': 0.7527849344268082, 'subsample': 0.8592361355343856, 'reg_lambda': 4.914327982817744, 'reg_alpha': 0.7515467888022813, 'learning_rate': 0.069009911451553, 'n_estimators': 1400, 'max_delta_step': 1}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:11:56,453] Trial 24 finished with value: 0.7782842521245028 and parameters: {'max_depth': 10, 'min_child_weight': 0.36132640877068456, 'gamma': 0.43149536421887613, 'colsample_bytree': 0.7255382864535742, 'subsample': 0.8111206948653102, 'reg_lambda': 3.6972674693234606, 'reg_alpha': 1.1868984688864699, 'learning_rate': 0.04273325674828916, 'n_estimators': 1600, 'max_delta_step': 0}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:18:48,563] Trial 25 finished with value: 0.781911630380371 and parameters: {'max_depth': 11, 'min_child_weight': 0.4752046241148567, 'gamma': 0.20078735373125167, 'colsample_bytree': 0.7761340392482122, 'subsample': 0.8410062627511729, 'reg_lambda': 0.44377640876556645, 'reg_alpha': 0.03765526124053875, 'learning_rate': 0.05696918228051485, 'n_estimators': 1400, 'max_delta_step': 1}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:27:08,901] Trial 26 finished with value: 0.7746647530955851 and parameters: {'max_depth': 10, 'min_child_weight': 0.14254356049123196, 'gamma': 0.6128879842806267, 'colsample_bytree': 0.8176482010325692, 'subsample': 0.8682315857962375, 'reg_lambda': 0.2477836622443128, 'reg_alpha': 0.5489414015421419, 'learning_rate': 0.03350771359831692, 'n_estimators': 1200, 'max_delta_step': 1}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:31:47,595] Trial 27 finished with value: 0.7750257366224942 and parameters: {'max_depth': 11, 'min_child_weight': 0.2332194611187455, 'gamma': 0.38207416686570406, 'colsample_bytree': 0.7368407316668534, 'subsample': 0.8704259136876356, 'reg_lambda': 0.795208058772709, 'reg_alpha': 0.3266672309218312, 'learning_rate': 0.07357385310450365, 'n_estimators': 1000, 'max_delta_step': 2}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:39:38,505] Trial 28 finished with value: 0.7840389113280625 and parameters: {'max_depth': 8, 'min_child_weight': 0.4625373070781935, 'gamma': 0.02050877947709881, 'colsample_bytree': 0.767252319622155, 'subsample': 0.8431603354153686, 'reg_lambda': 1.840536290142944, 'reg_alpha': 0.8220807244125494, 'learning_rate': 0.06489388907228055, 'n_estimators': 1200, 'max_delta_step': 0}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:44:22,613] Trial 29 finished with value: 0.7726491998790251 and parameters: {'max_depth': 7, 'min_child_weight': 0.14413679890413061, 'gamma': 1.1825226384352228, 'colsample_bytree': 0.7629956424282888, 'subsample': 0.8953382958862077, 'reg_lambda': 4.56240020297428, 'reg_alpha': 1.3262396394953755, 'learning_rate': 0.06572246724427247, 'n_estimators': 1500, 'max_delta_step': 0}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:51:51,188] Trial 30 finished with value: 0.7834324752467634 and parameters: {'max_depth': 8, 'min_child_weight': 0.5164884326658232, 'gamma': 0.1842092864143632, 'colsample_bytree': 0.8307505947744699, 'subsample': 0.8080861241780302, 'reg_lambda': 1.8219264737521665, 'reg_alpha': 0.7499433248319299, 'learning_rate': 0.051456735673036796, 'n_estimators': 1400, 'max_delta_step': 0}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 05:57:16,201] Trial 31 finished with value: 0.7842604620045608 and parameters: {'max_depth': 7, 'min_child_weight': 0.8176255953138963, 'gamma': 0.1020811682486821, 'colsample_bytree': 0.7689934790760123, 'subsample': 0.8412786405954225, 'reg_lambda': 1.031961527952143, 'reg_alpha': 0.8290299209766622, 'learning_rate': 0.07495249606848858, 'n_estimators': 1200, 'max_delta_step': 0}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 06:03:33,296] Trial 32 finished with value: 0.7789155259013476 and parameters: {'max_depth': 7, 'min_child_weight': 0.8128487497845992, 'gamma': 0.14461536861014473, 'colsample_bytree': 0.7725216172159347, 'subsample': 0.8376061473687961, 'reg_lambda': 2.063727916232425, 'reg_alpha': 1.050482814564963, 'learning_rate': 0.05878821973384114, 'n_estimators': 1200, 'max_delta_step': 0}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 06:09:11,936] Trial 33 finished with value: 0.7827723273891569 and parameters: {'max_depth': 6, 'min_child_weight': 1.192509410110154, 'gamma': 0.3475287270559032, 'colsample_bytree': 0.7944084694175012, 'subsample': 0.7761972807113307, 'reg_lambda': 9.437863493391069, 'reg_alpha': 0.5424101111342161, 'learning_rate': 0.07999325964609699, 'n_estimators': 1400, 'max_delta_step': 0}. Best is trial 22 with value: 0.784997778580232.\n",
      "[I 2025-06-14 06:18:31,708] Trial 34 finished with value: 0.7876913943954433 and parameters: {'max_depth': 7, 'min_child_weight': 1.2981855881232467, 'gamma': 0.007554297704760765, 'colsample_bytree': 0.6832596856333798, 'subsample': 0.8725277622525907, 'reg_lambda': 6.973774907130067, 'reg_alpha': 0.822608359209093, 'learning_rate': 0.06427782124906854, 'n_estimators': 1200, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 06:23:11,298] Trial 35 finished with value: 0.7807595617694286 and parameters: {'max_depth': 7, 'min_child_weight': 1.5089120298088756, 'gamma': 0.5679565973680532, 'colsample_bytree': 0.6370013312143947, 'subsample': 0.8243784281402062, 'reg_lambda': 6.947404097155997, 'reg_alpha': 0.24307767479802034, 'learning_rate': 0.06276866346307425, 'n_estimators': 1200, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 06:29:06,459] Trial 36 finished with value: 0.7853022461804232 and parameters: {'max_depth': 8, 'min_child_weight': 3.1756032146846684, 'gamma': 0.16459528762429854, 'colsample_bytree': 0.8522028156904076, 'subsample': 0.7004069728651297, 'reg_lambda': 6.044002925824077, 'reg_alpha': 0.6458749661441939, 'learning_rate': 0.07165928083164895, 'n_estimators': 1000, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 06:32:53,591] Trial 37 finished with value: 0.776347253004736 and parameters: {'max_depth': 7, 'min_child_weight': 2.715466479764668, 'gamma': 1.4553019326918304, 'colsample_bytree': 0.8953973012082492, 'subsample': 0.7099812774957527, 'reg_lambda': 6.5983311853054465, 'reg_alpha': 0.641363339453655, 'learning_rate': 0.07130542458860983, 'n_estimators': 1000, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 06:37:15,643] Trial 38 finished with value: 0.7806036255911397 and parameters: {'max_depth': 6, 'min_child_weight': 3.1560731588151394, 'gamma': 0.8106809148741124, 'colsample_bytree': 0.8562091583417789, 'subsample': 0.7021309854175715, 'reg_lambda': 5.2036238468019, 'reg_alpha': 0.1634762088610786, 'learning_rate': 0.060555010108270885, 'n_estimators': 1000, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 06:41:47,768] Trial 39 finished with value: 0.7799370205392825 and parameters: {'max_depth': 9, 'min_child_weight': 1.3957573254207327, 'gamma': 0.514628372520497, 'colsample_bytree': 0.6859191723921081, 'subsample': 0.7214709968592071, 'reg_lambda': 3.961396594651454, 'reg_alpha': 0.30027042301973944, 'learning_rate': 0.07372042734581587, 'n_estimators': 1100, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 06:49:35,423] Trial 40 finished with value: 0.7854640604382301 and parameters: {'max_depth': 8, 'min_child_weight': 2.51714557083912, 'gamma': 0.13338512331128716, 'colsample_bytree': 0.8655788914272693, 'subsample': 0.7393165905975927, 'reg_lambda': 9.062321231188275, 'reg_alpha': 0.45257519295022464, 'learning_rate': 0.06745488197009539, 'n_estimators': 1100, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 06:57:11,582] Trial 41 finished with value: 0.7842017492180444 and parameters: {'max_depth': 8, 'min_child_weight': 1.9350133851495734, 'gamma': 0.13389862640635866, 'colsample_bytree': 0.882060548703111, 'subsample': 0.7372718837662217, 'reg_lambda': 7.9151431921606115, 'reg_alpha': 0.4663782653374024, 'learning_rate': 0.06887159921390251, 'n_estimators': 1100, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:02:51,004] Trial 42 finished with value: 0.7851097512533667 and parameters: {'max_depth': 7, 'min_child_weight': 3.516034642545789, 'gamma': 0.3041771204194852, 'colsample_bytree': 0.8627844138488842, 'subsample': 0.766545319318313, 'reg_lambda': 9.881438653521883, 'reg_alpha': 0.6629819087801339, 'learning_rate': 0.06514182134254366, 'n_estimators': 1000, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:08:56,122] Trial 43 finished with value: 0.7828701556676929 and parameters: {'max_depth': 8, 'min_child_weight': 3.680504503729221, 'gamma': 0.34230377336440254, 'colsample_bytree': 0.8598306888806939, 'subsample': 0.7569667340583738, 'reg_lambda': 8.511256434512406, 'reg_alpha': 0.6646537558973916, 'learning_rate': 0.062258822763802284, 'n_estimators': 1000, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:15:58,118] Trial 44 finished with value: 0.7821358783669592 and parameters: {'max_depth': 9, 'min_child_weight': 2.828189145230109, 'gamma': 0.22683252964081482, 'colsample_bytree': 0.8406030208225537, 'subsample': 0.7776167675351355, 'reg_lambda': 9.935310135616678, 'reg_alpha': 0.5111180947749762, 'learning_rate': 0.058738882751828356, 'n_estimators': 900, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:21:31,144] Trial 45 finished with value: 0.7850335770619564 and parameters: {'max_depth': 8, 'min_child_weight': 2.2101509734957148, 'gamma': 0.3269240463920653, 'colsample_bytree': 0.8728517579081836, 'subsample': 0.7371853437274125, 'reg_lambda': 5.5347601842782375, 'reg_alpha': 0.21310958181668282, 'learning_rate': 0.06626921448916816, 'n_estimators': 1000, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:26:33,710] Trial 46 finished with value: 0.7828148183427495 and parameters: {'max_depth': 8, 'min_child_weight': 2.2430399402958106, 'gamma': 0.49455645071280707, 'colsample_bytree': 0.872943688615209, 'subsample': 0.7317815970821496, 'reg_lambda': 5.829781250721389, 'reg_alpha': 0.03684547695925475, 'learning_rate': 0.06589112259764497, 'n_estimators': 1000, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:30:34,891] Trial 47 finished with value: 0.7838093770702061 and parameters: {'max_depth': 7, 'min_child_weight': 4.521092715426633, 'gamma': 0.37692426264367707, 'colsample_bytree': 0.8730217405217832, 'subsample': 0.7525246352323383, 'reg_lambda': 2.752171052468326, 'reg_alpha': 0.13317715383626527, 'learning_rate': 0.06944627182608659, 'n_estimators': 700, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:35:42,414] Trial 48 finished with value: 0.7834357015027097 and parameters: {'max_depth': 8, 'min_child_weight': 1.8191391595831032, 'gamma': 0.6370411573498153, 'colsample_bytree': 0.8983382114560681, 'subsample': 0.7172349616173571, 'reg_lambda': 7.270991431764037, 'reg_alpha': 0.9068343364046335, 'learning_rate': 0.07699472087480089, 'n_estimators': 1100, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:39:47,549] Trial 49 finished with value: 0.7759473757764926 and parameters: {'max_depth': 6, 'min_child_weight': 3.5973763248614885, 'gamma': 1.092653679506766, 'colsample_bytree': 0.818477005240509, 'subsample': 0.770517854012744, 'reg_lambda': 3.2031430381972235, 'reg_alpha': 1.9802107204630583, 'learning_rate': 0.0629992032956344, 'n_estimators': 1100, 'max_delta_step': 0}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 07:51:08,246] Trial 50 finished with value: 0.7860274411628717 and parameters: {'max_depth': 9, 'min_child_weight': 2.424937721171295, 'gamma': 0.2887777431987852, 'colsample_bytree': 0.8363191378709346, 'subsample': 0.7292633812002716, 'reg_lambda': 5.981977959086033, 'reg_alpha': 0.22700651682733, 'learning_rate': 0.024304267066243217, 'n_estimators': 900, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 08:03:20,226] Trial 51 finished with value: 0.784247748948547 and parameters: {'max_depth': 9, 'min_child_weight': 2.425415713626369, 'gamma': 0.29743707717575735, 'colsample_bytree': 0.8344057038759193, 'subsample': 0.7454988377069457, 'reg_lambda': 5.767031870102261, 'reg_alpha': 0.23346415274826357, 'learning_rate': 0.022357667774281827, 'n_estimators': 900, 'max_delta_step': 1}. Best is trial 34 with value: 0.7876913943954433.\n",
      "[I 2025-06-14 08:18:06,859] Trial 52 finished with value: 0.7886465298434098 and parameters: {'max_depth': 9, 'min_child_weight': 3.894477499311441, 'gamma': 0.09499228374976071, 'colsample_bytree': 0.8855949442475192, 'subsample': 0.7280486585550866, 'reg_lambda': 7.633410606277347, 'reg_alpha': 0.18343965349754018, 'learning_rate': 0.028996322790846345, 'n_estimators': 1000, 'max_delta_step': 1}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 08:30:13,761] Trial 53 finished with value: 0.785251073694365 and parameters: {'max_depth': 9, 'min_child_weight': 3.679802638090401, 'gamma': 0.10791317769690179, 'colsample_bytree': 0.8869662135846021, 'subsample': 0.7226385235291429, 'reg_lambda': 9.189762694113483, 'reg_alpha': 0.6266523906166794, 'learning_rate': 0.02636274764014291, 'n_estimators': 900, 'max_delta_step': 0}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 08:39:43,746] Trial 54 finished with value: 0.7862680509148505 and parameters: {'max_depth': 9, 'min_child_weight': 4.145204371477155, 'gamma': 0.07340744103145519, 'colsample_bytree': 0.8819608879772746, 'subsample': 0.7280327232452634, 'reg_lambda': 7.85018012790632, 'reg_alpha': 0.008989078178031296, 'learning_rate': 0.027493923668407617, 'n_estimators': 800, 'max_delta_step': 1}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 08:47:50,342] Trial 55 finished with value: 0.7844759716864127 and parameters: {'max_depth': 9, 'min_child_weight': 4.965366897516142, 'gamma': 0.08655550555292452, 'colsample_bytree': 0.8468097812941713, 'subsample': 0.7103912772026306, 'reg_lambda': 7.470865894204361, 'reg_alpha': 0.021236141298381833, 'learning_rate': 0.026886671292681408, 'n_estimators': 700, 'max_delta_step': 1}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 08:55:18,045] Trial 56 finished with value: 0.7875218158128 and parameters: {'max_depth': 9, 'min_child_weight': 4.206941320444284, 'gamma': 0.21815703326584102, 'colsample_bytree': 0.8021938517875201, 'subsample': 0.7286544715607363, 'reg_lambda': 3.42317169240969, 'reg_alpha': 0.09803775936356696, 'learning_rate': 0.029113093542432595, 'n_estimators': 800, 'max_delta_step': 2}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:02:55,938] Trial 57 finished with value: 0.7865300584688736 and parameters: {'max_depth': 9, 'min_child_weight': 4.1915120865826845, 'gamma': 0.003204131350828643, 'colsample_bytree': 0.8013846700131114, 'subsample': 0.7273075955388038, 'reg_lambda': 3.361089151679145, 'reg_alpha': 0.10561465611345278, 'learning_rate': 0.03012522768706916, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:10:31,852] Trial 58 finished with value: 0.7850631311616616 and parameters: {'max_depth': 9, 'min_child_weight': 4.077726852306333, 'gamma': 0.028434073459520585, 'colsample_bytree': 0.8001048282736914, 'subsample': 0.7284210044429151, 'reg_lambda': 2.2951426808156534, 'reg_alpha': 0.11953283766022693, 'learning_rate': 0.02915196991132445, 'n_estimators': 700, 'max_delta_step': 2}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:17:25,641] Trial 59 finished with value: 0.7876085815472138 and parameters: {'max_depth': 9, 'min_child_weight': 4.314236039041084, 'gamma': 0.23776671516955888, 'colsample_bytree': 0.8247886982769845, 'subsample': 0.747417707786105, 'reg_lambda': 4.444891303273991, 'reg_alpha': 0.10250821933445568, 'learning_rate': 0.033576120422012544, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:20:51,237] Trial 60 finished with value: 0.7764816026817121 and parameters: {'max_depth': 9, 'min_child_weight': 4.304532460604522, 'gamma': 1.7469431127506652, 'colsample_bytree': 0.8107806899939833, 'subsample': 0.7471969635103322, 'reg_lambda': 3.2048139473545723, 'reg_alpha': 0.08959882164993983, 'learning_rate': 0.033029661985163467, 'n_estimators': 600, 'max_delta_step': 4}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:29:06,888] Trial 61 finished with value: 0.7851132868225525 and parameters: {'max_depth': 9, 'min_child_weight': 3.0835826911883637, 'gamma': 0.2476519337913976, 'colsample_bytree': 0.7814690551355429, 'subsample': 0.7291993750794555, 'reg_lambda': 4.589902749570181, 'reg_alpha': 0.18667297939712618, 'learning_rate': 0.027475327371822646, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:37:38,561] Trial 62 finished with value: 0.7880509198534714 and parameters: {'max_depth': 9, 'min_child_weight': 3.961324403879922, 'gamma': 0.008334187125738225, 'colsample_bytree': 0.8237637733954735, 'subsample': 0.7199833733253999, 'reg_lambda': 3.548024942653677, 'reg_alpha': 0.3014079322134254, 'learning_rate': 0.03276645251827323, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:45:35,639] Trial 63 finished with value: 0.7846157152572842 and parameters: {'max_depth': 9, 'min_child_weight': 4.957861489717452, 'gamma': 0.00855710959834411, 'colsample_bytree': 0.826173572611272, 'subsample': 0.7153824412736429, 'reg_lambda': 3.5206815232320574, 'reg_alpha': 0.3249995253030066, 'learning_rate': 0.03329889091828473, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:52:30,112] Trial 64 finished with value: 0.7872329144074847 and parameters: {'max_depth': 9, 'min_child_weight': 4.113914401089891, 'gamma': 0.08248534548417391, 'colsample_bytree': 0.791069265440483, 'subsample': 0.7240294201622465, 'reg_lambda': 2.7086492173926953, 'reg_alpha': 0.08156692776918759, 'learning_rate': 0.0363643443408174, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 09:58:55,970] Trial 65 finished with value: 0.7847282953916002 and parameters: {'max_depth': 10, 'min_child_weight': 4.018473320016654, 'gamma': 0.20283799128111565, 'colsample_bytree': 0.8019208483957863, 'subsample': 0.7099078072224162, 'reg_lambda': 2.4750305163313566, 'reg_alpha': 0.10346886255675644, 'learning_rate': 0.035334248049611515, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 10:07:01,365] Trial 66 finished with value: 0.7836120269366186 and parameters: {'max_depth': 9, 'min_child_weight': 2.8937643293629858, 'gamma': 0.07777301056039249, 'colsample_bytree': 0.8115204033792227, 'subsample': 0.7197256496555094, 'reg_lambda': 2.8424580922710594, 'reg_alpha': 1.7617845439533553, 'learning_rate': 0.03131152134940366, 'n_estimators': 600, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 10:14:53,710] Trial 67 finished with value: 0.7860473281068715 and parameters: {'max_depth': 9, 'min_child_weight': 3.2675391643652, 'gamma': 0.003651024287753102, 'colsample_bytree': 0.7882898818891937, 'subsample': 0.7542304714683383, 'reg_lambda': 4.217298016411982, 'reg_alpha': 0.38177986947085085, 'learning_rate': 0.037732326371734674, 'n_estimators': 700, 'max_delta_step': 4}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 10:21:06,257] Trial 68 finished with value: 0.7847844040730716 and parameters: {'max_depth': 10, 'min_child_weight': 4.645629428555274, 'gamma': 0.4394809499146261, 'colsample_bytree': 0.7935471086628766, 'subsample': 0.7435961834151297, 'reg_lambda': 3.604677378255086, 'reg_alpha': 0.2946063870653649, 'learning_rate': 0.031393764151291345, 'n_estimators': 800, 'max_delta_step': 2}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 10:27:01,712] Trial 69 finished with value: 0.7850515302732591 and parameters: {'max_depth': 9, 'min_child_weight': 3.936444004800247, 'gamma': 0.1982966214915745, 'colsample_bytree': 0.7194451109326989, 'subsample': 0.7894102977808993, 'reg_lambda': 2.6679092817681047, 'reg_alpha': 0.07766780958774788, 'learning_rate': 0.036129303078118825, 'n_estimators': 700, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 10:36:12,902] Trial 70 finished with value: 0.7882891764868953 and parameters: {'max_depth': 10, 'min_child_weight': 2.6017743903338983, 'gamma': 0.08964803300090707, 'colsample_bytree': 0.8230155472097059, 'subsample': 0.7340044637631034, 'reg_lambda': 1.556030854970758, 'reg_alpha': 0.1502220006774347, 'learning_rate': 0.028828203851006384, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 10:45:12,801] Trial 71 finished with value: 0.7879589549020826 and parameters: {'max_depth': 10, 'min_child_weight': 3.3977407131841546, 'gamma': 0.06069517911718711, 'colsample_bytree': 0.8198762489445645, 'subsample': 0.7343969767824418, 'reg_lambda': 1.7033212690716417, 'reg_alpha': 0.1740640084932218, 'learning_rate': 0.028927454508239997, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 10:55:44,629] Trial 72 finished with value: 0.7855040462779407 and parameters: {'max_depth': 10, 'min_child_weight': 1.094575570636044, 'gamma': 0.0891074733376551, 'colsample_bytree': 0.8435922654902672, 'subsample': 0.7365803782597097, 'reg_lambda': 1.507559126760007, 'reg_alpha': 0.16071896595018353, 'learning_rate': 0.028399464855843687, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:04:17,731] Trial 73 finished with value: 0.7867058578844516 and parameters: {'max_depth': 10, 'min_child_weight': 3.4039116885446727, 'gamma': 0.23917110050374615, 'colsample_bytree': 0.8249209366300827, 'subsample': 0.712686013703599, 'reg_lambda': 2.16545659722301, 'reg_alpha': 0.2846902539084029, 'learning_rate': 0.025445377292268086, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:10:09,726] Trial 74 finished with value: 0.7870706676112545 and parameters: {'max_depth': 10, 'min_child_weight': 2.712505478539549, 'gamma': 0.1441301445973691, 'colsample_bytree': 0.8190594226941775, 'subsample': 0.7215384099727357, 'reg_lambda': 1.2210383485978253, 'reg_alpha': 0.1736851138567903, 'learning_rate': 0.04237261014786159, 'n_estimators': 600, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:20:01,575] Trial 75 finished with value: 0.7873871838563375 and parameters: {'max_depth': 10, 'min_child_weight': 1.6918529554357415, 'gamma': 0.06327688890647948, 'colsample_bytree': 0.7806123103021704, 'subsample': 0.7336664267875499, 'reg_lambda': 1.8369655707251995, 'reg_alpha': 0.3577932036698702, 'learning_rate': 0.03454753602546714, 'n_estimators': 900, 'max_delta_step': 4}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:27:17,356] Trial 76 finished with value: 0.7853231724795815 and parameters: {'max_depth': 10, 'min_child_weight': 1.698782209904626, 'gamma': 0.16819638996826078, 'colsample_bytree': 0.6027831553343519, 'subsample': 0.750829497300985, 'reg_lambda': 1.6103302218803353, 'reg_alpha': 0.37710929146717775, 'learning_rate': 0.03465557057760366, 'n_estimators': 900, 'max_delta_step': 4}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:31:46,185] Trial 77 finished with value: 0.777899335121024 and parameters: {'max_depth': 10, 'min_child_weight': 1.3231065009217124, 'gamma': 1.355373111749551, 'colsample_bytree': 0.7617178455692117, 'subsample': 0.7596388257769191, 'reg_lambda': 1.813846389758678, 'reg_alpha': 0.266776492684178, 'learning_rate': 0.0321206825265548, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:38:50,004] Trial 78 finished with value: 0.7829640537739351 and parameters: {'max_depth': 10, 'min_child_weight': 2.0079448722941895, 'gamma': 0.40847028039464645, 'colsample_bytree': 0.7818165386024014, 'subsample': 0.7343622001124118, 'reg_lambda': 1.0056753406449086, 'reg_alpha': 0.4157937474035987, 'learning_rate': 0.028594984538593347, 'n_estimators': 900, 'max_delta_step': 4}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:49:59,106] Trial 79 finished with value: 0.7868838304544737 and parameters: {'max_depth': 10, 'min_child_weight': 1.6046111875811757, 'gamma': 0.057750131182251835, 'colsample_bytree': 0.8102026059529589, 'subsample': 0.7423845834753822, 'reg_lambda': 1.450307738103743, 'reg_alpha': 0.3404043706742111, 'learning_rate': 0.02964741990846398, 'n_estimators': 900, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 11:57:56,585] Trial 80 finished with value: 0.7852839522727088 and parameters: {'max_depth': 10, 'min_child_weight': 2.6472664536090216, 'gamma': 0.2497700880168972, 'colsample_bytree': 0.7479588045646595, 'subsample': 0.7058247968606632, 'reg_lambda': 4.875492327591086, 'reg_alpha': 1.3784713365576584, 'learning_rate': 0.038676411296093, 'n_estimators': 900, 'max_delta_step': 2}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 12:06:36,910] Trial 81 finished with value: 0.7871558424503029 and parameters: {'max_depth': 9, 'min_child_weight': 3.0706039634639937, 'gamma': 0.10737496195445903, 'colsample_bytree': 0.7563391460615475, 'subsample': 0.7236347825408397, 'reg_lambda': 2.4090304249013754, 'reg_alpha': 0.04828839560504557, 'learning_rate': 0.03232755348632298, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 12:15:02,180] Trial 82 finished with value: 0.7882376833813035 and parameters: {'max_depth': 9, 'min_child_weight': 3.757513536293188, 'gamma': 0.18679700895078047, 'colsample_bytree': 0.8240196157953598, 'subsample': 0.7334987860896547, 'reg_lambda': 1.8938042988118746, 'reg_alpha': 0.19278831022493548, 'learning_rate': 0.03076585829904714, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 12:22:23,710] Trial 83 finished with value: 0.7868419048301262 and parameters: {'max_depth': 9, 'min_child_weight': 3.590778677845165, 'gamma': 0.1775292562118969, 'colsample_bytree': 0.8262772757042564, 'subsample': 0.7493527286047299, 'reg_lambda': 1.8930214025083032, 'reg_alpha': 0.20279318854567285, 'learning_rate': 0.03462074340433478, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 12:32:11,331] Trial 84 finished with value: 0.7874325688375514 and parameters: {'max_depth': 10, 'min_child_weight': 2.21438621652131, 'gamma': 0.054919934238946616, 'colsample_bytree': 0.8177628560344102, 'subsample': 0.7402956917973336, 'reg_lambda': 1.2859113104108206, 'reg_alpha': 0.1508785115206009, 'learning_rate': 0.03023898062558749, 'n_estimators': 800, 'max_delta_step': 4}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 12:40:10,363] Trial 85 finished with value: 0.7867578155344219 and parameters: {'max_depth': 11, 'min_child_weight': 2.1730490806384664, 'gamma': 0.19170037144973476, 'colsample_bytree': 0.6491987429493056, 'subsample': 0.74202830233921, 'reg_lambda': 1.186522819929146, 'reg_alpha': 0.1518337334011426, 'learning_rate': 0.026077786263806725, 'n_estimators': 800, 'max_delta_step': 3}. Best is trial 52 with value: 0.7886465298434098.\n",
      "[I 2025-06-14 12:49:20,192] Trial 86 finished with value: 0.7892753373803477 and parameters: {'max_depth': 9, 'min_child_weight': 4.634232191055498, 'gamma': 0.13068307704960275, 'colsample_bytree': 0.8527034745262859, 'subsample': 0.7657175762606607, 'reg_lambda': 0.8767113203132394, 'reg_alpha': 0.2579842694602782, 'learning_rate': 0.030734261285110462, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 12:58:48,995] Trial 87 finished with value: 0.7878466189520743 and parameters: {'max_depth': 9, 'min_child_weight': 4.604546757642537, 'gamma': 0.13389649417588273, 'colsample_bytree': 0.8379183064014595, 'subsample': 0.7614775279497938, 'reg_lambda': 0.5730602831173639, 'reg_alpha': 0.2629515737347069, 'learning_rate': 0.028115254389529283, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 13:04:54,276] Trial 88 finished with value: 0.7801588812459335 and parameters: {'max_depth': 9, 'min_child_weight': 4.638641520019858, 'gamma': 0.9156392194467297, 'colsample_bytree': 0.8519364764928801, 'subsample': 0.7649345342479233, 'reg_lambda': 0.603034503703583, 'reg_alpha': 0.25615152594272234, 'learning_rate': 0.024941481385839685, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 13:15:11,291] Trial 89 finished with value: 0.7856796047119523 and parameters: {'max_depth': 9, 'min_child_weight': 2.938047848958351, 'gamma': 0.13323274198765414, 'colsample_bytree': 0.8382877501937073, 'subsample': 0.7735099828990988, 'reg_lambda': 0.6817256029693566, 'reg_alpha': 1.102450312462243, 'learning_rate': 0.027802294823353894, 'n_estimators': 1300, 'max_delta_step': 3}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 13:24:04,655] Trial 90 finished with value: 0.7848221051790273 and parameters: {'max_depth': 8, 'min_child_weight': 3.7731849069782357, 'gamma': 0.2724461383854798, 'colsample_bytree': 0.8307301169253789, 'subsample': 0.7846674201447349, 'reg_lambda': 0.49378462272153556, 'reg_alpha': 0.42923809127867757, 'learning_rate': 0.023114749308145343, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 13:33:13,670] Trial 91 finished with value: 0.7885222349883665 and parameters: {'max_depth': 9, 'min_child_weight': 4.5257587535453165, 'gamma': 0.13602710314061806, 'colsample_bytree': 0.8655780944181781, 'subsample': 0.7615728866086262, 'reg_lambda': 0.8891330632364218, 'reg_alpha': 0.24468094836538018, 'learning_rate': 0.029137556875828682, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 13:42:21,715] Trial 92 finished with value: 0.7888397259509554 and parameters: {'max_depth': 9, 'min_child_weight': 4.995610982758431, 'gamma': 0.1268651656827025, 'colsample_bytree': 0.866261632249009, 'subsample': 0.80413868356658, 'reg_lambda': 0.8489359451715748, 'reg_alpha': 0.2093322082719548, 'learning_rate': 0.030904291336349286, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 13:54:08,951] Trial 93 finished with value: 0.7879283619385374 and parameters: {'max_depth': 9, 'min_child_weight': 3.3534276393754716, 'gamma': 0.03869639714448405, 'colsample_bytree': 0.8675350722758717, 'subsample': 0.805446037407471, 'reg_lambda': 0.8794872518148014, 'reg_alpha': 0.5020698701641719, 'learning_rate': 0.03080706679063451, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 14:03:04,597] Trial 94 finished with value: 0.7883504091444036 and parameters: {'max_depth': 9, 'min_child_weight': 3.3537261857425182, 'gamma': 0.1506615721555801, 'colsample_bytree': 0.8668509534187193, 'subsample': 0.802373568996703, 'reg_lambda': 0.8492557028451447, 'reg_alpha': 0.21681087203202243, 'learning_rate': 0.03133222398735993, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 14:10:31,823] Trial 95 finished with value: 0.7843058011700343 and parameters: {'max_depth': 9, 'min_child_weight': 3.3748824660199035, 'gamma': 0.35491999916029066, 'colsample_bytree': 0.8908029290630652, 'subsample': 0.8009520485056144, 'reg_lambda': 0.8850388434520033, 'reg_alpha': 0.21095680551074464, 'learning_rate': 0.031055056216098508, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 14:21:53,492] Trial 96 finished with value: 0.78782801651959 and parameters: {'max_depth': 9, 'min_child_weight': 3.84771378463677, 'gamma': 0.0395967069287253, 'colsample_bytree': 0.8637724631650341, 'subsample': 0.8145684056330674, 'reg_lambda': 1.0691544564548892, 'reg_alpha': 0.3081244922614937, 'learning_rate': 0.030635815853749773, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 14:30:01,638] Trial 97 finished with value: 0.7873572842862347 and parameters: {'max_depth': 9, 'min_child_weight': 4.983307379765051, 'gamma': 0.16737049238658977, 'colsample_bytree': 0.8703633886490892, 'subsample': 0.8011555969468921, 'reg_lambda': 0.7956784912677608, 'reg_alpha': 0.20075930271859904, 'learning_rate': 0.03190512157408595, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 14:40:15,301] Trial 98 finished with value: 0.7869130835014365 and parameters: {'max_depth': 9, 'min_child_weight': 3.3361719722935343, 'gamma': 0.12320233594345317, 'colsample_bytree': 0.8564571849419423, 'subsample': 0.8057454450498586, 'reg_lambda': 0.6817675239576911, 'reg_alpha': 0.5113751784634937, 'learning_rate': 0.026937957460437124, 'n_estimators': 1300, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n",
      "[I 2025-06-14 14:47:54,556] Trial 99 finished with value: 0.783044036759774 and parameters: {'max_depth': 9, 'min_child_weight': 4.504663828707589, 'gamma': 0.32438445416121303, 'colsample_bytree': 0.8814772682921582, 'subsample': 0.7953181698895404, 'reg_lambda': 0.9246891048538765, 'reg_alpha': 0.4177043739604597, 'learning_rate': 0.02918761082414536, 'n_estimators': 1200, 'max_delta_step': 2}. Best is trial 86 with value: 0.7892753373803477.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'max_depth': 9, 'min_child_weight': 4.634232191055498, 'gamma': 0.13068307704960275, 'colsample_bytree': 0.8527034745262859, 'subsample': 0.7657175762606607, 'reg_lambda': 0.8767113203132394, 'reg_alpha': 0.2579842694602782, 'learning_rate': 0.030734261285110462, 'n_estimators': 1300, 'max_delta_step': 2}\n",
      "Best trial score: 0.7893\n",
      "En iyi model kaydedildi: Metric score = 0.7893\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "\n",
    "imu_features = [col for col in features_df.columns if not col.startswith(('thm_','tof_'))]\n",
    "\n",
    "X_imu = features_df[imu_features].drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_imu = features_df['gesture']\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded_imu = le.fit_transform(y_imu)\n",
    "\n",
    "X_full = features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_full = features_df['gesture']\n",
    "\n",
    "y_encoded_full = le.fit_transform(y_full)\n",
    "\n",
    "\n",
    "def objective(trial, X, y, sequence_ids):\n",
    "    params = {\n",
    "        \"max_depth\":        trial.suggest_int(\"max_depth\", 6, 11),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0.1, 5.0, log=True),\n",
    "        \"gamma\":            trial.suggest_float(\"gamma\", 0.0, 2.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 0.9),\n",
    "        \"subsample\":        trial.suggest_float(\"subsample\", 0.7, 0.9),\n",
    "        \"reg_lambda\":       trial.suggest_float(\"reg_lambda\", 0.1, 10, log=True),\n",
    "        \"reg_alpha\":        trial.suggest_float(\"reg_alpha\", 0.0, 2.0),\n",
    "        \"learning_rate\":    trial.suggest_float(\"learning_rate\", 0.02, 0.08, log=True),\n",
    "        \"n_estimators\":     trial.suggest_int(\"n_estimators\", 600, 1600, step = 100),\n",
    "        \"max_delta_step\":   trial.suggest_int(\"max_delta_step\", 0, 4),\n",
    "        \"objective\":        \"multi:softprob\",\n",
    "        \"num_class\":        len(np.unique(y)),\n",
    "        \"verbosity\":        0,\n",
    "        \"random_state\":     42,\n",
    "        \"tree_method\":      \"hist\",          # varsa GPU: \"gpu_hist\"\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]          # <-- dzeltildi\n",
    "        val_seq_ids    = sequence_ids.iloc[val_idx]\n",
    "\n",
    "        model = XGBClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        preds = model.predict(X_val)\n",
    "        preds_decoded = le.inverse_transform(preds)\n",
    "        # print('pred decoded: ',val_preds_decoded)\n",
    "        # print('pred y_val: ',y_val)\n",
    "        y_val_decoded = le.inverse_transform(y_val)\n",
    "        score = hierarchical_macro_f1_score(y_val_decoded, preds_decoded, val_seq_ids)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def train_and_save_model_with_optuna(X, y, sequence_ids, model_path, model_name=\"IMU\", n_trials=100):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, X, y, sequence_ids), n_trials=n_trials)\n",
    "\n",
    "    print(f\"Best trial params: {study.best_trial.params}\")\n",
    "    print(f\"Best trial score: {study.best_trial.value:.4f}\")\n",
    "\n",
    "    # En iyi parametrelerle modeli tekrar tm veride eit\n",
    "    best_params = study.best_trial.params\n",
    "    best_params[\"random_state\"] = 42\n",
    "\n",
    "    best_model = XGBClassifier(**best_params)\n",
    "    best_model.fit(X, y)\n",
    "\n",
    "    joblib.dump(best_model, f\"{model_path}_{model_name}_{study.best_trial.value:.4f}.pkl\")\n",
    "    print(f\"En iyi model kaydedildi: Metric score = {study.best_trial.value:.4f}\")\n",
    "\n",
    "# Eitim  \n",
    "print(\"TRAINING IMU MODEL WITH OPTUNA...\")\n",
    "train_and_save_model_with_optuna(X_imu, y_encoded_imu, features_df['sequence_id'], model_path=\"model_xgb_optuna\", model_name=\"imu\", n_trials=100)\n",
    "\n",
    "print(\"\\nTRAINING FULL MODEL WITH OPTUNA...\")\n",
    "train_and_save_model_with_optuna(X_full, y_encoded_full, features_df['sequence_id'], model_path=\"model_xgb_optuna\", model_name=\"full\", n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc467279",
   "metadata": {},
   "source": [
    "## CATBOOST With OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ef7169f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huseyin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-06-15 11:31:47,862] A new study created in memory with name: no-name-02f91358-11a5-4ac1-9cd4-3ad8c520cb8a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING FULL MODEL WITH OPTUNA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-15 11:35:31,725] Trial 0 finished with value: 0.7900933402661228 and parameters: {'depth': 8, 'learning_rate': 0.07992244392323199, 'l2_leaf_reg': 6.0429747828337845, 'random_strength': 1.9732482015051698, 'bagging_temperature': 1.3594021764984867, 'grow_policy': 'SymmetricTree', 'border_count': 135, 'min_data_in_leaf': 29, 'iterations': 1400}. Best is trial 0 with value: 0.7900933402661228.\n",
      "[I 2025-06-15 11:38:27,443] Trial 1 finished with value: 0.790157816726034 and parameters: {'depth': 7, 'learning_rate': 0.046030032231654645, 'l2_leaf_reg': 5.287070036532777, 'random_strength': 2.5874625661594832, 'bagging_temperature': 1.456361195813098, 'grow_policy': 'SymmetricTree', 'border_count': 143, 'min_data_in_leaf': 27, 'iterations': 1800}. Best is trial 1 with value: 0.790157816726034.\n",
      "[I 2025-06-15 11:44:53,307] Trial 2 finished with value: 0.7899055598702988 and parameters: {'depth': 8, 'learning_rate': 0.06244953611024144, 'l2_leaf_reg': 7.743922850430787, 'random_strength': 2.2832646641115804, 'bagging_temperature': 0.2054414975273425, 'grow_policy': 'SymmetricTree', 'border_count': 129, 'min_data_in_leaf': 23, 'iterations': 2400}. Best is trial 1 with value: 0.790157816726034.\n",
      "[I 2025-06-15 11:52:42,382] Trial 3 finished with value: 0.7921499098560768 and parameters: {'depth': 8, 'learning_rate': 0.05748295845950434, 'l2_leaf_reg': 5.333047366647799, 'random_strength': 0.6416220848900676, 'bagging_temperature': 1.0320392918753587, 'grow_policy': 'SymmetricTree', 'border_count': 164, 'min_data_in_leaf': 23, 'iterations': 2600}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 11:55:43,249] Trial 4 finished with value: 0.7821057548371873 and parameters: {'depth': 7, 'learning_rate': 0.031044265860251802, 'l2_leaf_reg': 11.934825966748145, 'random_strength': 0.6810189413134247, 'bagging_temperature': 0.6683273804953983, 'grow_policy': 'SymmetricTree', 'border_count': 157, 'min_data_in_leaf': 23, 'iterations': 1800}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 12:07:08,803] Trial 5 finished with value: 0.7838547848334813 and parameters: {'depth': 10, 'learning_rate': 0.07848578799774038, 'l2_leaf_reg': 9.476971161342572, 'random_strength': 2.443919387125715, 'bagging_temperature': 1.2937449123301954, 'grow_policy': 'SymmetricTree', 'border_count': 125, 'min_data_in_leaf': 15, 'iterations': 1600}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 12:09:33,116] Trial 6 finished with value: 0.7895904655318773 and parameters: {'depth': 6, 'learning_rate': 0.05399493814972631, 'l2_leaf_reg': 9.495642828356642, 'random_strength': 2.522577822872888, 'bagging_temperature': 0.20445834662746223, 'grow_policy': 'SymmetricTree', 'border_count': 109, 'min_data_in_leaf': 26, 'iterations': 2400}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 12:13:42,766] Trial 7 finished with value: 0.7851512114265394 and parameters: {'depth': 7, 'learning_rate': 0.042386474221858685, 'l2_leaf_reg': 11.955992789930765, 'random_strength': 2.1726097061310448, 'bagging_temperature': 0.28399807871723415, 'grow_policy': 'SymmetricTree', 'border_count': 176, 'min_data_in_leaf': 15, 'iterations': 2200}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 12:19:21,585] Trial 8 finished with value: 0.7904032986440291 and parameters: {'depth': 8, 'learning_rate': 0.07152096551030125, 'l2_leaf_reg': 5.645994601210934, 'random_strength': 1.9379039347822804, 'bagging_temperature': 1.4124245210657957, 'grow_policy': 'SymmetricTree', 'border_count': 143, 'min_data_in_leaf': 16, 'iterations': 2200}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 12:23:48,190] Trial 9 finished with value: 0.7793720267329661 and parameters: {'depth': 8, 'learning_rate': 0.03898283938129026, 'l2_leaf_reg': 10.580425443664907, 'random_strength': 1.2504935419080396, 'bagging_temperature': 0.26293575746193876, 'grow_policy': 'SymmetricTree', 'border_count': 176, 'min_data_in_leaf': 17, 'iterations': 1400}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 12:49:40,056] Trial 10 finished with value: 0.7863560577499144 and parameters: {'depth': 10, 'learning_rate': 0.058926635900829166, 'l2_leaf_reg': 3.558872745250598, 'random_strength': 0.5020327343001252, 'bagging_temperature': 1.0030946337117446, 'grow_policy': 'SymmetricTree', 'border_count': 163, 'min_data_in_leaf': 20, 'iterations': 2800}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 13:04:13,467] Trial 11 finished with value: 0.791707776304714 and parameters: {'depth': 9, 'learning_rate': 0.0684341460347187, 'l2_leaf_reg': 4.565514674235808, 'random_strength': 1.4867413120676654, 'bagging_temperature': 1.020971619401789, 'grow_policy': 'SymmetricTree', 'border_count': 192, 'min_data_in_leaf': 10, 'iterations': 2800}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 13:19:08,023] Trial 12 finished with value: 0.7910040355901976 and parameters: {'depth': 9, 'learning_rate': 0.06466122143354198, 'l2_leaf_reg': 3.1366390365073222, 'random_strength': 1.3782028457879052, 'bagging_temperature': 1.0025730786073188, 'grow_policy': 'SymmetricTree', 'border_count': 192, 'min_data_in_leaf': 11, 'iterations': 2800}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 13:32:57,992] Trial 13 finished with value: 0.7896520556128563 and parameters: {'depth': 9, 'learning_rate': 0.05269090430409021, 'l2_leaf_reg': 4.600502283525665, 'random_strength': 1.0300305883569991, 'bagging_temperature': 0.7823990476029196, 'grow_policy': 'SymmetricTree', 'border_count': 192, 'min_data_in_leaf': 10, 'iterations': 2600}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 13:46:21,979] Trial 14 finished with value: 0.7898019680172639 and parameters: {'depth': 9, 'learning_rate': 0.06810461180417315, 'l2_leaf_reg': 7.095086642243789, 'random_strength': 2.9112661109045046, 'bagging_temperature': 1.101868018543982, 'grow_policy': 'SymmetricTree', 'border_count': 173, 'min_data_in_leaf': 21, 'iterations': 2600}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 13:59:13,105] Trial 15 finished with value: 0.7899929121924271 and parameters: {'depth': 9, 'learning_rate': 0.05670741386815277, 'l2_leaf_reg': 4.407743979268062, 'random_strength': 1.6182708603148106, 'bagging_temperature': 0.6477000622199485, 'grow_policy': 'SymmetricTree', 'border_count': 158, 'min_data_in_leaf': 19, 'iterations': 2800}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 14:14:22,079] Trial 16 finished with value: 0.7845413049494929 and parameters: {'depth': 10, 'learning_rate': 0.04736455824919129, 'l2_leaf_reg': 6.753886789929137, 'random_strength': 0.9272264592694854, 'bagging_temperature': 1.1912269699285494, 'grow_policy': 'SymmetricTree', 'border_count': 99, 'min_data_in_leaf': 12, 'iterations': 2600}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 14:17:14,399] Trial 17 finished with value: 0.7907007318437207 and parameters: {'depth': 6, 'learning_rate': 0.03510199358381008, 'l2_leaf_reg': 4.198705963331246, 'random_strength': 1.4272871016729602, 'bagging_temperature': 0.8997537691765869, 'grow_policy': 'SymmetricTree', 'border_count': 182, 'min_data_in_leaf': 24, 'iterations': 2400}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 14:31:09,618] Trial 18 finished with value: 0.7886144760915654 and parameters: {'depth': 9, 'learning_rate': 0.07067424537928473, 'l2_leaf_reg': 8.15906609411151, 'random_strength': 0.8863333825946094, 'bagging_temperature': 0.5687284303645959, 'grow_policy': 'SymmetricTree', 'border_count': 163, 'min_data_in_leaf': 13, 'iterations': 2600}. Best is trial 3 with value: 0.7921499098560768.\n",
      "[I 2025-06-15 14:34:29,696] Trial 19 finished with value: 0.7922732445356849 and parameters: {'depth': 7, 'learning_rate': 0.05124380345582078, 'l2_leaf_reg': 6.28939771290621, 'random_strength': 1.656364892291617, 'bagging_temperature': 0.4939953252423596, 'grow_policy': 'SymmetricTree', 'border_count': 151, 'min_data_in_leaf': 18, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 14:37:50,391] Trial 20 finished with value: 0.7903378072331734 and parameters: {'depth': 7, 'learning_rate': 0.050325053358079706, 'l2_leaf_reg': 6.360831792744702, 'random_strength': 1.8060383531234523, 'bagging_temperature': 0.4349947861967861, 'grow_policy': 'SymmetricTree', 'border_count': 148, 'min_data_in_leaf': 18, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 14:43:09,063] Trial 21 finished with value: 0.7922456434047774 and parameters: {'depth': 8, 'learning_rate': 0.06111946852466635, 'l2_leaf_reg': 5.112176040988822, 'random_strength': 1.6216176193530065, 'bagging_temperature': 0.8282650931787748, 'grow_policy': 'SymmetricTree', 'border_count': 151, 'min_data_in_leaf': 21, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 14:48:34,864] Trial 22 finished with value: 0.7907937184271058 and parameters: {'depth': 8, 'learning_rate': 0.05929345760821337, 'l2_leaf_reg': 5.2741161063829285, 'random_strength': 1.1582672884252276, 'bagging_temperature': 0.7914368608785189, 'grow_policy': 'SymmetricTree', 'border_count': 151, 'min_data_in_leaf': 21, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 14:52:02,014] Trial 23 finished with value: 0.7872598643026243 and parameters: {'depth': 7, 'learning_rate': 0.04623268316347218, 'l2_leaf_reg': 8.053606461351587, 'random_strength': 1.722989739488732, 'bagging_temperature': 0.43674627492085216, 'grow_policy': 'SymmetricTree', 'border_count': 165, 'min_data_in_leaf': 25, 'iterations': 1800}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 14:57:21,935] Trial 24 finished with value: 0.7921416949431428 and parameters: {'depth': 8, 'learning_rate': 0.053716934459249494, 'l2_leaf_reg': 5.971425960610672, 'random_strength': 0.6380466561821091, 'bagging_temperature': 0.8709913431195389, 'grow_policy': 'SymmetricTree', 'border_count': 137, 'min_data_in_leaf': 22, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 14:59:36,944] Trial 25 finished with value: 0.7888686714132159 and parameters: {'depth': 6, 'learning_rate': 0.042612761814854905, 'l2_leaf_reg': 7.068197935980521, 'random_strength': 2.0898433849289835, 'bagging_temperature': 0.3990912754828049, 'grow_policy': 'SymmetricTree', 'border_count': 120, 'min_data_in_leaf': 28, 'iterations': 2200}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:02:19,135] Trial 26 finished with value: 0.7905089776303419 and parameters: {'depth': 7, 'learning_rate': 0.0623111899718864, 'l2_leaf_reg': 5.061323473847033, 'random_strength': 1.537808963857972, 'bagging_temperature': 0.5931537481738796, 'grow_policy': 'SymmetricTree', 'border_count': 156, 'min_data_in_leaf': 19, 'iterations': 1600}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:08:31,166] Trial 27 finished with value: 0.7904754323388642 and parameters: {'depth': 8, 'learning_rate': 0.05046643896110256, 'l2_leaf_reg': 3.571834804773169, 'random_strength': 1.2325663426495095, 'bagging_temperature': 0.742915263440838, 'grow_policy': 'SymmetricTree', 'border_count': 168, 'min_data_in_leaf': 30, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:12:15,318] Trial 28 finished with value: 0.7892539386804713 and parameters: {'depth': 7, 'learning_rate': 0.05708454981946196, 'l2_leaf_reg': 6.648987859411015, 'random_strength': 0.7964016334369877, 'bagging_temperature': 0.10535300258599434, 'grow_policy': 'SymmetricTree', 'border_count': 150, 'min_data_in_leaf': 25, 'iterations': 2200}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:16:26,740] Trial 29 finished with value: 0.7916668996051575 and parameters: {'depth': 8, 'learning_rate': 0.07854682149424635, 'l2_leaf_reg': 6.010923395063639, 'random_strength': 1.840471963163023, 'bagging_temperature': 1.2640008020215685, 'grow_policy': 'SymmetricTree', 'border_count': 134, 'min_data_in_leaf': 21, 'iterations': 1600}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:18:25,225] Trial 30 finished with value: 0.7869715143459551 and parameters: {'depth': 6, 'learning_rate': 0.041995305482310105, 'l2_leaf_reg': 8.720051746691142, 'random_strength': 1.0562673223109522, 'bagging_temperature': 0.8895593714348139, 'grow_policy': 'SymmetricTree', 'border_count': 139, 'min_data_in_leaf': 18, 'iterations': 1800}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:23:44,641] Trial 31 finished with value: 0.7905375107844443 and parameters: {'depth': 8, 'learning_rate': 0.05425082644783969, 'l2_leaf_reg': 5.919508873212004, 'random_strength': 0.5444063395754797, 'bagging_temperature': 0.8592802986053584, 'grow_policy': 'SymmetricTree', 'border_count': 135, 'min_data_in_leaf': 22, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:29:01,429] Trial 32 finished with value: 0.7915208070945333 and parameters: {'depth': 8, 'learning_rate': 0.04993675787582271, 'l2_leaf_reg': 5.527597888740585, 'random_strength': 0.7046894704003955, 'bagging_temperature': 1.094631659302976, 'grow_policy': 'SymmetricTree', 'border_count': 143, 'min_data_in_leaf': 23, 'iterations': 2000}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:32:00,226] Trial 33 finished with value: 0.790830948720434 and parameters: {'depth': 7, 'learning_rate': 0.06219113876040445, 'l2_leaf_reg': 4.965578839463101, 'random_strength': 2.839414569724201, 'bagging_temperature': 0.904687718993045, 'grow_policy': 'SymmetricTree', 'border_count': 152, 'min_data_in_leaf': 22, 'iterations': 1800}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:37:33,676] Trial 34 finished with value: 0.7911921236458568 and parameters: {'depth': 8, 'learning_rate': 0.05346710882902646, 'l2_leaf_reg': 6.361358011946653, 'random_strength': 0.6621826277896232, 'bagging_temperature': 0.5268762427710649, 'grow_policy': 'SymmetricTree', 'border_count': 118, 'min_data_in_leaf': 20, 'iterations': 2200}. Best is trial 19 with value: 0.7922732445356849.\n",
      "[I 2025-06-15 15:43:51,553] Trial 35 finished with value: 0.7934039930085046 and parameters: {'depth': 8, 'learning_rate': 0.05641384726535253, 'l2_leaf_reg': 7.4332697402628005, 'random_strength': 2.6958118806400035, 'bagging_temperature': 1.0734128251664412, 'grow_policy': 'SymmetricTree', 'border_count': 129, 'min_data_in_leaf': 24, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 15:47:45,545] Trial 36 finished with value: 0.7925709454412152 and parameters: {'depth': 7, 'learning_rate': 0.06401859231996762, 'l2_leaf_reg': 7.787080015249455, 'random_strength': 2.6689445234369464, 'bagging_temperature': 1.159995756581548, 'grow_policy': 'SymmetricTree', 'border_count': 130, 'min_data_in_leaf': 26, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 15:51:25,753] Trial 37 finished with value: 0.7932059627869159 and parameters: {'depth': 7, 'learning_rate': 0.06540878711547905, 'l2_leaf_reg': 7.522267168252383, 'random_strength': 2.7392796011930516, 'bagging_temperature': 1.184357726994539, 'grow_policy': 'SymmetricTree', 'border_count': 128, 'min_data_in_leaf': 27, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 15:55:04,940] Trial 38 finished with value: 0.792157708916119 and parameters: {'depth': 7, 'learning_rate': 0.06728082593917818, 'l2_leaf_reg': 7.606146302321196, 'random_strength': 2.683323135975745, 'bagging_temperature': 1.3318609939981498, 'grow_policy': 'SymmetricTree', 'border_count': 126, 'min_data_in_leaf': 27, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 15:57:29,449] Trial 39 finished with value: 0.7928092859729743 and parameters: {'depth': 6, 'learning_rate': 0.073974987001415, 'l2_leaf_reg': 8.813453193761857, 'random_strength': 2.3556419828362283, 'bagging_temperature': 1.1664009070749528, 'grow_policy': 'SymmetricTree', 'border_count': 114, 'min_data_in_leaf': 26, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 15:59:53,149] Trial 40 finished with value: 0.7919048280825856 and parameters: {'depth': 6, 'learning_rate': 0.07484562634159192, 'l2_leaf_reg': 9.061670611343054, 'random_strength': 2.3995221001443388, 'bagging_temperature': 1.4875688664639155, 'grow_policy': 'SymmetricTree', 'border_count': 113, 'min_data_in_leaf': 28, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 16:02:17,037] Trial 41 finished with value: 0.7902074374449171 and parameters: {'depth': 6, 'learning_rate': 0.07438578641297766, 'l2_leaf_reg': 10.429814382759474, 'random_strength': 2.706528296106295, 'bagging_temperature': 1.173474423763969, 'grow_policy': 'SymmetricTree', 'border_count': 107, 'min_data_in_leaf': 26, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 16:05:56,618] Trial 42 finished with value: 0.7917543870420161 and parameters: {'depth': 7, 'learning_rate': 0.06434835163693207, 'l2_leaf_reg': 8.164450782630345, 'random_strength': 2.988980395579799, 'bagging_temperature': 1.2105678659182302, 'grow_policy': 'SymmetricTree', 'border_count': 127, 'min_data_in_leaf': 29, 'iterations': 2400}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 16:08:17,153] Trial 43 finished with value: 0.7905966038626421 and parameters: {'depth': 6, 'learning_rate': 0.07294442474476319, 'l2_leaf_reg': 8.570770675171241, 'random_strength': 2.287498949258471, 'bagging_temperature': 1.3890886882662856, 'grow_policy': 'SymmetricTree', 'border_count': 131, 'min_data_in_leaf': 26, 'iterations': 2200}. Best is trial 35 with value: 0.7934039930085046.\n",
      "[I 2025-06-15 16:12:14,124] Trial 44 finished with value: 0.7956731470437881 and parameters: {'depth': 7, 'learning_rate': 0.06562893192522636, 'l2_leaf_reg': 7.382560221980152, 'random_strength': 2.573389458706914, 'bagging_temperature': 1.1415454751177083, 'grow_policy': 'SymmetricTree', 'border_count': 122, 'min_data_in_leaf': 24, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:14:50,767] Trial 45 finished with value: 0.7909073069924867 and parameters: {'depth': 6, 'learning_rate': 0.06599987029843346, 'l2_leaf_reg': 9.920341772274357, 'random_strength': 2.5702681936149228, 'bagging_temperature': 1.0807315688497072, 'grow_policy': 'SymmetricTree', 'border_count': 120, 'min_data_in_leaf': 24, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:18:46,351] Trial 46 finished with value: 0.7953794310463369 and parameters: {'depth': 7, 'learning_rate': 0.06960971875034841, 'l2_leaf_reg': 7.375837832096089, 'random_strength': 2.756097384994149, 'bagging_temperature': 1.2439102599960834, 'grow_policy': 'SymmetricTree', 'border_count': 113, 'min_data_in_leaf': 27, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:22:09,579] Trial 47 finished with value: 0.7902959496499247 and parameters: {'depth': 7, 'learning_rate': 0.07014364587839983, 'l2_leaf_reg': 7.280848275773715, 'random_strength': 2.8083565071032783, 'bagging_temperature': 1.2790498569007036, 'grow_policy': 'SymmetricTree', 'border_count': 102, 'min_data_in_leaf': 30, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:24:58,124] Trial 48 finished with value: 0.7935527507717854 and parameters: {'depth': 6, 'learning_rate': 0.07656946233348669, 'l2_leaf_reg': 8.645830991739224, 'random_strength': 2.3910885323072506, 'bagging_temperature': 0.9686916167677306, 'grow_policy': 'SymmetricTree', 'border_count': 116, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:29:14,668] Trial 49 finished with value: 0.7929817991956931 and parameters: {'depth': 7, 'learning_rate': 0.07920537227339565, 'l2_leaf_reg': 9.329927680036032, 'random_strength': 2.4998683432805198, 'bagging_temperature': 0.9659875475851496, 'grow_policy': 'SymmetricTree', 'border_count': 123, 'min_data_in_leaf': 28, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:32:02,339] Trial 50 finished with value: 0.7945137469331902 and parameters: {'depth': 6, 'learning_rate': 0.059575380030850306, 'l2_leaf_reg': 7.294312036264388, 'random_strength': 2.2074640978930655, 'bagging_temperature': 0.9555566797348184, 'grow_policy': 'SymmetricTree', 'border_count': 107, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:34:32,225] Trial 51 finished with value: 0.7930558145242076 and parameters: {'depth': 6, 'learning_rate': 0.058943858381573164, 'l2_leaf_reg': 7.447543873095908, 'random_strength': 2.1571639733844394, 'bagging_temperature': 0.9610848204747818, 'grow_policy': 'SymmetricTree', 'border_count': 104, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:37:20,366] Trial 52 finished with value: 0.7936766525071695 and parameters: {'depth': 6, 'learning_rate': 0.07632018117846705, 'l2_leaf_reg': 7.887587609408099, 'random_strength': 2.7536484484964934, 'bagging_temperature': 1.0665624370966973, 'grow_policy': 'SymmetricTree', 'border_count': 114, 'min_data_in_leaf': 29, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:40:08,416] Trial 53 finished with value: 0.7930699211951799 and parameters: {'depth': 6, 'learning_rate': 0.07641059817572593, 'l2_leaf_reg': 8.36572554479282, 'random_strength': 2.5841848179534193, 'bagging_temperature': 1.0407418325098308, 'grow_policy': 'SymmetricTree', 'border_count': 112, 'min_data_in_leaf': 29, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:42:44,746] Trial 54 finished with value: 0.792987218728647 and parameters: {'depth': 6, 'learning_rate': 0.06940062743282055, 'l2_leaf_reg': 6.931996655138996, 'random_strength': 2.015543577052802, 'bagging_temperature': 1.1161405436221816, 'grow_policy': 'SymmetricTree', 'border_count': 116, 'min_data_in_leaf': 24, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:45:32,450] Trial 55 finished with value: 0.7910130639603332 and parameters: {'depth': 6, 'learning_rate': 0.07676886803292186, 'l2_leaf_reg': 7.931821237432039, 'random_strength': 2.4507782523370047, 'bagging_temperature': 0.9667376687164458, 'grow_policy': 'SymmetricTree', 'border_count': 109, 'min_data_in_leaf': 25, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:48:08,755] Trial 56 finished with value: 0.7930424927810897 and parameters: {'depth': 6, 'learning_rate': 0.0710857506165151, 'l2_leaf_reg': 6.5971094695031915, 'random_strength': 2.265454807008965, 'bagging_temperature': 1.2404768555088213, 'grow_policy': 'SymmetricTree', 'border_count': 123, 'min_data_in_leaf': 28, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:50:39,634] Trial 57 finished with value: 0.7894820566703575 and parameters: {'depth': 6, 'learning_rate': 0.030168275414543214, 'l2_leaf_reg': 7.281109806030437, 'random_strength': 2.9243682066773866, 'bagging_temperature': 1.0363731481912173, 'grow_policy': 'SymmetricTree', 'border_count': 105, 'min_data_in_leaf': 30, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:52:58,849] Trial 58 finished with value: 0.793130533734287 and parameters: {'depth': 6, 'learning_rate': 0.055742123844860346, 'l2_leaf_reg': 11.507755401264655, 'random_strength': 2.7924820416808354, 'bagging_temperature': 0.7079406549592275, 'grow_policy': 'SymmetricTree', 'border_count': 96, 'min_data_in_leaf': 29, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:55:45,694] Trial 59 finished with value: 0.7942063554176909 and parameters: {'depth': 6, 'learning_rate': 0.06041765326313656, 'l2_leaf_reg': 8.35132265752742, 'random_strength': 2.5986699084813467, 'bagging_temperature': 1.3500789165812255, 'grow_policy': 'SymmetricTree', 'border_count': 109, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 16:58:32,304] Trial 60 finished with value: 0.7943161412927866 and parameters: {'depth': 6, 'learning_rate': 0.07194835216429259, 'l2_leaf_reg': 9.80805528962403, 'random_strength': 2.3063080341206232, 'bagging_temperature': 1.3458418604310687, 'grow_policy': 'SymmetricTree', 'border_count': 109, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:01:18,975] Trial 61 finished with value: 0.7927211965557464 and parameters: {'depth': 6, 'learning_rate': 0.07995546505221712, 'l2_leaf_reg': 9.75880228718949, 'random_strength': 2.3181908361738923, 'bagging_temperature': 1.4437309623992345, 'grow_policy': 'SymmetricTree', 'border_count': 111, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:03:47,723] Trial 62 finished with value: 0.793060911300113 and parameters: {'depth': 6, 'learning_rate': 0.07240005681445527, 'l2_leaf_reg': 8.416615675402923, 'random_strength': 2.2184517524286833, 'bagging_temperature': 1.3359894831182693, 'grow_policy': 'SymmetricTree', 'border_count': 99, 'min_data_in_leaf': 29, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:06:34,422] Trial 63 finished with value: 0.7948066026070179 and parameters: {'depth': 6, 'learning_rate': 0.06776497491446833, 'l2_leaf_reg': 8.964001586783102, 'random_strength': 2.487429439198122, 'bagging_temperature': 1.3955720807420062, 'grow_policy': 'SymmetricTree', 'border_count': 109, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:09:20,955] Trial 64 finished with value: 0.7942081570234638 and parameters: {'depth': 6, 'learning_rate': 0.06763649876588543, 'l2_leaf_reg': 9.043616614052707, 'random_strength': 2.478429267083627, 'bagging_temperature': 1.3647971634961669, 'grow_policy': 'SymmetricTree', 'border_count': 107, 'min_data_in_leaf': 28, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:11:56,122] Trial 65 finished with value: 0.7909559090779383 and parameters: {'depth': 6, 'learning_rate': 0.060852266368714644, 'l2_leaf_reg': 9.10689075874195, 'random_strength': 2.482197773339073, 'bagging_temperature': 1.3853864551949504, 'grow_policy': 'SymmetricTree', 'border_count': 108, 'min_data_in_leaf': 25, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:14:25,116] Trial 66 finished with value: 0.793547190022643 and parameters: {'depth': 6, 'learning_rate': 0.06778191572337403, 'l2_leaf_reg': 10.006251764362254, 'random_strength': 2.5956969586907825, 'bagging_temperature': 1.3196551684979936, 'grow_policy': 'SymmetricTree', 'border_count': 103, 'min_data_in_leaf': 28, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:16:43,448] Trial 67 finished with value: 0.7908525068426735 and parameters: {'depth': 6, 'learning_rate': 0.06704535270211222, 'l2_leaf_reg': 10.739793251124905, 'random_strength': 2.14449484770548, 'bagging_temperature': 1.4484488097575843, 'grow_policy': 'SymmetricTree', 'border_count': 101, 'min_data_in_leaf': 25, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:20:18,561] Trial 68 finished with value: 0.793768528779297 and parameters: {'depth': 7, 'learning_rate': 0.06251376902834432, 'l2_leaf_reg': 9.63607938125916, 'random_strength': 2.016317232085989, 'bagging_temperature': 1.4979912863867746, 'grow_policy': 'SymmetricTree', 'border_count': 96, 'min_data_in_leaf': 26, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:23:01,236] Trial 69 finished with value: 0.7946538292355146 and parameters: {'depth': 6, 'learning_rate': 0.06922033037067628, 'l2_leaf_reg': 9.010584003607182, 'random_strength': 2.51833104745681, 'bagging_temperature': 1.36952707257996, 'grow_policy': 'SymmetricTree', 'border_count': 106, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:26:48,249] Trial 70 finished with value: 0.7911378172080159 and parameters: {'depth': 7, 'learning_rate': 0.06958410402358597, 'l2_leaf_reg': 10.123004860566907, 'random_strength': 2.5232571779945405, 'bagging_temperature': 1.4166443699841826, 'grow_policy': 'SymmetricTree', 'border_count': 106, 'min_data_in_leaf': 28, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:29:35,303] Trial 71 finished with value: 0.7912497572454159 and parameters: {'depth': 6, 'learning_rate': 0.06394537223732104, 'l2_leaf_reg': 9.244858562456502, 'random_strength': 2.635682220400763, 'bagging_temperature': 1.3603305238100085, 'grow_policy': 'SymmetricTree', 'border_count': 110, 'min_data_in_leaf': 26, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:32:22,217] Trial 72 finished with value: 0.791971778587963 and parameters: {'depth': 6, 'learning_rate': 0.06568508443881776, 'l2_leaf_reg': 8.909983233713422, 'random_strength': 2.414250276867471, 'bagging_temperature': 1.292604223753651, 'grow_policy': 'SymmetricTree', 'border_count': 108, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:34:51,323] Trial 73 finished with value: 0.7949302721487246 and parameters: {'depth': 6, 'learning_rate': 0.06027017747113215, 'l2_leaf_reg': 9.435990972980482, 'random_strength': 2.529344779936592, 'bagging_temperature': 1.2358216808334928, 'grow_policy': 'SymmetricTree', 'border_count': 99, 'min_data_in_leaf': 28, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:37:09,903] Trial 74 finished with value: 0.7924217162198742 and parameters: {'depth': 6, 'learning_rate': 0.07160606561503577, 'l2_leaf_reg': 10.849217144625971, 'random_strength': 2.8847590683315176, 'bagging_temperature': 1.249859611441635, 'grow_policy': 'SymmetricTree', 'border_count': 99, 'min_data_in_leaf': 30, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:39:40,021] Trial 75 finished with value: 0.7888501603509112 and parameters: {'depth': 6, 'learning_rate': 0.032828507072371386, 'l2_leaf_reg': 9.45221063101041, 'random_strength': 2.522601101294512, 'bagging_temperature': 1.229594068345203, 'grow_policy': 'SymmetricTree', 'border_count': 101, 'min_data_in_leaf': 28, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:43:37,427] Trial 76 finished with value: 0.7923021286044275 and parameters: {'depth': 7, 'learning_rate': 0.06857507568400346, 'l2_leaf_reg': 11.1328385113341, 'random_strength': 1.9166490073833764, 'bagging_temperature': 1.1304508377104687, 'grow_policy': 'SymmetricTree', 'border_count': 119, 'min_data_in_leaf': 23, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 17:46:25,638] Trial 77 finished with value: 0.7910510660587889 and parameters: {'depth': 6, 'learning_rate': 0.06290805806195837, 'l2_leaf_reg': 9.686226021525732, 'random_strength': 2.2702640628271498, 'bagging_temperature': 1.2971302298408176, 'grow_policy': 'SymmetricTree', 'border_count': 117, 'min_data_in_leaf': 28, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 18:02:52,456] Trial 78 finished with value: 0.7844347874009767 and parameters: {'depth': 10, 'learning_rate': 0.05813371749458207, 'l2_leaf_reg': 10.39738773169038, 'random_strength': 2.0904094989303976, 'bagging_temperature': 1.3891219326705957, 'grow_policy': 'SymmetricTree', 'border_count': 105, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 18:05:21,137] Trial 79 finished with value: 0.7921743146443457 and parameters: {'depth': 6, 'learning_rate': 0.059973759805217824, 'l2_leaf_reg': 10.183731712617584, 'random_strength': 2.3467020684525606, 'bagging_temperature': 1.4360032804185412, 'grow_policy': 'SymmetricTree', 'border_count': 98, 'min_data_in_leaf': 25, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 18:09:16,008] Trial 80 finished with value: 0.792864654631962 and parameters: {'depth': 7, 'learning_rate': 0.0671167234701274, 'l2_leaf_reg': 8.881812043631781, 'random_strength': 2.4359688169688916, 'bagging_temperature': 1.22105859878786, 'grow_policy': 'SymmetricTree', 'border_count': 112, 'min_data_in_leaf': 15, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 18:11:58,469] Trial 81 finished with value: 0.7941374949380908 and parameters: {'depth': 6, 'learning_rate': 0.06076535166893263, 'l2_leaf_reg': 8.096508793132132, 'random_strength': 2.6350073727620917, 'bagging_temperature': 1.347102263730244, 'grow_policy': 'SymmetricTree', 'border_count': 106, 'min_data_in_leaf': 26, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:07:43,151] Trial 82 finished with value: 0.7917058656623132 and parameters: {'depth': 6, 'learning_rate': 0.06592276460636287, 'l2_leaf_reg': 8.447048113689943, 'random_strength': 2.537902845793063, 'bagging_temperature': 1.3643337704793668, 'grow_policy': 'SymmetricTree', 'border_count': 110, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:10:33,901] Trial 83 finished with value: 0.7915929867475789 and parameters: {'depth': 6, 'learning_rate': 0.06322771757426571, 'l2_leaf_reg': 7.701348991661359, 'random_strength': 2.6173470890899027, 'bagging_temperature': 1.305043719854144, 'grow_policy': 'SymmetricTree', 'border_count': 122, 'min_data_in_leaf': 29, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:13:24,650] Trial 84 finished with value: 0.793237458834893 and parameters: {'depth': 6, 'learning_rate': 0.07287384113257951, 'l2_leaf_reg': 9.101855317218122, 'random_strength': 2.4586278032834152, 'bagging_temperature': 1.261893430759475, 'grow_policy': 'SymmetricTree', 'border_count': 115, 'min_data_in_leaf': 27, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:15:57,939] Trial 85 finished with value: 0.7925073426125916 and parameters: {'depth': 6, 'learning_rate': 0.07032504455218297, 'l2_leaf_reg': 8.217375117350095, 'random_strength': 2.230113393345991, 'bagging_temperature': 1.414909907736796, 'grow_policy': 'SymmetricTree', 'border_count': 103, 'min_data_in_leaf': 26, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:18:42,140] Trial 86 finished with value: 0.7928689881388603 and parameters: {'depth': 6, 'learning_rate': 0.05470579625566931, 'l2_leaf_reg': 6.961887587985366, 'random_strength': 2.3574291867706627, 'bagging_temperature': 1.1512361034994611, 'grow_policy': 'SymmetricTree', 'border_count': 108, 'min_data_in_leaf': 28, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:20:04,041] Trial 87 finished with value: 0.7806866941338613 and parameters: {'depth': 6, 'learning_rate': 0.0482520762798289, 'l2_leaf_reg': 9.43934172311779, 'random_strength': 2.8387274735135772, 'bagging_temperature': 1.4661405489798227, 'grow_policy': 'SymmetricTree', 'border_count': 101, 'min_data_in_leaf': 29, 'iterations': 1400}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:24:14,066] Trial 88 finished with value: 0.7942609588518412 and parameters: {'depth': 7, 'learning_rate': 0.06859925405972854, 'l2_leaf_reg': 8.644980151639345, 'random_strength': 2.7491914488959837, 'bagging_temperature': 1.2046082314603832, 'grow_policy': 'SymmetricTree', 'border_count': 112, 'min_data_in_leaf': 24, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:28:20,777] Trial 89 finished with value: 0.794501499184588 and parameters: {'depth': 7, 'learning_rate': 0.06849106301516476, 'l2_leaf_reg': 8.654041784983152, 'random_strength': 2.7664910104369485, 'bagging_temperature': 1.2797321759757703, 'grow_policy': 'SymmetricTree', 'border_count': 113, 'min_data_in_leaf': 22, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:32:31,571] Trial 90 finished with value: 0.7921423719485079 and parameters: {'depth': 7, 'learning_rate': 0.07405171731655102, 'l2_leaf_reg': 8.592793930703616, 'random_strength': 2.941211049796624, 'bagging_temperature': 1.1309696272410008, 'grow_policy': 'SymmetricTree', 'border_count': 114, 'min_data_in_leaf': 22, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:36:36,362] Trial 91 finished with value: 0.791132802618926 and parameters: {'depth': 7, 'learning_rate': 0.06878644637435442, 'l2_leaf_reg': 9.257733390594883, 'random_strength': 2.755223926764665, 'bagging_temperature': 1.204890370221988, 'grow_policy': 'SymmetricTree', 'border_count': 112, 'min_data_in_leaf': 24, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:40:44,450] Trial 92 finished with value: 0.7925794456272813 and parameters: {'depth': 7, 'learning_rate': 0.06481593268838413, 'l2_leaf_reg': 8.964972484496062, 'random_strength': 2.70744121294028, 'bagging_temperature': 1.2537314193816724, 'grow_policy': 'SymmetricTree', 'border_count': 121, 'min_data_in_leaf': 23, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:44:49,835] Trial 93 finished with value: 0.7930314417375903 and parameters: {'depth': 7, 'learning_rate': 0.06711047333080711, 'l2_leaf_reg': 9.797110912500731, 'random_strength': 2.866184224939751, 'bagging_temperature': 1.3166427779710757, 'grow_policy': 'SymmetricTree', 'border_count': 117, 'min_data_in_leaf': 24, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:48:56,116] Trial 94 finished with value: 0.7922069094740344 and parameters: {'depth': 7, 'learning_rate': 0.0709830912792224, 'l2_leaf_reg': 7.23829611711794, 'random_strength': 2.7552087428996472, 'bagging_temperature': 1.1886880197490393, 'grow_policy': 'SymmetricTree', 'border_count': 107, 'min_data_in_leaf': 20, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:52:47,117] Trial 95 finished with value: 0.7930677701999789 and parameters: {'depth': 7, 'learning_rate': 0.06184671450448366, 'l2_leaf_reg': 8.66567527524673, 'random_strength': 2.549519886206173, 'bagging_temperature': 1.2806665472435879, 'grow_policy': 'SymmetricTree', 'border_count': 104, 'min_data_in_leaf': 25, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 21:56:53,603] Trial 96 finished with value: 0.790637506493549 and parameters: {'depth': 7, 'learning_rate': 0.06859958497946012, 'l2_leaf_reg': 7.930405191546328, 'random_strength': 2.987657751508069, 'bagging_temperature': 1.374156630632757, 'grow_policy': 'SymmetricTree', 'border_count': 112, 'min_data_in_leaf': 23, 'iterations': 2600}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 22:01:22,904] Trial 97 finished with value: 0.7924887798846884 and parameters: {'depth': 7, 'learning_rate': 0.04399410727489399, 'l2_leaf_reg': 9.617824428819707, 'random_strength': 2.6722672574861197, 'bagging_temperature': 1.3252271086916747, 'grow_policy': 'SymmetricTree', 'border_count': 124, 'min_data_in_leaf': 22, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 22:16:22,748] Trial 98 finished with value: 0.7905984129897474 and parameters: {'depth': 9, 'learning_rate': 0.07223320663861019, 'l2_leaf_reg': 6.830044574836604, 'random_strength': 2.485189934156115, 'bagging_temperature': 1.413391073613413, 'grow_policy': 'SymmetricTree', 'border_count': 188, 'min_data_in_leaf': 26, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n",
      "[I 2025-06-15 22:23:31,444] Trial 99 finished with value: 0.7913310114962883 and parameters: {'depth': 8, 'learning_rate': 0.06609762532985965, 'l2_leaf_reg': 7.6531084929621365, 'random_strength': 2.7825097856417864, 'bagging_temperature': 1.2165057071696923, 'grow_policy': 'SymmetricTree', 'border_count': 118, 'min_data_in_leaf': 25, 'iterations': 2800}. Best is trial 44 with value: 0.7956731470437881.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial params: {'depth': 7, 'learning_rate': 0.06562893192522636, 'l2_leaf_reg': 7.382560221980152, 'random_strength': 2.573389458706914, 'bagging_temperature': 1.1415454751177083, 'grow_policy': 'SymmetricTree', 'border_count': 122, 'min_data_in_leaf': 24, 'iterations': 2600}\n",
      "Best trial score: 0.7957\n",
      "0:\tlearn: 2.8152968\ttotal: 204ms\tremaining: 8m 50s\n",
      "1:\tlearn: 2.7660062\ttotal: 415ms\tremaining: 8m 59s\n",
      "2:\tlearn: 2.7098519\ttotal: 624ms\tremaining: 9m\n",
      "3:\tlearn: 2.6558566\ttotal: 835ms\tremaining: 9m 1s\n",
      "4:\tlearn: 2.6161625\ttotal: 1.02s\tremaining: 8m 51s\n",
      "5:\tlearn: 2.5682736\ttotal: 1.22s\tremaining: 8m 46s\n",
      "6:\tlearn: 2.5268785\ttotal: 1.41s\tremaining: 8m 41s\n",
      "7:\tlearn: 2.4823106\ttotal: 1.59s\tremaining: 8m 36s\n",
      "8:\tlearn: 2.4558621\ttotal: 1.78s\tremaining: 8m 33s\n",
      "9:\tlearn: 2.4213634\ttotal: 1.98s\tremaining: 8m 31s\n",
      "10:\tlearn: 2.3881177\ttotal: 2.19s\tremaining: 8m 36s\n",
      "11:\tlearn: 2.3541768\ttotal: 2.4s\tremaining: 8m 38s\n",
      "12:\tlearn: 2.3262009\ttotal: 2.6s\tremaining: 8m 36s\n",
      "13:\tlearn: 2.2971701\ttotal: 2.78s\tremaining: 8m 34s\n",
      "14:\tlearn: 2.2738409\ttotal: 2.97s\tremaining: 8m 32s\n",
      "15:\tlearn: 2.2507624\ttotal: 3.19s\tremaining: 8m 35s\n",
      "16:\tlearn: 2.2218855\ttotal: 3.38s\tremaining: 8m 34s\n",
      "17:\tlearn: 2.1982702\ttotal: 3.57s\tremaining: 8m 32s\n",
      "18:\tlearn: 2.1722732\ttotal: 3.76s\tremaining: 8m 30s\n",
      "19:\tlearn: 2.1535269\ttotal: 3.94s\tremaining: 8m 28s\n",
      "20:\tlearn: 2.1275779\ttotal: 4.16s\tremaining: 8m 30s\n",
      "21:\tlearn: 2.1002622\ttotal: 4.36s\tremaining: 8m 30s\n",
      "22:\tlearn: 2.0793560\ttotal: 4.55s\tremaining: 8m 30s\n",
      "23:\tlearn: 2.0556714\ttotal: 4.74s\tremaining: 8m 28s\n",
      "24:\tlearn: 2.0321517\ttotal: 4.93s\tremaining: 8m 27s\n",
      "25:\tlearn: 2.0077896\ttotal: 5.13s\tremaining: 8m 27s\n",
      "26:\tlearn: 1.9881873\ttotal: 5.33s\tremaining: 8m 28s\n",
      "27:\tlearn: 1.9686611\ttotal: 5.53s\tremaining: 8m 28s\n",
      "28:\tlearn: 1.9485139\ttotal: 5.72s\tremaining: 8m 27s\n",
      "29:\tlearn: 1.9296642\ttotal: 5.91s\tremaining: 8m 26s\n",
      "30:\tlearn: 1.9117667\ttotal: 6.12s\tremaining: 8m 26s\n",
      "31:\tlearn: 1.8955330\ttotal: 6.32s\tremaining: 8m 26s\n",
      "32:\tlearn: 1.8789654\ttotal: 6.5s\tremaining: 8m 25s\n",
      "33:\tlearn: 1.8637793\ttotal: 6.69s\tremaining: 8m 24s\n",
      "34:\tlearn: 1.8456203\ttotal: 6.88s\tremaining: 8m 23s\n",
      "35:\tlearn: 1.8317566\ttotal: 7.08s\tremaining: 8m 24s\n",
      "36:\tlearn: 1.8201046\ttotal: 7.3s\tremaining: 8m 25s\n",
      "37:\tlearn: 1.8062885\ttotal: 7.49s\tremaining: 8m 25s\n",
      "38:\tlearn: 1.7924858\ttotal: 7.67s\tremaining: 8m 24s\n",
      "39:\tlearn: 1.7785202\ttotal: 7.86s\tremaining: 8m 23s\n",
      "40:\tlearn: 1.7661346\ttotal: 8.05s\tremaining: 8m 22s\n",
      "41:\tlearn: 1.7544092\ttotal: 8.28s\tremaining: 8m 24s\n",
      "42:\tlearn: 1.7428052\ttotal: 8.47s\tremaining: 8m 23s\n",
      "43:\tlearn: 1.7316740\ttotal: 8.65s\tremaining: 8m 22s\n",
      "44:\tlearn: 1.7219310\ttotal: 8.84s\tremaining: 8m 21s\n",
      "45:\tlearn: 1.7094837\ttotal: 9.03s\tremaining: 8m 21s\n",
      "46:\tlearn: 1.6979929\ttotal: 9.25s\tremaining: 8m 22s\n",
      "47:\tlearn: 1.6874835\ttotal: 9.45s\tremaining: 8m 22s\n",
      "48:\tlearn: 1.6776846\ttotal: 9.63s\tremaining: 8m 21s\n",
      "49:\tlearn: 1.6684212\ttotal: 9.82s\tremaining: 8m 20s\n",
      "50:\tlearn: 1.6603204\ttotal: 10s\tremaining: 8m 19s\n",
      "51:\tlearn: 1.6505520\ttotal: 10.2s\tremaining: 8m 20s\n",
      "52:\tlearn: 1.6412867\ttotal: 10.4s\tremaining: 8m 20s\n",
      "53:\tlearn: 1.6327625\ttotal: 10.6s\tremaining: 8m 20s\n",
      "54:\tlearn: 1.6222045\ttotal: 10.8s\tremaining: 8m 19s\n",
      "55:\tlearn: 1.6137083\ttotal: 11s\tremaining: 8m 19s\n",
      "56:\tlearn: 1.6042611\ttotal: 11.2s\tremaining: 8m 19s\n",
      "57:\tlearn: 1.5961940\ttotal: 11.4s\tremaining: 8m 19s\n",
      "58:\tlearn: 1.5900976\ttotal: 11.6s\tremaining: 8m 18s\n",
      "59:\tlearn: 1.5811682\ttotal: 11.8s\tremaining: 8m 18s\n",
      "60:\tlearn: 1.5728582\ttotal: 12s\tremaining: 8m 17s\n",
      "61:\tlearn: 1.5660668\ttotal: 12.2s\tremaining: 8m 17s\n",
      "62:\tlearn: 1.5568991\ttotal: 12.4s\tremaining: 8m 17s\n",
      "63:\tlearn: 1.5481286\ttotal: 12.6s\tremaining: 8m 17s\n",
      "64:\tlearn: 1.5395973\ttotal: 12.7s\tremaining: 8m 17s\n",
      "65:\tlearn: 1.5325100\ttotal: 12.9s\tremaining: 8m 16s\n",
      "66:\tlearn: 1.5251886\ttotal: 13.1s\tremaining: 8m 16s\n",
      "67:\tlearn: 1.5170372\ttotal: 13.3s\tremaining: 8m 16s\n",
      "68:\tlearn: 1.5118242\ttotal: 13.5s\tremaining: 8m 16s\n",
      "69:\tlearn: 1.5045362\ttotal: 13.7s\tremaining: 8m 15s\n",
      "70:\tlearn: 1.4971879\ttotal: 13.9s\tremaining: 8m 15s\n",
      "71:\tlearn: 1.4906944\ttotal: 14.1s\tremaining: 8m 15s\n",
      "72:\tlearn: 1.4837456\ttotal: 14.3s\tremaining: 8m 15s\n",
      "73:\tlearn: 1.4763120\ttotal: 14.5s\tremaining: 8m 15s\n",
      "74:\tlearn: 1.4692481\ttotal: 14.7s\tremaining: 8m 14s\n",
      "75:\tlearn: 1.4625781\ttotal: 14.9s\tremaining: 8m 13s\n",
      "76:\tlearn: 1.4553536\ttotal: 15.1s\tremaining: 8m 14s\n",
      "77:\tlearn: 1.4482986\ttotal: 15.3s\tremaining: 8m 14s\n",
      "78:\tlearn: 1.4415874\ttotal: 15.5s\tremaining: 8m 13s\n",
      "79:\tlearn: 1.4355059\ttotal: 15.7s\tremaining: 8m 13s\n",
      "80:\tlearn: 1.4291046\ttotal: 15.8s\tremaining: 8m 12s\n",
      "81:\tlearn: 1.4233772\ttotal: 16s\tremaining: 8m 12s\n",
      "82:\tlearn: 1.4180830\ttotal: 16.2s\tremaining: 8m 12s\n",
      "83:\tlearn: 1.4112110\ttotal: 16.4s\tremaining: 8m 12s\n",
      "84:\tlearn: 1.4061609\ttotal: 16.6s\tremaining: 8m 12s\n",
      "85:\tlearn: 1.3987905\ttotal: 16.8s\tremaining: 8m 11s\n",
      "86:\tlearn: 1.3927011\ttotal: 17s\tremaining: 8m 11s\n",
      "87:\tlearn: 1.3848529\ttotal: 17.2s\tremaining: 8m 11s\n",
      "88:\tlearn: 1.3789518\ttotal: 17.4s\tremaining: 8m 11s\n",
      "89:\tlearn: 1.3743045\ttotal: 17.6s\tremaining: 8m 10s\n",
      "90:\tlearn: 1.3680603\ttotal: 17.8s\tremaining: 8m 10s\n",
      "91:\tlearn: 1.3624427\ttotal: 18s\tremaining: 8m 10s\n",
      "92:\tlearn: 1.3574516\ttotal: 18.2s\tremaining: 8m 10s\n",
      "93:\tlearn: 1.3516717\ttotal: 18.4s\tremaining: 8m 10s\n",
      "94:\tlearn: 1.3458530\ttotal: 18.6s\tremaining: 8m 10s\n",
      "95:\tlearn: 1.3412923\ttotal: 18.8s\tremaining: 8m 10s\n",
      "96:\tlearn: 1.3356353\ttotal: 19s\tremaining: 8m 9s\n",
      "97:\tlearn: 1.3310144\ttotal: 19.2s\tremaining: 8m 9s\n",
      "98:\tlearn: 1.3263596\ttotal: 19.4s\tremaining: 8m 9s\n",
      "99:\tlearn: 1.3234171\ttotal: 19.6s\tremaining: 8m 9s\n",
      "100:\tlearn: 1.3191069\ttotal: 19.8s\tremaining: 8m 9s\n",
      "101:\tlearn: 1.3149791\ttotal: 20s\tremaining: 8m 8s\n",
      "102:\tlearn: 1.3113845\ttotal: 20.2s\tremaining: 8m 8s\n",
      "103:\tlearn: 1.3066134\ttotal: 20.4s\tremaining: 8m 8s\n",
      "104:\tlearn: 1.3028888\ttotal: 20.6s\tremaining: 8m 8s\n",
      "105:\tlearn: 1.2976208\ttotal: 20.8s\tremaining: 8m 8s\n",
      "106:\tlearn: 1.2928293\ttotal: 20.9s\tremaining: 8m 7s\n",
      "107:\tlearn: 1.2871192\ttotal: 21.1s\tremaining: 8m 7s\n",
      "108:\tlearn: 1.2829825\ttotal: 21.3s\tremaining: 8m 7s\n",
      "109:\tlearn: 1.2783751\ttotal: 21.5s\tremaining: 8m 6s\n",
      "110:\tlearn: 1.2742058\ttotal: 21.7s\tremaining: 8m 6s\n",
      "111:\tlearn: 1.2705919\ttotal: 21.9s\tremaining: 8m 6s\n",
      "112:\tlearn: 1.2667398\ttotal: 22.1s\tremaining: 8m 6s\n",
      "113:\tlearn: 1.2617101\ttotal: 22.3s\tremaining: 8m 6s\n",
      "114:\tlearn: 1.2575480\ttotal: 22.5s\tremaining: 8m 6s\n",
      "115:\tlearn: 1.2538987\ttotal: 22.7s\tremaining: 8m 5s\n",
      "116:\tlearn: 1.2489736\ttotal: 22.9s\tremaining: 8m 5s\n",
      "117:\tlearn: 1.2447828\ttotal: 23.1s\tremaining: 8m 5s\n",
      "118:\tlearn: 1.2406114\ttotal: 23.3s\tremaining: 8m 5s\n",
      "119:\tlearn: 1.2371824\ttotal: 23.5s\tremaining: 8m 4s\n",
      "120:\tlearn: 1.2325656\ttotal: 23.6s\tremaining: 8m 4s\n",
      "121:\tlearn: 1.2284178\ttotal: 23.8s\tremaining: 8m 3s\n",
      "122:\tlearn: 1.2238493\ttotal: 24s\tremaining: 8m 3s\n",
      "123:\tlearn: 1.2197069\ttotal: 24.2s\tremaining: 8m 3s\n",
      "124:\tlearn: 1.2159615\ttotal: 24.4s\tremaining: 8m 3s\n",
      "125:\tlearn: 1.2118219\ttotal: 24.6s\tremaining: 8m 3s\n",
      "126:\tlearn: 1.2073300\ttotal: 24.8s\tremaining: 8m 3s\n",
      "127:\tlearn: 1.2038202\ttotal: 25s\tremaining: 8m 2s\n",
      "128:\tlearn: 1.2001815\ttotal: 25.2s\tremaining: 8m 2s\n",
      "129:\tlearn: 1.1957266\ttotal: 25.4s\tremaining: 8m 2s\n",
      "130:\tlearn: 1.1929381\ttotal: 25.6s\tremaining: 8m 2s\n",
      "131:\tlearn: 1.1885847\ttotal: 25.8s\tremaining: 8m 1s\n",
      "132:\tlearn: 1.1847632\ttotal: 26s\tremaining: 8m 1s\n",
      "133:\tlearn: 1.1811275\ttotal: 26.2s\tremaining: 8m 1s\n",
      "134:\tlearn: 1.1778860\ttotal: 26.4s\tremaining: 8m 1s\n",
      "135:\tlearn: 1.1744598\ttotal: 26.6s\tremaining: 8m 1s\n",
      "136:\tlearn: 1.1703065\ttotal: 26.8s\tremaining: 8m 1s\n",
      "137:\tlearn: 1.1670352\ttotal: 26.9s\tremaining: 8m\n",
      "138:\tlearn: 1.1627283\ttotal: 27.1s\tremaining: 8m\n",
      "139:\tlearn: 1.1587911\ttotal: 27.3s\tremaining: 8m\n",
      "140:\tlearn: 1.1553571\ttotal: 27.5s\tremaining: 8m\n",
      "141:\tlearn: 1.1518057\ttotal: 27.7s\tremaining: 7m 59s\n",
      "142:\tlearn: 1.1482037\ttotal: 27.9s\tremaining: 7m 59s\n",
      "143:\tlearn: 1.1446705\ttotal: 28.1s\tremaining: 7m 59s\n",
      "144:\tlearn: 1.1422322\ttotal: 28.3s\tremaining: 7m 59s\n",
      "145:\tlearn: 1.1389559\ttotal: 28.5s\tremaining: 7m 59s\n",
      "146:\tlearn: 1.1360907\ttotal: 28.7s\tremaining: 7m 58s\n",
      "147:\tlearn: 1.1327048\ttotal: 28.9s\tremaining: 7m 58s\n",
      "148:\tlearn: 1.1284543\ttotal: 29.1s\tremaining: 7m 58s\n",
      "149:\tlearn: 1.1260411\ttotal: 29.3s\tremaining: 7m 58s\n",
      "150:\tlearn: 1.1219748\ttotal: 29.5s\tremaining: 7m 58s\n",
      "151:\tlearn: 1.1181365\ttotal: 29.7s\tremaining: 7m 58s\n",
      "152:\tlearn: 1.1155463\ttotal: 29.9s\tremaining: 7m 57s\n",
      "153:\tlearn: 1.1119688\ttotal: 30.1s\tremaining: 7m 57s\n",
      "154:\tlearn: 1.1089797\ttotal: 30.3s\tremaining: 7m 57s\n",
      "155:\tlearn: 1.1057554\ttotal: 30.5s\tremaining: 7m 57s\n",
      "156:\tlearn: 1.1026785\ttotal: 30.6s\tremaining: 7m 56s\n",
      "157:\tlearn: 1.0994332\ttotal: 30.8s\tremaining: 7m 56s\n",
      "158:\tlearn: 1.0963529\ttotal: 31s\tremaining: 7m 56s\n",
      "159:\tlearn: 1.0929428\ttotal: 31.2s\tremaining: 7m 56s\n",
      "160:\tlearn: 1.0889520\ttotal: 31.4s\tremaining: 7m 56s\n",
      "161:\tlearn: 1.0853758\ttotal: 31.6s\tremaining: 7m 55s\n",
      "162:\tlearn: 1.0817476\ttotal: 31.8s\tremaining: 7m 55s\n",
      "163:\tlearn: 1.0785589\ttotal: 32s\tremaining: 7m 55s\n",
      "164:\tlearn: 1.0749085\ttotal: 32.2s\tremaining: 7m 55s\n",
      "165:\tlearn: 1.0726536\ttotal: 32.4s\tremaining: 7m 55s\n",
      "166:\tlearn: 1.0699694\ttotal: 32.6s\tremaining: 7m 54s\n",
      "167:\tlearn: 1.0669390\ttotal: 32.8s\tremaining: 7m 54s\n",
      "168:\tlearn: 1.0641597\ttotal: 33s\tremaining: 7m 54s\n",
      "169:\tlearn: 1.0611438\ttotal: 33.2s\tremaining: 7m 54s\n",
      "170:\tlearn: 1.0576537\ttotal: 33.4s\tremaining: 7m 53s\n",
      "171:\tlearn: 1.0547284\ttotal: 33.5s\tremaining: 7m 53s\n",
      "172:\tlearn: 1.0515160\ttotal: 33.7s\tremaining: 7m 53s\n",
      "173:\tlearn: 1.0478015\ttotal: 33.9s\tremaining: 7m 52s\n",
      "174:\tlearn: 1.0461987\ttotal: 34.2s\tremaining: 7m 53s\n",
      "175:\tlearn: 1.0440841\ttotal: 34.3s\tremaining: 7m 53s\n",
      "176:\tlearn: 1.0420556\ttotal: 34.5s\tremaining: 7m 52s\n",
      "177:\tlearn: 1.0385252\ttotal: 34.7s\tremaining: 7m 52s\n",
      "178:\tlearn: 1.0352470\ttotal: 34.9s\tremaining: 7m 52s\n",
      "179:\tlearn: 1.0326921\ttotal: 35.1s\tremaining: 7m 51s\n",
      "180:\tlearn: 1.0297947\ttotal: 35.3s\tremaining: 7m 52s\n",
      "181:\tlearn: 1.0275112\ttotal: 35.5s\tremaining: 7m 51s\n",
      "182:\tlearn: 1.0256978\ttotal: 35.7s\tremaining: 7m 51s\n",
      "183:\tlearn: 1.0227561\ttotal: 35.9s\tremaining: 7m 51s\n",
      "184:\tlearn: 1.0199155\ttotal: 36.1s\tremaining: 7m 50s\n",
      "185:\tlearn: 1.0174156\ttotal: 36.3s\tremaining: 7m 50s\n",
      "186:\tlearn: 1.0143181\ttotal: 36.5s\tremaining: 7m 50s\n",
      "187:\tlearn: 1.0111564\ttotal: 36.7s\tremaining: 7m 50s\n",
      "188:\tlearn: 1.0091156\ttotal: 36.9s\tremaining: 7m 50s\n",
      "189:\tlearn: 1.0058708\ttotal: 37.1s\tremaining: 7m 50s\n",
      "190:\tlearn: 1.0031261\ttotal: 37.3s\tremaining: 7m 50s\n",
      "191:\tlearn: 1.0002602\ttotal: 37.5s\tremaining: 7m 49s\n",
      "192:\tlearn: 0.9978951\ttotal: 37.6s\tremaining: 7m 49s\n",
      "193:\tlearn: 0.9945765\ttotal: 37.8s\tremaining: 7m 49s\n",
      "194:\tlearn: 0.9916594\ttotal: 38s\tremaining: 7m 48s\n",
      "195:\tlearn: 0.9894067\ttotal: 38.2s\tremaining: 7m 48s\n",
      "196:\tlearn: 0.9867172\ttotal: 38.4s\tremaining: 7m 48s\n",
      "197:\tlearn: 0.9839260\ttotal: 38.6s\tremaining: 7m 48s\n",
      "198:\tlearn: 0.9811639\ttotal: 38.8s\tremaining: 7m 48s\n",
      "199:\tlearn: 0.9788702\ttotal: 39s\tremaining: 7m 48s\n",
      "200:\tlearn: 0.9763850\ttotal: 39.2s\tremaining: 7m 47s\n",
      "201:\tlearn: 0.9725578\ttotal: 39.4s\tremaining: 7m 47s\n",
      "202:\tlearn: 0.9703257\ttotal: 39.6s\tremaining: 7m 47s\n",
      "203:\tlearn: 0.9683315\ttotal: 39.8s\tremaining: 7m 46s\n",
      "204:\tlearn: 0.9658167\ttotal: 39.9s\tremaining: 7m 46s\n",
      "205:\tlearn: 0.9636888\ttotal: 40.2s\tremaining: 7m 46s\n",
      "206:\tlearn: 0.9614705\ttotal: 40.3s\tremaining: 7m 46s\n",
      "207:\tlearn: 0.9596143\ttotal: 40.5s\tremaining: 7m 46s\n",
      "208:\tlearn: 0.9576563\ttotal: 40.7s\tremaining: 7m 45s\n",
      "209:\tlearn: 0.9552847\ttotal: 40.9s\tremaining: 7m 45s\n",
      "210:\tlearn: 0.9522425\ttotal: 41.1s\tremaining: 7m 45s\n",
      "211:\tlearn: 0.9501760\ttotal: 41.3s\tremaining: 7m 45s\n",
      "212:\tlearn: 0.9480407\ttotal: 41.5s\tremaining: 7m 45s\n",
      "213:\tlearn: 0.9454457\ttotal: 41.7s\tremaining: 7m 44s\n",
      "214:\tlearn: 0.9430402\ttotal: 41.9s\tremaining: 7m 44s\n",
      "215:\tlearn: 0.9415301\ttotal: 42.1s\tremaining: 7m 44s\n",
      "216:\tlearn: 0.9395887\ttotal: 42.3s\tremaining: 7m 44s\n",
      "217:\tlearn: 0.9378587\ttotal: 42.5s\tremaining: 7m 44s\n",
      "218:\tlearn: 0.9355616\ttotal: 42.7s\tremaining: 7m 44s\n",
      "219:\tlearn: 0.9337181\ttotal: 42.9s\tremaining: 7m 43s\n",
      "220:\tlearn: 0.9309378\ttotal: 43.1s\tremaining: 7m 43s\n",
      "221:\tlearn: 0.9295504\ttotal: 43.3s\tremaining: 7m 43s\n",
      "222:\tlearn: 0.9269148\ttotal: 43.4s\tremaining: 7m 43s\n",
      "223:\tlearn: 0.9253076\ttotal: 43.6s\tremaining: 7m 42s\n",
      "224:\tlearn: 0.9228319\ttotal: 43.8s\tremaining: 7m 42s\n",
      "225:\tlearn: 0.9204512\ttotal: 44s\tremaining: 7m 42s\n",
      "226:\tlearn: 0.9187805\ttotal: 44.2s\tremaining: 7m 42s\n",
      "227:\tlearn: 0.9167510\ttotal: 44.4s\tremaining: 7m 42s\n",
      "228:\tlearn: 0.9146700\ttotal: 44.6s\tremaining: 7m 41s\n",
      "229:\tlearn: 0.9125964\ttotal: 44.8s\tremaining: 7m 41s\n",
      "230:\tlearn: 0.9105495\ttotal: 45s\tremaining: 7m 41s\n",
      "231:\tlearn: 0.9079335\ttotal: 45.2s\tremaining: 7m 41s\n",
      "232:\tlearn: 0.9053532\ttotal: 45.4s\tremaining: 7m 41s\n",
      "233:\tlearn: 0.9032817\ttotal: 45.6s\tremaining: 7m 41s\n",
      "234:\tlearn: 0.9008500\ttotal: 45.8s\tremaining: 7m 40s\n",
      "235:\tlearn: 0.8987956\ttotal: 46s\tremaining: 7m 40s\n",
      "236:\tlearn: 0.8967433\ttotal: 46.2s\tremaining: 7m 40s\n",
      "237:\tlearn: 0.8945244\ttotal: 46.4s\tremaining: 7m 40s\n",
      "238:\tlearn: 0.8923251\ttotal: 46.6s\tremaining: 7m 40s\n",
      "239:\tlearn: 0.8906257\ttotal: 46.8s\tremaining: 7m 39s\n",
      "240:\tlearn: 0.8885031\ttotal: 46.9s\tremaining: 7m 39s\n",
      "241:\tlearn: 0.8860531\ttotal: 47.1s\tremaining: 7m 39s\n",
      "242:\tlearn: 0.8838654\ttotal: 47.3s\tremaining: 7m 39s\n",
      "243:\tlearn: 0.8822354\ttotal: 47.5s\tremaining: 7m 38s\n",
      "244:\tlearn: 0.8801662\ttotal: 47.7s\tremaining: 7m 38s\n",
      "245:\tlearn: 0.8780644\ttotal: 47.9s\tremaining: 7m 38s\n",
      "246:\tlearn: 0.8761749\ttotal: 48.1s\tremaining: 7m 38s\n",
      "247:\tlearn: 0.8746425\ttotal: 48.3s\tremaining: 7m 38s\n",
      "248:\tlearn: 0.8728938\ttotal: 48.5s\tremaining: 7m 38s\n",
      "249:\tlearn: 0.8710355\ttotal: 48.7s\tremaining: 7m 37s\n",
      "250:\tlearn: 0.8690931\ttotal: 48.9s\tremaining: 7m 37s\n",
      "251:\tlearn: 0.8676216\ttotal: 49.1s\tremaining: 7m 37s\n",
      "252:\tlearn: 0.8657336\ttotal: 49.3s\tremaining: 7m 37s\n",
      "253:\tlearn: 0.8636171\ttotal: 49.5s\tremaining: 7m 36s\n",
      "254:\tlearn: 0.8618622\ttotal: 49.7s\tremaining: 7m 36s\n",
      "255:\tlearn: 0.8601776\ttotal: 49.9s\tremaining: 7m 36s\n",
      "256:\tlearn: 0.8585215\ttotal: 50s\tremaining: 7m 36s\n",
      "257:\tlearn: 0.8572376\ttotal: 50.3s\tremaining: 7m 36s\n",
      "258:\tlearn: 0.8548946\ttotal: 50.5s\tremaining: 7m 36s\n",
      "259:\tlearn: 0.8537961\ttotal: 50.7s\tremaining: 7m 35s\n",
      "260:\tlearn: 0.8521218\ttotal: 50.8s\tremaining: 7m 35s\n",
      "261:\tlearn: 0.8505666\ttotal: 51s\tremaining: 7m 35s\n",
      "262:\tlearn: 0.8489698\ttotal: 51.2s\tremaining: 7m 35s\n",
      "263:\tlearn: 0.8471281\ttotal: 51.4s\tremaining: 7m 35s\n",
      "264:\tlearn: 0.8459910\ttotal: 51.6s\tremaining: 7m 34s\n",
      "265:\tlearn: 0.8442300\ttotal: 51.8s\tremaining: 7m 34s\n",
      "266:\tlearn: 0.8425071\ttotal: 52s\tremaining: 7m 34s\n",
      "267:\tlearn: 0.8410653\ttotal: 52.2s\tremaining: 7m 34s\n",
      "268:\tlearn: 0.8393246\ttotal: 52.4s\tremaining: 7m 34s\n",
      "269:\tlearn: 0.8372429\ttotal: 52.6s\tremaining: 7m 33s\n",
      "270:\tlearn: 0.8358125\ttotal: 52.8s\tremaining: 7m 33s\n",
      "271:\tlearn: 0.8339290\ttotal: 53s\tremaining: 7m 33s\n",
      "272:\tlearn: 0.8324203\ttotal: 53.2s\tremaining: 7m 33s\n",
      "273:\tlearn: 0.8308935\ttotal: 53.4s\tremaining: 7m 33s\n",
      "274:\tlearn: 0.8298131\ttotal: 53.6s\tremaining: 7m 32s\n",
      "275:\tlearn: 0.8286473\ttotal: 53.8s\tremaining: 7m 32s\n",
      "276:\tlearn: 0.8266502\ttotal: 53.9s\tremaining: 7m 32s\n",
      "277:\tlearn: 0.8253761\ttotal: 54.2s\tremaining: 7m 32s\n",
      "278:\tlearn: 0.8234195\ttotal: 54.4s\tremaining: 7m 32s\n",
      "279:\tlearn: 0.8216532\ttotal: 54.5s\tremaining: 7m 31s\n",
      "280:\tlearn: 0.8198731\ttotal: 54.7s\tremaining: 7m 31s\n",
      "281:\tlearn: 0.8187010\ttotal: 54.9s\tremaining: 7m 31s\n",
      "282:\tlearn: 0.8173771\ttotal: 55.1s\tremaining: 7m 31s\n",
      "283:\tlearn: 0.8162599\ttotal: 55.3s\tremaining: 7m 31s\n",
      "284:\tlearn: 0.8148174\ttotal: 55.5s\tremaining: 7m 30s\n",
      "285:\tlearn: 0.8133334\ttotal: 55.7s\tremaining: 7m 30s\n",
      "286:\tlearn: 0.8118891\ttotal: 55.9s\tremaining: 7m 30s\n",
      "287:\tlearn: 0.8098025\ttotal: 56.1s\tremaining: 7m 30s\n",
      "288:\tlearn: 0.8081036\ttotal: 56.3s\tremaining: 7m 30s\n",
      "289:\tlearn: 0.8068403\ttotal: 56.5s\tremaining: 7m 29s\n",
      "290:\tlearn: 0.8054100\ttotal: 56.7s\tremaining: 7m 29s\n",
      "291:\tlearn: 0.8038611\ttotal: 56.9s\tremaining: 7m 29s\n",
      "292:\tlearn: 0.8023397\ttotal: 57.1s\tremaining: 7m 29s\n",
      "293:\tlearn: 0.8005145\ttotal: 57.3s\tremaining: 7m 29s\n",
      "294:\tlearn: 0.7990524\ttotal: 57.5s\tremaining: 7m 29s\n",
      "295:\tlearn: 0.7972584\ttotal: 57.7s\tremaining: 7m 28s\n",
      "296:\tlearn: 0.7959001\ttotal: 57.8s\tremaining: 7m 28s\n",
      "297:\tlearn: 0.7940530\ttotal: 58.1s\tremaining: 7m 28s\n",
      "298:\tlearn: 0.7924823\ttotal: 58.3s\tremaining: 7m 28s\n",
      "299:\tlearn: 0.7905234\ttotal: 58.5s\tremaining: 7m 28s\n",
      "300:\tlearn: 0.7890274\ttotal: 58.6s\tremaining: 7m 27s\n",
      "301:\tlearn: 0.7876401\ttotal: 58.8s\tremaining: 7m 27s\n",
      "302:\tlearn: 0.7860526\ttotal: 59.1s\tremaining: 7m 27s\n",
      "303:\tlearn: 0.7845245\ttotal: 59.2s\tremaining: 7m 27s\n",
      "304:\tlearn: 0.7834077\ttotal: 59.4s\tremaining: 7m 27s\n",
      "305:\tlearn: 0.7814761\ttotal: 59.6s\tremaining: 7m 26s\n",
      "306:\tlearn: 0.7800871\ttotal: 59.8s\tremaining: 7m 26s\n",
      "307:\tlearn: 0.7790253\ttotal: 1m\tremaining: 7m 26s\n",
      "308:\tlearn: 0.7779464\ttotal: 1m\tremaining: 7m 26s\n",
      "309:\tlearn: 0.7764154\ttotal: 1m\tremaining: 7m 26s\n",
      "310:\tlearn: 0.7750047\ttotal: 1m\tremaining: 7m 26s\n",
      "311:\tlearn: 0.7737137\ttotal: 1m\tremaining: 7m 25s\n",
      "312:\tlearn: 0.7730777\ttotal: 1m\tremaining: 7m 25s\n",
      "313:\tlearn: 0.7718178\ttotal: 1m 1s\tremaining: 7m 25s\n",
      "314:\tlearn: 0.7703132\ttotal: 1m 1s\tremaining: 7m 25s\n",
      "315:\tlearn: 0.7688565\ttotal: 1m 1s\tremaining: 7m 25s\n",
      "316:\tlearn: 0.7675601\ttotal: 1m 1s\tremaining: 7m 24s\n",
      "317:\tlearn: 0.7664677\ttotal: 1m 1s\tremaining: 7m 24s\n",
      "318:\tlearn: 0.7655907\ttotal: 1m 2s\tremaining: 7m 24s\n",
      "319:\tlearn: 0.7641139\ttotal: 1m 2s\tremaining: 7m 24s\n",
      "320:\tlearn: 0.7631925\ttotal: 1m 2s\tremaining: 7m 24s\n",
      "321:\tlearn: 0.7617418\ttotal: 1m 2s\tremaining: 7m 23s\n",
      "322:\tlearn: 0.7601032\ttotal: 1m 2s\tremaining: 7m 23s\n",
      "323:\tlearn: 0.7590210\ttotal: 1m 3s\tremaining: 7m 23s\n",
      "324:\tlearn: 0.7581458\ttotal: 1m 3s\tremaining: 7m 23s\n",
      "325:\tlearn: 0.7573356\ttotal: 1m 3s\tremaining: 7m 23s\n",
      "326:\tlearn: 0.7559924\ttotal: 1m 3s\tremaining: 7m 22s\n",
      "327:\tlearn: 0.7545625\ttotal: 1m 3s\tremaining: 7m 22s\n",
      "328:\tlearn: 0.7535677\ttotal: 1m 4s\tremaining: 7m 22s\n",
      "329:\tlearn: 0.7522230\ttotal: 1m 4s\tremaining: 7m 22s\n",
      "330:\tlearn: 0.7510562\ttotal: 1m 4s\tremaining: 7m 22s\n",
      "331:\tlearn: 0.7498593\ttotal: 1m 4s\tremaining: 7m 22s\n",
      "332:\tlearn: 0.7485417\ttotal: 1m 4s\tremaining: 7m 21s\n",
      "333:\tlearn: 0.7472627\ttotal: 1m 5s\tremaining: 7m 21s\n",
      "334:\tlearn: 0.7457290\ttotal: 1m 5s\tremaining: 7m 21s\n",
      "335:\tlearn: 0.7443640\ttotal: 1m 5s\tremaining: 7m 21s\n",
      "336:\tlearn: 0.7426715\ttotal: 1m 5s\tremaining: 7m 21s\n",
      "337:\tlearn: 0.7415947\ttotal: 1m 5s\tremaining: 7m 20s\n",
      "338:\tlearn: 0.7404403\ttotal: 1m 6s\tremaining: 7m 20s\n",
      "339:\tlearn: 0.7389802\ttotal: 1m 6s\tremaining: 7m 20s\n",
      "340:\tlearn: 0.7374906\ttotal: 1m 6s\tremaining: 7m 20s\n",
      "341:\tlearn: 0.7361698\ttotal: 1m 6s\tremaining: 7m 20s\n",
      "342:\tlearn: 0.7351569\ttotal: 1m 6s\tremaining: 7m 19s\n",
      "343:\tlearn: 0.7334660\ttotal: 1m 7s\tremaining: 7m 19s\n",
      "344:\tlearn: 0.7322735\ttotal: 1m 7s\tremaining: 7m 19s\n",
      "345:\tlearn: 0.7312719\ttotal: 1m 7s\tremaining: 7m 19s\n",
      "346:\tlearn: 0.7302626\ttotal: 1m 7s\tremaining: 7m 19s\n",
      "347:\tlearn: 0.7290852\ttotal: 1m 7s\tremaining: 7m 18s\n",
      "348:\tlearn: 0.7282912\ttotal: 1m 8s\tremaining: 7m 18s\n",
      "349:\tlearn: 0.7270729\ttotal: 1m 8s\tremaining: 7m 18s\n",
      "350:\tlearn: 0.7257770\ttotal: 1m 8s\tremaining: 7m 18s\n",
      "351:\tlearn: 0.7247225\ttotal: 1m 8s\tremaining: 7m 18s\n",
      "352:\tlearn: 0.7234446\ttotal: 1m 8s\tremaining: 7m 18s\n",
      "353:\tlearn: 0.7221806\ttotal: 1m 9s\tremaining: 7m 17s\n",
      "354:\tlearn: 0.7210575\ttotal: 1m 9s\tremaining: 7m 17s\n",
      "355:\tlearn: 0.7196344\ttotal: 1m 9s\tremaining: 7m 17s\n",
      "356:\tlearn: 0.7186537\ttotal: 1m 9s\tremaining: 7m 17s\n",
      "357:\tlearn: 0.7172486\ttotal: 1m 9s\tremaining: 7m 17s\n",
      "358:\tlearn: 0.7160435\ttotal: 1m 9s\tremaining: 7m 16s\n",
      "359:\tlearn: 0.7144770\ttotal: 1m 10s\tremaining: 7m 16s\n",
      "360:\tlearn: 0.7133651\ttotal: 1m 10s\tremaining: 7m 16s\n",
      "361:\tlearn: 0.7124454\ttotal: 1m 10s\tremaining: 7m 16s\n",
      "362:\tlearn: 0.7112762\ttotal: 1m 10s\tremaining: 7m 16s\n",
      "363:\tlearn: 0.7104658\ttotal: 1m 10s\tremaining: 7m 15s\n",
      "364:\tlearn: 0.7090977\ttotal: 1m 11s\tremaining: 7m 15s\n",
      "365:\tlearn: 0.7079272\ttotal: 1m 11s\tremaining: 7m 15s\n",
      "366:\tlearn: 0.7062911\ttotal: 1m 11s\tremaining: 7m 15s\n",
      "367:\tlearn: 0.7052840\ttotal: 1m 11s\tremaining: 7m 15s\n",
      "368:\tlearn: 0.7041755\ttotal: 1m 11s\tremaining: 7m 14s\n",
      "369:\tlearn: 0.7032070\ttotal: 1m 12s\tremaining: 7m 14s\n",
      "370:\tlearn: 0.7019087\ttotal: 1m 12s\tremaining: 7m 14s\n",
      "371:\tlearn: 0.7008414\ttotal: 1m 12s\tremaining: 7m 14s\n",
      "372:\tlearn: 0.7000064\ttotal: 1m 12s\tremaining: 7m 14s\n",
      "373:\tlearn: 0.6989620\ttotal: 1m 12s\tremaining: 7m 13s\n",
      "374:\tlearn: 0.6980899\ttotal: 1m 13s\tremaining: 7m 13s\n",
      "375:\tlearn: 0.6970946\ttotal: 1m 13s\tremaining: 7m 13s\n",
      "376:\tlearn: 0.6962105\ttotal: 1m 13s\tremaining: 7m 13s\n",
      "377:\tlearn: 0.6955027\ttotal: 1m 13s\tremaining: 7m 13s\n",
      "378:\tlearn: 0.6945613\ttotal: 1m 13s\tremaining: 7m 12s\n",
      "379:\tlearn: 0.6932509\ttotal: 1m 14s\tremaining: 7m 12s\n",
      "380:\tlearn: 0.6923919\ttotal: 1m 14s\tremaining: 7m 12s\n",
      "381:\tlearn: 0.6913482\ttotal: 1m 14s\tremaining: 7m 12s\n",
      "382:\tlearn: 0.6906600\ttotal: 1m 14s\tremaining: 7m 12s\n",
      "383:\tlearn: 0.6893292\ttotal: 1m 14s\tremaining: 7m 11s\n",
      "384:\tlearn: 0.6878811\ttotal: 1m 15s\tremaining: 7m 11s\n",
      "385:\tlearn: 0.6869248\ttotal: 1m 15s\tremaining: 7m 11s\n",
      "386:\tlearn: 0.6858746\ttotal: 1m 15s\tremaining: 7m 11s\n",
      "387:\tlearn: 0.6850009\ttotal: 1m 15s\tremaining: 7m 11s\n",
      "388:\tlearn: 0.6837386\ttotal: 1m 15s\tremaining: 7m 11s\n",
      "389:\tlearn: 0.6827609\ttotal: 1m 16s\tremaining: 7m 10s\n",
      "390:\tlearn: 0.6822646\ttotal: 1m 16s\tremaining: 7m 10s\n",
      "391:\tlearn: 0.6813318\ttotal: 1m 16s\tremaining: 7m 10s\n",
      "392:\tlearn: 0.6802489\ttotal: 1m 16s\tremaining: 7m 10s\n",
      "393:\tlearn: 0.6794482\ttotal: 1m 16s\tremaining: 7m 9s\n",
      "394:\tlearn: 0.6779951\ttotal: 1m 17s\tremaining: 7m 9s\n",
      "395:\tlearn: 0.6772170\ttotal: 1m 17s\tremaining: 7m 9s\n",
      "396:\tlearn: 0.6759799\ttotal: 1m 17s\tremaining: 7m 9s\n",
      "397:\tlearn: 0.6749537\ttotal: 1m 17s\tremaining: 7m 9s\n",
      "398:\tlearn: 0.6740026\ttotal: 1m 17s\tremaining: 7m 8s\n",
      "399:\tlearn: 0.6729519\ttotal: 1m 17s\tremaining: 7m 8s\n",
      "400:\tlearn: 0.6718257\ttotal: 1m 18s\tremaining: 7m 8s\n",
      "401:\tlearn: 0.6704217\ttotal: 1m 18s\tremaining: 7m 8s\n",
      "402:\tlearn: 0.6692963\ttotal: 1m 18s\tremaining: 7m 8s\n",
      "403:\tlearn: 0.6682530\ttotal: 1m 18s\tremaining: 7m 8s\n",
      "404:\tlearn: 0.6674164\ttotal: 1m 18s\tremaining: 7m 7s\n",
      "405:\tlearn: 0.6663852\ttotal: 1m 19s\tremaining: 7m 7s\n",
      "406:\tlearn: 0.6654392\ttotal: 1m 19s\tremaining: 7m 7s\n",
      "407:\tlearn: 0.6642649\ttotal: 1m 19s\tremaining: 7m 7s\n",
      "408:\tlearn: 0.6635614\ttotal: 1m 19s\tremaining: 7m 7s\n",
      "409:\tlearn: 0.6620431\ttotal: 1m 19s\tremaining: 7m 6s\n",
      "410:\tlearn: 0.6608990\ttotal: 1m 20s\tremaining: 7m 6s\n",
      "411:\tlearn: 0.6600732\ttotal: 1m 20s\tremaining: 7m 6s\n",
      "412:\tlearn: 0.6590591\ttotal: 1m 20s\tremaining: 7m 6s\n",
      "413:\tlearn: 0.6581025\ttotal: 1m 20s\tremaining: 7m 6s\n",
      "414:\tlearn: 0.6570178\ttotal: 1m 20s\tremaining: 7m 5s\n",
      "415:\tlearn: 0.6559304\ttotal: 1m 21s\tremaining: 7m 5s\n",
      "416:\tlearn: 0.6549158\ttotal: 1m 21s\tremaining: 7m 5s\n",
      "417:\tlearn: 0.6537208\ttotal: 1m 21s\tremaining: 7m 5s\n",
      "418:\tlearn: 0.6526109\ttotal: 1m 21s\tremaining: 7m 5s\n",
      "419:\tlearn: 0.6514414\ttotal: 1m 21s\tremaining: 7m 4s\n",
      "420:\tlearn: 0.6502138\ttotal: 1m 22s\tremaining: 7m 4s\n",
      "421:\tlearn: 0.6490745\ttotal: 1m 22s\tremaining: 7m 4s\n",
      "422:\tlearn: 0.6481031\ttotal: 1m 22s\tremaining: 7m 4s\n",
      "423:\tlearn: 0.6473058\ttotal: 1m 22s\tremaining: 7m 4s\n",
      "424:\tlearn: 0.6463824\ttotal: 1m 22s\tremaining: 7m 3s\n",
      "425:\tlearn: 0.6453001\ttotal: 1m 23s\tremaining: 7m 3s\n",
      "426:\tlearn: 0.6442120\ttotal: 1m 23s\tremaining: 7m 3s\n",
      "427:\tlearn: 0.6432963\ttotal: 1m 23s\tremaining: 7m 3s\n",
      "428:\tlearn: 0.6420733\ttotal: 1m 23s\tremaining: 7m 3s\n",
      "429:\tlearn: 0.6409653\ttotal: 1m 23s\tremaining: 7m 2s\n",
      "430:\tlearn: 0.6401537\ttotal: 1m 24s\tremaining: 7m 2s\n",
      "431:\tlearn: 0.6393568\ttotal: 1m 24s\tremaining: 7m 2s\n",
      "432:\tlearn: 0.6386010\ttotal: 1m 24s\tremaining: 7m 2s\n",
      "433:\tlearn: 0.6378764\ttotal: 1m 24s\tremaining: 7m 2s\n",
      "434:\tlearn: 0.6367940\ttotal: 1m 24s\tremaining: 7m 1s\n",
      "435:\tlearn: 0.6355450\ttotal: 1m 24s\tremaining: 7m 1s\n",
      "436:\tlearn: 0.6344624\ttotal: 1m 25s\tremaining: 7m 1s\n",
      "437:\tlearn: 0.6330086\ttotal: 1m 25s\tremaining: 7m 1s\n",
      "438:\tlearn: 0.6321771\ttotal: 1m 25s\tremaining: 7m 1s\n",
      "439:\tlearn: 0.6311768\ttotal: 1m 25s\tremaining: 7m 1s\n",
      "440:\tlearn: 0.6302299\ttotal: 1m 25s\tremaining: 7m\n",
      "441:\tlearn: 0.6294300\ttotal: 1m 26s\tremaining: 7m\n",
      "442:\tlearn: 0.6288072\ttotal: 1m 26s\tremaining: 7m\n",
      "443:\tlearn: 0.6280717\ttotal: 1m 26s\tremaining: 7m\n",
      "444:\tlearn: 0.6269640\ttotal: 1m 26s\tremaining: 7m\n",
      "445:\tlearn: 0.6260421\ttotal: 1m 26s\tremaining: 6m 59s\n",
      "446:\tlearn: 0.6251142\ttotal: 1m 27s\tremaining: 6m 59s\n",
      "447:\tlearn: 0.6238394\ttotal: 1m 27s\tremaining: 6m 59s\n",
      "448:\tlearn: 0.6229379\ttotal: 1m 27s\tremaining: 6m 59s\n",
      "449:\tlearn: 0.6217042\ttotal: 1m 27s\tremaining: 6m 59s\n",
      "450:\tlearn: 0.6209939\ttotal: 1m 27s\tremaining: 6m 58s\n",
      "451:\tlearn: 0.6201378\ttotal: 1m 28s\tremaining: 6m 58s\n",
      "452:\tlearn: 0.6195112\ttotal: 1m 28s\tremaining: 6m 58s\n",
      "453:\tlearn: 0.6188739\ttotal: 1m 28s\tremaining: 6m 58s\n",
      "454:\tlearn: 0.6180615\ttotal: 1m 28s\tremaining: 6m 58s\n",
      "455:\tlearn: 0.6173160\ttotal: 1m 28s\tremaining: 6m 58s\n",
      "456:\tlearn: 0.6166313\ttotal: 1m 29s\tremaining: 6m 57s\n",
      "457:\tlearn: 0.6156633\ttotal: 1m 29s\tremaining: 6m 57s\n",
      "458:\tlearn: 0.6148462\ttotal: 1m 29s\tremaining: 6m 57s\n",
      "459:\tlearn: 0.6138089\ttotal: 1m 29s\tremaining: 6m 57s\n",
      "460:\tlearn: 0.6126510\ttotal: 1m 29s\tremaining: 6m 56s\n",
      "461:\tlearn: 0.6118282\ttotal: 1m 30s\tremaining: 6m 56s\n",
      "462:\tlearn: 0.6107969\ttotal: 1m 30s\tremaining: 6m 56s\n",
      "463:\tlearn: 0.6098960\ttotal: 1m 30s\tremaining: 6m 56s\n",
      "464:\tlearn: 0.6092662\ttotal: 1m 30s\tremaining: 6m 56s\n",
      "465:\tlearn: 0.6082945\ttotal: 1m 30s\tremaining: 6m 56s\n",
      "466:\tlearn: 0.6075019\ttotal: 1m 31s\tremaining: 6m 55s\n",
      "467:\tlearn: 0.6066750\ttotal: 1m 31s\tremaining: 6m 55s\n",
      "468:\tlearn: 0.6060569\ttotal: 1m 31s\tremaining: 6m 55s\n",
      "469:\tlearn: 0.6052263\ttotal: 1m 31s\tremaining: 6m 55s\n",
      "470:\tlearn: 0.6046670\ttotal: 1m 31s\tremaining: 6m 54s\n",
      "471:\tlearn: 0.6038642\ttotal: 1m 32s\tremaining: 6m 54s\n",
      "472:\tlearn: 0.6028125\ttotal: 1m 32s\tremaining: 6m 54s\n",
      "473:\tlearn: 0.6023452\ttotal: 1m 32s\tremaining: 6m 54s\n",
      "474:\tlearn: 0.6014450\ttotal: 1m 32s\tremaining: 6m 54s\n",
      "475:\tlearn: 0.6005374\ttotal: 1m 32s\tremaining: 6m 54s\n",
      "476:\tlearn: 0.5996928\ttotal: 1m 33s\tremaining: 6m 53s\n",
      "477:\tlearn: 0.5991221\ttotal: 1m 33s\tremaining: 6m 53s\n",
      "478:\tlearn: 0.5983538\ttotal: 1m 33s\tremaining: 6m 53s\n",
      "479:\tlearn: 0.5978829\ttotal: 1m 33s\tremaining: 6m 53s\n",
      "480:\tlearn: 0.5972266\ttotal: 1m 33s\tremaining: 6m 53s\n",
      "481:\tlearn: 0.5963646\ttotal: 1m 33s\tremaining: 6m 52s\n",
      "482:\tlearn: 0.5959302\ttotal: 1m 34s\tremaining: 6m 52s\n",
      "483:\tlearn: 0.5950104\ttotal: 1m 34s\tremaining: 6m 52s\n",
      "484:\tlearn: 0.5939743\ttotal: 1m 34s\tremaining: 6m 52s\n",
      "485:\tlearn: 0.5928888\ttotal: 1m 34s\tremaining: 6m 52s\n",
      "486:\tlearn: 0.5919148\ttotal: 1m 34s\tremaining: 6m 52s\n",
      "487:\tlearn: 0.5912474\ttotal: 1m 35s\tremaining: 6m 51s\n",
      "488:\tlearn: 0.5903446\ttotal: 1m 35s\tremaining: 6m 51s\n",
      "489:\tlearn: 0.5897458\ttotal: 1m 35s\tremaining: 6m 51s\n",
      "490:\tlearn: 0.5892508\ttotal: 1m 35s\tremaining: 6m 51s\n",
      "491:\tlearn: 0.5885399\ttotal: 1m 35s\tremaining: 6m 51s\n",
      "492:\tlearn: 0.5873372\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "493:\tlearn: 0.5863316\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "494:\tlearn: 0.5853633\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "495:\tlearn: 0.5845220\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "496:\tlearn: 0.5834782\ttotal: 1m 36s\tremaining: 6m 50s\n",
      "497:\tlearn: 0.5829992\ttotal: 1m 37s\tremaining: 6m 50s\n",
      "498:\tlearn: 0.5822483\ttotal: 1m 37s\tremaining: 6m 49s\n",
      "499:\tlearn: 0.5816891\ttotal: 1m 37s\tremaining: 6m 49s\n",
      "500:\tlearn: 0.5808735\ttotal: 1m 37s\tremaining: 6m 49s\n",
      "501:\tlearn: 0.5800538\ttotal: 1m 37s\tremaining: 6m 49s\n",
      "502:\tlearn: 0.5792381\ttotal: 1m 38s\tremaining: 6m 48s\n",
      "503:\tlearn: 0.5782378\ttotal: 1m 38s\tremaining: 6m 48s\n",
      "504:\tlearn: 0.5772000\ttotal: 1m 38s\tremaining: 6m 48s\n",
      "505:\tlearn: 0.5764334\ttotal: 1m 38s\tremaining: 6m 48s\n",
      "506:\tlearn: 0.5756255\ttotal: 1m 38s\tremaining: 6m 48s\n",
      "507:\tlearn: 0.5745553\ttotal: 1m 39s\tremaining: 6m 47s\n",
      "508:\tlearn: 0.5735358\ttotal: 1m 39s\tremaining: 6m 47s\n",
      "509:\tlearn: 0.5723950\ttotal: 1m 39s\tremaining: 6m 47s\n",
      "510:\tlearn: 0.5714089\ttotal: 1m 39s\tremaining: 6m 47s\n",
      "511:\tlearn: 0.5706798\ttotal: 1m 39s\tremaining: 6m 47s\n",
      "512:\tlearn: 0.5699011\ttotal: 1m 40s\tremaining: 6m 47s\n",
      "513:\tlearn: 0.5690600\ttotal: 1m 40s\tremaining: 6m 46s\n",
      "514:\tlearn: 0.5683868\ttotal: 1m 40s\tremaining: 6m 46s\n",
      "515:\tlearn: 0.5677226\ttotal: 1m 40s\tremaining: 6m 46s\n",
      "516:\tlearn: 0.5672033\ttotal: 1m 40s\tremaining: 6m 46s\n",
      "517:\tlearn: 0.5664331\ttotal: 1m 41s\tremaining: 6m 46s\n",
      "518:\tlearn: 0.5660240\ttotal: 1m 41s\tremaining: 6m 45s\n",
      "519:\tlearn: 0.5651691\ttotal: 1m 41s\tremaining: 6m 45s\n",
      "520:\tlearn: 0.5645717\ttotal: 1m 41s\tremaining: 6m 45s\n",
      "521:\tlearn: 0.5640062\ttotal: 1m 41s\tremaining: 6m 45s\n",
      "522:\tlearn: 0.5633987\ttotal: 1m 41s\tremaining: 6m 44s\n",
      "523:\tlearn: 0.5625781\ttotal: 1m 42s\tremaining: 6m 44s\n",
      "524:\tlearn: 0.5619077\ttotal: 1m 42s\tremaining: 6m 44s\n",
      "525:\tlearn: 0.5610129\ttotal: 1m 42s\tremaining: 6m 44s\n",
      "526:\tlearn: 0.5601563\ttotal: 1m 42s\tremaining: 6m 44s\n",
      "527:\tlearn: 0.5594945\ttotal: 1m 42s\tremaining: 6m 44s\n",
      "528:\tlearn: 0.5588771\ttotal: 1m 43s\tremaining: 6m 43s\n",
      "529:\tlearn: 0.5580008\ttotal: 1m 43s\tremaining: 6m 43s\n",
      "530:\tlearn: 0.5574061\ttotal: 1m 43s\tremaining: 6m 43s\n",
      "531:\tlearn: 0.5566488\ttotal: 1m 43s\tremaining: 6m 43s\n",
      "532:\tlearn: 0.5557657\ttotal: 1m 43s\tremaining: 6m 43s\n",
      "533:\tlearn: 0.5548829\ttotal: 1m 44s\tremaining: 6m 42s\n",
      "534:\tlearn: 0.5540221\ttotal: 1m 44s\tremaining: 6m 42s\n",
      "535:\tlearn: 0.5532788\ttotal: 1m 44s\tremaining: 6m 42s\n",
      "536:\tlearn: 0.5522044\ttotal: 1m 44s\tremaining: 6m 42s\n",
      "537:\tlearn: 0.5515572\ttotal: 1m 44s\tremaining: 6m 42s\n",
      "538:\tlearn: 0.5509283\ttotal: 1m 45s\tremaining: 6m 41s\n",
      "539:\tlearn: 0.5501492\ttotal: 1m 45s\tremaining: 6m 41s\n",
      "540:\tlearn: 0.5492624\ttotal: 1m 45s\tremaining: 6m 41s\n",
      "541:\tlearn: 0.5484362\ttotal: 1m 45s\tremaining: 6m 41s\n",
      "542:\tlearn: 0.5478694\ttotal: 1m 45s\tremaining: 6m 40s\n",
      "543:\tlearn: 0.5474719\ttotal: 1m 46s\tremaining: 6m 40s\n",
      "544:\tlearn: 0.5468293\ttotal: 1m 46s\tremaining: 6m 40s\n",
      "545:\tlearn: 0.5460886\ttotal: 1m 46s\tremaining: 6m 40s\n",
      "546:\tlearn: 0.5453565\ttotal: 1m 46s\tremaining: 6m 40s\n",
      "547:\tlearn: 0.5444426\ttotal: 1m 46s\tremaining: 6m 39s\n",
      "548:\tlearn: 0.5438926\ttotal: 1m 47s\tremaining: 6m 39s\n",
      "549:\tlearn: 0.5428301\ttotal: 1m 47s\tremaining: 6m 39s\n",
      "550:\tlearn: 0.5421743\ttotal: 1m 47s\tremaining: 6m 39s\n",
      "551:\tlearn: 0.5415569\ttotal: 1m 47s\tremaining: 6m 39s\n",
      "552:\tlearn: 0.5407124\ttotal: 1m 47s\tremaining: 6m 38s\n",
      "553:\tlearn: 0.5401161\ttotal: 1m 47s\tremaining: 6m 38s\n",
      "554:\tlearn: 0.5395874\ttotal: 1m 48s\tremaining: 6m 38s\n",
      "555:\tlearn: 0.5386153\ttotal: 1m 48s\tremaining: 6m 38s\n",
      "556:\tlearn: 0.5379482\ttotal: 1m 48s\tremaining: 6m 38s\n",
      "557:\tlearn: 0.5372175\ttotal: 1m 48s\tremaining: 6m 37s\n",
      "558:\tlearn: 0.5366451\ttotal: 1m 48s\tremaining: 6m 37s\n",
      "559:\tlearn: 0.5359877\ttotal: 1m 49s\tremaining: 6m 37s\n",
      "560:\tlearn: 0.5352876\ttotal: 1m 49s\tremaining: 6m 37s\n",
      "561:\tlearn: 0.5343835\ttotal: 1m 49s\tremaining: 6m 37s\n",
      "562:\tlearn: 0.5337213\ttotal: 1m 49s\tremaining: 6m 36s\n",
      "563:\tlearn: 0.5332606\ttotal: 1m 49s\tremaining: 6m 36s\n",
      "564:\tlearn: 0.5326186\ttotal: 1m 50s\tremaining: 6m 36s\n",
      "565:\tlearn: 0.5319399\ttotal: 1m 50s\tremaining: 6m 36s\n",
      "566:\tlearn: 0.5313020\ttotal: 1m 50s\tremaining: 6m 36s\n",
      "567:\tlearn: 0.5303577\ttotal: 1m 50s\tremaining: 6m 35s\n",
      "568:\tlearn: 0.5296762\ttotal: 1m 50s\tremaining: 6m 35s\n",
      "569:\tlearn: 0.5288196\ttotal: 1m 51s\tremaining: 6m 35s\n",
      "570:\tlearn: 0.5281873\ttotal: 1m 51s\tremaining: 6m 35s\n",
      "571:\tlearn: 0.5274260\ttotal: 1m 51s\tremaining: 6m 35s\n",
      "572:\tlearn: 0.5268213\ttotal: 1m 51s\tremaining: 6m 35s\n",
      "573:\tlearn: 0.5261816\ttotal: 1m 51s\tremaining: 6m 34s\n",
      "574:\tlearn: 0.5256751\ttotal: 1m 52s\tremaining: 6m 34s\n",
      "575:\tlearn: 0.5252591\ttotal: 1m 52s\tremaining: 6m 34s\n",
      "576:\tlearn: 0.5245135\ttotal: 1m 52s\tremaining: 6m 34s\n",
      "577:\tlearn: 0.5237275\ttotal: 1m 52s\tremaining: 6m 34s\n",
      "578:\tlearn: 0.5230772\ttotal: 1m 52s\tremaining: 6m 33s\n",
      "579:\tlearn: 0.5220313\ttotal: 1m 53s\tremaining: 6m 33s\n",
      "580:\tlearn: 0.5213713\ttotal: 1m 53s\tremaining: 6m 33s\n",
      "581:\tlearn: 0.5206905\ttotal: 1m 53s\tremaining: 6m 33s\n",
      "582:\tlearn: 0.5202021\ttotal: 1m 53s\tremaining: 6m 33s\n",
      "583:\tlearn: 0.5195718\ttotal: 1m 53s\tremaining: 6m 32s\n",
      "584:\tlearn: 0.5190280\ttotal: 1m 54s\tremaining: 6m 32s\n",
      "585:\tlearn: 0.5183305\ttotal: 1m 54s\tremaining: 6m 32s\n",
      "586:\tlearn: 0.5178417\ttotal: 1m 54s\tremaining: 6m 32s\n",
      "587:\tlearn: 0.5170698\ttotal: 1m 54s\tremaining: 6m 32s\n",
      "588:\tlearn: 0.5165051\ttotal: 1m 54s\tremaining: 6m 31s\n",
      "589:\tlearn: 0.5158204\ttotal: 1m 55s\tremaining: 6m 31s\n",
      "590:\tlearn: 0.5152104\ttotal: 1m 55s\tremaining: 6m 31s\n",
      "591:\tlearn: 0.5146046\ttotal: 1m 55s\tremaining: 6m 31s\n",
      "592:\tlearn: 0.5138262\ttotal: 1m 55s\tremaining: 6m 31s\n",
      "593:\tlearn: 0.5131543\ttotal: 1m 55s\tremaining: 6m 30s\n",
      "594:\tlearn: 0.5125766\ttotal: 1m 55s\tremaining: 6m 30s\n",
      "595:\tlearn: 0.5118928\ttotal: 1m 56s\tremaining: 6m 30s\n",
      "596:\tlearn: 0.5113024\ttotal: 1m 56s\tremaining: 6m 30s\n",
      "597:\tlearn: 0.5107023\ttotal: 1m 56s\tremaining: 6m 30s\n",
      "598:\tlearn: 0.5101769\ttotal: 1m 56s\tremaining: 6m 30s\n",
      "599:\tlearn: 0.5093581\ttotal: 1m 56s\tremaining: 6m 29s\n",
      "600:\tlearn: 0.5087103\ttotal: 1m 57s\tremaining: 6m 29s\n",
      "601:\tlearn: 0.5077269\ttotal: 1m 57s\tremaining: 6m 29s\n",
      "602:\tlearn: 0.5068542\ttotal: 1m 57s\tremaining: 6m 29s\n",
      "603:\tlearn: 0.5064719\ttotal: 1m 57s\tremaining: 6m 29s\n",
      "604:\tlearn: 0.5057936\ttotal: 1m 57s\tremaining: 6m 28s\n",
      "605:\tlearn: 0.5049813\ttotal: 1m 58s\tremaining: 6m 28s\n",
      "606:\tlearn: 0.5044152\ttotal: 1m 58s\tremaining: 6m 28s\n",
      "607:\tlearn: 0.5038411\ttotal: 1m 58s\tremaining: 6m 28s\n",
      "608:\tlearn: 0.5028144\ttotal: 1m 58s\tremaining: 6m 28s\n",
      "609:\tlearn: 0.5022153\ttotal: 1m 58s\tremaining: 6m 27s\n",
      "610:\tlearn: 0.5015082\ttotal: 1m 59s\tremaining: 6m 27s\n",
      "611:\tlearn: 0.5009582\ttotal: 1m 59s\tremaining: 6m 27s\n",
      "612:\tlearn: 0.5000939\ttotal: 1m 59s\tremaining: 6m 27s\n",
      "613:\tlearn: 0.4996831\ttotal: 1m 59s\tremaining: 6m 27s\n",
      "614:\tlearn: 0.4990722\ttotal: 1m 59s\tremaining: 6m 26s\n",
      "615:\tlearn: 0.4984373\ttotal: 2m\tremaining: 6m 26s\n",
      "616:\tlearn: 0.4979192\ttotal: 2m\tremaining: 6m 26s\n",
      "617:\tlearn: 0.4973720\ttotal: 2m\tremaining: 6m 26s\n",
      "618:\tlearn: 0.4964713\ttotal: 2m\tremaining: 6m 26s\n",
      "619:\tlearn: 0.4958748\ttotal: 2m\tremaining: 6m 25s\n",
      "620:\tlearn: 0.4949850\ttotal: 2m 1s\tremaining: 6m 25s\n",
      "621:\tlearn: 0.4943575\ttotal: 2m 1s\tremaining: 6m 25s\n",
      "622:\tlearn: 0.4935072\ttotal: 2m 1s\tremaining: 6m 25s\n",
      "623:\tlearn: 0.4931415\ttotal: 2m 1s\tremaining: 6m 25s\n",
      "624:\tlearn: 0.4925870\ttotal: 2m 1s\tremaining: 6m 25s\n",
      "625:\tlearn: 0.4922656\ttotal: 2m 2s\tremaining: 6m 24s\n",
      "626:\tlearn: 0.4915744\ttotal: 2m 2s\tremaining: 6m 24s\n",
      "627:\tlearn: 0.4908298\ttotal: 2m 2s\tremaining: 6m 24s\n",
      "628:\tlearn: 0.4902978\ttotal: 2m 2s\tremaining: 6m 24s\n",
      "629:\tlearn: 0.4896872\ttotal: 2m 2s\tremaining: 6m 24s\n",
      "630:\tlearn: 0.4890045\ttotal: 2m 3s\tremaining: 6m 24s\n",
      "631:\tlearn: 0.4884569\ttotal: 2m 3s\tremaining: 6m 23s\n",
      "632:\tlearn: 0.4877383\ttotal: 2m 3s\tremaining: 6m 23s\n",
      "633:\tlearn: 0.4869683\ttotal: 2m 3s\tremaining: 6m 23s\n",
      "634:\tlearn: 0.4864099\ttotal: 2m 3s\tremaining: 6m 23s\n",
      "635:\tlearn: 0.4859717\ttotal: 2m 4s\tremaining: 6m 23s\n",
      "636:\tlearn: 0.4854203\ttotal: 2m 4s\tremaining: 6m 22s\n",
      "637:\tlearn: 0.4846836\ttotal: 2m 4s\tremaining: 6m 22s\n",
      "638:\tlearn: 0.4840005\ttotal: 2m 4s\tremaining: 6m 22s\n",
      "639:\tlearn: 0.4832688\ttotal: 2m 4s\tremaining: 6m 22s\n",
      "640:\tlearn: 0.4828150\ttotal: 2m 5s\tremaining: 6m 22s\n",
      "641:\tlearn: 0.4823349\ttotal: 2m 5s\tremaining: 6m 21s\n",
      "642:\tlearn: 0.4820963\ttotal: 2m 5s\tremaining: 6m 21s\n",
      "643:\tlearn: 0.4814453\ttotal: 2m 5s\tremaining: 6m 21s\n",
      "644:\tlearn: 0.4809485\ttotal: 2m 5s\tremaining: 6m 21s\n",
      "645:\tlearn: 0.4804600\ttotal: 2m 5s\tremaining: 6m 21s\n",
      "646:\tlearn: 0.4801013\ttotal: 2m 6s\tremaining: 6m 20s\n",
      "647:\tlearn: 0.4795019\ttotal: 2m 6s\tremaining: 6m 20s\n",
      "648:\tlearn: 0.4786877\ttotal: 2m 6s\tremaining: 6m 20s\n",
      "649:\tlearn: 0.4780409\ttotal: 2m 6s\tremaining: 6m 20s\n",
      "650:\tlearn: 0.4776012\ttotal: 2m 6s\tremaining: 6m 20s\n",
      "651:\tlearn: 0.4770257\ttotal: 2m 7s\tremaining: 6m 19s\n",
      "652:\tlearn: 0.4766986\ttotal: 2m 7s\tremaining: 6m 19s\n",
      "653:\tlearn: 0.4761271\ttotal: 2m 7s\tremaining: 6m 19s\n",
      "654:\tlearn: 0.4757473\ttotal: 2m 7s\tremaining: 6m 19s\n",
      "655:\tlearn: 0.4752796\ttotal: 2m 7s\tremaining: 6m 19s\n",
      "656:\tlearn: 0.4748036\ttotal: 2m 8s\tremaining: 6m 18s\n",
      "657:\tlearn: 0.4742523\ttotal: 2m 8s\tremaining: 6m 18s\n",
      "658:\tlearn: 0.4735889\ttotal: 2m 8s\tremaining: 6m 18s\n",
      "659:\tlearn: 0.4729043\ttotal: 2m 8s\tremaining: 6m 18s\n",
      "660:\tlearn: 0.4721798\ttotal: 2m 8s\tremaining: 6m 18s\n",
      "661:\tlearn: 0.4715330\ttotal: 2m 9s\tremaining: 6m 17s\n",
      "662:\tlearn: 0.4711133\ttotal: 2m 9s\tremaining: 6m 17s\n",
      "663:\tlearn: 0.4707509\ttotal: 2m 9s\tremaining: 6m 17s\n",
      "664:\tlearn: 0.4701366\ttotal: 2m 9s\tremaining: 6m 17s\n",
      "665:\tlearn: 0.4695681\ttotal: 2m 9s\tremaining: 6m 17s\n",
      "666:\tlearn: 0.4689642\ttotal: 2m 10s\tremaining: 6m 16s\n",
      "667:\tlearn: 0.4684705\ttotal: 2m 10s\tremaining: 6m 16s\n",
      "668:\tlearn: 0.4679814\ttotal: 2m 10s\tremaining: 6m 16s\n",
      "669:\tlearn: 0.4674365\ttotal: 2m 10s\tremaining: 6m 16s\n",
      "670:\tlearn: 0.4667444\ttotal: 2m 10s\tremaining: 6m 16s\n",
      "671:\tlearn: 0.4662434\ttotal: 2m 11s\tremaining: 6m 15s\n",
      "672:\tlearn: 0.4656117\ttotal: 2m 11s\tremaining: 6m 15s\n",
      "673:\tlearn: 0.4652813\ttotal: 2m 11s\tremaining: 6m 15s\n",
      "674:\tlearn: 0.4650225\ttotal: 2m 11s\tremaining: 6m 15s\n",
      "675:\tlearn: 0.4645356\ttotal: 2m 11s\tremaining: 6m 15s\n",
      "676:\tlearn: 0.4639611\ttotal: 2m 11s\tremaining: 6m 14s\n",
      "677:\tlearn: 0.4633701\ttotal: 2m 12s\tremaining: 6m 14s\n",
      "678:\tlearn: 0.4628906\ttotal: 2m 12s\tremaining: 6m 14s\n",
      "679:\tlearn: 0.4624125\ttotal: 2m 12s\tremaining: 6m 14s\n",
      "680:\tlearn: 0.4621017\ttotal: 2m 12s\tremaining: 6m 14s\n",
      "681:\tlearn: 0.4616622\ttotal: 2m 12s\tremaining: 6m 13s\n",
      "682:\tlearn: 0.4612138\ttotal: 2m 13s\tremaining: 6m 13s\n",
      "683:\tlearn: 0.4606754\ttotal: 2m 13s\tremaining: 6m 13s\n",
      "684:\tlearn: 0.4599828\ttotal: 2m 13s\tremaining: 6m 13s\n",
      "685:\tlearn: 0.4595396\ttotal: 2m 13s\tremaining: 6m 13s\n",
      "686:\tlearn: 0.4587339\ttotal: 2m 13s\tremaining: 6m 13s\n",
      "687:\tlearn: 0.4579859\ttotal: 2m 14s\tremaining: 6m 12s\n",
      "688:\tlearn: 0.4572397\ttotal: 2m 14s\tremaining: 6m 12s\n",
      "689:\tlearn: 0.4568941\ttotal: 2m 14s\tremaining: 6m 12s\n",
      "690:\tlearn: 0.4564127\ttotal: 2m 14s\tremaining: 6m 12s\n",
      "691:\tlearn: 0.4558326\ttotal: 2m 14s\tremaining: 6m 12s\n",
      "692:\tlearn: 0.4554201\ttotal: 2m 15s\tremaining: 6m 11s\n",
      "693:\tlearn: 0.4549331\ttotal: 2m 15s\tremaining: 6m 11s\n",
      "694:\tlearn: 0.4545027\ttotal: 2m 15s\tremaining: 6m 11s\n",
      "695:\tlearn: 0.4538912\ttotal: 2m 15s\tremaining: 6m 11s\n",
      "696:\tlearn: 0.4533177\ttotal: 2m 15s\tremaining: 6m 11s\n",
      "697:\tlearn: 0.4527215\ttotal: 2m 16s\tremaining: 6m 10s\n",
      "698:\tlearn: 0.4522237\ttotal: 2m 16s\tremaining: 6m 10s\n",
      "699:\tlearn: 0.4514638\ttotal: 2m 16s\tremaining: 6m 10s\n",
      "700:\tlearn: 0.4511853\ttotal: 2m 16s\tremaining: 6m 10s\n",
      "701:\tlearn: 0.4507912\ttotal: 2m 16s\tremaining: 6m 10s\n",
      "702:\tlearn: 0.4502629\ttotal: 2m 17s\tremaining: 6m 9s\n",
      "703:\tlearn: 0.4496921\ttotal: 2m 17s\tremaining: 6m 9s\n",
      "704:\tlearn: 0.4489538\ttotal: 2m 17s\tremaining: 6m 9s\n",
      "705:\tlearn: 0.4486566\ttotal: 2m 17s\tremaining: 6m 9s\n",
      "706:\tlearn: 0.4481267\ttotal: 2m 17s\tremaining: 6m 9s\n",
      "707:\tlearn: 0.4476385\ttotal: 2m 18s\tremaining: 6m 8s\n",
      "708:\tlearn: 0.4469696\ttotal: 2m 18s\tremaining: 6m 8s\n",
      "709:\tlearn: 0.4464373\ttotal: 2m 18s\tremaining: 6m 8s\n",
      "710:\tlearn: 0.4458315\ttotal: 2m 18s\tremaining: 6m 8s\n",
      "711:\tlearn: 0.4451849\ttotal: 2m 18s\tremaining: 6m 8s\n",
      "712:\tlearn: 0.4444783\ttotal: 2m 19s\tremaining: 6m 7s\n",
      "713:\tlearn: 0.4437200\ttotal: 2m 19s\tremaining: 6m 7s\n",
      "714:\tlearn: 0.4432514\ttotal: 2m 19s\tremaining: 6m 7s\n",
      "715:\tlearn: 0.4428320\ttotal: 2m 19s\tremaining: 6m 7s\n",
      "716:\tlearn: 0.4421697\ttotal: 2m 19s\tremaining: 6m 7s\n",
      "717:\tlearn: 0.4418409\ttotal: 2m 19s\tremaining: 6m 6s\n",
      "718:\tlearn: 0.4412483\ttotal: 2m 20s\tremaining: 6m 6s\n",
      "719:\tlearn: 0.4406847\ttotal: 2m 20s\tremaining: 6m 6s\n",
      "720:\tlearn: 0.4401715\ttotal: 2m 20s\tremaining: 6m 6s\n",
      "721:\tlearn: 0.4395025\ttotal: 2m 20s\tremaining: 6m 6s\n",
      "722:\tlearn: 0.4390861\ttotal: 2m 20s\tremaining: 6m 6s\n",
      "723:\tlearn: 0.4386169\ttotal: 2m 21s\tremaining: 6m 5s\n",
      "724:\tlearn: 0.4381801\ttotal: 2m 21s\tremaining: 6m 5s\n",
      "725:\tlearn: 0.4376711\ttotal: 2m 21s\tremaining: 6m 5s\n",
      "726:\tlearn: 0.4372634\ttotal: 2m 21s\tremaining: 6m 5s\n",
      "727:\tlearn: 0.4369159\ttotal: 2m 21s\tremaining: 6m 4s\n",
      "728:\tlearn: 0.4364213\ttotal: 2m 22s\tremaining: 6m 4s\n",
      "729:\tlearn: 0.4360370\ttotal: 2m 22s\tremaining: 6m 4s\n",
      "730:\tlearn: 0.4355515\ttotal: 2m 22s\tremaining: 6m 4s\n",
      "731:\tlearn: 0.4349234\ttotal: 2m 22s\tremaining: 6m 4s\n",
      "732:\tlearn: 0.4342456\ttotal: 2m 22s\tremaining: 6m 4s\n",
      "733:\tlearn: 0.4338639\ttotal: 2m 23s\tremaining: 6m 3s\n",
      "734:\tlearn: 0.4332587\ttotal: 2m 23s\tremaining: 6m 3s\n",
      "735:\tlearn: 0.4326873\ttotal: 2m 23s\tremaining: 6m 3s\n",
      "736:\tlearn: 0.4322639\ttotal: 2m 23s\tremaining: 6m 3s\n",
      "737:\tlearn: 0.4316815\ttotal: 2m 23s\tremaining: 6m 3s\n",
      "738:\tlearn: 0.4313596\ttotal: 2m 24s\tremaining: 6m 2s\n",
      "739:\tlearn: 0.4308170\ttotal: 2m 24s\tremaining: 6m 2s\n",
      "740:\tlearn: 0.4304667\ttotal: 2m 24s\tremaining: 6m 2s\n",
      "741:\tlearn: 0.4300322\ttotal: 2m 24s\tremaining: 6m 2s\n",
      "742:\tlearn: 0.4296701\ttotal: 2m 24s\tremaining: 6m 2s\n",
      "743:\tlearn: 0.4292136\ttotal: 2m 25s\tremaining: 6m 1s\n",
      "744:\tlearn: 0.4287650\ttotal: 2m 25s\tremaining: 6m 1s\n",
      "745:\tlearn: 0.4282055\ttotal: 2m 25s\tremaining: 6m 1s\n",
      "746:\tlearn: 0.4277529\ttotal: 2m 25s\tremaining: 6m 1s\n",
      "747:\tlearn: 0.4273287\ttotal: 2m 25s\tremaining: 6m 1s\n",
      "748:\tlearn: 0.4269488\ttotal: 2m 26s\tremaining: 6m\n",
      "749:\tlearn: 0.4267034\ttotal: 2m 26s\tremaining: 6m\n",
      "750:\tlearn: 0.4263605\ttotal: 2m 26s\tremaining: 6m\n",
      "751:\tlearn: 0.4258883\ttotal: 2m 26s\tremaining: 6m\n",
      "752:\tlearn: 0.4254625\ttotal: 2m 26s\tremaining: 6m\n",
      "753:\tlearn: 0.4251407\ttotal: 2m 27s\tremaining: 5m 59s\n",
      "754:\tlearn: 0.4246645\ttotal: 2m 27s\tremaining: 5m 59s\n",
      "755:\tlearn: 0.4240642\ttotal: 2m 27s\tremaining: 5m 59s\n",
      "756:\tlearn: 0.4236586\ttotal: 2m 27s\tremaining: 5m 59s\n",
      "757:\tlearn: 0.4228189\ttotal: 2m 27s\tremaining: 5m 59s\n",
      "758:\tlearn: 0.4221991\ttotal: 2m 27s\tremaining: 5m 58s\n",
      "759:\tlearn: 0.4217597\ttotal: 2m 28s\tremaining: 5m 58s\n",
      "760:\tlearn: 0.4212883\ttotal: 2m 28s\tremaining: 5m 58s\n",
      "761:\tlearn: 0.4209051\ttotal: 2m 28s\tremaining: 5m 58s\n",
      "762:\tlearn: 0.4205304\ttotal: 2m 28s\tremaining: 5m 58s\n",
      "763:\tlearn: 0.4201171\ttotal: 2m 28s\tremaining: 5m 57s\n",
      "764:\tlearn: 0.4194203\ttotal: 2m 29s\tremaining: 5m 57s\n",
      "765:\tlearn: 0.4190515\ttotal: 2m 29s\tremaining: 5m 57s\n",
      "766:\tlearn: 0.4184995\ttotal: 2m 29s\tremaining: 5m 57s\n",
      "767:\tlearn: 0.4179132\ttotal: 2m 29s\tremaining: 5m 57s\n",
      "768:\tlearn: 0.4175077\ttotal: 2m 29s\tremaining: 5m 56s\n",
      "769:\tlearn: 0.4171459\ttotal: 2m 30s\tremaining: 5m 56s\n",
      "770:\tlearn: 0.4166339\ttotal: 2m 30s\tremaining: 5m 56s\n",
      "771:\tlearn: 0.4159356\ttotal: 2m 30s\tremaining: 5m 56s\n",
      "772:\tlearn: 0.4156688\ttotal: 2m 30s\tremaining: 5m 56s\n",
      "773:\tlearn: 0.4152276\ttotal: 2m 30s\tremaining: 5m 55s\n",
      "774:\tlearn: 0.4147897\ttotal: 2m 31s\tremaining: 5m 55s\n",
      "775:\tlearn: 0.4143188\ttotal: 2m 31s\tremaining: 5m 55s\n",
      "776:\tlearn: 0.4138192\ttotal: 2m 31s\tremaining: 5m 55s\n",
      "777:\tlearn: 0.4134270\ttotal: 2m 31s\tremaining: 5m 55s\n",
      "778:\tlearn: 0.4129587\ttotal: 2m 31s\tremaining: 5m 54s\n",
      "779:\tlearn: 0.4124953\ttotal: 2m 31s\tremaining: 5m 54s\n",
      "780:\tlearn: 0.4118205\ttotal: 2m 32s\tremaining: 5m 54s\n",
      "781:\tlearn: 0.4114795\ttotal: 2m 32s\tremaining: 5m 54s\n",
      "782:\tlearn: 0.4108397\ttotal: 2m 32s\tremaining: 5m 54s\n",
      "783:\tlearn: 0.4103817\ttotal: 2m 32s\tremaining: 5m 53s\n",
      "784:\tlearn: 0.4099329\ttotal: 2m 32s\tremaining: 5m 53s\n",
      "785:\tlearn: 0.4093393\ttotal: 2m 33s\tremaining: 5m 53s\n",
      "786:\tlearn: 0.4087774\ttotal: 2m 33s\tremaining: 5m 53s\n",
      "787:\tlearn: 0.4084627\ttotal: 2m 33s\tremaining: 5m 53s\n",
      "788:\tlearn: 0.4079923\ttotal: 2m 33s\tremaining: 5m 52s\n",
      "789:\tlearn: 0.4075945\ttotal: 2m 33s\tremaining: 5m 52s\n",
      "790:\tlearn: 0.4070522\ttotal: 2m 34s\tremaining: 5m 52s\n",
      "791:\tlearn: 0.4065034\ttotal: 2m 34s\tremaining: 5m 52s\n",
      "792:\tlearn: 0.4059856\ttotal: 2m 34s\tremaining: 5m 52s\n",
      "793:\tlearn: 0.4056012\ttotal: 2m 34s\tremaining: 5m 51s\n",
      "794:\tlearn: 0.4052438\ttotal: 2m 34s\tremaining: 5m 51s\n",
      "795:\tlearn: 0.4047274\ttotal: 2m 35s\tremaining: 5m 51s\n",
      "796:\tlearn: 0.4043783\ttotal: 2m 35s\tremaining: 5m 51s\n",
      "797:\tlearn: 0.4041144\ttotal: 2m 35s\tremaining: 5m 51s\n",
      "798:\tlearn: 0.4038171\ttotal: 2m 35s\tremaining: 5m 50s\n",
      "799:\tlearn: 0.4031673\ttotal: 2m 35s\tremaining: 5m 50s\n",
      "800:\tlearn: 0.4024321\ttotal: 2m 36s\tremaining: 5m 50s\n",
      "801:\tlearn: 0.4019105\ttotal: 2m 36s\tremaining: 5m 50s\n",
      "802:\tlearn: 0.4012725\ttotal: 2m 36s\tremaining: 5m 50s\n",
      "803:\tlearn: 0.4005769\ttotal: 2m 36s\tremaining: 5m 49s\n",
      "804:\tlearn: 0.4001888\ttotal: 2m 36s\tremaining: 5m 49s\n",
      "805:\tlearn: 0.3998020\ttotal: 2m 37s\tremaining: 5m 49s\n",
      "806:\tlearn: 0.3994559\ttotal: 2m 37s\tremaining: 5m 49s\n",
      "807:\tlearn: 0.3988783\ttotal: 2m 37s\tremaining: 5m 49s\n",
      "808:\tlearn: 0.3983639\ttotal: 2m 37s\tremaining: 5m 48s\n",
      "809:\tlearn: 0.3976734\ttotal: 2m 37s\tremaining: 5m 48s\n",
      "810:\tlearn: 0.3972925\ttotal: 2m 38s\tremaining: 5m 48s\n",
      "811:\tlearn: 0.3970167\ttotal: 2m 38s\tremaining: 5m 48s\n",
      "812:\tlearn: 0.3963126\ttotal: 2m 38s\tremaining: 5m 48s\n",
      "813:\tlearn: 0.3956878\ttotal: 2m 38s\tremaining: 5m 47s\n",
      "814:\tlearn: 0.3952019\ttotal: 2m 38s\tremaining: 5m 47s\n",
      "815:\tlearn: 0.3947492\ttotal: 2m 38s\tremaining: 5m 47s\n",
      "816:\tlearn: 0.3942536\ttotal: 2m 39s\tremaining: 5m 47s\n",
      "817:\tlearn: 0.3939542\ttotal: 2m 39s\tremaining: 5m 47s\n",
      "818:\tlearn: 0.3935574\ttotal: 2m 39s\tremaining: 5m 46s\n",
      "819:\tlearn: 0.3930623\ttotal: 2m 39s\tremaining: 5m 46s\n",
      "820:\tlearn: 0.3926358\ttotal: 2m 39s\tremaining: 5m 46s\n",
      "821:\tlearn: 0.3920658\ttotal: 2m 40s\tremaining: 5m 46s\n",
      "822:\tlearn: 0.3916328\ttotal: 2m 40s\tremaining: 5m 46s\n",
      "823:\tlearn: 0.3912357\ttotal: 2m 40s\tremaining: 5m 45s\n",
      "824:\tlearn: 0.3909228\ttotal: 2m 40s\tremaining: 5m 45s\n",
      "825:\tlearn: 0.3905541\ttotal: 2m 40s\tremaining: 5m 45s\n",
      "826:\tlearn: 0.3903073\ttotal: 2m 41s\tremaining: 5m 45s\n",
      "827:\tlearn: 0.3899507\ttotal: 2m 41s\tremaining: 5m 45s\n",
      "828:\tlearn: 0.3895171\ttotal: 2m 41s\tremaining: 5m 44s\n",
      "829:\tlearn: 0.3891115\ttotal: 2m 41s\tremaining: 5m 44s\n",
      "830:\tlearn: 0.3888442\ttotal: 2m 41s\tremaining: 5m 44s\n",
      "831:\tlearn: 0.3884011\ttotal: 2m 42s\tremaining: 5m 44s\n",
      "832:\tlearn: 0.3880518\ttotal: 2m 42s\tremaining: 5m 44s\n",
      "833:\tlearn: 0.3874841\ttotal: 2m 42s\tremaining: 5m 44s\n",
      "834:\tlearn: 0.3870536\ttotal: 2m 42s\tremaining: 5m 43s\n",
      "835:\tlearn: 0.3864100\ttotal: 2m 42s\tremaining: 5m 43s\n",
      "836:\tlearn: 0.3858885\ttotal: 2m 43s\tremaining: 5m 43s\n",
      "837:\tlearn: 0.3855240\ttotal: 2m 43s\tremaining: 5m 43s\n",
      "838:\tlearn: 0.3852242\ttotal: 2m 43s\tremaining: 5m 43s\n",
      "839:\tlearn: 0.3846174\ttotal: 2m 43s\tremaining: 5m 42s\n",
      "840:\tlearn: 0.3842103\ttotal: 2m 43s\tremaining: 5m 42s\n",
      "841:\tlearn: 0.3837703\ttotal: 2m 44s\tremaining: 5m 42s\n",
      "842:\tlearn: 0.3833694\ttotal: 2m 44s\tremaining: 5m 42s\n",
      "843:\tlearn: 0.3829187\ttotal: 2m 44s\tremaining: 5m 42s\n",
      "844:\tlearn: 0.3825954\ttotal: 2m 44s\tremaining: 5m 41s\n",
      "845:\tlearn: 0.3820934\ttotal: 2m 44s\tremaining: 5m 41s\n",
      "846:\tlearn: 0.3815174\ttotal: 2m 45s\tremaining: 5m 41s\n",
      "847:\tlearn: 0.3810198\ttotal: 2m 45s\tremaining: 5m 41s\n",
      "848:\tlearn: 0.3806079\ttotal: 2m 45s\tremaining: 5m 41s\n",
      "849:\tlearn: 0.3802620\ttotal: 2m 45s\tremaining: 5m 40s\n",
      "850:\tlearn: 0.3799200\ttotal: 2m 45s\tremaining: 5m 40s\n",
      "851:\tlearn: 0.3796511\ttotal: 2m 45s\tremaining: 5m 40s\n",
      "852:\tlearn: 0.3791737\ttotal: 2m 46s\tremaining: 5m 40s\n",
      "853:\tlearn: 0.3786787\ttotal: 2m 46s\tremaining: 5m 40s\n",
      "854:\tlearn: 0.3782465\ttotal: 2m 46s\tremaining: 5m 39s\n",
      "855:\tlearn: 0.3777237\ttotal: 2m 46s\tremaining: 5m 39s\n",
      "856:\tlearn: 0.3773439\ttotal: 2m 46s\tremaining: 5m 39s\n",
      "857:\tlearn: 0.3770956\ttotal: 2m 47s\tremaining: 5m 39s\n",
      "858:\tlearn: 0.3768393\ttotal: 2m 47s\tremaining: 5m 39s\n",
      "859:\tlearn: 0.3763281\ttotal: 2m 47s\tremaining: 5m 38s\n",
      "860:\tlearn: 0.3760177\ttotal: 2m 47s\tremaining: 5m 38s\n",
      "861:\tlearn: 0.3757279\ttotal: 2m 47s\tremaining: 5m 38s\n",
      "862:\tlearn: 0.3754501\ttotal: 2m 48s\tremaining: 5m 38s\n",
      "863:\tlearn: 0.3751903\ttotal: 2m 48s\tremaining: 5m 38s\n",
      "864:\tlearn: 0.3749086\ttotal: 2m 48s\tremaining: 5m 37s\n",
      "865:\tlearn: 0.3745436\ttotal: 2m 48s\tremaining: 5m 37s\n",
      "866:\tlearn: 0.3740612\ttotal: 2m 48s\tremaining: 5m 37s\n",
      "867:\tlearn: 0.3736494\ttotal: 2m 49s\tremaining: 5m 37s\n",
      "868:\tlearn: 0.3732706\ttotal: 2m 49s\tremaining: 5m 37s\n",
      "869:\tlearn: 0.3729739\ttotal: 2m 49s\tremaining: 5m 36s\n",
      "870:\tlearn: 0.3725550\ttotal: 2m 49s\tremaining: 5m 36s\n",
      "871:\tlearn: 0.3720021\ttotal: 2m 49s\tremaining: 5m 36s\n",
      "872:\tlearn: 0.3717031\ttotal: 2m 50s\tremaining: 5m 36s\n",
      "873:\tlearn: 0.3712998\ttotal: 2m 50s\tremaining: 5m 36s\n",
      "874:\tlearn: 0.3708819\ttotal: 2m 50s\tremaining: 5m 35s\n",
      "875:\tlearn: 0.3703827\ttotal: 2m 50s\tremaining: 5m 35s\n",
      "876:\tlearn: 0.3699779\ttotal: 2m 50s\tremaining: 5m 35s\n",
      "877:\tlearn: 0.3695547\ttotal: 2m 51s\tremaining: 5m 35s\n",
      "878:\tlearn: 0.3691170\ttotal: 2m 51s\tremaining: 5m 35s\n",
      "879:\tlearn: 0.3687005\ttotal: 2m 51s\tremaining: 5m 34s\n",
      "880:\tlearn: 0.3683114\ttotal: 2m 51s\tremaining: 5m 34s\n",
      "881:\tlearn: 0.3679730\ttotal: 2m 51s\tremaining: 5m 34s\n",
      "882:\tlearn: 0.3676570\ttotal: 2m 51s\tremaining: 5m 34s\n",
      "883:\tlearn: 0.3671445\ttotal: 2m 52s\tremaining: 5m 34s\n",
      "884:\tlearn: 0.3666159\ttotal: 2m 52s\tremaining: 5m 34s\n",
      "885:\tlearn: 0.3662417\ttotal: 2m 52s\tremaining: 5m 33s\n",
      "886:\tlearn: 0.3659793\ttotal: 2m 52s\tremaining: 5m 33s\n",
      "887:\tlearn: 0.3657579\ttotal: 2m 52s\tremaining: 5m 33s\n",
      "888:\tlearn: 0.3654042\ttotal: 2m 53s\tremaining: 5m 33s\n",
      "889:\tlearn: 0.3649916\ttotal: 2m 53s\tremaining: 5m 32s\n",
      "890:\tlearn: 0.3644245\ttotal: 2m 53s\tremaining: 5m 32s\n",
      "891:\tlearn: 0.3641138\ttotal: 2m 53s\tremaining: 5m 32s\n",
      "892:\tlearn: 0.3637103\ttotal: 2m 53s\tremaining: 5m 32s\n",
      "893:\tlearn: 0.3631745\ttotal: 2m 54s\tremaining: 5m 32s\n",
      "894:\tlearn: 0.3629310\ttotal: 2m 54s\tremaining: 5m 32s\n",
      "895:\tlearn: 0.3627462\ttotal: 2m 54s\tremaining: 5m 31s\n",
      "896:\tlearn: 0.3623988\ttotal: 2m 54s\tremaining: 5m 31s\n",
      "897:\tlearn: 0.3620722\ttotal: 2m 54s\tremaining: 5m 31s\n",
      "898:\tlearn: 0.3617024\ttotal: 2m 55s\tremaining: 5m 31s\n",
      "899:\tlearn: 0.3613253\ttotal: 2m 55s\tremaining: 5m 31s\n",
      "900:\tlearn: 0.3610769\ttotal: 2m 55s\tremaining: 5m 30s\n",
      "901:\tlearn: 0.3605129\ttotal: 2m 55s\tremaining: 5m 30s\n",
      "902:\tlearn: 0.3602308\ttotal: 2m 55s\tremaining: 5m 30s\n",
      "903:\tlearn: 0.3597980\ttotal: 2m 56s\tremaining: 5m 30s\n",
      "904:\tlearn: 0.3594310\ttotal: 2m 56s\tremaining: 5m 30s\n",
      "905:\tlearn: 0.3590802\ttotal: 2m 56s\tremaining: 5m 29s\n",
      "906:\tlearn: 0.3588501\ttotal: 2m 56s\tremaining: 5m 29s\n",
      "907:\tlearn: 0.3584775\ttotal: 2m 56s\tremaining: 5m 29s\n",
      "908:\tlearn: 0.3582383\ttotal: 2m 56s\tremaining: 5m 29s\n",
      "909:\tlearn: 0.3577927\ttotal: 2m 57s\tremaining: 5m 29s\n",
      "910:\tlearn: 0.3573195\ttotal: 2m 57s\tremaining: 5m 28s\n",
      "911:\tlearn: 0.3571282\ttotal: 2m 57s\tremaining: 5m 28s\n",
      "912:\tlearn: 0.3568826\ttotal: 2m 57s\tremaining: 5m 28s\n",
      "913:\tlearn: 0.3565231\ttotal: 2m 57s\tremaining: 5m 28s\n",
      "914:\tlearn: 0.3559914\ttotal: 2m 58s\tremaining: 5m 28s\n",
      "915:\tlearn: 0.3557149\ttotal: 2m 58s\tremaining: 5m 27s\n",
      "916:\tlearn: 0.3552022\ttotal: 2m 58s\tremaining: 5m 27s\n",
      "917:\tlearn: 0.3547249\ttotal: 2m 58s\tremaining: 5m 27s\n",
      "918:\tlearn: 0.3543280\ttotal: 2m 58s\tremaining: 5m 27s\n",
      "919:\tlearn: 0.3539757\ttotal: 2m 59s\tremaining: 5m 27s\n",
      "920:\tlearn: 0.3535984\ttotal: 2m 59s\tremaining: 5m 26s\n",
      "921:\tlearn: 0.3533938\ttotal: 2m 59s\tremaining: 5m 26s\n",
      "922:\tlearn: 0.3531022\ttotal: 2m 59s\tremaining: 5m 26s\n",
      "923:\tlearn: 0.3527511\ttotal: 2m 59s\tremaining: 5m 26s\n",
      "924:\tlearn: 0.3523352\ttotal: 3m\tremaining: 5m 26s\n",
      "925:\tlearn: 0.3521227\ttotal: 3m\tremaining: 5m 25s\n",
      "926:\tlearn: 0.3519194\ttotal: 3m\tremaining: 5m 25s\n",
      "927:\tlearn: 0.3516057\ttotal: 3m\tremaining: 5m 25s\n",
      "928:\tlearn: 0.3512563\ttotal: 3m\tremaining: 5m 25s\n",
      "929:\tlearn: 0.3508293\ttotal: 3m 1s\tremaining: 5m 25s\n",
      "930:\tlearn: 0.3504313\ttotal: 3m 1s\tremaining: 5m 24s\n",
      "931:\tlearn: 0.3502335\ttotal: 3m 1s\tremaining: 5m 24s\n",
      "932:\tlearn: 0.3498525\ttotal: 3m 1s\tremaining: 5m 24s\n",
      "933:\tlearn: 0.3495162\ttotal: 3m 1s\tremaining: 5m 24s\n",
      "934:\tlearn: 0.3491778\ttotal: 3m 2s\tremaining: 5m 24s\n",
      "935:\tlearn: 0.3487258\ttotal: 3m 2s\tremaining: 5m 23s\n",
      "936:\tlearn: 0.3484451\ttotal: 3m 2s\tremaining: 5m 23s\n",
      "937:\tlearn: 0.3481040\ttotal: 3m 2s\tremaining: 5m 23s\n",
      "938:\tlearn: 0.3477500\ttotal: 3m 2s\tremaining: 5m 23s\n",
      "939:\tlearn: 0.3473285\ttotal: 3m 3s\tremaining: 5m 23s\n",
      "940:\tlearn: 0.3469347\ttotal: 3m 3s\tremaining: 5m 23s\n",
      "941:\tlearn: 0.3466821\ttotal: 3m 3s\tremaining: 5m 22s\n",
      "942:\tlearn: 0.3464169\ttotal: 3m 3s\tremaining: 5m 22s\n",
      "943:\tlearn: 0.3461567\ttotal: 3m 3s\tremaining: 5m 22s\n",
      "944:\tlearn: 0.3458795\ttotal: 3m 4s\tremaining: 5m 22s\n",
      "945:\tlearn: 0.3453955\ttotal: 3m 4s\tremaining: 5m 22s\n",
      "946:\tlearn: 0.3449567\ttotal: 3m 4s\tremaining: 5m 21s\n",
      "947:\tlearn: 0.3445692\ttotal: 3m 4s\tremaining: 5m 21s\n",
      "948:\tlearn: 0.3442457\ttotal: 3m 4s\tremaining: 5m 21s\n",
      "949:\tlearn: 0.3437713\ttotal: 3m 4s\tremaining: 5m 21s\n",
      "950:\tlearn: 0.3434165\ttotal: 3m 5s\tremaining: 5m 21s\n",
      "951:\tlearn: 0.3430383\ttotal: 3m 5s\tremaining: 5m 20s\n",
      "952:\tlearn: 0.3427005\ttotal: 3m 5s\tremaining: 5m 20s\n",
      "953:\tlearn: 0.3423358\ttotal: 3m 5s\tremaining: 5m 20s\n",
      "954:\tlearn: 0.3420142\ttotal: 3m 5s\tremaining: 5m 20s\n",
      "955:\tlearn: 0.3417904\ttotal: 3m 6s\tremaining: 5m 20s\n",
      "956:\tlearn: 0.3414041\ttotal: 3m 6s\tremaining: 5m 19s\n",
      "957:\tlearn: 0.3410329\ttotal: 3m 6s\tremaining: 5m 19s\n",
      "958:\tlearn: 0.3406372\ttotal: 3m 6s\tremaining: 5m 19s\n",
      "959:\tlearn: 0.3404083\ttotal: 3m 6s\tremaining: 5m 19s\n",
      "960:\tlearn: 0.3400890\ttotal: 3m 7s\tremaining: 5m 19s\n",
      "961:\tlearn: 0.3398640\ttotal: 3m 7s\tremaining: 5m 18s\n",
      "962:\tlearn: 0.3395501\ttotal: 3m 7s\tremaining: 5m 18s\n",
      "963:\tlearn: 0.3390524\ttotal: 3m 7s\tremaining: 5m 18s\n",
      "964:\tlearn: 0.3387275\ttotal: 3m 7s\tremaining: 5m 18s\n",
      "965:\tlearn: 0.3382587\ttotal: 3m 8s\tremaining: 5m 18s\n",
      "966:\tlearn: 0.3376946\ttotal: 3m 8s\tremaining: 5m 17s\n",
      "967:\tlearn: 0.3374275\ttotal: 3m 8s\tremaining: 5m 17s\n",
      "968:\tlearn: 0.3370991\ttotal: 3m 8s\tremaining: 5m 17s\n",
      "969:\tlearn: 0.3365461\ttotal: 3m 8s\tremaining: 5m 17s\n",
      "970:\tlearn: 0.3361350\ttotal: 3m 9s\tremaining: 5m 17s\n",
      "971:\tlearn: 0.3358974\ttotal: 3m 9s\tremaining: 5m 16s\n",
      "972:\tlearn: 0.3353985\ttotal: 3m 9s\tremaining: 5m 16s\n",
      "973:\tlearn: 0.3350574\ttotal: 3m 9s\tremaining: 5m 16s\n",
      "974:\tlearn: 0.3347465\ttotal: 3m 9s\tremaining: 5m 16s\n",
      "975:\tlearn: 0.3343271\ttotal: 3m 10s\tremaining: 5m 16s\n",
      "976:\tlearn: 0.3339784\ttotal: 3m 10s\tremaining: 5m 16s\n",
      "977:\tlearn: 0.3335456\ttotal: 3m 10s\tremaining: 5m 15s\n",
      "978:\tlearn: 0.3333058\ttotal: 3m 10s\tremaining: 5m 15s\n",
      "979:\tlearn: 0.3329203\ttotal: 3m 10s\tremaining: 5m 15s\n",
      "980:\tlearn: 0.3325642\ttotal: 3m 10s\tremaining: 5m 15s\n",
      "981:\tlearn: 0.3322724\ttotal: 3m 11s\tremaining: 5m 15s\n",
      "982:\tlearn: 0.3318819\ttotal: 3m 11s\tremaining: 5m 14s\n",
      "983:\tlearn: 0.3316493\ttotal: 3m 11s\tremaining: 5m 14s\n",
      "984:\tlearn: 0.3312158\ttotal: 3m 11s\tremaining: 5m 14s\n",
      "985:\tlearn: 0.3309061\ttotal: 3m 11s\tremaining: 5m 14s\n",
      "986:\tlearn: 0.3306755\ttotal: 3m 12s\tremaining: 5m 14s\n",
      "987:\tlearn: 0.3302804\ttotal: 3m 12s\tremaining: 5m 13s\n",
      "988:\tlearn: 0.3300357\ttotal: 3m 12s\tremaining: 5m 13s\n",
      "989:\tlearn: 0.3295855\ttotal: 3m 12s\tremaining: 5m 13s\n",
      "990:\tlearn: 0.3293477\ttotal: 3m 12s\tremaining: 5m 13s\n",
      "991:\tlearn: 0.3290489\ttotal: 3m 13s\tremaining: 5m 13s\n",
      "992:\tlearn: 0.3287778\ttotal: 3m 13s\tremaining: 5m 12s\n",
      "993:\tlearn: 0.3283475\ttotal: 3m 13s\tremaining: 5m 12s\n",
      "994:\tlearn: 0.3278277\ttotal: 3m 13s\tremaining: 5m 12s\n",
      "995:\tlearn: 0.3275220\ttotal: 3m 13s\tremaining: 5m 12s\n",
      "996:\tlearn: 0.3271672\ttotal: 3m 14s\tremaining: 5m 12s\n",
      "997:\tlearn: 0.3269544\ttotal: 3m 14s\tremaining: 5m 11s\n",
      "998:\tlearn: 0.3266168\ttotal: 3m 14s\tremaining: 5m 11s\n",
      "999:\tlearn: 0.3263147\ttotal: 3m 14s\tremaining: 5m 11s\n",
      "1000:\tlearn: 0.3261623\ttotal: 3m 14s\tremaining: 5m 11s\n",
      "1001:\tlearn: 0.3259585\ttotal: 3m 15s\tremaining: 5m 11s\n",
      "1002:\tlearn: 0.3257190\ttotal: 3m 15s\tremaining: 5m 10s\n",
      "1003:\tlearn: 0.3253221\ttotal: 3m 15s\tremaining: 5m 10s\n",
      "1004:\tlearn: 0.3249846\ttotal: 3m 15s\tremaining: 5m 10s\n",
      "1005:\tlearn: 0.3247630\ttotal: 3m 15s\tremaining: 5m 10s\n",
      "1006:\tlearn: 0.3244116\ttotal: 3m 16s\tremaining: 5m 10s\n",
      "1007:\tlearn: 0.3240168\ttotal: 3m 16s\tremaining: 5m 9s\n",
      "1008:\tlearn: 0.3238476\ttotal: 3m 16s\tremaining: 5m 9s\n",
      "1009:\tlearn: 0.3235367\ttotal: 3m 16s\tremaining: 5m 9s\n",
      "1010:\tlearn: 0.3233869\ttotal: 3m 16s\tremaining: 5m 9s\n",
      "1011:\tlearn: 0.3230715\ttotal: 3m 17s\tremaining: 5m 9s\n",
      "1012:\tlearn: 0.3228099\ttotal: 3m 17s\tremaining: 5m 8s\n",
      "1013:\tlearn: 0.3223931\ttotal: 3m 17s\tremaining: 5m 8s\n",
      "1014:\tlearn: 0.3219699\ttotal: 3m 17s\tremaining: 5m 8s\n",
      "1015:\tlearn: 0.3216491\ttotal: 3m 17s\tremaining: 5m 8s\n",
      "1016:\tlearn: 0.3213846\ttotal: 3m 17s\tremaining: 5m 8s\n",
      "1017:\tlearn: 0.3210030\ttotal: 3m 18s\tremaining: 5m 7s\n",
      "1018:\tlearn: 0.3206246\ttotal: 3m 18s\tremaining: 5m 7s\n",
      "1019:\tlearn: 0.3203790\ttotal: 3m 18s\tremaining: 5m 7s\n",
      "1020:\tlearn: 0.3200082\ttotal: 3m 18s\tremaining: 5m 7s\n",
      "1021:\tlearn: 0.3197644\ttotal: 3m 18s\tremaining: 5m 7s\n",
      "1022:\tlearn: 0.3195384\ttotal: 3m 19s\tremaining: 5m 6s\n",
      "1023:\tlearn: 0.3192257\ttotal: 3m 19s\tremaining: 5m 6s\n",
      "1024:\tlearn: 0.3188831\ttotal: 3m 19s\tremaining: 5m 6s\n",
      "1025:\tlearn: 0.3186718\ttotal: 3m 19s\tremaining: 5m 6s\n",
      "1026:\tlearn: 0.3184073\ttotal: 3m 19s\tremaining: 5m 6s\n",
      "1027:\tlearn: 0.3180233\ttotal: 3m 20s\tremaining: 5m 6s\n",
      "1028:\tlearn: 0.3176675\ttotal: 3m 20s\tremaining: 5m 5s\n",
      "1029:\tlearn: 0.3175076\ttotal: 3m 20s\tremaining: 5m 5s\n",
      "1030:\tlearn: 0.3171597\ttotal: 3m 20s\tremaining: 5m 5s\n",
      "1031:\tlearn: 0.3170041\ttotal: 3m 20s\tremaining: 5m 5s\n",
      "1032:\tlearn: 0.3165944\ttotal: 3m 21s\tremaining: 5m 5s\n",
      "1033:\tlearn: 0.3163801\ttotal: 3m 21s\tremaining: 5m 4s\n",
      "1034:\tlearn: 0.3159413\ttotal: 3m 21s\tremaining: 5m 4s\n",
      "1035:\tlearn: 0.3157968\ttotal: 3m 21s\tremaining: 5m 4s\n",
      "1036:\tlearn: 0.3155491\ttotal: 3m 21s\tremaining: 5m 4s\n",
      "1037:\tlearn: 0.3151968\ttotal: 3m 22s\tremaining: 5m 4s\n",
      "1038:\tlearn: 0.3149812\ttotal: 3m 22s\tremaining: 5m 3s\n",
      "1039:\tlearn: 0.3146587\ttotal: 3m 22s\tremaining: 5m 3s\n",
      "1040:\tlearn: 0.3143806\ttotal: 3m 22s\tremaining: 5m 3s\n",
      "1041:\tlearn: 0.3140246\ttotal: 3m 22s\tremaining: 5m 3s\n",
      "1042:\tlearn: 0.3138083\ttotal: 3m 23s\tremaining: 5m 3s\n",
      "1043:\tlearn: 0.3135916\ttotal: 3m 23s\tremaining: 5m 2s\n",
      "1044:\tlearn: 0.3132836\ttotal: 3m 23s\tremaining: 5m 2s\n",
      "1045:\tlearn: 0.3129139\ttotal: 3m 23s\tremaining: 5m 2s\n",
      "1046:\tlearn: 0.3125267\ttotal: 3m 23s\tremaining: 5m 2s\n",
      "1047:\tlearn: 0.3121699\ttotal: 3m 24s\tremaining: 5m 2s\n",
      "1048:\tlearn: 0.3118618\ttotal: 3m 24s\tremaining: 5m 1s\n",
      "1049:\tlearn: 0.3116116\ttotal: 3m 24s\tremaining: 5m 1s\n",
      "1050:\tlearn: 0.3111728\ttotal: 3m 24s\tremaining: 5m 1s\n",
      "1051:\tlearn: 0.3109149\ttotal: 3m 24s\tremaining: 5m 1s\n",
      "1052:\tlearn: 0.3106667\ttotal: 3m 24s\tremaining: 5m 1s\n",
      "1053:\tlearn: 0.3103394\ttotal: 3m 25s\tremaining: 5m\n",
      "1054:\tlearn: 0.3101480\ttotal: 3m 25s\tremaining: 5m\n",
      "1055:\tlearn: 0.3098904\ttotal: 3m 25s\tremaining: 5m\n",
      "1056:\tlearn: 0.3096090\ttotal: 3m 25s\tremaining: 5m\n",
      "1057:\tlearn: 0.3093037\ttotal: 3m 25s\tremaining: 5m\n",
      "1058:\tlearn: 0.3090635\ttotal: 3m 26s\tremaining: 4m 59s\n",
      "1059:\tlearn: 0.3087129\ttotal: 3m 26s\tremaining: 4m 59s\n",
      "1060:\tlearn: 0.3083631\ttotal: 3m 26s\tremaining: 4m 59s\n",
      "1061:\tlearn: 0.3081221\ttotal: 3m 26s\tremaining: 4m 59s\n",
      "1062:\tlearn: 0.3077184\ttotal: 3m 26s\tremaining: 4m 59s\n",
      "1063:\tlearn: 0.3074376\ttotal: 3m 27s\tremaining: 4m 58s\n",
      "1064:\tlearn: 0.3069984\ttotal: 3m 27s\tremaining: 4m 58s\n",
      "1065:\tlearn: 0.3067392\ttotal: 3m 27s\tremaining: 4m 58s\n",
      "1066:\tlearn: 0.3063614\ttotal: 3m 27s\tremaining: 4m 58s\n",
      "1067:\tlearn: 0.3061131\ttotal: 3m 27s\tremaining: 4m 58s\n",
      "1068:\tlearn: 0.3057612\ttotal: 3m 28s\tremaining: 4m 57s\n",
      "1069:\tlearn: 0.3054038\ttotal: 3m 28s\tremaining: 4m 57s\n",
      "1070:\tlearn: 0.3051224\ttotal: 3m 28s\tremaining: 4m 57s\n",
      "1071:\tlearn: 0.3048893\ttotal: 3m 28s\tremaining: 4m 57s\n",
      "1072:\tlearn: 0.3047084\ttotal: 3m 28s\tremaining: 4m 57s\n",
      "1073:\tlearn: 0.3044303\ttotal: 3m 29s\tremaining: 4m 56s\n",
      "1074:\tlearn: 0.3042915\ttotal: 3m 29s\tremaining: 4m 56s\n",
      "1075:\tlearn: 0.3040105\ttotal: 3m 29s\tremaining: 4m 56s\n",
      "1076:\tlearn: 0.3036971\ttotal: 3m 29s\tremaining: 4m 56s\n",
      "1077:\tlearn: 0.3034868\ttotal: 3m 29s\tremaining: 4m 56s\n",
      "1078:\tlearn: 0.3032687\ttotal: 3m 30s\tremaining: 4m 56s\n",
      "1079:\tlearn: 0.3030568\ttotal: 3m 30s\tremaining: 4m 55s\n",
      "1080:\tlearn: 0.3026710\ttotal: 3m 30s\tremaining: 4m 55s\n",
      "1081:\tlearn: 0.3024545\ttotal: 3m 30s\tremaining: 4m 55s\n",
      "1082:\tlearn: 0.3022263\ttotal: 3m 30s\tremaining: 4m 55s\n",
      "1083:\tlearn: 0.3018710\ttotal: 3m 30s\tremaining: 4m 55s\n",
      "1084:\tlearn: 0.3015289\ttotal: 3m 31s\tremaining: 4m 54s\n",
      "1085:\tlearn: 0.3013936\ttotal: 3m 31s\tremaining: 4m 54s\n",
      "1086:\tlearn: 0.3011561\ttotal: 3m 31s\tremaining: 4m 54s\n",
      "1087:\tlearn: 0.3009037\ttotal: 3m 31s\tremaining: 4m 54s\n",
      "1088:\tlearn: 0.3007075\ttotal: 3m 31s\tremaining: 4m 54s\n",
      "1089:\tlearn: 0.3003756\ttotal: 3m 32s\tremaining: 4m 53s\n",
      "1090:\tlearn: 0.3000097\ttotal: 3m 32s\tremaining: 4m 53s\n",
      "1091:\tlearn: 0.2997814\ttotal: 3m 32s\tremaining: 4m 53s\n",
      "1092:\tlearn: 0.2994666\ttotal: 3m 32s\tremaining: 4m 53s\n",
      "1093:\tlearn: 0.2991888\ttotal: 3m 32s\tremaining: 4m 53s\n",
      "1094:\tlearn: 0.2989231\ttotal: 3m 33s\tremaining: 4m 52s\n",
      "1095:\tlearn: 0.2986459\ttotal: 3m 33s\tremaining: 4m 52s\n",
      "1096:\tlearn: 0.2983940\ttotal: 3m 33s\tremaining: 4m 52s\n",
      "1097:\tlearn: 0.2980787\ttotal: 3m 33s\tremaining: 4m 52s\n",
      "1098:\tlearn: 0.2977228\ttotal: 3m 33s\tremaining: 4m 52s\n",
      "1099:\tlearn: 0.2975773\ttotal: 3m 34s\tremaining: 4m 51s\n",
      "1100:\tlearn: 0.2973318\ttotal: 3m 34s\tremaining: 4m 51s\n",
      "1101:\tlearn: 0.2970893\ttotal: 3m 34s\tremaining: 4m 51s\n",
      "1102:\tlearn: 0.2968178\ttotal: 3m 34s\tremaining: 4m 51s\n",
      "1103:\tlearn: 0.2966492\ttotal: 3m 34s\tremaining: 4m 51s\n",
      "1104:\tlearn: 0.2964134\ttotal: 3m 34s\tremaining: 4m 50s\n",
      "1105:\tlearn: 0.2960311\ttotal: 3m 35s\tremaining: 4m 50s\n",
      "1106:\tlearn: 0.2957297\ttotal: 3m 35s\tremaining: 4m 50s\n",
      "1107:\tlearn: 0.2954247\ttotal: 3m 35s\tremaining: 4m 50s\n",
      "1108:\tlearn: 0.2951031\ttotal: 3m 35s\tremaining: 4m 50s\n",
      "1109:\tlearn: 0.2949744\ttotal: 3m 35s\tremaining: 4m 49s\n",
      "1110:\tlearn: 0.2946533\ttotal: 3m 36s\tremaining: 4m 49s\n",
      "1111:\tlearn: 0.2942790\ttotal: 3m 36s\tremaining: 4m 49s\n",
      "1112:\tlearn: 0.2940150\ttotal: 3m 36s\tremaining: 4m 49s\n",
      "1113:\tlearn: 0.2936585\ttotal: 3m 36s\tremaining: 4m 49s\n",
      "1114:\tlearn: 0.2934862\ttotal: 3m 36s\tremaining: 4m 48s\n",
      "1115:\tlearn: 0.2931167\ttotal: 3m 37s\tremaining: 4m 48s\n",
      "1116:\tlearn: 0.2928703\ttotal: 3m 37s\tremaining: 4m 48s\n",
      "1117:\tlearn: 0.2925617\ttotal: 3m 37s\tremaining: 4m 48s\n",
      "1118:\tlearn: 0.2922324\ttotal: 3m 37s\tremaining: 4m 48s\n",
      "1119:\tlearn: 0.2919610\ttotal: 3m 37s\tremaining: 4m 47s\n",
      "1120:\tlearn: 0.2916615\ttotal: 3m 38s\tremaining: 4m 47s\n",
      "1121:\tlearn: 0.2912034\ttotal: 3m 38s\tremaining: 4m 47s\n",
      "1122:\tlearn: 0.2909202\ttotal: 3m 38s\tremaining: 4m 47s\n",
      "1123:\tlearn: 0.2907649\ttotal: 3m 38s\tremaining: 4m 47s\n",
      "1124:\tlearn: 0.2903184\ttotal: 3m 38s\tremaining: 4m 46s\n",
      "1125:\tlearn: 0.2901371\ttotal: 3m 39s\tremaining: 4m 46s\n",
      "1126:\tlearn: 0.2898374\ttotal: 3m 39s\tremaining: 4m 46s\n",
      "1127:\tlearn: 0.2896262\ttotal: 3m 39s\tremaining: 4m 46s\n",
      "1128:\tlearn: 0.2892909\ttotal: 3m 39s\tremaining: 4m 46s\n",
      "1129:\tlearn: 0.2889866\ttotal: 3m 39s\tremaining: 4m 45s\n",
      "1130:\tlearn: 0.2886858\ttotal: 3m 40s\tremaining: 4m 45s\n",
      "1131:\tlearn: 0.2884222\ttotal: 3m 40s\tremaining: 4m 45s\n",
      "1132:\tlearn: 0.2882779\ttotal: 3m 40s\tremaining: 4m 45s\n",
      "1133:\tlearn: 0.2879075\ttotal: 3m 40s\tremaining: 4m 45s\n",
      "1134:\tlearn: 0.2875185\ttotal: 3m 40s\tremaining: 4m 45s\n",
      "1135:\tlearn: 0.2872267\ttotal: 3m 40s\tremaining: 4m 44s\n",
      "1136:\tlearn: 0.2870171\ttotal: 3m 41s\tremaining: 4m 44s\n",
      "1137:\tlearn: 0.2867366\ttotal: 3m 41s\tremaining: 4m 44s\n",
      "1138:\tlearn: 0.2864212\ttotal: 3m 41s\tremaining: 4m 44s\n",
      "1139:\tlearn: 0.2861068\ttotal: 3m 41s\tremaining: 4m 44s\n",
      "1140:\tlearn: 0.2857288\ttotal: 3m 41s\tremaining: 4m 43s\n",
      "1141:\tlearn: 0.2854452\ttotal: 3m 42s\tremaining: 4m 43s\n",
      "1142:\tlearn: 0.2851293\ttotal: 3m 42s\tremaining: 4m 43s\n",
      "1143:\tlearn: 0.2849840\ttotal: 3m 42s\tremaining: 4m 43s\n",
      "1144:\tlearn: 0.2847662\ttotal: 3m 42s\tremaining: 4m 43s\n",
      "1145:\tlearn: 0.2845067\ttotal: 3m 42s\tremaining: 4m 42s\n",
      "1146:\tlearn: 0.2843028\ttotal: 3m 43s\tremaining: 4m 42s\n",
      "1147:\tlearn: 0.2840646\ttotal: 3m 43s\tremaining: 4m 42s\n",
      "1148:\tlearn: 0.2838136\ttotal: 3m 43s\tremaining: 4m 42s\n",
      "1149:\tlearn: 0.2833970\ttotal: 3m 43s\tremaining: 4m 42s\n",
      "1150:\tlearn: 0.2832237\ttotal: 3m 43s\tremaining: 4m 41s\n",
      "1151:\tlearn: 0.2829042\ttotal: 3m 44s\tremaining: 4m 41s\n",
      "1152:\tlearn: 0.2826609\ttotal: 3m 44s\tremaining: 4m 41s\n",
      "1153:\tlearn: 0.2824635\ttotal: 3m 44s\tremaining: 4m 41s\n",
      "1154:\tlearn: 0.2823041\ttotal: 3m 44s\tremaining: 4m 41s\n",
      "1155:\tlearn: 0.2819821\ttotal: 3m 44s\tremaining: 4m 40s\n",
      "1156:\tlearn: 0.2817876\ttotal: 3m 45s\tremaining: 4m 40s\n",
      "1157:\tlearn: 0.2814713\ttotal: 3m 45s\tremaining: 4m 40s\n",
      "1158:\tlearn: 0.2812503\ttotal: 3m 45s\tremaining: 4m 40s\n",
      "1159:\tlearn: 0.2810058\ttotal: 3m 45s\tremaining: 4m 40s\n",
      "1160:\tlearn: 0.2807697\ttotal: 3m 45s\tremaining: 4m 39s\n",
      "1161:\tlearn: 0.2806393\ttotal: 3m 46s\tremaining: 4m 39s\n",
      "1162:\tlearn: 0.2802567\ttotal: 3m 46s\tremaining: 4m 39s\n",
      "1163:\tlearn: 0.2800002\ttotal: 3m 46s\tremaining: 4m 39s\n",
      "1164:\tlearn: 0.2797410\ttotal: 3m 46s\tremaining: 4m 39s\n",
      "1165:\tlearn: 0.2795940\ttotal: 3m 46s\tremaining: 4m 38s\n",
      "1166:\tlearn: 0.2793062\ttotal: 3m 46s\tremaining: 4m 38s\n",
      "1167:\tlearn: 0.2790617\ttotal: 3m 47s\tremaining: 4m 38s\n",
      "1168:\tlearn: 0.2787538\ttotal: 3m 47s\tremaining: 4m 38s\n",
      "1169:\tlearn: 0.2785529\ttotal: 3m 47s\tremaining: 4m 38s\n",
      "1170:\tlearn: 0.2783378\ttotal: 3m 47s\tremaining: 4m 37s\n",
      "1171:\tlearn: 0.2781712\ttotal: 3m 47s\tremaining: 4m 37s\n",
      "1172:\tlearn: 0.2779435\ttotal: 3m 48s\tremaining: 4m 37s\n",
      "1173:\tlearn: 0.2775813\ttotal: 3m 48s\tremaining: 4m 37s\n",
      "1174:\tlearn: 0.2773051\ttotal: 3m 48s\tremaining: 4m 37s\n",
      "1175:\tlearn: 0.2770140\ttotal: 3m 48s\tremaining: 4m 36s\n",
      "1176:\tlearn: 0.2766961\ttotal: 3m 48s\tremaining: 4m 36s\n",
      "1177:\tlearn: 0.2762489\ttotal: 3m 49s\tremaining: 4m 36s\n",
      "1178:\tlearn: 0.2759538\ttotal: 3m 49s\tremaining: 4m 36s\n",
      "1179:\tlearn: 0.2755649\ttotal: 3m 49s\tremaining: 4m 36s\n",
      "1180:\tlearn: 0.2753404\ttotal: 3m 49s\tremaining: 4m 35s\n",
      "1181:\tlearn: 0.2750080\ttotal: 3m 49s\tremaining: 4m 35s\n",
      "1182:\tlearn: 0.2746930\ttotal: 3m 50s\tremaining: 4m 35s\n",
      "1183:\tlearn: 0.2744245\ttotal: 3m 50s\tremaining: 4m 35s\n",
      "1184:\tlearn: 0.2742127\ttotal: 3m 50s\tremaining: 4m 35s\n",
      "1185:\tlearn: 0.2739410\ttotal: 3m 50s\tremaining: 4m 34s\n",
      "1186:\tlearn: 0.2736472\ttotal: 3m 50s\tremaining: 4m 34s\n",
      "1187:\tlearn: 0.2734454\ttotal: 3m 51s\tremaining: 4m 34s\n",
      "1188:\tlearn: 0.2731803\ttotal: 3m 51s\tremaining: 4m 34s\n",
      "1189:\tlearn: 0.2729106\ttotal: 3m 51s\tremaining: 4m 34s\n",
      "1190:\tlearn: 0.2726990\ttotal: 3m 51s\tremaining: 4m 34s\n",
      "1191:\tlearn: 0.2724603\ttotal: 3m 51s\tremaining: 4m 33s\n",
      "1192:\tlearn: 0.2723097\ttotal: 3m 52s\tremaining: 4m 33s\n",
      "1193:\tlearn: 0.2719526\ttotal: 3m 52s\tremaining: 4m 33s\n",
      "1194:\tlearn: 0.2717609\ttotal: 3m 52s\tremaining: 4m 33s\n",
      "1195:\tlearn: 0.2714807\ttotal: 3m 52s\tremaining: 4m 33s\n",
      "1196:\tlearn: 0.2711181\ttotal: 3m 52s\tremaining: 4m 32s\n",
      "1197:\tlearn: 0.2708939\ttotal: 3m 52s\tremaining: 4m 32s\n",
      "1198:\tlearn: 0.2704667\ttotal: 3m 53s\tremaining: 4m 32s\n",
      "1199:\tlearn: 0.2702499\ttotal: 3m 53s\tremaining: 4m 32s\n",
      "1200:\tlearn: 0.2699102\ttotal: 3m 53s\tremaining: 4m 32s\n",
      "1201:\tlearn: 0.2697027\ttotal: 3m 53s\tremaining: 4m 31s\n",
      "1202:\tlearn: 0.2693475\ttotal: 3m 53s\tremaining: 4m 31s\n",
      "1203:\tlearn: 0.2690697\ttotal: 3m 54s\tremaining: 4m 31s\n",
      "1204:\tlearn: 0.2687287\ttotal: 3m 54s\tremaining: 4m 31s\n",
      "1205:\tlearn: 0.2684817\ttotal: 3m 54s\tremaining: 4m 31s\n",
      "1206:\tlearn: 0.2682469\ttotal: 3m 54s\tremaining: 4m 30s\n",
      "1207:\tlearn: 0.2680463\ttotal: 3m 54s\tremaining: 4m 30s\n",
      "1208:\tlearn: 0.2677690\ttotal: 3m 55s\tremaining: 4m 30s\n",
      "1209:\tlearn: 0.2675390\ttotal: 3m 55s\tremaining: 4m 30s\n",
      "1210:\tlearn: 0.2672965\ttotal: 3m 55s\tremaining: 4m 30s\n",
      "1211:\tlearn: 0.2670306\ttotal: 3m 55s\tremaining: 4m 29s\n",
      "1212:\tlearn: 0.2668471\ttotal: 3m 55s\tremaining: 4m 29s\n",
      "1213:\tlearn: 0.2666644\ttotal: 3m 56s\tremaining: 4m 29s\n",
      "1214:\tlearn: 0.2663684\ttotal: 3m 56s\tremaining: 4m 29s\n",
      "1215:\tlearn: 0.2662068\ttotal: 3m 56s\tremaining: 4m 29s\n",
      "1216:\tlearn: 0.2660003\ttotal: 3m 56s\tremaining: 4m 28s\n",
      "1217:\tlearn: 0.2657746\ttotal: 3m 56s\tremaining: 4m 28s\n",
      "1218:\tlearn: 0.2655400\ttotal: 3m 57s\tremaining: 4m 28s\n",
      "1219:\tlearn: 0.2653421\ttotal: 3m 57s\tremaining: 4m 28s\n",
      "1220:\tlearn: 0.2650151\ttotal: 3m 57s\tremaining: 4m 28s\n",
      "1221:\tlearn: 0.2648425\ttotal: 3m 57s\tremaining: 4m 28s\n",
      "1222:\tlearn: 0.2646000\ttotal: 3m 57s\tremaining: 4m 27s\n",
      "1223:\tlearn: 0.2644295\ttotal: 3m 58s\tremaining: 4m 27s\n",
      "1224:\tlearn: 0.2642063\ttotal: 3m 58s\tremaining: 4m 27s\n",
      "1225:\tlearn: 0.2639424\ttotal: 3m 58s\tremaining: 4m 27s\n",
      "1226:\tlearn: 0.2636943\ttotal: 3m 58s\tremaining: 4m 27s\n",
      "1227:\tlearn: 0.2634504\ttotal: 3m 58s\tremaining: 4m 26s\n",
      "1228:\tlearn: 0.2632473\ttotal: 3m 59s\tremaining: 4m 26s\n",
      "1229:\tlearn: 0.2630327\ttotal: 3m 59s\tremaining: 4m 26s\n",
      "1230:\tlearn: 0.2627567\ttotal: 3m 59s\tremaining: 4m 26s\n",
      "1231:\tlearn: 0.2625773\ttotal: 3m 59s\tremaining: 4m 26s\n",
      "1232:\tlearn: 0.2623094\ttotal: 3m 59s\tremaining: 4m 25s\n",
      "1233:\tlearn: 0.2620436\ttotal: 4m\tremaining: 4m 25s\n",
      "1234:\tlearn: 0.2618155\ttotal: 4m\tremaining: 4m 25s\n",
      "1235:\tlearn: 0.2615498\ttotal: 4m\tremaining: 4m 25s\n",
      "1236:\tlearn: 0.2612175\ttotal: 4m\tremaining: 4m 25s\n",
      "1237:\tlearn: 0.2608874\ttotal: 4m\tremaining: 4m 24s\n",
      "1238:\tlearn: 0.2607055\ttotal: 4m\tremaining: 4m 24s\n",
      "1239:\tlearn: 0.2604684\ttotal: 4m 1s\tremaining: 4m 24s\n",
      "1240:\tlearn: 0.2601917\ttotal: 4m 1s\tremaining: 4m 24s\n",
      "1241:\tlearn: 0.2598973\ttotal: 4m 1s\tremaining: 4m 24s\n",
      "1242:\tlearn: 0.2595919\ttotal: 4m 1s\tremaining: 4m 23s\n",
      "1243:\tlearn: 0.2592532\ttotal: 4m 1s\tremaining: 4m 23s\n",
      "1244:\tlearn: 0.2590135\ttotal: 4m 2s\tremaining: 4m 23s\n",
      "1245:\tlearn: 0.2588456\ttotal: 4m 2s\tremaining: 4m 23s\n",
      "1246:\tlearn: 0.2586807\ttotal: 4m 2s\tremaining: 4m 23s\n",
      "1247:\tlearn: 0.2585264\ttotal: 4m 2s\tremaining: 4m 22s\n",
      "1248:\tlearn: 0.2582331\ttotal: 4m 2s\tremaining: 4m 22s\n",
      "1249:\tlearn: 0.2579254\ttotal: 4m 3s\tremaining: 4m 22s\n",
      "1250:\tlearn: 0.2576288\ttotal: 4m 3s\tremaining: 4m 22s\n",
      "1251:\tlearn: 0.2572984\ttotal: 4m 3s\tremaining: 4m 22s\n",
      "1252:\tlearn: 0.2571008\ttotal: 4m 3s\tremaining: 4m 21s\n",
      "1253:\tlearn: 0.2568883\ttotal: 4m 3s\tremaining: 4m 21s\n",
      "1254:\tlearn: 0.2565857\ttotal: 4m 4s\tremaining: 4m 21s\n",
      "1255:\tlearn: 0.2562477\ttotal: 4m 4s\tremaining: 4m 21s\n",
      "1256:\tlearn: 0.2560281\ttotal: 4m 4s\tremaining: 4m 21s\n",
      "1257:\tlearn: 0.2558181\ttotal: 4m 4s\tremaining: 4m 20s\n",
      "1258:\tlearn: 0.2555378\ttotal: 4m 4s\tremaining: 4m 20s\n",
      "1259:\tlearn: 0.2553626\ttotal: 4m 5s\tremaining: 4m 20s\n",
      "1260:\tlearn: 0.2551264\ttotal: 4m 5s\tremaining: 4m 20s\n",
      "1261:\tlearn: 0.2549246\ttotal: 4m 5s\tremaining: 4m 20s\n",
      "1262:\tlearn: 0.2546375\ttotal: 4m 5s\tremaining: 4m 20s\n",
      "1263:\tlearn: 0.2544160\ttotal: 4m 5s\tremaining: 4m 19s\n",
      "1264:\tlearn: 0.2540705\ttotal: 4m 6s\tremaining: 4m 19s\n",
      "1265:\tlearn: 0.2538302\ttotal: 4m 6s\tremaining: 4m 19s\n",
      "1266:\tlearn: 0.2535677\ttotal: 4m 6s\tremaining: 4m 19s\n",
      "1267:\tlearn: 0.2533877\ttotal: 4m 6s\tremaining: 4m 19s\n",
      "1268:\tlearn: 0.2531731\ttotal: 4m 6s\tremaining: 4m 18s\n",
      "1269:\tlearn: 0.2530065\ttotal: 4m 7s\tremaining: 4m 18s\n",
      "1270:\tlearn: 0.2527976\ttotal: 4m 7s\tremaining: 4m 18s\n",
      "1271:\tlearn: 0.2526003\ttotal: 4m 7s\tremaining: 4m 18s\n",
      "1272:\tlearn: 0.2523887\ttotal: 4m 7s\tremaining: 4m 18s\n",
      "1273:\tlearn: 0.2522574\ttotal: 4m 7s\tremaining: 4m 17s\n",
      "1274:\tlearn: 0.2519767\ttotal: 4m 7s\tremaining: 4m 17s\n",
      "1275:\tlearn: 0.2518154\ttotal: 4m 8s\tremaining: 4m 17s\n",
      "1276:\tlearn: 0.2516811\ttotal: 4m 8s\tremaining: 4m 17s\n",
      "1277:\tlearn: 0.2514491\ttotal: 4m 8s\tremaining: 4m 17s\n",
      "1278:\tlearn: 0.2512304\ttotal: 4m 8s\tremaining: 4m 16s\n",
      "1279:\tlearn: 0.2509800\ttotal: 4m 8s\tremaining: 4m 16s\n",
      "1280:\tlearn: 0.2507828\ttotal: 4m 9s\tremaining: 4m 16s\n",
      "1281:\tlearn: 0.2505723\ttotal: 4m 9s\tremaining: 4m 16s\n",
      "1282:\tlearn: 0.2502578\ttotal: 4m 9s\tremaining: 4m 16s\n",
      "1283:\tlearn: 0.2501052\ttotal: 4m 9s\tremaining: 4m 15s\n",
      "1284:\tlearn: 0.2498485\ttotal: 4m 9s\tremaining: 4m 15s\n",
      "1285:\tlearn: 0.2497174\ttotal: 4m 10s\tremaining: 4m 15s\n",
      "1286:\tlearn: 0.2495975\ttotal: 4m 10s\tremaining: 4m 15s\n",
      "1287:\tlearn: 0.2493060\ttotal: 4m 10s\tremaining: 4m 15s\n",
      "1288:\tlearn: 0.2490848\ttotal: 4m 10s\tremaining: 4m 14s\n",
      "1289:\tlearn: 0.2487851\ttotal: 4m 10s\tremaining: 4m 14s\n",
      "1290:\tlearn: 0.2485069\ttotal: 4m 11s\tremaining: 4m 14s\n",
      "1291:\tlearn: 0.2482886\ttotal: 4m 11s\tremaining: 4m 14s\n",
      "1292:\tlearn: 0.2479753\ttotal: 4m 11s\tremaining: 4m 14s\n",
      "1293:\tlearn: 0.2476649\ttotal: 4m 11s\tremaining: 4m 13s\n",
      "1294:\tlearn: 0.2474466\ttotal: 4m 11s\tremaining: 4m 13s\n",
      "1295:\tlearn: 0.2472999\ttotal: 4m 12s\tremaining: 4m 13s\n",
      "1296:\tlearn: 0.2470478\ttotal: 4m 12s\tremaining: 4m 13s\n",
      "1297:\tlearn: 0.2468247\ttotal: 4m 12s\tremaining: 4m 13s\n",
      "1298:\tlearn: 0.2465528\ttotal: 4m 12s\tremaining: 4m 13s\n",
      "1299:\tlearn: 0.2463896\ttotal: 4m 12s\tremaining: 4m 12s\n",
      "1300:\tlearn: 0.2462005\ttotal: 4m 12s\tremaining: 4m 12s\n",
      "1301:\tlearn: 0.2459478\ttotal: 4m 13s\tremaining: 4m 12s\n",
      "1302:\tlearn: 0.2457747\ttotal: 4m 13s\tremaining: 4m 12s\n",
      "1303:\tlearn: 0.2455035\ttotal: 4m 13s\tremaining: 4m 12s\n",
      "1304:\tlearn: 0.2453936\ttotal: 4m 13s\tremaining: 4m 11s\n",
      "1305:\tlearn: 0.2451839\ttotal: 4m 13s\tremaining: 4m 11s\n",
      "1306:\tlearn: 0.2449732\ttotal: 4m 14s\tremaining: 4m 11s\n",
      "1307:\tlearn: 0.2447690\ttotal: 4m 14s\tremaining: 4m 11s\n",
      "1308:\tlearn: 0.2444968\ttotal: 4m 14s\tremaining: 4m 11s\n",
      "1309:\tlearn: 0.2443076\ttotal: 4m 14s\tremaining: 4m 10s\n",
      "1310:\tlearn: 0.2441317\ttotal: 4m 14s\tremaining: 4m 10s\n",
      "1311:\tlearn: 0.2438788\ttotal: 4m 15s\tremaining: 4m 10s\n",
      "1312:\tlearn: 0.2437840\ttotal: 4m 15s\tremaining: 4m 10s\n",
      "1313:\tlearn: 0.2436313\ttotal: 4m 15s\tremaining: 4m 10s\n",
      "1314:\tlearn: 0.2434400\ttotal: 4m 15s\tremaining: 4m 9s\n",
      "1315:\tlearn: 0.2432016\ttotal: 4m 15s\tremaining: 4m 9s\n",
      "1316:\tlearn: 0.2430208\ttotal: 4m 16s\tremaining: 4m 9s\n",
      "1317:\tlearn: 0.2429051\ttotal: 4m 16s\tremaining: 4m 9s\n",
      "1318:\tlearn: 0.2427348\ttotal: 4m 16s\tremaining: 4m 9s\n",
      "1319:\tlearn: 0.2425539\ttotal: 4m 16s\tremaining: 4m 8s\n",
      "1320:\tlearn: 0.2423453\ttotal: 4m 16s\tremaining: 4m 8s\n",
      "1321:\tlearn: 0.2422349\ttotal: 4m 17s\tremaining: 4m 8s\n",
      "1322:\tlearn: 0.2420261\ttotal: 4m 17s\tremaining: 4m 8s\n",
      "1323:\tlearn: 0.2417842\ttotal: 4m 17s\tremaining: 4m 8s\n",
      "1324:\tlearn: 0.2415374\ttotal: 4m 17s\tremaining: 4m 7s\n",
      "1325:\tlearn: 0.2414396\ttotal: 4m 17s\tremaining: 4m 7s\n",
      "1326:\tlearn: 0.2412598\ttotal: 4m 18s\tremaining: 4m 7s\n",
      "1327:\tlearn: 0.2409129\ttotal: 4m 18s\tremaining: 4m 7s\n",
      "1328:\tlearn: 0.2407772\ttotal: 4m 18s\tremaining: 4m 7s\n",
      "1329:\tlearn: 0.2405810\ttotal: 4m 18s\tremaining: 4m 6s\n",
      "1330:\tlearn: 0.2404248\ttotal: 4m 18s\tremaining: 4m 6s\n",
      "1331:\tlearn: 0.2402998\ttotal: 4m 19s\tremaining: 4m 6s\n",
      "1332:\tlearn: 0.2399501\ttotal: 4m 19s\tremaining: 4m 6s\n",
      "1333:\tlearn: 0.2397800\ttotal: 4m 19s\tremaining: 4m 6s\n",
      "1334:\tlearn: 0.2395676\ttotal: 4m 19s\tremaining: 4m 6s\n",
      "1335:\tlearn: 0.2393971\ttotal: 4m 19s\tremaining: 4m 5s\n",
      "1336:\tlearn: 0.2392074\ttotal: 4m 20s\tremaining: 4m 5s\n",
      "1337:\tlearn: 0.2388942\ttotal: 4m 20s\tremaining: 4m 5s\n",
      "1338:\tlearn: 0.2387218\ttotal: 4m 20s\tremaining: 4m 5s\n",
      "1339:\tlearn: 0.2385441\ttotal: 4m 20s\tremaining: 4m 5s\n",
      "1340:\tlearn: 0.2383751\ttotal: 4m 20s\tremaining: 4m 4s\n",
      "1341:\tlearn: 0.2380986\ttotal: 4m 21s\tremaining: 4m 4s\n",
      "1342:\tlearn: 0.2378873\ttotal: 4m 21s\tremaining: 4m 4s\n",
      "1343:\tlearn: 0.2376125\ttotal: 4m 21s\tremaining: 4m 4s\n",
      "1344:\tlearn: 0.2374448\ttotal: 4m 21s\tremaining: 4m 4s\n",
      "1345:\tlearn: 0.2372048\ttotal: 4m 21s\tremaining: 4m 3s\n",
      "1346:\tlearn: 0.2370029\ttotal: 4m 21s\tremaining: 4m 3s\n",
      "1347:\tlearn: 0.2368608\ttotal: 4m 22s\tremaining: 4m 3s\n",
      "1348:\tlearn: 0.2366130\ttotal: 4m 22s\tremaining: 4m 3s\n",
      "1349:\tlearn: 0.2364272\ttotal: 4m 22s\tremaining: 4m 3s\n",
      "1350:\tlearn: 0.2361908\ttotal: 4m 22s\tremaining: 4m 2s\n",
      "1351:\tlearn: 0.2359682\ttotal: 4m 22s\tremaining: 4m 2s\n",
      "1352:\tlearn: 0.2357988\ttotal: 4m 23s\tremaining: 4m 2s\n",
      "1353:\tlearn: 0.2354935\ttotal: 4m 23s\tremaining: 4m 2s\n",
      "1354:\tlearn: 0.2353274\ttotal: 4m 23s\tremaining: 4m 2s\n",
      "1355:\tlearn: 0.2351068\ttotal: 4m 23s\tremaining: 4m 1s\n",
      "1356:\tlearn: 0.2349476\ttotal: 4m 23s\tremaining: 4m 1s\n",
      "1357:\tlearn: 0.2347788\ttotal: 4m 24s\tremaining: 4m 1s\n",
      "1358:\tlearn: 0.2344941\ttotal: 4m 24s\tremaining: 4m 1s\n",
      "1359:\tlearn: 0.2344188\ttotal: 4m 24s\tremaining: 4m 1s\n",
      "1360:\tlearn: 0.2342972\ttotal: 4m 24s\tremaining: 4m 1s\n",
      "1361:\tlearn: 0.2341329\ttotal: 4m 24s\tremaining: 4m\n",
      "1362:\tlearn: 0.2339277\ttotal: 4m 25s\tremaining: 4m\n",
      "1363:\tlearn: 0.2337307\ttotal: 4m 25s\tremaining: 4m\n",
      "1364:\tlearn: 0.2335777\ttotal: 4m 25s\tremaining: 4m\n",
      "1365:\tlearn: 0.2333808\ttotal: 4m 25s\tremaining: 4m\n",
      "1366:\tlearn: 0.2331021\ttotal: 4m 25s\tremaining: 3m 59s\n",
      "1367:\tlearn: 0.2328548\ttotal: 4m 26s\tremaining: 3m 59s\n",
      "1368:\tlearn: 0.2326219\ttotal: 4m 26s\tremaining: 3m 59s\n",
      "1369:\tlearn: 0.2323641\ttotal: 4m 26s\tremaining: 3m 59s\n",
      "1370:\tlearn: 0.2321786\ttotal: 4m 26s\tremaining: 3m 59s\n",
      "1371:\tlearn: 0.2319477\ttotal: 4m 26s\tremaining: 3m 58s\n",
      "1372:\tlearn: 0.2317871\ttotal: 4m 27s\tremaining: 3m 58s\n",
      "1373:\tlearn: 0.2315089\ttotal: 4m 27s\tremaining: 3m 58s\n",
      "1374:\tlearn: 0.2313942\ttotal: 4m 27s\tremaining: 3m 58s\n",
      "1375:\tlearn: 0.2312268\ttotal: 4m 27s\tremaining: 3m 58s\n",
      "1376:\tlearn: 0.2311072\ttotal: 4m 27s\tremaining: 3m 57s\n",
      "1377:\tlearn: 0.2308416\ttotal: 4m 28s\tremaining: 3m 57s\n",
      "1378:\tlearn: 0.2306165\ttotal: 4m 28s\tremaining: 3m 57s\n",
      "1379:\tlearn: 0.2303858\ttotal: 4m 28s\tremaining: 3m 57s\n",
      "1380:\tlearn: 0.2301586\ttotal: 4m 28s\tremaining: 3m 57s\n",
      "1381:\tlearn: 0.2300026\ttotal: 4m 28s\tremaining: 3m 56s\n",
      "1382:\tlearn: 0.2298431\ttotal: 4m 29s\tremaining: 3m 56s\n",
      "1383:\tlearn: 0.2296945\ttotal: 4m 29s\tremaining: 3m 56s\n",
      "1384:\tlearn: 0.2294597\ttotal: 4m 29s\tremaining: 3m 56s\n",
      "1385:\tlearn: 0.2291858\ttotal: 4m 29s\tremaining: 3m 56s\n",
      "1386:\tlearn: 0.2290359\ttotal: 4m 29s\tremaining: 3m 55s\n",
      "1387:\tlearn: 0.2288956\ttotal: 4m 29s\tremaining: 3m 55s\n",
      "1388:\tlearn: 0.2285540\ttotal: 4m 30s\tremaining: 3m 55s\n",
      "1389:\tlearn: 0.2283884\ttotal: 4m 30s\tremaining: 3m 55s\n",
      "1390:\tlearn: 0.2282292\ttotal: 4m 30s\tremaining: 3m 55s\n",
      "1391:\tlearn: 0.2280388\ttotal: 4m 30s\tremaining: 3m 54s\n",
      "1392:\tlearn: 0.2278749\ttotal: 4m 30s\tremaining: 3m 54s\n",
      "1393:\tlearn: 0.2277170\ttotal: 4m 31s\tremaining: 3m 54s\n",
      "1394:\tlearn: 0.2275220\ttotal: 4m 31s\tremaining: 3m 54s\n",
      "1395:\tlearn: 0.2273821\ttotal: 4m 31s\tremaining: 3m 54s\n",
      "1396:\tlearn: 0.2272558\ttotal: 4m 31s\tremaining: 3m 54s\n",
      "1397:\tlearn: 0.2271088\ttotal: 4m 31s\tremaining: 3m 53s\n",
      "1398:\tlearn: 0.2269202\ttotal: 4m 32s\tremaining: 3m 53s\n",
      "1399:\tlearn: 0.2268080\ttotal: 4m 32s\tremaining: 3m 53s\n",
      "1400:\tlearn: 0.2266140\ttotal: 4m 32s\tremaining: 3m 53s\n",
      "1401:\tlearn: 0.2265203\ttotal: 4m 32s\tremaining: 3m 53s\n",
      "1402:\tlearn: 0.2262955\ttotal: 4m 32s\tremaining: 3m 52s\n",
      "1403:\tlearn: 0.2261282\ttotal: 4m 33s\tremaining: 3m 52s\n",
      "1404:\tlearn: 0.2258659\ttotal: 4m 33s\tremaining: 3m 52s\n",
      "1405:\tlearn: 0.2255761\ttotal: 4m 33s\tremaining: 3m 52s\n",
      "1406:\tlearn: 0.2253785\ttotal: 4m 33s\tremaining: 3m 52s\n",
      "1407:\tlearn: 0.2252283\ttotal: 4m 33s\tremaining: 3m 51s\n",
      "1408:\tlearn: 0.2250712\ttotal: 4m 34s\tremaining: 3m 51s\n",
      "1409:\tlearn: 0.2248684\ttotal: 4m 34s\tremaining: 3m 51s\n",
      "1410:\tlearn: 0.2247776\ttotal: 4m 34s\tremaining: 3m 51s\n",
      "1411:\tlearn: 0.2246151\ttotal: 4m 34s\tremaining: 3m 51s\n",
      "1412:\tlearn: 0.2244456\ttotal: 4m 34s\tremaining: 3m 50s\n",
      "1413:\tlearn: 0.2242312\ttotal: 4m 35s\tremaining: 3m 50s\n",
      "1414:\tlearn: 0.2241025\ttotal: 4m 35s\tremaining: 3m 50s\n",
      "1415:\tlearn: 0.2239049\ttotal: 4m 35s\tremaining: 3m 50s\n",
      "1416:\tlearn: 0.2237345\ttotal: 4m 35s\tremaining: 3m 50s\n",
      "1417:\tlearn: 0.2235621\ttotal: 4m 35s\tremaining: 3m 49s\n",
      "1418:\tlearn: 0.2233385\ttotal: 4m 36s\tremaining: 3m 49s\n",
      "1419:\tlearn: 0.2231869\ttotal: 4m 36s\tremaining: 3m 49s\n",
      "1420:\tlearn: 0.2230258\ttotal: 4m 36s\tremaining: 3m 49s\n",
      "1421:\tlearn: 0.2228033\ttotal: 4m 36s\tremaining: 3m 49s\n",
      "1422:\tlearn: 0.2225929\ttotal: 4m 36s\tremaining: 3m 48s\n",
      "1423:\tlearn: 0.2224292\ttotal: 4m 37s\tremaining: 3m 48s\n",
      "1424:\tlearn: 0.2221755\ttotal: 4m 37s\tremaining: 3m 48s\n",
      "1425:\tlearn: 0.2220119\ttotal: 4m 37s\tremaining: 3m 48s\n",
      "1426:\tlearn: 0.2218434\ttotal: 4m 37s\tremaining: 3m 48s\n",
      "1427:\tlearn: 0.2216679\ttotal: 4m 37s\tremaining: 3m 48s\n",
      "1428:\tlearn: 0.2214387\ttotal: 4m 38s\tremaining: 3m 47s\n",
      "1429:\tlearn: 0.2212036\ttotal: 4m 38s\tremaining: 3m 47s\n",
      "1430:\tlearn: 0.2209833\ttotal: 4m 38s\tremaining: 3m 47s\n",
      "1431:\tlearn: 0.2208080\ttotal: 4m 38s\tremaining: 3m 47s\n",
      "1432:\tlearn: 0.2205818\ttotal: 4m 38s\tremaining: 3m 47s\n",
      "1433:\tlearn: 0.2204253\ttotal: 4m 39s\tremaining: 3m 46s\n",
      "1434:\tlearn: 0.2203454\ttotal: 4m 39s\tremaining: 3m 46s\n",
      "1435:\tlearn: 0.2201078\ttotal: 4m 39s\tremaining: 3m 46s\n",
      "1436:\tlearn: 0.2199994\ttotal: 4m 39s\tremaining: 3m 46s\n",
      "1437:\tlearn: 0.2197670\ttotal: 4m 39s\tremaining: 3m 46s\n",
      "1438:\tlearn: 0.2195803\ttotal: 4m 40s\tremaining: 3m 45s\n",
      "1439:\tlearn: 0.2193543\ttotal: 4m 40s\tremaining: 3m 45s\n",
      "1440:\tlearn: 0.2191931\ttotal: 4m 40s\tremaining: 3m 45s\n",
      "1441:\tlearn: 0.2190238\ttotal: 4m 40s\tremaining: 3m 45s\n",
      "1442:\tlearn: 0.2189086\ttotal: 4m 40s\tremaining: 3m 45s\n",
      "1443:\tlearn: 0.2187304\ttotal: 4m 40s\tremaining: 3m 44s\n",
      "1444:\tlearn: 0.2184741\ttotal: 4m 41s\tremaining: 3m 44s\n",
      "1445:\tlearn: 0.2183120\ttotal: 4m 41s\tremaining: 3m 44s\n",
      "1446:\tlearn: 0.2181462\ttotal: 4m 41s\tremaining: 3m 44s\n",
      "1447:\tlearn: 0.2180082\ttotal: 4m 41s\tremaining: 3m 44s\n",
      "1448:\tlearn: 0.2178807\ttotal: 4m 41s\tremaining: 3m 43s\n",
      "1449:\tlearn: 0.2177020\ttotal: 4m 42s\tremaining: 3m 43s\n",
      "1450:\tlearn: 0.2174384\ttotal: 4m 42s\tremaining: 3m 43s\n",
      "1451:\tlearn: 0.2172406\ttotal: 4m 42s\tremaining: 3m 43s\n",
      "1452:\tlearn: 0.2170253\ttotal: 4m 42s\tremaining: 3m 43s\n",
      "1453:\tlearn: 0.2168974\ttotal: 4m 42s\tremaining: 3m 42s\n",
      "1454:\tlearn: 0.2166950\ttotal: 4m 43s\tremaining: 3m 42s\n",
      "1455:\tlearn: 0.2165219\ttotal: 4m 43s\tremaining: 3m 42s\n",
      "1456:\tlearn: 0.2164282\ttotal: 4m 43s\tremaining: 3m 42s\n",
      "1457:\tlearn: 0.2162479\ttotal: 4m 43s\tremaining: 3m 42s\n",
      "1458:\tlearn: 0.2160927\ttotal: 4m 43s\tremaining: 3m 42s\n",
      "1459:\tlearn: 0.2159495\ttotal: 4m 44s\tremaining: 3m 41s\n",
      "1460:\tlearn: 0.2157529\ttotal: 4m 44s\tremaining: 3m 41s\n",
      "1461:\tlearn: 0.2155295\ttotal: 4m 44s\tremaining: 3m 41s\n",
      "1462:\tlearn: 0.2153359\ttotal: 4m 44s\tremaining: 3m 41s\n",
      "1463:\tlearn: 0.2150352\ttotal: 4m 44s\tremaining: 3m 41s\n",
      "1464:\tlearn: 0.2149384\ttotal: 4m 45s\tremaining: 3m 40s\n",
      "1465:\tlearn: 0.2147576\ttotal: 4m 45s\tremaining: 3m 40s\n",
      "1466:\tlearn: 0.2145826\ttotal: 4m 45s\tremaining: 3m 40s\n",
      "1467:\tlearn: 0.2144141\ttotal: 4m 45s\tremaining: 3m 40s\n",
      "1468:\tlearn: 0.2141521\ttotal: 4m 45s\tremaining: 3m 40s\n",
      "1469:\tlearn: 0.2139644\ttotal: 4m 46s\tremaining: 3m 39s\n",
      "1470:\tlearn: 0.2137636\ttotal: 4m 46s\tremaining: 3m 39s\n",
      "1471:\tlearn: 0.2136318\ttotal: 4m 46s\tremaining: 3m 39s\n",
      "1472:\tlearn: 0.2134299\ttotal: 4m 46s\tremaining: 3m 39s\n",
      "1473:\tlearn: 0.2131883\ttotal: 4m 46s\tremaining: 3m 39s\n",
      "1474:\tlearn: 0.2130330\ttotal: 4m 47s\tremaining: 3m 38s\n",
      "1475:\tlearn: 0.2128800\ttotal: 4m 47s\tremaining: 3m 38s\n",
      "1476:\tlearn: 0.2127490\ttotal: 4m 47s\tremaining: 3m 38s\n",
      "1477:\tlearn: 0.2125577\ttotal: 4m 47s\tremaining: 3m 38s\n",
      "1478:\tlearn: 0.2124436\ttotal: 4m 47s\tremaining: 3m 38s\n",
      "1479:\tlearn: 0.2123312\ttotal: 4m 47s\tremaining: 3m 37s\n",
      "1480:\tlearn: 0.2121725\ttotal: 4m 48s\tremaining: 3m 37s\n",
      "1481:\tlearn: 0.2120377\ttotal: 4m 48s\tremaining: 3m 37s\n",
      "1482:\tlearn: 0.2118822\ttotal: 4m 48s\tremaining: 3m 37s\n",
      "1483:\tlearn: 0.2116213\ttotal: 4m 48s\tremaining: 3m 37s\n",
      "1484:\tlearn: 0.2113579\ttotal: 4m 48s\tremaining: 3m 36s\n",
      "1485:\tlearn: 0.2112261\ttotal: 4m 49s\tremaining: 3m 36s\n",
      "1486:\tlearn: 0.2110469\ttotal: 4m 49s\tremaining: 3m 36s\n",
      "1487:\tlearn: 0.2109212\ttotal: 4m 49s\tremaining: 3m 36s\n",
      "1488:\tlearn: 0.2106614\ttotal: 4m 49s\tremaining: 3m 36s\n",
      "1489:\tlearn: 0.2105317\ttotal: 4m 49s\tremaining: 3m 35s\n",
      "1490:\tlearn: 0.2102968\ttotal: 4m 50s\tremaining: 3m 35s\n",
      "1491:\tlearn: 0.2101423\ttotal: 4m 50s\tremaining: 3m 35s\n",
      "1492:\tlearn: 0.2099205\ttotal: 4m 50s\tremaining: 3m 35s\n",
      "1493:\tlearn: 0.2098168\ttotal: 4m 50s\tremaining: 3m 35s\n",
      "1494:\tlearn: 0.2096916\ttotal: 4m 50s\tremaining: 3m 35s\n",
      "1495:\tlearn: 0.2093791\ttotal: 4m 51s\tremaining: 3m 34s\n",
      "1496:\tlearn: 0.2091669\ttotal: 4m 51s\tremaining: 3m 34s\n",
      "1497:\tlearn: 0.2090807\ttotal: 4m 51s\tremaining: 3m 34s\n",
      "1498:\tlearn: 0.2088886\ttotal: 4m 51s\tremaining: 3m 34s\n",
      "1499:\tlearn: 0.2086929\ttotal: 4m 51s\tremaining: 3m 34s\n",
      "1500:\tlearn: 0.2085564\ttotal: 4m 52s\tremaining: 3m 33s\n",
      "1501:\tlearn: 0.2084828\ttotal: 4m 52s\tremaining: 3m 33s\n",
      "1502:\tlearn: 0.2083411\ttotal: 4m 52s\tremaining: 3m 33s\n",
      "1503:\tlearn: 0.2082241\ttotal: 4m 52s\tremaining: 3m 33s\n",
      "1504:\tlearn: 0.2080099\ttotal: 4m 52s\tremaining: 3m 33s\n",
      "1505:\tlearn: 0.2078507\ttotal: 4m 53s\tremaining: 3m 32s\n",
      "1506:\tlearn: 0.2076972\ttotal: 4m 53s\tremaining: 3m 32s\n",
      "1507:\tlearn: 0.2074625\ttotal: 4m 53s\tremaining: 3m 32s\n",
      "1508:\tlearn: 0.2073019\ttotal: 4m 53s\tremaining: 3m 32s\n",
      "1509:\tlearn: 0.2071180\ttotal: 4m 53s\tremaining: 3m 32s\n",
      "1510:\tlearn: 0.2069731\ttotal: 4m 54s\tremaining: 3m 31s\n",
      "1511:\tlearn: 0.2067461\ttotal: 4m 54s\tremaining: 3m 31s\n",
      "1512:\tlearn: 0.2065170\ttotal: 4m 54s\tremaining: 3m 31s\n",
      "1513:\tlearn: 0.2062257\ttotal: 4m 54s\tremaining: 3m 31s\n",
      "1514:\tlearn: 0.2060415\ttotal: 4m 54s\tremaining: 3m 31s\n",
      "1515:\tlearn: 0.2058985\ttotal: 4m 54s\tremaining: 3m 30s\n",
      "1516:\tlearn: 0.2056840\ttotal: 4m 55s\tremaining: 3m 30s\n",
      "1517:\tlearn: 0.2055230\ttotal: 4m 55s\tremaining: 3m 30s\n",
      "1518:\tlearn: 0.2053350\ttotal: 4m 55s\tremaining: 3m 30s\n",
      "1519:\tlearn: 0.2051916\ttotal: 4m 55s\tremaining: 3m 30s\n",
      "1520:\tlearn: 0.2050769\ttotal: 4m 55s\tremaining: 3m 29s\n",
      "1521:\tlearn: 0.2049500\ttotal: 4m 56s\tremaining: 3m 29s\n",
      "1522:\tlearn: 0.2048415\ttotal: 4m 56s\tremaining: 3m 29s\n",
      "1523:\tlearn: 0.2047061\ttotal: 4m 56s\tremaining: 3m 29s\n",
      "1524:\tlearn: 0.2045188\ttotal: 4m 56s\tremaining: 3m 29s\n",
      "1525:\tlearn: 0.2044005\ttotal: 4m 56s\tremaining: 3m 28s\n",
      "1526:\tlearn: 0.2042878\ttotal: 4m 57s\tremaining: 3m 28s\n",
      "1527:\tlearn: 0.2041349\ttotal: 4m 57s\tremaining: 3m 28s\n",
      "1528:\tlearn: 0.2039336\ttotal: 4m 57s\tremaining: 3m 28s\n",
      "1529:\tlearn: 0.2038058\ttotal: 4m 57s\tremaining: 3m 28s\n",
      "1530:\tlearn: 0.2035652\ttotal: 4m 57s\tremaining: 3m 28s\n",
      "1531:\tlearn: 0.2034210\ttotal: 4m 58s\tremaining: 3m 27s\n",
      "1532:\tlearn: 0.2032074\ttotal: 4m 58s\tremaining: 3m 27s\n",
      "1533:\tlearn: 0.2030719\ttotal: 4m 58s\tremaining: 3m 27s\n",
      "1534:\tlearn: 0.2029642\ttotal: 4m 58s\tremaining: 3m 27s\n",
      "1535:\tlearn: 0.2027401\ttotal: 4m 58s\tremaining: 3m 27s\n",
      "1536:\tlearn: 0.2026096\ttotal: 4m 59s\tremaining: 3m 26s\n",
      "1537:\tlearn: 0.2024602\ttotal: 4m 59s\tremaining: 3m 26s\n",
      "1538:\tlearn: 0.2022939\ttotal: 4m 59s\tremaining: 3m 26s\n",
      "1539:\tlearn: 0.2021003\ttotal: 4m 59s\tremaining: 3m 26s\n",
      "1540:\tlearn: 0.2019427\ttotal: 4m 59s\tremaining: 3m 26s\n",
      "1541:\tlearn: 0.2017326\ttotal: 5m\tremaining: 3m 25s\n",
      "1542:\tlearn: 0.2014362\ttotal: 5m\tremaining: 3m 25s\n",
      "1543:\tlearn: 0.2012592\ttotal: 5m\tremaining: 3m 25s\n",
      "1544:\tlearn: 0.2011603\ttotal: 5m\tremaining: 3m 25s\n",
      "1545:\tlearn: 0.2010792\ttotal: 5m\tremaining: 3m 25s\n",
      "1546:\tlearn: 0.2009403\ttotal: 5m 1s\tremaining: 3m 24s\n",
      "1547:\tlearn: 0.2007168\ttotal: 5m 1s\tremaining: 3m 24s\n",
      "1548:\tlearn: 0.2005870\ttotal: 5m 1s\tremaining: 3m 24s\n",
      "1549:\tlearn: 0.2004359\ttotal: 5m 1s\tremaining: 3m 24s\n",
      "1550:\tlearn: 0.2002738\ttotal: 5m 1s\tremaining: 3m 24s\n",
      "1551:\tlearn: 0.2001145\ttotal: 5m 2s\tremaining: 3m 23s\n",
      "1552:\tlearn: 0.1999588\ttotal: 5m 2s\tremaining: 3m 23s\n",
      "1553:\tlearn: 0.1997637\ttotal: 5m 2s\tremaining: 3m 23s\n",
      "1554:\tlearn: 0.1996259\ttotal: 5m 2s\tremaining: 3m 23s\n",
      "1555:\tlearn: 0.1995263\ttotal: 5m 2s\tremaining: 3m 23s\n",
      "1556:\tlearn: 0.1993237\ttotal: 5m 2s\tremaining: 3m 22s\n",
      "1557:\tlearn: 0.1991185\ttotal: 5m 3s\tremaining: 3m 22s\n",
      "1558:\tlearn: 0.1990052\ttotal: 5m 3s\tremaining: 3m 22s\n",
      "1559:\tlearn: 0.1988895\ttotal: 5m 3s\tremaining: 3m 22s\n",
      "1560:\tlearn: 0.1987714\ttotal: 5m 3s\tremaining: 3m 22s\n",
      "1561:\tlearn: 0.1986458\ttotal: 5m 3s\tremaining: 3m 22s\n",
      "1562:\tlearn: 0.1984558\ttotal: 5m 4s\tremaining: 3m 21s\n",
      "1563:\tlearn: 0.1983428\ttotal: 5m 4s\tremaining: 3m 21s\n",
      "1564:\tlearn: 0.1982690\ttotal: 5m 4s\tremaining: 3m 21s\n",
      "1565:\tlearn: 0.1980855\ttotal: 5m 4s\tremaining: 3m 21s\n",
      "1566:\tlearn: 0.1979621\ttotal: 5m 4s\tremaining: 3m 21s\n",
      "1567:\tlearn: 0.1979019\ttotal: 5m 5s\tremaining: 3m 20s\n",
      "1568:\tlearn: 0.1976478\ttotal: 5m 5s\tremaining: 3m 20s\n",
      "1569:\tlearn: 0.1975432\ttotal: 5m 5s\tremaining: 3m 20s\n",
      "1570:\tlearn: 0.1973791\ttotal: 5m 5s\tremaining: 3m 20s\n",
      "1571:\tlearn: 0.1972628\ttotal: 5m 5s\tremaining: 3m 20s\n",
      "1572:\tlearn: 0.1970332\ttotal: 5m 6s\tremaining: 3m 19s\n",
      "1573:\tlearn: 0.1968943\ttotal: 5m 6s\tremaining: 3m 19s\n",
      "1574:\tlearn: 0.1967421\ttotal: 5m 6s\tremaining: 3m 19s\n",
      "1575:\tlearn: 0.1965408\ttotal: 5m 6s\tremaining: 3m 19s\n",
      "1576:\tlearn: 0.1964119\ttotal: 5m 6s\tremaining: 3m 19s\n",
      "1577:\tlearn: 0.1961863\ttotal: 5m 7s\tremaining: 3m 18s\n",
      "1578:\tlearn: 0.1960006\ttotal: 5m 7s\tremaining: 3m 18s\n",
      "1579:\tlearn: 0.1958039\ttotal: 5m 7s\tremaining: 3m 18s\n",
      "1580:\tlearn: 0.1956581\ttotal: 5m 7s\tremaining: 3m 18s\n",
      "1581:\tlearn: 0.1955711\ttotal: 5m 7s\tremaining: 3m 18s\n",
      "1582:\tlearn: 0.1953981\ttotal: 5m 8s\tremaining: 3m 17s\n",
      "1583:\tlearn: 0.1952813\ttotal: 5m 8s\tremaining: 3m 17s\n",
      "1584:\tlearn: 0.1951120\ttotal: 5m 8s\tremaining: 3m 17s\n",
      "1585:\tlearn: 0.1949554\ttotal: 5m 8s\tremaining: 3m 17s\n",
      "1586:\tlearn: 0.1947800\ttotal: 5m 8s\tremaining: 3m 17s\n",
      "1587:\tlearn: 0.1946229\ttotal: 5m 9s\tremaining: 3m 16s\n",
      "1588:\tlearn: 0.1945137\ttotal: 5m 9s\tremaining: 3m 16s\n",
      "1589:\tlearn: 0.1943678\ttotal: 5m 9s\tremaining: 3m 16s\n",
      "1590:\tlearn: 0.1942285\ttotal: 5m 9s\tremaining: 3m 16s\n",
      "1591:\tlearn: 0.1941504\ttotal: 5m 9s\tremaining: 3m 16s\n",
      "1592:\tlearn: 0.1939627\ttotal: 5m 10s\tremaining: 3m 15s\n",
      "1593:\tlearn: 0.1937541\ttotal: 5m 10s\tremaining: 3m 15s\n",
      "1594:\tlearn: 0.1936008\ttotal: 5m 10s\tremaining: 3m 15s\n",
      "1595:\tlearn: 0.1934601\ttotal: 5m 10s\tremaining: 3m 15s\n",
      "1596:\tlearn: 0.1933256\ttotal: 5m 10s\tremaining: 3m 15s\n",
      "1597:\tlearn: 0.1932269\ttotal: 5m 11s\tremaining: 3m 15s\n",
      "1598:\tlearn: 0.1930953\ttotal: 5m 11s\tremaining: 3m 14s\n",
      "1599:\tlearn: 0.1928479\ttotal: 5m 11s\tremaining: 3m 14s\n",
      "1600:\tlearn: 0.1926946\ttotal: 5m 11s\tremaining: 3m 14s\n",
      "1601:\tlearn: 0.1925488\ttotal: 5m 11s\tremaining: 3m 14s\n",
      "1602:\tlearn: 0.1923681\ttotal: 5m 11s\tremaining: 3m 14s\n",
      "1603:\tlearn: 0.1922989\ttotal: 5m 12s\tremaining: 3m 13s\n",
      "1604:\tlearn: 0.1921592\ttotal: 5m 12s\tremaining: 3m 13s\n",
      "1605:\tlearn: 0.1919709\ttotal: 5m 12s\tremaining: 3m 13s\n",
      "1606:\tlearn: 0.1918614\ttotal: 5m 12s\tremaining: 3m 13s\n",
      "1607:\tlearn: 0.1917452\ttotal: 5m 12s\tremaining: 3m 13s\n",
      "1608:\tlearn: 0.1916281\ttotal: 5m 13s\tremaining: 3m 12s\n",
      "1609:\tlearn: 0.1914287\ttotal: 5m 13s\tremaining: 3m 12s\n",
      "1610:\tlearn: 0.1912432\ttotal: 5m 13s\tremaining: 3m 12s\n",
      "1611:\tlearn: 0.1911029\ttotal: 5m 13s\tremaining: 3m 12s\n",
      "1612:\tlearn: 0.1909203\ttotal: 5m 13s\tremaining: 3m 12s\n",
      "1613:\tlearn: 0.1908039\ttotal: 5m 14s\tremaining: 3m 11s\n",
      "1614:\tlearn: 0.1906642\ttotal: 5m 14s\tremaining: 3m 11s\n",
      "1615:\tlearn: 0.1905523\ttotal: 5m 14s\tremaining: 3m 11s\n",
      "1616:\tlearn: 0.1903877\ttotal: 5m 14s\tremaining: 3m 11s\n",
      "1617:\tlearn: 0.1902163\ttotal: 5m 14s\tremaining: 3m 11s\n",
      "1618:\tlearn: 0.1901173\ttotal: 5m 15s\tremaining: 3m 10s\n",
      "1619:\tlearn: 0.1900100\ttotal: 5m 15s\tremaining: 3m 10s\n",
      "1620:\tlearn: 0.1898447\ttotal: 5m 15s\tremaining: 3m 10s\n",
      "1621:\tlearn: 0.1897924\ttotal: 5m 15s\tremaining: 3m 10s\n",
      "1622:\tlearn: 0.1896118\ttotal: 5m 15s\tremaining: 3m 10s\n",
      "1623:\tlearn: 0.1894210\ttotal: 5m 16s\tremaining: 3m 9s\n",
      "1624:\tlearn: 0.1892976\ttotal: 5m 16s\tremaining: 3m 9s\n",
      "1625:\tlearn: 0.1891792\ttotal: 5m 16s\tremaining: 3m 9s\n",
      "1626:\tlearn: 0.1890188\ttotal: 5m 16s\tremaining: 3m 9s\n",
      "1627:\tlearn: 0.1889062\ttotal: 5m 16s\tremaining: 3m 9s\n",
      "1628:\tlearn: 0.1887339\ttotal: 5m 17s\tremaining: 3m 8s\n",
      "1629:\tlearn: 0.1885202\ttotal: 5m 17s\tremaining: 3m 8s\n",
      "1630:\tlearn: 0.1883664\ttotal: 5m 17s\tremaining: 3m 8s\n",
      "1631:\tlearn: 0.1881377\ttotal: 5m 17s\tremaining: 3m 8s\n",
      "1632:\tlearn: 0.1879927\ttotal: 5m 17s\tremaining: 3m 8s\n",
      "1633:\tlearn: 0.1879098\ttotal: 5m 18s\tremaining: 3m 8s\n",
      "1634:\tlearn: 0.1878227\ttotal: 5m 18s\tremaining: 3m 7s\n",
      "1635:\tlearn: 0.1877187\ttotal: 5m 18s\tremaining: 3m 7s\n",
      "1636:\tlearn: 0.1875795\ttotal: 5m 18s\tremaining: 3m 7s\n",
      "1637:\tlearn: 0.1873142\ttotal: 5m 18s\tremaining: 3m 7s\n",
      "1638:\tlearn: 0.1871609\ttotal: 5m 19s\tremaining: 3m 7s\n",
      "1639:\tlearn: 0.1869923\ttotal: 5m 19s\tremaining: 3m 6s\n",
      "1640:\tlearn: 0.1868915\ttotal: 5m 19s\tremaining: 3m 6s\n",
      "1641:\tlearn: 0.1867095\ttotal: 5m 19s\tremaining: 3m 6s\n",
      "1642:\tlearn: 0.1866018\ttotal: 5m 19s\tremaining: 3m 6s\n",
      "1643:\tlearn: 0.1863958\ttotal: 5m 20s\tremaining: 3m 6s\n",
      "1644:\tlearn: 0.1862317\ttotal: 5m 20s\tremaining: 3m 5s\n",
      "1645:\tlearn: 0.1860952\ttotal: 5m 20s\tremaining: 3m 5s\n",
      "1646:\tlearn: 0.1859250\ttotal: 5m 20s\tremaining: 3m 5s\n",
      "1647:\tlearn: 0.1857976\ttotal: 5m 20s\tremaining: 3m 5s\n",
      "1648:\tlearn: 0.1856460\ttotal: 5m 20s\tremaining: 3m 5s\n",
      "1649:\tlearn: 0.1854465\ttotal: 5m 21s\tremaining: 3m 4s\n",
      "1650:\tlearn: 0.1853348\ttotal: 5m 21s\tremaining: 3m 4s\n",
      "1651:\tlearn: 0.1851313\ttotal: 5m 21s\tremaining: 3m 4s\n",
      "1652:\tlearn: 0.1850305\ttotal: 5m 21s\tremaining: 3m 4s\n",
      "1653:\tlearn: 0.1849497\ttotal: 5m 21s\tremaining: 3m 4s\n",
      "1654:\tlearn: 0.1847594\ttotal: 5m 22s\tremaining: 3m 3s\n",
      "1655:\tlearn: 0.1845283\ttotal: 5m 22s\tremaining: 3m 3s\n",
      "1656:\tlearn: 0.1843765\ttotal: 5m 22s\tremaining: 3m 3s\n",
      "1657:\tlearn: 0.1841606\ttotal: 5m 22s\tremaining: 3m 3s\n",
      "1658:\tlearn: 0.1840242\ttotal: 5m 22s\tremaining: 3m 3s\n",
      "1659:\tlearn: 0.1838652\ttotal: 5m 23s\tremaining: 3m 2s\n",
      "1660:\tlearn: 0.1837245\ttotal: 5m 23s\tremaining: 3m 2s\n",
      "1661:\tlearn: 0.1835249\ttotal: 5m 23s\tremaining: 3m 2s\n",
      "1662:\tlearn: 0.1834197\ttotal: 5m 23s\tremaining: 3m 2s\n",
      "1663:\tlearn: 0.1832552\ttotal: 5m 23s\tremaining: 3m 2s\n",
      "1664:\tlearn: 0.1831010\ttotal: 5m 24s\tremaining: 3m 1s\n",
      "1665:\tlearn: 0.1829032\ttotal: 5m 24s\tremaining: 3m 1s\n",
      "1666:\tlearn: 0.1827922\ttotal: 5m 24s\tremaining: 3m 1s\n",
      "1667:\tlearn: 0.1826138\ttotal: 5m 24s\tremaining: 3m 1s\n",
      "1668:\tlearn: 0.1824271\ttotal: 5m 24s\tremaining: 3m 1s\n",
      "1669:\tlearn: 0.1822897\ttotal: 5m 25s\tremaining: 3m 1s\n",
      "1670:\tlearn: 0.1821748\ttotal: 5m 25s\tremaining: 3m\n",
      "1671:\tlearn: 0.1820334\ttotal: 5m 25s\tremaining: 3m\n",
      "1672:\tlearn: 0.1819266\ttotal: 5m 25s\tremaining: 3m\n",
      "1673:\tlearn: 0.1817712\ttotal: 5m 25s\tremaining: 3m\n",
      "1674:\tlearn: 0.1816229\ttotal: 5m 26s\tremaining: 3m\n",
      "1675:\tlearn: 0.1815225\ttotal: 5m 26s\tremaining: 2m 59s\n",
      "1676:\tlearn: 0.1814189\ttotal: 5m 26s\tremaining: 2m 59s\n",
      "1677:\tlearn: 0.1812874\ttotal: 5m 26s\tremaining: 2m 59s\n",
      "1678:\tlearn: 0.1811706\ttotal: 5m 26s\tremaining: 2m 59s\n",
      "1679:\tlearn: 0.1810826\ttotal: 5m 26s\tremaining: 2m 59s\n",
      "1680:\tlearn: 0.1810051\ttotal: 5m 27s\tremaining: 2m 58s\n",
      "1681:\tlearn: 0.1808247\ttotal: 5m 27s\tremaining: 2m 58s\n",
      "1682:\tlearn: 0.1807142\ttotal: 5m 27s\tremaining: 2m 58s\n",
      "1683:\tlearn: 0.1805657\ttotal: 5m 27s\tremaining: 2m 58s\n",
      "1684:\tlearn: 0.1803803\ttotal: 5m 27s\tremaining: 2m 58s\n",
      "1685:\tlearn: 0.1802594\ttotal: 5m 28s\tremaining: 2m 57s\n",
      "1686:\tlearn: 0.1800614\ttotal: 5m 28s\tremaining: 2m 57s\n",
      "1687:\tlearn: 0.1799428\ttotal: 5m 28s\tremaining: 2m 57s\n",
      "1688:\tlearn: 0.1798108\ttotal: 5m 28s\tremaining: 2m 57s\n",
      "1689:\tlearn: 0.1797364\ttotal: 5m 28s\tremaining: 2m 57s\n",
      "1690:\tlearn: 0.1795947\ttotal: 5m 29s\tremaining: 2m 56s\n",
      "1691:\tlearn: 0.1794251\ttotal: 5m 29s\tremaining: 2m 56s\n",
      "1692:\tlearn: 0.1792834\ttotal: 5m 29s\tremaining: 2m 56s\n",
      "1693:\tlearn: 0.1791063\ttotal: 5m 29s\tremaining: 2m 56s\n",
      "1694:\tlearn: 0.1789641\ttotal: 5m 29s\tremaining: 2m 56s\n",
      "1695:\tlearn: 0.1788464\ttotal: 5m 30s\tremaining: 2m 55s\n",
      "1696:\tlearn: 0.1787469\ttotal: 5m 30s\tremaining: 2m 55s\n",
      "1697:\tlearn: 0.1786245\ttotal: 5m 30s\tremaining: 2m 55s\n",
      "1698:\tlearn: 0.1784828\ttotal: 5m 30s\tremaining: 2m 55s\n",
      "1699:\tlearn: 0.1782671\ttotal: 5m 30s\tremaining: 2m 55s\n",
      "1700:\tlearn: 0.1781128\ttotal: 5m 31s\tremaining: 2m 54s\n",
      "1701:\tlearn: 0.1780104\ttotal: 5m 31s\tremaining: 2m 54s\n",
      "1702:\tlearn: 0.1777941\ttotal: 5m 31s\tremaining: 2m 54s\n",
      "1703:\tlearn: 0.1776131\ttotal: 5m 31s\tremaining: 2m 54s\n",
      "1704:\tlearn: 0.1774781\ttotal: 5m 31s\tremaining: 2m 54s\n",
      "1705:\tlearn: 0.1774302\ttotal: 5m 31s\tremaining: 2m 53s\n",
      "1706:\tlearn: 0.1772209\ttotal: 5m 32s\tremaining: 2m 53s\n",
      "1707:\tlearn: 0.1770924\ttotal: 5m 32s\tremaining: 2m 53s\n",
      "1708:\tlearn: 0.1769646\ttotal: 5m 32s\tremaining: 2m 53s\n",
      "1709:\tlearn: 0.1768256\ttotal: 5m 32s\tremaining: 2m 53s\n",
      "1710:\tlearn: 0.1766667\ttotal: 5m 32s\tremaining: 2m 53s\n",
      "1711:\tlearn: 0.1764965\ttotal: 5m 33s\tremaining: 2m 52s\n",
      "1712:\tlearn: 0.1763161\ttotal: 5m 33s\tremaining: 2m 52s\n",
      "1713:\tlearn: 0.1762212\ttotal: 5m 33s\tremaining: 2m 52s\n",
      "1714:\tlearn: 0.1760785\ttotal: 5m 33s\tremaining: 2m 52s\n",
      "1715:\tlearn: 0.1758716\ttotal: 5m 33s\tremaining: 2m 52s\n",
      "1716:\tlearn: 0.1757519\ttotal: 5m 34s\tremaining: 2m 51s\n",
      "1717:\tlearn: 0.1756233\ttotal: 5m 34s\tremaining: 2m 51s\n",
      "1718:\tlearn: 0.1755064\ttotal: 5m 34s\tremaining: 2m 51s\n",
      "1719:\tlearn: 0.1753562\ttotal: 5m 34s\tremaining: 2m 51s\n",
      "1720:\tlearn: 0.1752816\ttotal: 5m 34s\tremaining: 2m 51s\n",
      "1721:\tlearn: 0.1751807\ttotal: 5m 35s\tremaining: 2m 50s\n",
      "1722:\tlearn: 0.1750408\ttotal: 5m 35s\tremaining: 2m 50s\n",
      "1723:\tlearn: 0.1749410\ttotal: 5m 35s\tremaining: 2m 50s\n",
      "1724:\tlearn: 0.1748491\ttotal: 5m 35s\tremaining: 2m 50s\n",
      "1725:\tlearn: 0.1747302\ttotal: 5m 35s\tremaining: 2m 50s\n",
      "1726:\tlearn: 0.1745956\ttotal: 5m 36s\tremaining: 2m 49s\n",
      "1727:\tlearn: 0.1745151\ttotal: 5m 36s\tremaining: 2m 49s\n",
      "1728:\tlearn: 0.1743520\ttotal: 5m 36s\tremaining: 2m 49s\n",
      "1729:\tlearn: 0.1742068\ttotal: 5m 36s\tremaining: 2m 49s\n",
      "1730:\tlearn: 0.1740501\ttotal: 5m 36s\tremaining: 2m 49s\n",
      "1731:\tlearn: 0.1738530\ttotal: 5m 37s\tremaining: 2m 48s\n",
      "1732:\tlearn: 0.1737627\ttotal: 5m 37s\tremaining: 2m 48s\n",
      "1733:\tlearn: 0.1736619\ttotal: 5m 37s\tremaining: 2m 48s\n",
      "1734:\tlearn: 0.1735741\ttotal: 5m 37s\tremaining: 2m 48s\n",
      "1735:\tlearn: 0.1734328\ttotal: 5m 37s\tremaining: 2m 48s\n",
      "1736:\tlearn: 0.1732772\ttotal: 5m 38s\tremaining: 2m 47s\n",
      "1737:\tlearn: 0.1731040\ttotal: 5m 38s\tremaining: 2m 47s\n",
      "1738:\tlearn: 0.1729841\ttotal: 5m 38s\tremaining: 2m 47s\n",
      "1739:\tlearn: 0.1728437\ttotal: 5m 38s\tremaining: 2m 47s\n",
      "1740:\tlearn: 0.1727110\ttotal: 5m 38s\tremaining: 2m 47s\n",
      "1741:\tlearn: 0.1725288\ttotal: 5m 39s\tremaining: 2m 47s\n",
      "1742:\tlearn: 0.1723614\ttotal: 5m 39s\tremaining: 2m 46s\n",
      "1743:\tlearn: 0.1722297\ttotal: 5m 39s\tremaining: 2m 46s\n",
      "1744:\tlearn: 0.1720929\ttotal: 5m 39s\tremaining: 2m 46s\n",
      "1745:\tlearn: 0.1719014\ttotal: 5m 39s\tremaining: 2m 46s\n",
      "1746:\tlearn: 0.1718033\ttotal: 5m 40s\tremaining: 2m 46s\n",
      "1747:\tlearn: 0.1716771\ttotal: 5m 40s\tremaining: 2m 45s\n",
      "1748:\tlearn: 0.1715815\ttotal: 5m 40s\tremaining: 2m 45s\n",
      "1749:\tlearn: 0.1714393\ttotal: 5m 40s\tremaining: 2m 45s\n",
      "1750:\tlearn: 0.1713563\ttotal: 5m 40s\tremaining: 2m 45s\n",
      "1751:\tlearn: 0.1712727\ttotal: 5m 41s\tremaining: 2m 45s\n",
      "1752:\tlearn: 0.1711104\ttotal: 5m 41s\tremaining: 2m 44s\n",
      "1753:\tlearn: 0.1709916\ttotal: 5m 41s\tremaining: 2m 44s\n",
      "1754:\tlearn: 0.1708648\ttotal: 5m 41s\tremaining: 2m 44s\n",
      "1755:\tlearn: 0.1707500\ttotal: 5m 41s\tremaining: 2m 44s\n",
      "1756:\tlearn: 0.1706454\ttotal: 5m 41s\tremaining: 2m 44s\n",
      "1757:\tlearn: 0.1704614\ttotal: 5m 42s\tremaining: 2m 43s\n",
      "1758:\tlearn: 0.1703550\ttotal: 5m 42s\tremaining: 2m 43s\n",
      "1759:\tlearn: 0.1701814\ttotal: 5m 42s\tremaining: 2m 43s\n",
      "1760:\tlearn: 0.1700856\ttotal: 5m 42s\tremaining: 2m 43s\n",
      "1761:\tlearn: 0.1699313\ttotal: 5m 42s\tremaining: 2m 43s\n",
      "1762:\tlearn: 0.1698465\ttotal: 5m 43s\tremaining: 2m 42s\n",
      "1763:\tlearn: 0.1697280\ttotal: 5m 43s\tremaining: 2m 42s\n",
      "1764:\tlearn: 0.1695931\ttotal: 5m 43s\tremaining: 2m 42s\n",
      "1765:\tlearn: 0.1694690\ttotal: 5m 43s\tremaining: 2m 42s\n",
      "1766:\tlearn: 0.1693011\ttotal: 5m 43s\tremaining: 2m 42s\n",
      "1767:\tlearn: 0.1691303\ttotal: 5m 44s\tremaining: 2m 41s\n",
      "1768:\tlearn: 0.1690318\ttotal: 5m 44s\tremaining: 2m 41s\n",
      "1769:\tlearn: 0.1688524\ttotal: 5m 44s\tremaining: 2m 41s\n",
      "1770:\tlearn: 0.1686823\ttotal: 5m 44s\tremaining: 2m 41s\n",
      "1771:\tlearn: 0.1685552\ttotal: 5m 44s\tremaining: 2m 41s\n",
      "1772:\tlearn: 0.1684358\ttotal: 5m 45s\tremaining: 2m 40s\n",
      "1773:\tlearn: 0.1683766\ttotal: 5m 45s\tremaining: 2m 40s\n",
      "1774:\tlearn: 0.1682811\ttotal: 5m 45s\tremaining: 2m 40s\n",
      "1775:\tlearn: 0.1681616\ttotal: 5m 45s\tremaining: 2m 40s\n",
      "1776:\tlearn: 0.1680506\ttotal: 5m 45s\tremaining: 2m 40s\n",
      "1777:\tlearn: 0.1679085\ttotal: 5m 46s\tremaining: 2m 39s\n",
      "1778:\tlearn: 0.1677838\ttotal: 5m 46s\tremaining: 2m 39s\n",
      "1779:\tlearn: 0.1676393\ttotal: 5m 46s\tremaining: 2m 39s\n",
      "1780:\tlearn: 0.1675840\ttotal: 5m 46s\tremaining: 2m 39s\n",
      "1781:\tlearn: 0.1674594\ttotal: 5m 46s\tremaining: 2m 39s\n",
      "1782:\tlearn: 0.1674017\ttotal: 5m 47s\tremaining: 2m 39s\n",
      "1783:\tlearn: 0.1672447\ttotal: 5m 47s\tremaining: 2m 38s\n",
      "1784:\tlearn: 0.1670979\ttotal: 5m 47s\tremaining: 2m 38s\n",
      "1785:\tlearn: 0.1669269\ttotal: 5m 47s\tremaining: 2m 38s\n",
      "1786:\tlearn: 0.1668219\ttotal: 5m 47s\tremaining: 2m 38s\n",
      "1787:\tlearn: 0.1667180\ttotal: 5m 48s\tremaining: 2m 38s\n",
      "1788:\tlearn: 0.1666018\ttotal: 5m 48s\tremaining: 2m 37s\n",
      "1789:\tlearn: 0.1665035\ttotal: 5m 48s\tremaining: 2m 37s\n",
      "1790:\tlearn: 0.1663873\ttotal: 5m 48s\tremaining: 2m 37s\n",
      "1791:\tlearn: 0.1662238\ttotal: 5m 48s\tremaining: 2m 37s\n",
      "1792:\tlearn: 0.1661092\ttotal: 5m 49s\tremaining: 2m 37s\n",
      "1793:\tlearn: 0.1659854\ttotal: 5m 49s\tremaining: 2m 36s\n",
      "1794:\tlearn: 0.1658386\ttotal: 5m 49s\tremaining: 2m 36s\n",
      "1795:\tlearn: 0.1657259\ttotal: 5m 49s\tremaining: 2m 36s\n",
      "1796:\tlearn: 0.1656087\ttotal: 5m 49s\tremaining: 2m 36s\n",
      "1797:\tlearn: 0.1654392\ttotal: 5m 50s\tremaining: 2m 36s\n",
      "1798:\tlearn: 0.1653387\ttotal: 5m 50s\tremaining: 2m 35s\n",
      "1799:\tlearn: 0.1651647\ttotal: 5m 50s\tremaining: 2m 35s\n",
      "1800:\tlearn: 0.1650068\ttotal: 5m 50s\tremaining: 2m 35s\n",
      "1801:\tlearn: 0.1648959\ttotal: 5m 50s\tremaining: 2m 35s\n",
      "1802:\tlearn: 0.1647084\ttotal: 5m 51s\tremaining: 2m 35s\n",
      "1803:\tlearn: 0.1645637\ttotal: 5m 51s\tremaining: 2m 34s\n",
      "1804:\tlearn: 0.1644557\ttotal: 5m 51s\tremaining: 2m 34s\n",
      "1805:\tlearn: 0.1643489\ttotal: 5m 51s\tremaining: 2m 34s\n",
      "1806:\tlearn: 0.1642407\ttotal: 5m 51s\tremaining: 2m 34s\n",
      "1807:\tlearn: 0.1641438\ttotal: 5m 52s\tremaining: 2m 34s\n",
      "1808:\tlearn: 0.1639847\ttotal: 5m 52s\tremaining: 2m 33s\n",
      "1809:\tlearn: 0.1638419\ttotal: 5m 52s\tremaining: 2m 33s\n",
      "1810:\tlearn: 0.1637910\ttotal: 5m 52s\tremaining: 2m 33s\n",
      "1811:\tlearn: 0.1636939\ttotal: 5m 52s\tremaining: 2m 33s\n",
      "1812:\tlearn: 0.1636088\ttotal: 5m 52s\tremaining: 2m 33s\n",
      "1813:\tlearn: 0.1634736\ttotal: 5m 53s\tremaining: 2m 33s\n",
      "1814:\tlearn: 0.1633417\ttotal: 5m 53s\tremaining: 2m 32s\n",
      "1815:\tlearn: 0.1632213\ttotal: 5m 53s\tremaining: 2m 32s\n",
      "1816:\tlearn: 0.1630713\ttotal: 5m 53s\tremaining: 2m 32s\n",
      "1817:\tlearn: 0.1629905\ttotal: 5m 53s\tremaining: 2m 32s\n",
      "1818:\tlearn: 0.1628652\ttotal: 5m 54s\tremaining: 2m 32s\n",
      "1819:\tlearn: 0.1627815\ttotal: 5m 54s\tremaining: 2m 31s\n",
      "1820:\tlearn: 0.1626451\ttotal: 5m 54s\tremaining: 2m 31s\n",
      "1821:\tlearn: 0.1625935\ttotal: 5m 54s\tremaining: 2m 31s\n",
      "1822:\tlearn: 0.1625088\ttotal: 5m 54s\tremaining: 2m 31s\n",
      "1823:\tlearn: 0.1623819\ttotal: 5m 55s\tremaining: 2m 31s\n",
      "1824:\tlearn: 0.1622785\ttotal: 5m 55s\tremaining: 2m 30s\n",
      "1825:\tlearn: 0.1621250\ttotal: 5m 55s\tremaining: 2m 30s\n",
      "1826:\tlearn: 0.1620283\ttotal: 5m 55s\tremaining: 2m 30s\n",
      "1827:\tlearn: 0.1618879\ttotal: 5m 55s\tremaining: 2m 30s\n",
      "1828:\tlearn: 0.1617341\ttotal: 5m 56s\tremaining: 2m 30s\n",
      "1829:\tlearn: 0.1615743\ttotal: 5m 56s\tremaining: 2m 29s\n",
      "1830:\tlearn: 0.1614548\ttotal: 5m 56s\tremaining: 2m 29s\n",
      "1831:\tlearn: 0.1613823\ttotal: 5m 56s\tremaining: 2m 29s\n",
      "1832:\tlearn: 0.1612834\ttotal: 5m 56s\tremaining: 2m 29s\n",
      "1833:\tlearn: 0.1612239\ttotal: 5m 57s\tremaining: 2m 29s\n",
      "1834:\tlearn: 0.1610565\ttotal: 5m 57s\tremaining: 2m 28s\n",
      "1835:\tlearn: 0.1609117\ttotal: 5m 57s\tremaining: 2m 28s\n",
      "1836:\tlearn: 0.1607908\ttotal: 5m 57s\tremaining: 2m 28s\n",
      "1837:\tlearn: 0.1606628\ttotal: 5m 57s\tremaining: 2m 28s\n",
      "1838:\tlearn: 0.1605647\ttotal: 5m 58s\tremaining: 2m 28s\n",
      "1839:\tlearn: 0.1604545\ttotal: 5m 58s\tremaining: 2m 27s\n",
      "1840:\tlearn: 0.1603267\ttotal: 5m 58s\tremaining: 2m 27s\n",
      "1841:\tlearn: 0.1601685\ttotal: 5m 58s\tremaining: 2m 27s\n",
      "1842:\tlearn: 0.1600027\ttotal: 5m 58s\tremaining: 2m 27s\n",
      "1843:\tlearn: 0.1598711\ttotal: 5m 59s\tremaining: 2m 27s\n",
      "1844:\tlearn: 0.1597764\ttotal: 5m 59s\tremaining: 2m 27s\n",
      "1845:\tlearn: 0.1596415\ttotal: 5m 59s\tremaining: 2m 26s\n",
      "1846:\tlearn: 0.1595394\ttotal: 5m 59s\tremaining: 2m 26s\n",
      "1847:\tlearn: 0.1593847\ttotal: 5m 59s\tremaining: 2m 26s\n",
      "1848:\tlearn: 0.1592935\ttotal: 6m\tremaining: 2m 26s\n",
      "1849:\tlearn: 0.1591399\ttotal: 6m\tremaining: 2m 26s\n",
      "1850:\tlearn: 0.1589891\ttotal: 6m\tremaining: 2m 25s\n",
      "1851:\tlearn: 0.1589037\ttotal: 6m\tremaining: 2m 25s\n",
      "1852:\tlearn: 0.1588325\ttotal: 6m\tremaining: 2m 25s\n",
      "1853:\tlearn: 0.1587229\ttotal: 6m 1s\tremaining: 2m 25s\n",
      "1854:\tlearn: 0.1585578\ttotal: 6m 1s\tremaining: 2m 25s\n",
      "1855:\tlearn: 0.1584524\ttotal: 6m 1s\tremaining: 2m 24s\n",
      "1856:\tlearn: 0.1583790\ttotal: 6m 1s\tremaining: 2m 24s\n",
      "1857:\tlearn: 0.1582978\ttotal: 6m 1s\tremaining: 2m 24s\n",
      "1858:\tlearn: 0.1581515\ttotal: 6m 2s\tremaining: 2m 24s\n",
      "1859:\tlearn: 0.1580741\ttotal: 6m 2s\tremaining: 2m 24s\n",
      "1860:\tlearn: 0.1579393\ttotal: 6m 2s\tremaining: 2m 23s\n",
      "1861:\tlearn: 0.1578078\ttotal: 6m 2s\tremaining: 2m 23s\n",
      "1862:\tlearn: 0.1577404\ttotal: 6m 2s\tremaining: 2m 23s\n",
      "1863:\tlearn: 0.1576265\ttotal: 6m 3s\tremaining: 2m 23s\n",
      "1864:\tlearn: 0.1575385\ttotal: 6m 3s\tremaining: 2m 23s\n",
      "1865:\tlearn: 0.1573962\ttotal: 6m 3s\tremaining: 2m 22s\n",
      "1866:\tlearn: 0.1573000\ttotal: 6m 3s\tremaining: 2m 22s\n",
      "1867:\tlearn: 0.1571871\ttotal: 6m 3s\tremaining: 2m 22s\n",
      "1868:\tlearn: 0.1571248\ttotal: 6m 3s\tremaining: 2m 22s\n",
      "1869:\tlearn: 0.1570342\ttotal: 6m 4s\tremaining: 2m 22s\n",
      "1870:\tlearn: 0.1568811\ttotal: 6m 4s\tremaining: 2m 21s\n",
      "1871:\tlearn: 0.1568121\ttotal: 6m 4s\tremaining: 2m 21s\n",
      "1872:\tlearn: 0.1567045\ttotal: 6m 4s\tremaining: 2m 21s\n",
      "1873:\tlearn: 0.1565948\ttotal: 6m 4s\tremaining: 2m 21s\n",
      "1874:\tlearn: 0.1565255\ttotal: 6m 5s\tremaining: 2m 21s\n",
      "1875:\tlearn: 0.1564105\ttotal: 6m 5s\tremaining: 2m 20s\n",
      "1876:\tlearn: 0.1563156\ttotal: 6m 5s\tremaining: 2m 20s\n",
      "1877:\tlearn: 0.1562557\ttotal: 6m 5s\tremaining: 2m 20s\n",
      "1878:\tlearn: 0.1560766\ttotal: 6m 5s\tremaining: 2m 20s\n",
      "1879:\tlearn: 0.1559884\ttotal: 6m 6s\tremaining: 2m 20s\n",
      "1880:\tlearn: 0.1558553\ttotal: 6m 6s\tremaining: 2m 20s\n",
      "1881:\tlearn: 0.1557404\ttotal: 6m 6s\tremaining: 2m 19s\n",
      "1882:\tlearn: 0.1556394\ttotal: 6m 6s\tremaining: 2m 19s\n",
      "1883:\tlearn: 0.1555429\ttotal: 6m 6s\tremaining: 2m 19s\n",
      "1884:\tlearn: 0.1554403\ttotal: 6m 7s\tremaining: 2m 19s\n",
      "1885:\tlearn: 0.1553827\ttotal: 6m 7s\tremaining: 2m 19s\n",
      "1886:\tlearn: 0.1552204\ttotal: 6m 7s\tremaining: 2m 18s\n",
      "1887:\tlearn: 0.1551443\ttotal: 6m 7s\tremaining: 2m 18s\n",
      "1888:\tlearn: 0.1549944\ttotal: 6m 7s\tremaining: 2m 18s\n",
      "1889:\tlearn: 0.1549210\ttotal: 6m 8s\tremaining: 2m 18s\n",
      "1890:\tlearn: 0.1548220\ttotal: 6m 8s\tremaining: 2m 18s\n",
      "1891:\tlearn: 0.1547507\ttotal: 6m 8s\tremaining: 2m 17s\n",
      "1892:\tlearn: 0.1546034\ttotal: 6m 8s\tremaining: 2m 17s\n",
      "1893:\tlearn: 0.1545029\ttotal: 6m 8s\tremaining: 2m 17s\n",
      "1894:\tlearn: 0.1544201\ttotal: 6m 9s\tremaining: 2m 17s\n",
      "1895:\tlearn: 0.1543013\ttotal: 6m 9s\tremaining: 2m 17s\n",
      "1896:\tlearn: 0.1542050\ttotal: 6m 9s\tremaining: 2m 16s\n",
      "1897:\tlearn: 0.1540739\ttotal: 6m 9s\tremaining: 2m 16s\n",
      "1898:\tlearn: 0.1539666\ttotal: 6m 9s\tremaining: 2m 16s\n",
      "1899:\tlearn: 0.1538404\ttotal: 6m 10s\tremaining: 2m 16s\n",
      "1900:\tlearn: 0.1537843\ttotal: 6m 10s\tremaining: 2m 16s\n",
      "1901:\tlearn: 0.1536957\ttotal: 6m 10s\tremaining: 2m 15s\n",
      "1902:\tlearn: 0.1535508\ttotal: 6m 10s\tremaining: 2m 15s\n",
      "1903:\tlearn: 0.1534507\ttotal: 6m 10s\tremaining: 2m 15s\n",
      "1904:\tlearn: 0.1532871\ttotal: 6m 10s\tremaining: 2m 15s\n",
      "1905:\tlearn: 0.1531948\ttotal: 6m 11s\tremaining: 2m 15s\n",
      "1906:\tlearn: 0.1530790\ttotal: 6m 11s\tremaining: 2m 14s\n",
      "1907:\tlearn: 0.1529993\ttotal: 6m 11s\tremaining: 2m 14s\n",
      "1908:\tlearn: 0.1529128\ttotal: 6m 11s\tremaining: 2m 14s\n",
      "1909:\tlearn: 0.1527741\ttotal: 6m 11s\tremaining: 2m 14s\n",
      "1910:\tlearn: 0.1526716\ttotal: 6m 12s\tremaining: 2m 14s\n",
      "1911:\tlearn: 0.1525562\ttotal: 6m 12s\tremaining: 2m 13s\n",
      "1912:\tlearn: 0.1524344\ttotal: 6m 12s\tremaining: 2m 13s\n",
      "1913:\tlearn: 0.1523234\ttotal: 6m 12s\tremaining: 2m 13s\n",
      "1914:\tlearn: 0.1522212\ttotal: 6m 12s\tremaining: 2m 13s\n",
      "1915:\tlearn: 0.1521127\ttotal: 6m 13s\tremaining: 2m 13s\n",
      "1916:\tlearn: 0.1519979\ttotal: 6m 13s\tremaining: 2m 12s\n",
      "1917:\tlearn: 0.1518882\ttotal: 6m 13s\tremaining: 2m 12s\n",
      "1918:\tlearn: 0.1518238\ttotal: 6m 13s\tremaining: 2m 12s\n",
      "1919:\tlearn: 0.1517358\ttotal: 6m 13s\tremaining: 2m 12s\n",
      "1920:\tlearn: 0.1515950\ttotal: 6m 14s\tremaining: 2m 12s\n",
      "1921:\tlearn: 0.1515085\ttotal: 6m 14s\tremaining: 2m 12s\n",
      "1922:\tlearn: 0.1514176\ttotal: 6m 14s\tremaining: 2m 11s\n",
      "1923:\tlearn: 0.1513850\ttotal: 6m 14s\tremaining: 2m 11s\n",
      "1924:\tlearn: 0.1512722\ttotal: 6m 14s\tremaining: 2m 11s\n",
      "1925:\tlearn: 0.1511237\ttotal: 6m 15s\tremaining: 2m 11s\n",
      "1926:\tlearn: 0.1510150\ttotal: 6m 15s\tremaining: 2m 11s\n",
      "1927:\tlearn: 0.1509099\ttotal: 6m 15s\tremaining: 2m 10s\n",
      "1928:\tlearn: 0.1508115\ttotal: 6m 15s\tremaining: 2m 10s\n",
      "1929:\tlearn: 0.1507276\ttotal: 6m 15s\tremaining: 2m 10s\n",
      "1930:\tlearn: 0.1506596\ttotal: 6m 15s\tremaining: 2m 10s\n",
      "1931:\tlearn: 0.1505524\ttotal: 6m 16s\tremaining: 2m 10s\n",
      "1932:\tlearn: 0.1504787\ttotal: 6m 16s\tremaining: 2m 9s\n",
      "1933:\tlearn: 0.1504057\ttotal: 6m 16s\tremaining: 2m 9s\n",
      "1934:\tlearn: 0.1502858\ttotal: 6m 16s\tremaining: 2m 9s\n",
      "1935:\tlearn: 0.1501712\ttotal: 6m 16s\tremaining: 2m 9s\n",
      "1936:\tlearn: 0.1501048\ttotal: 6m 17s\tremaining: 2m 9s\n",
      "1937:\tlearn: 0.1499984\ttotal: 6m 17s\tremaining: 2m 8s\n",
      "1938:\tlearn: 0.1499439\ttotal: 6m 17s\tremaining: 2m 8s\n",
      "1939:\tlearn: 0.1498189\ttotal: 6m 17s\tremaining: 2m 8s\n",
      "1940:\tlearn: 0.1497190\ttotal: 6m 17s\tremaining: 2m 8s\n",
      "1941:\tlearn: 0.1496403\ttotal: 6m 18s\tremaining: 2m 8s\n",
      "1942:\tlearn: 0.1495149\ttotal: 6m 18s\tremaining: 2m 7s\n",
      "1943:\tlearn: 0.1494440\ttotal: 6m 18s\tremaining: 2m 7s\n",
      "1944:\tlearn: 0.1493384\ttotal: 6m 18s\tremaining: 2m 7s\n",
      "1945:\tlearn: 0.1492331\ttotal: 6m 18s\tremaining: 2m 7s\n",
      "1946:\tlearn: 0.1490635\ttotal: 6m 19s\tremaining: 2m 7s\n",
      "1947:\tlearn: 0.1489906\ttotal: 6m 19s\tremaining: 2m 6s\n",
      "1948:\tlearn: 0.1488737\ttotal: 6m 19s\tremaining: 2m 6s\n",
      "1949:\tlearn: 0.1487579\ttotal: 6m 19s\tremaining: 2m 6s\n",
      "1950:\tlearn: 0.1486667\ttotal: 6m 19s\tremaining: 2m 6s\n",
      "1951:\tlearn: 0.1485711\ttotal: 6m 20s\tremaining: 2m 6s\n",
      "1952:\tlearn: 0.1484951\ttotal: 6m 20s\tremaining: 2m 5s\n",
      "1953:\tlearn: 0.1483584\ttotal: 6m 20s\tremaining: 2m 5s\n",
      "1954:\tlearn: 0.1482549\ttotal: 6m 20s\tremaining: 2m 5s\n",
      "1955:\tlearn: 0.1481665\ttotal: 6m 20s\tremaining: 2m 5s\n",
      "1956:\tlearn: 0.1480679\ttotal: 6m 21s\tremaining: 2m 5s\n",
      "1957:\tlearn: 0.1479669\ttotal: 6m 21s\tremaining: 2m 5s\n",
      "1958:\tlearn: 0.1478383\ttotal: 6m 21s\tremaining: 2m 4s\n",
      "1959:\tlearn: 0.1476959\ttotal: 6m 21s\tremaining: 2m 4s\n",
      "1960:\tlearn: 0.1475595\ttotal: 6m 21s\tremaining: 2m 4s\n",
      "1961:\tlearn: 0.1474232\ttotal: 6m 22s\tremaining: 2m 4s\n",
      "1962:\tlearn: 0.1473433\ttotal: 6m 22s\tremaining: 2m 4s\n",
      "1963:\tlearn: 0.1472684\ttotal: 6m 22s\tremaining: 2m 3s\n",
      "1964:\tlearn: 0.1471699\ttotal: 6m 22s\tremaining: 2m 3s\n",
      "1965:\tlearn: 0.1471235\ttotal: 6m 22s\tremaining: 2m 3s\n",
      "1966:\tlearn: 0.1470182\ttotal: 6m 22s\tremaining: 2m 3s\n",
      "1967:\tlearn: 0.1469295\ttotal: 6m 23s\tremaining: 2m 3s\n",
      "1968:\tlearn: 0.1468030\ttotal: 6m 23s\tremaining: 2m 2s\n",
      "1969:\tlearn: 0.1467062\ttotal: 6m 23s\tremaining: 2m 2s\n",
      "1970:\tlearn: 0.1466188\ttotal: 6m 23s\tremaining: 2m 2s\n",
      "1971:\tlearn: 0.1465047\ttotal: 6m 23s\tremaining: 2m 2s\n",
      "1972:\tlearn: 0.1464407\ttotal: 6m 24s\tremaining: 2m 2s\n",
      "1973:\tlearn: 0.1463395\ttotal: 6m 24s\tremaining: 2m 1s\n",
      "1974:\tlearn: 0.1462059\ttotal: 6m 24s\tremaining: 2m 1s\n",
      "1975:\tlearn: 0.1461357\ttotal: 6m 24s\tremaining: 2m 1s\n",
      "1976:\tlearn: 0.1459391\ttotal: 6m 24s\tremaining: 2m 1s\n",
      "1977:\tlearn: 0.1458282\ttotal: 6m 25s\tremaining: 2m 1s\n",
      "1978:\tlearn: 0.1457061\ttotal: 6m 25s\tremaining: 2m\n",
      "1979:\tlearn: 0.1456153\ttotal: 6m 25s\tremaining: 2m\n",
      "1980:\tlearn: 0.1454948\ttotal: 6m 25s\tremaining: 2m\n",
      "1981:\tlearn: 0.1453674\ttotal: 6m 25s\tremaining: 2m\n",
      "1982:\tlearn: 0.1452765\ttotal: 6m 26s\tremaining: 2m\n",
      "1983:\tlearn: 0.1451665\ttotal: 6m 26s\tremaining: 1m 59s\n",
      "1984:\tlearn: 0.1450489\ttotal: 6m 26s\tremaining: 1m 59s\n",
      "1985:\tlearn: 0.1449873\ttotal: 6m 26s\tremaining: 1m 59s\n",
      "1986:\tlearn: 0.1449090\ttotal: 6m 26s\tremaining: 1m 59s\n",
      "1987:\tlearn: 0.1447941\ttotal: 6m 27s\tremaining: 1m 59s\n",
      "1988:\tlearn: 0.1447209\ttotal: 6m 27s\tremaining: 1m 58s\n",
      "1989:\tlearn: 0.1446566\ttotal: 6m 27s\tremaining: 1m 58s\n",
      "1990:\tlearn: 0.1445176\ttotal: 6m 27s\tremaining: 1m 58s\n",
      "1991:\tlearn: 0.1444088\ttotal: 6m 27s\tremaining: 1m 58s\n",
      "1992:\tlearn: 0.1443157\ttotal: 6m 28s\tremaining: 1m 58s\n",
      "1993:\tlearn: 0.1442385\ttotal: 6m 28s\tremaining: 1m 57s\n",
      "1994:\tlearn: 0.1441006\ttotal: 6m 28s\tremaining: 1m 57s\n",
      "1995:\tlearn: 0.1440163\ttotal: 6m 28s\tremaining: 1m 57s\n",
      "1996:\tlearn: 0.1438957\ttotal: 6m 28s\tremaining: 1m 57s\n",
      "1997:\tlearn: 0.1437731\ttotal: 6m 29s\tremaining: 1m 57s\n",
      "1998:\tlearn: 0.1436706\ttotal: 6m 29s\tremaining: 1m 57s\n",
      "1999:\tlearn: 0.1435656\ttotal: 6m 29s\tremaining: 1m 56s\n",
      "2000:\tlearn: 0.1434299\ttotal: 6m 29s\tremaining: 1m 56s\n",
      "2001:\tlearn: 0.1433707\ttotal: 6m 29s\tremaining: 1m 56s\n",
      "2002:\tlearn: 0.1432522\ttotal: 6m 30s\tremaining: 1m 56s\n",
      "2003:\tlearn: 0.1431799\ttotal: 6m 30s\tremaining: 1m 56s\n",
      "2004:\tlearn: 0.1430553\ttotal: 6m 30s\tremaining: 1m 55s\n",
      "2005:\tlearn: 0.1429800\ttotal: 6m 30s\tremaining: 1m 55s\n",
      "2006:\tlearn: 0.1429050\ttotal: 6m 30s\tremaining: 1m 55s\n",
      "2007:\tlearn: 0.1428041\ttotal: 6m 30s\tremaining: 1m 55s\n",
      "2008:\tlearn: 0.1427108\ttotal: 6m 31s\tremaining: 1m 55s\n",
      "2009:\tlearn: 0.1426415\ttotal: 6m 31s\tremaining: 1m 54s\n",
      "2010:\tlearn: 0.1425540\ttotal: 6m 31s\tremaining: 1m 54s\n",
      "2011:\tlearn: 0.1424479\ttotal: 6m 31s\tremaining: 1m 54s\n",
      "2012:\tlearn: 0.1423513\ttotal: 6m 31s\tremaining: 1m 54s\n",
      "2013:\tlearn: 0.1422483\ttotal: 6m 32s\tremaining: 1m 54s\n",
      "2014:\tlearn: 0.1421725\ttotal: 6m 32s\tremaining: 1m 53s\n",
      "2015:\tlearn: 0.1420398\ttotal: 6m 32s\tremaining: 1m 53s\n",
      "2016:\tlearn: 0.1418949\ttotal: 6m 32s\tremaining: 1m 53s\n",
      "2017:\tlearn: 0.1417664\ttotal: 6m 32s\tremaining: 1m 53s\n",
      "2018:\tlearn: 0.1416512\ttotal: 6m 33s\tremaining: 1m 53s\n",
      "2019:\tlearn: 0.1415548\ttotal: 6m 33s\tremaining: 1m 52s\n",
      "2020:\tlearn: 0.1414259\ttotal: 6m 33s\tremaining: 1m 52s\n",
      "2021:\tlearn: 0.1413418\ttotal: 6m 33s\tremaining: 1m 52s\n",
      "2022:\tlearn: 0.1412445\ttotal: 6m 33s\tremaining: 1m 52s\n",
      "2023:\tlearn: 0.1411806\ttotal: 6m 34s\tremaining: 1m 52s\n",
      "2024:\tlearn: 0.1410769\ttotal: 6m 34s\tremaining: 1m 51s\n",
      "2025:\tlearn: 0.1409750\ttotal: 6m 34s\tremaining: 1m 51s\n",
      "2026:\tlearn: 0.1408625\ttotal: 6m 34s\tremaining: 1m 51s\n",
      "2027:\tlearn: 0.1407354\ttotal: 6m 34s\tremaining: 1m 51s\n",
      "2028:\tlearn: 0.1406548\ttotal: 6m 35s\tremaining: 1m 51s\n",
      "2029:\tlearn: 0.1405463\ttotal: 6m 35s\tremaining: 1m 50s\n",
      "2030:\tlearn: 0.1404550\ttotal: 6m 35s\tremaining: 1m 50s\n",
      "2031:\tlearn: 0.1403445\ttotal: 6m 35s\tremaining: 1m 50s\n",
      "2032:\tlearn: 0.1402681\ttotal: 6m 35s\tremaining: 1m 50s\n",
      "2033:\tlearn: 0.1401621\ttotal: 6m 36s\tremaining: 1m 50s\n",
      "2034:\tlearn: 0.1400521\ttotal: 6m 36s\tremaining: 1m 50s\n",
      "2035:\tlearn: 0.1399789\ttotal: 6m 36s\tremaining: 1m 49s\n",
      "2036:\tlearn: 0.1398588\ttotal: 6m 36s\tremaining: 1m 49s\n",
      "2037:\tlearn: 0.1397849\ttotal: 6m 36s\tremaining: 1m 49s\n",
      "2038:\tlearn: 0.1396805\ttotal: 6m 37s\tremaining: 1m 49s\n",
      "2039:\tlearn: 0.1395731\ttotal: 6m 37s\tremaining: 1m 49s\n",
      "2040:\tlearn: 0.1394858\ttotal: 6m 37s\tremaining: 1m 48s\n",
      "2041:\tlearn: 0.1393783\ttotal: 6m 37s\tremaining: 1m 48s\n",
      "2042:\tlearn: 0.1393071\ttotal: 6m 37s\tremaining: 1m 48s\n",
      "2043:\tlearn: 0.1392448\ttotal: 6m 38s\tremaining: 1m 48s\n",
      "2044:\tlearn: 0.1391342\ttotal: 6m 38s\tremaining: 1m 48s\n",
      "2045:\tlearn: 0.1390527\ttotal: 6m 38s\tremaining: 1m 47s\n",
      "2046:\tlearn: 0.1389320\ttotal: 6m 38s\tremaining: 1m 47s\n",
      "2047:\tlearn: 0.1387984\ttotal: 6m 38s\tremaining: 1m 47s\n",
      "2048:\tlearn: 0.1386939\ttotal: 6m 38s\tremaining: 1m 47s\n",
      "2049:\tlearn: 0.1386152\ttotal: 6m 39s\tremaining: 1m 47s\n",
      "2050:\tlearn: 0.1385391\ttotal: 6m 39s\tremaining: 1m 46s\n",
      "2051:\tlearn: 0.1384113\ttotal: 6m 39s\tremaining: 1m 46s\n",
      "2052:\tlearn: 0.1383201\ttotal: 6m 39s\tremaining: 1m 46s\n",
      "2053:\tlearn: 0.1382453\ttotal: 6m 39s\tremaining: 1m 46s\n",
      "2054:\tlearn: 0.1381468\ttotal: 6m 40s\tremaining: 1m 46s\n",
      "2055:\tlearn: 0.1380485\ttotal: 6m 40s\tremaining: 1m 45s\n",
      "2056:\tlearn: 0.1379779\ttotal: 6m 40s\tremaining: 1m 45s\n",
      "2057:\tlearn: 0.1379092\ttotal: 6m 40s\tremaining: 1m 45s\n",
      "2058:\tlearn: 0.1378491\ttotal: 6m 40s\tremaining: 1m 45s\n",
      "2059:\tlearn: 0.1377823\ttotal: 6m 41s\tremaining: 1m 45s\n",
      "2060:\tlearn: 0.1376929\ttotal: 6m 41s\tremaining: 1m 44s\n",
      "2061:\tlearn: 0.1376368\ttotal: 6m 41s\tremaining: 1m 44s\n",
      "2062:\tlearn: 0.1375359\ttotal: 6m 41s\tremaining: 1m 44s\n",
      "2063:\tlearn: 0.1374475\ttotal: 6m 41s\tremaining: 1m 44s\n",
      "2064:\tlearn: 0.1373159\ttotal: 6m 42s\tremaining: 1m 44s\n",
      "2065:\tlearn: 0.1372215\ttotal: 6m 42s\tremaining: 1m 43s\n",
      "2066:\tlearn: 0.1371179\ttotal: 6m 42s\tremaining: 1m 43s\n",
      "2067:\tlearn: 0.1370677\ttotal: 6m 42s\tremaining: 1m 43s\n",
      "2068:\tlearn: 0.1369965\ttotal: 6m 42s\tremaining: 1m 43s\n",
      "2069:\tlearn: 0.1369031\ttotal: 6m 43s\tremaining: 1m 43s\n",
      "2070:\tlearn: 0.1367986\ttotal: 6m 43s\tremaining: 1m 43s\n",
      "2071:\tlearn: 0.1366821\ttotal: 6m 43s\tremaining: 1m 42s\n",
      "2072:\tlearn: 0.1365613\ttotal: 6m 43s\tremaining: 1m 42s\n",
      "2073:\tlearn: 0.1364159\ttotal: 6m 43s\tremaining: 1m 42s\n",
      "2074:\tlearn: 0.1363205\ttotal: 6m 44s\tremaining: 1m 42s\n",
      "2075:\tlearn: 0.1362220\ttotal: 6m 44s\tremaining: 1m 42s\n",
      "2076:\tlearn: 0.1360892\ttotal: 6m 44s\tremaining: 1m 41s\n",
      "2077:\tlearn: 0.1359814\ttotal: 6m 44s\tremaining: 1m 41s\n",
      "2078:\tlearn: 0.1359127\ttotal: 6m 44s\tremaining: 1m 41s\n",
      "2079:\tlearn: 0.1358316\ttotal: 6m 45s\tremaining: 1m 41s\n",
      "2080:\tlearn: 0.1357215\ttotal: 6m 45s\tremaining: 1m 41s\n",
      "2081:\tlearn: 0.1356206\ttotal: 6m 45s\tremaining: 1m 40s\n",
      "2082:\tlearn: 0.1354871\ttotal: 6m 45s\tremaining: 1m 40s\n",
      "2083:\tlearn: 0.1354033\ttotal: 6m 45s\tremaining: 1m 40s\n",
      "2084:\tlearn: 0.1353458\ttotal: 6m 46s\tremaining: 1m 40s\n",
      "2085:\tlearn: 0.1352613\ttotal: 6m 46s\tremaining: 1m 40s\n",
      "2086:\tlearn: 0.1351861\ttotal: 6m 46s\tremaining: 1m 39s\n",
      "2087:\tlearn: 0.1351136\ttotal: 6m 46s\tremaining: 1m 39s\n",
      "2088:\tlearn: 0.1350333\ttotal: 6m 46s\tremaining: 1m 39s\n",
      "2089:\tlearn: 0.1349598\ttotal: 6m 46s\tremaining: 1m 39s\n",
      "2090:\tlearn: 0.1349137\ttotal: 6m 47s\tremaining: 1m 39s\n",
      "2091:\tlearn: 0.1348236\ttotal: 6m 47s\tremaining: 1m 38s\n",
      "2092:\tlearn: 0.1347419\ttotal: 6m 47s\tremaining: 1m 38s\n",
      "2093:\tlearn: 0.1346640\ttotal: 6m 47s\tremaining: 1m 38s\n",
      "2094:\tlearn: 0.1345888\ttotal: 6m 47s\tremaining: 1m 38s\n",
      "2095:\tlearn: 0.1345058\ttotal: 6m 48s\tremaining: 1m 38s\n",
      "2096:\tlearn: 0.1343871\ttotal: 6m 48s\tremaining: 1m 37s\n",
      "2097:\tlearn: 0.1343391\ttotal: 6m 48s\tremaining: 1m 37s\n",
      "2098:\tlearn: 0.1342131\ttotal: 6m 48s\tremaining: 1m 37s\n",
      "2099:\tlearn: 0.1341520\ttotal: 6m 48s\tremaining: 1m 37s\n",
      "2100:\tlearn: 0.1340565\ttotal: 6m 49s\tremaining: 1m 37s\n",
      "2101:\tlearn: 0.1339859\ttotal: 6m 49s\tremaining: 1m 36s\n",
      "2102:\tlearn: 0.1338871\ttotal: 6m 49s\tremaining: 1m 36s\n",
      "2103:\tlearn: 0.1338144\ttotal: 6m 49s\tremaining: 1m 36s\n",
      "2104:\tlearn: 0.1337482\ttotal: 6m 49s\tremaining: 1m 36s\n",
      "2105:\tlearn: 0.1337029\ttotal: 6m 50s\tremaining: 1m 36s\n",
      "2106:\tlearn: 0.1336347\ttotal: 6m 50s\tremaining: 1m 35s\n",
      "2107:\tlearn: 0.1335699\ttotal: 6m 50s\tremaining: 1m 35s\n",
      "2108:\tlearn: 0.1334878\ttotal: 6m 50s\tremaining: 1m 35s\n",
      "2109:\tlearn: 0.1333800\ttotal: 6m 50s\tremaining: 1m 35s\n",
      "2110:\tlearn: 0.1332907\ttotal: 6m 51s\tremaining: 1m 35s\n",
      "2111:\tlearn: 0.1332021\ttotal: 6m 51s\tremaining: 1m 35s\n",
      "2112:\tlearn: 0.1331645\ttotal: 6m 51s\tremaining: 1m 34s\n",
      "2113:\tlearn: 0.1330630\ttotal: 6m 51s\tremaining: 1m 34s\n",
      "2114:\tlearn: 0.1329971\ttotal: 6m 51s\tremaining: 1m 34s\n",
      "2115:\tlearn: 0.1329091\ttotal: 6m 52s\tremaining: 1m 34s\n",
      "2116:\tlearn: 0.1327800\ttotal: 6m 52s\tremaining: 1m 34s\n",
      "2117:\tlearn: 0.1326861\ttotal: 6m 52s\tremaining: 1m 33s\n",
      "2118:\tlearn: 0.1325841\ttotal: 6m 52s\tremaining: 1m 33s\n",
      "2119:\tlearn: 0.1324653\ttotal: 6m 52s\tremaining: 1m 33s\n",
      "2120:\tlearn: 0.1323911\ttotal: 6m 53s\tremaining: 1m 33s\n",
      "2121:\tlearn: 0.1323271\ttotal: 6m 53s\tremaining: 1m 33s\n",
      "2122:\tlearn: 0.1322712\ttotal: 6m 53s\tremaining: 1m 32s\n",
      "2123:\tlearn: 0.1322251\ttotal: 6m 53s\tremaining: 1m 32s\n",
      "2124:\tlearn: 0.1321229\ttotal: 6m 53s\tremaining: 1m 32s\n",
      "2125:\tlearn: 0.1320634\ttotal: 6m 53s\tremaining: 1m 32s\n",
      "2126:\tlearn: 0.1319896\ttotal: 6m 54s\tremaining: 1m 32s\n",
      "2127:\tlearn: 0.1318786\ttotal: 6m 54s\tremaining: 1m 31s\n",
      "2128:\tlearn: 0.1318252\ttotal: 6m 54s\tremaining: 1m 31s\n",
      "2129:\tlearn: 0.1317349\ttotal: 6m 54s\tremaining: 1m 31s\n",
      "2130:\tlearn: 0.1316700\ttotal: 6m 54s\tremaining: 1m 31s\n",
      "2131:\tlearn: 0.1315667\ttotal: 6m 55s\tremaining: 1m 31s\n",
      "2132:\tlearn: 0.1314913\ttotal: 6m 55s\tremaining: 1m 30s\n",
      "2133:\tlearn: 0.1314145\ttotal: 6m 55s\tremaining: 1m 30s\n",
      "2134:\tlearn: 0.1313520\ttotal: 6m 55s\tremaining: 1m 30s\n",
      "2135:\tlearn: 0.1312640\ttotal: 6m 55s\tremaining: 1m 30s\n",
      "2136:\tlearn: 0.1312091\ttotal: 6m 56s\tremaining: 1m 30s\n",
      "2137:\tlearn: 0.1311421\ttotal: 6m 56s\tremaining: 1m 29s\n",
      "2138:\tlearn: 0.1310117\ttotal: 6m 56s\tremaining: 1m 29s\n",
      "2139:\tlearn: 0.1309473\ttotal: 6m 56s\tremaining: 1m 29s\n",
      "2140:\tlearn: 0.1308674\ttotal: 6m 56s\tremaining: 1m 29s\n",
      "2141:\tlearn: 0.1307493\ttotal: 6m 57s\tremaining: 1m 29s\n",
      "2142:\tlearn: 0.1307052\ttotal: 6m 57s\tremaining: 1m 28s\n",
      "2143:\tlearn: 0.1305981\ttotal: 6m 57s\tremaining: 1m 28s\n",
      "2144:\tlearn: 0.1304899\ttotal: 6m 57s\tremaining: 1m 28s\n",
      "2145:\tlearn: 0.1304393\ttotal: 6m 57s\tremaining: 1m 28s\n",
      "2146:\tlearn: 0.1303797\ttotal: 6m 58s\tremaining: 1m 28s\n",
      "2147:\tlearn: 0.1302866\ttotal: 6m 58s\tremaining: 1m 28s\n",
      "2148:\tlearn: 0.1302217\ttotal: 6m 58s\tremaining: 1m 27s\n",
      "2149:\tlearn: 0.1301451\ttotal: 6m 58s\tremaining: 1m 27s\n",
      "2150:\tlearn: 0.1301073\ttotal: 6m 58s\tremaining: 1m 27s\n",
      "2151:\tlearn: 0.1300334\ttotal: 6m 59s\tremaining: 1m 27s\n",
      "2152:\tlearn: 0.1299481\ttotal: 6m 59s\tremaining: 1m 27s\n",
      "2153:\tlearn: 0.1298455\ttotal: 6m 59s\tremaining: 1m 26s\n",
      "2154:\tlearn: 0.1297599\ttotal: 6m 59s\tremaining: 1m 26s\n",
      "2155:\tlearn: 0.1296179\ttotal: 6m 59s\tremaining: 1m 26s\n",
      "2156:\tlearn: 0.1295242\ttotal: 6m 59s\tremaining: 1m 26s\n",
      "2157:\tlearn: 0.1294733\ttotal: 7m\tremaining: 1m 26s\n",
      "2158:\tlearn: 0.1293771\ttotal: 7m\tremaining: 1m 25s\n",
      "2159:\tlearn: 0.1292769\ttotal: 7m\tremaining: 1m 25s\n",
      "2160:\tlearn: 0.1292096\ttotal: 7m\tremaining: 1m 25s\n",
      "2161:\tlearn: 0.1291527\ttotal: 7m\tremaining: 1m 25s\n",
      "2162:\tlearn: 0.1290633\ttotal: 7m 1s\tremaining: 1m 25s\n",
      "2163:\tlearn: 0.1290198\ttotal: 7m 1s\tremaining: 1m 24s\n",
      "2164:\tlearn: 0.1289038\ttotal: 7m 1s\tremaining: 1m 24s\n",
      "2165:\tlearn: 0.1288134\ttotal: 7m 1s\tremaining: 1m 24s\n",
      "2166:\tlearn: 0.1287023\ttotal: 7m 1s\tremaining: 1m 24s\n",
      "2167:\tlearn: 0.1285798\ttotal: 7m 2s\tremaining: 1m 24s\n",
      "2168:\tlearn: 0.1285175\ttotal: 7m 2s\tremaining: 1m 23s\n",
      "2169:\tlearn: 0.1284568\ttotal: 7m 2s\tremaining: 1m 23s\n",
      "2170:\tlearn: 0.1283930\ttotal: 7m 2s\tremaining: 1m 23s\n",
      "2171:\tlearn: 0.1282980\ttotal: 7m 2s\tremaining: 1m 23s\n",
      "2172:\tlearn: 0.1282217\ttotal: 7m 3s\tremaining: 1m 23s\n",
      "2173:\tlearn: 0.1280861\ttotal: 7m 3s\tremaining: 1m 22s\n",
      "2174:\tlearn: 0.1280407\ttotal: 7m 3s\tremaining: 1m 22s\n",
      "2175:\tlearn: 0.1279542\ttotal: 7m 3s\tremaining: 1m 22s\n",
      "2176:\tlearn: 0.1278635\ttotal: 7m 3s\tremaining: 1m 22s\n",
      "2177:\tlearn: 0.1277787\ttotal: 7m 4s\tremaining: 1m 22s\n",
      "2178:\tlearn: 0.1277089\ttotal: 7m 4s\tremaining: 1m 21s\n",
      "2179:\tlearn: 0.1275880\ttotal: 7m 4s\tremaining: 1m 21s\n",
      "2180:\tlearn: 0.1275224\ttotal: 7m 4s\tremaining: 1m 21s\n",
      "2181:\tlearn: 0.1274348\ttotal: 7m 4s\tremaining: 1m 21s\n",
      "2182:\tlearn: 0.1273484\ttotal: 7m 5s\tremaining: 1m 21s\n",
      "2183:\tlearn: 0.1272744\ttotal: 7m 5s\tremaining: 1m 21s\n",
      "2184:\tlearn: 0.1272070\ttotal: 7m 5s\tremaining: 1m 20s\n",
      "2185:\tlearn: 0.1271481\ttotal: 7m 5s\tremaining: 1m 20s\n",
      "2186:\tlearn: 0.1270417\ttotal: 7m 5s\tremaining: 1m 20s\n",
      "2187:\tlearn: 0.1269462\ttotal: 7m 6s\tremaining: 1m 20s\n",
      "2188:\tlearn: 0.1268560\ttotal: 7m 6s\tremaining: 1m 20s\n",
      "2189:\tlearn: 0.1267994\ttotal: 7m 6s\tremaining: 1m 19s\n",
      "2190:\tlearn: 0.1266716\ttotal: 7m 6s\tremaining: 1m 19s\n",
      "2191:\tlearn: 0.1265513\ttotal: 7m 6s\tremaining: 1m 19s\n",
      "2192:\tlearn: 0.1264534\ttotal: 7m 7s\tremaining: 1m 19s\n",
      "2193:\tlearn: 0.1263527\ttotal: 7m 7s\tremaining: 1m 19s\n",
      "2194:\tlearn: 0.1262648\ttotal: 7m 7s\tremaining: 1m 18s\n",
      "2195:\tlearn: 0.1261557\ttotal: 7m 7s\tremaining: 1m 18s\n",
      "2196:\tlearn: 0.1260841\ttotal: 7m 7s\tremaining: 1m 18s\n",
      "2197:\tlearn: 0.1260152\ttotal: 7m 8s\tremaining: 1m 18s\n",
      "2198:\tlearn: 0.1259427\ttotal: 7m 8s\tremaining: 1m 18s\n",
      "2199:\tlearn: 0.1258921\ttotal: 7m 8s\tremaining: 1m 17s\n",
      "2200:\tlearn: 0.1257880\ttotal: 7m 8s\tremaining: 1m 17s\n",
      "2201:\tlearn: 0.1257222\ttotal: 7m 8s\tremaining: 1m 17s\n",
      "2202:\tlearn: 0.1256314\ttotal: 7m 8s\tremaining: 1m 17s\n",
      "2203:\tlearn: 0.1255441\ttotal: 7m 9s\tremaining: 1m 17s\n",
      "2204:\tlearn: 0.1254551\ttotal: 7m 9s\tremaining: 1m 16s\n",
      "2205:\tlearn: 0.1253625\ttotal: 7m 9s\tremaining: 1m 16s\n",
      "2206:\tlearn: 0.1252839\ttotal: 7m 9s\tremaining: 1m 16s\n",
      "2207:\tlearn: 0.1252072\ttotal: 7m 9s\tremaining: 1m 16s\n",
      "2208:\tlearn: 0.1251228\ttotal: 7m 10s\tremaining: 1m 16s\n",
      "2209:\tlearn: 0.1250382\ttotal: 7m 10s\tremaining: 1m 15s\n",
      "2210:\tlearn: 0.1249589\ttotal: 7m 10s\tremaining: 1m 15s\n",
      "2211:\tlearn: 0.1248551\ttotal: 7m 10s\tremaining: 1m 15s\n",
      "2212:\tlearn: 0.1247956\ttotal: 7m 10s\tremaining: 1m 15s\n",
      "2213:\tlearn: 0.1247153\ttotal: 7m 11s\tremaining: 1m 15s\n",
      "2214:\tlearn: 0.1246490\ttotal: 7m 11s\tremaining: 1m 14s\n",
      "2215:\tlearn: 0.1245656\ttotal: 7m 11s\tremaining: 1m 14s\n",
      "2216:\tlearn: 0.1245021\ttotal: 7m 11s\tremaining: 1m 14s\n",
      "2217:\tlearn: 0.1244258\ttotal: 7m 11s\tremaining: 1m 14s\n",
      "2218:\tlearn: 0.1243598\ttotal: 7m 12s\tremaining: 1m 14s\n",
      "2219:\tlearn: 0.1242938\ttotal: 7m 12s\tremaining: 1m 13s\n",
      "2220:\tlearn: 0.1241725\ttotal: 7m 12s\tremaining: 1m 13s\n",
      "2221:\tlearn: 0.1240885\ttotal: 7m 12s\tremaining: 1m 13s\n",
      "2222:\tlearn: 0.1240015\ttotal: 7m 12s\tremaining: 1m 13s\n",
      "2223:\tlearn: 0.1238879\ttotal: 7m 13s\tremaining: 1m 13s\n",
      "2224:\tlearn: 0.1237914\ttotal: 7m 13s\tremaining: 1m 13s\n",
      "2225:\tlearn: 0.1236903\ttotal: 7m 13s\tremaining: 1m 12s\n",
      "2226:\tlearn: 0.1236471\ttotal: 7m 13s\tremaining: 1m 12s\n",
      "2227:\tlearn: 0.1235637\ttotal: 7m 13s\tremaining: 1m 12s\n",
      "2228:\tlearn: 0.1235098\ttotal: 7m 14s\tremaining: 1m 12s\n",
      "2229:\tlearn: 0.1234318\ttotal: 7m 14s\tremaining: 1m 12s\n",
      "2230:\tlearn: 0.1233806\ttotal: 7m 14s\tremaining: 1m 11s\n",
      "2231:\tlearn: 0.1233057\ttotal: 7m 14s\tremaining: 1m 11s\n",
      "2232:\tlearn: 0.1231881\ttotal: 7m 14s\tremaining: 1m 11s\n",
      "2233:\tlearn: 0.1231077\ttotal: 7m 15s\tremaining: 1m 11s\n",
      "2234:\tlearn: 0.1230497\ttotal: 7m 15s\tremaining: 1m 11s\n",
      "2235:\tlearn: 0.1229931\ttotal: 7m 15s\tremaining: 1m 10s\n",
      "2236:\tlearn: 0.1229076\ttotal: 7m 15s\tremaining: 1m 10s\n",
      "2237:\tlearn: 0.1228115\ttotal: 7m 15s\tremaining: 1m 10s\n",
      "2238:\tlearn: 0.1227258\ttotal: 7m 15s\tremaining: 1m 10s\n",
      "2239:\tlearn: 0.1226560\ttotal: 7m 16s\tremaining: 1m 10s\n",
      "2240:\tlearn: 0.1225956\ttotal: 7m 16s\tremaining: 1m 9s\n",
      "2241:\tlearn: 0.1225463\ttotal: 7m 16s\tremaining: 1m 9s\n",
      "2242:\tlearn: 0.1224934\ttotal: 7m 16s\tremaining: 1m 9s\n",
      "2243:\tlearn: 0.1224257\ttotal: 7m 16s\tremaining: 1m 9s\n",
      "2244:\tlearn: 0.1223356\ttotal: 7m 17s\tremaining: 1m 9s\n",
      "2245:\tlearn: 0.1222808\ttotal: 7m 17s\tremaining: 1m 8s\n",
      "2246:\tlearn: 0.1222151\ttotal: 7m 17s\tremaining: 1m 8s\n",
      "2247:\tlearn: 0.1221108\ttotal: 7m 17s\tremaining: 1m 8s\n",
      "2248:\tlearn: 0.1220320\ttotal: 7m 17s\tremaining: 1m 8s\n",
      "2249:\tlearn: 0.1219535\ttotal: 7m 18s\tremaining: 1m 8s\n",
      "2250:\tlearn: 0.1218707\ttotal: 7m 18s\tremaining: 1m 7s\n",
      "2251:\tlearn: 0.1218011\ttotal: 7m 18s\tremaining: 1m 7s\n",
      "2252:\tlearn: 0.1217045\ttotal: 7m 18s\tremaining: 1m 7s\n",
      "2253:\tlearn: 0.1216104\ttotal: 7m 18s\tremaining: 1m 7s\n",
      "2254:\tlearn: 0.1215522\ttotal: 7m 19s\tremaining: 1m 7s\n",
      "2255:\tlearn: 0.1214970\ttotal: 7m 19s\tremaining: 1m 6s\n",
      "2256:\tlearn: 0.1214339\ttotal: 7m 19s\tremaining: 1m 6s\n",
      "2257:\tlearn: 0.1213617\ttotal: 7m 19s\tremaining: 1m 6s\n",
      "2258:\tlearn: 0.1212861\ttotal: 7m 19s\tremaining: 1m 6s\n",
      "2259:\tlearn: 0.1212026\ttotal: 7m 20s\tremaining: 1m 6s\n",
      "2260:\tlearn: 0.1211131\ttotal: 7m 20s\tremaining: 1m 6s\n",
      "2261:\tlearn: 0.1210363\ttotal: 7m 20s\tremaining: 1m 5s\n",
      "2262:\tlearn: 0.1209990\ttotal: 7m 20s\tremaining: 1m 5s\n",
      "2263:\tlearn: 0.1209395\ttotal: 7m 20s\tremaining: 1m 5s\n",
      "2264:\tlearn: 0.1208405\ttotal: 7m 21s\tremaining: 1m 5s\n",
      "2265:\tlearn: 0.1207359\ttotal: 7m 21s\tremaining: 1m 5s\n",
      "2266:\tlearn: 0.1206545\ttotal: 7m 21s\tremaining: 1m 4s\n",
      "2267:\tlearn: 0.1205778\ttotal: 7m 21s\tremaining: 1m 4s\n",
      "2268:\tlearn: 0.1204993\ttotal: 7m 21s\tremaining: 1m 4s\n",
      "2269:\tlearn: 0.1204237\ttotal: 7m 22s\tremaining: 1m 4s\n",
      "2270:\tlearn: 0.1203289\ttotal: 7m 22s\tremaining: 1m 4s\n",
      "2271:\tlearn: 0.1202442\ttotal: 7m 22s\tremaining: 1m 3s\n",
      "2272:\tlearn: 0.1201941\ttotal: 7m 22s\tremaining: 1m 3s\n",
      "2273:\tlearn: 0.1201481\ttotal: 7m 22s\tremaining: 1m 3s\n",
      "2274:\tlearn: 0.1200880\ttotal: 7m 22s\tremaining: 1m 3s\n",
      "2275:\tlearn: 0.1200079\ttotal: 7m 23s\tremaining: 1m 3s\n",
      "2276:\tlearn: 0.1199464\ttotal: 7m 23s\tremaining: 1m 2s\n",
      "2277:\tlearn: 0.1198781\ttotal: 7m 23s\tremaining: 1m 2s\n",
      "2278:\tlearn: 0.1198009\ttotal: 7m 23s\tremaining: 1m 2s\n",
      "2279:\tlearn: 0.1197326\ttotal: 7m 23s\tremaining: 1m 2s\n",
      "2280:\tlearn: 0.1196510\ttotal: 7m 24s\tremaining: 1m 2s\n",
      "2281:\tlearn: 0.1195759\ttotal: 7m 24s\tremaining: 1m 1s\n",
      "2282:\tlearn: 0.1195308\ttotal: 7m 24s\tremaining: 1m 1s\n",
      "2283:\tlearn: 0.1194149\ttotal: 7m 24s\tremaining: 1m 1s\n",
      "2284:\tlearn: 0.1193499\ttotal: 7m 24s\tremaining: 1m 1s\n",
      "2285:\tlearn: 0.1192787\ttotal: 7m 25s\tremaining: 1m 1s\n",
      "2286:\tlearn: 0.1192346\ttotal: 7m 25s\tremaining: 1m\n",
      "2287:\tlearn: 0.1191508\ttotal: 7m 25s\tremaining: 1m\n",
      "2288:\tlearn: 0.1191025\ttotal: 7m 25s\tremaining: 1m\n",
      "2289:\tlearn: 0.1190434\ttotal: 7m 25s\tremaining: 1m\n",
      "2290:\tlearn: 0.1189888\ttotal: 7m 26s\tremaining: 1m\n",
      "2291:\tlearn: 0.1188731\ttotal: 7m 26s\tremaining: 60s\n",
      "2292:\tlearn: 0.1188165\ttotal: 7m 26s\tremaining: 59.8s\n",
      "2293:\tlearn: 0.1187709\ttotal: 7m 26s\tremaining: 59.6s\n",
      "2294:\tlearn: 0.1186976\ttotal: 7m 26s\tremaining: 59.4s\n",
      "2295:\tlearn: 0.1186096\ttotal: 7m 27s\tremaining: 59.2s\n",
      "2296:\tlearn: 0.1185502\ttotal: 7m 27s\tremaining: 59s\n",
      "2297:\tlearn: 0.1184579\ttotal: 7m 27s\tremaining: 58.8s\n",
      "2298:\tlearn: 0.1183657\ttotal: 7m 27s\tremaining: 58.6s\n",
      "2299:\tlearn: 0.1182944\ttotal: 7m 27s\tremaining: 58.4s\n",
      "2300:\tlearn: 0.1182386\ttotal: 7m 28s\tremaining: 58.2s\n",
      "2301:\tlearn: 0.1181832\ttotal: 7m 28s\tremaining: 58s\n",
      "2302:\tlearn: 0.1181212\ttotal: 7m 28s\tremaining: 57.8s\n",
      "2303:\tlearn: 0.1180527\ttotal: 7m 28s\tremaining: 57.6s\n",
      "2304:\tlearn: 0.1179820\ttotal: 7m 28s\tremaining: 57.4s\n",
      "2305:\tlearn: 0.1179124\ttotal: 7m 29s\tremaining: 57.2s\n",
      "2306:\tlearn: 0.1178134\ttotal: 7m 29s\tremaining: 57.1s\n",
      "2307:\tlearn: 0.1177216\ttotal: 7m 29s\tremaining: 56.9s\n",
      "2308:\tlearn: 0.1176540\ttotal: 7m 29s\tremaining: 56.7s\n",
      "2309:\tlearn: 0.1175661\ttotal: 7m 29s\tremaining: 56.5s\n",
      "2310:\tlearn: 0.1175087\ttotal: 7m 30s\tremaining: 56.3s\n",
      "2311:\tlearn: 0.1174604\ttotal: 7m 30s\tremaining: 56.1s\n",
      "2312:\tlearn: 0.1174053\ttotal: 7m 30s\tremaining: 55.9s\n",
      "2313:\tlearn: 0.1173643\ttotal: 7m 30s\tremaining: 55.7s\n",
      "2314:\tlearn: 0.1172971\ttotal: 7m 30s\tremaining: 55.5s\n",
      "2315:\tlearn: 0.1172317\ttotal: 7m 30s\tremaining: 55.3s\n",
      "2316:\tlearn: 0.1171593\ttotal: 7m 31s\tremaining: 55.1s\n",
      "2317:\tlearn: 0.1170788\ttotal: 7m 31s\tremaining: 54.9s\n",
      "2318:\tlearn: 0.1169946\ttotal: 7m 31s\tremaining: 54.7s\n",
      "2319:\tlearn: 0.1168987\ttotal: 7m 31s\tremaining: 54.5s\n",
      "2320:\tlearn: 0.1168391\ttotal: 7m 31s\tremaining: 54.3s\n",
      "2321:\tlearn: 0.1167572\ttotal: 7m 32s\tremaining: 54.1s\n",
      "2322:\tlearn: 0.1166814\ttotal: 7m 32s\tremaining: 53.9s\n",
      "2323:\tlearn: 0.1166302\ttotal: 7m 32s\tremaining: 53.7s\n",
      "2324:\tlearn: 0.1165532\ttotal: 7m 32s\tremaining: 53.5s\n",
      "2325:\tlearn: 0.1165057\ttotal: 7m 32s\tremaining: 53.4s\n",
      "2326:\tlearn: 0.1164304\ttotal: 7m 33s\tremaining: 53.2s\n",
      "2327:\tlearn: 0.1163520\ttotal: 7m 33s\tremaining: 53s\n",
      "2328:\tlearn: 0.1162821\ttotal: 7m 33s\tremaining: 52.8s\n",
      "2329:\tlearn: 0.1162277\ttotal: 7m 33s\tremaining: 52.6s\n",
      "2330:\tlearn: 0.1161842\ttotal: 7m 33s\tremaining: 52.4s\n",
      "2331:\tlearn: 0.1161124\ttotal: 7m 34s\tremaining: 52.2s\n",
      "2332:\tlearn: 0.1160557\ttotal: 7m 34s\tremaining: 52s\n",
      "2333:\tlearn: 0.1159758\ttotal: 7m 34s\tremaining: 51.8s\n",
      "2334:\tlearn: 0.1159050\ttotal: 7m 34s\tremaining: 51.6s\n",
      "2335:\tlearn: 0.1158263\ttotal: 7m 34s\tremaining: 51.4s\n",
      "2336:\tlearn: 0.1157461\ttotal: 7m 35s\tremaining: 51.2s\n",
      "2337:\tlearn: 0.1156595\ttotal: 7m 35s\tremaining: 51s\n",
      "2338:\tlearn: 0.1156122\ttotal: 7m 35s\tremaining: 50.8s\n",
      "2339:\tlearn: 0.1155502\ttotal: 7m 35s\tremaining: 50.6s\n",
      "2340:\tlearn: 0.1154610\ttotal: 7m 35s\tremaining: 50.4s\n",
      "2341:\tlearn: 0.1154215\ttotal: 7m 36s\tremaining: 50.2s\n",
      "2342:\tlearn: 0.1153566\ttotal: 7m 36s\tremaining: 50s\n",
      "2343:\tlearn: 0.1152744\ttotal: 7m 36s\tremaining: 49.9s\n",
      "2344:\tlearn: 0.1152193\ttotal: 7m 36s\tremaining: 49.7s\n",
      "2345:\tlearn: 0.1151812\ttotal: 7m 36s\tremaining: 49.5s\n",
      "2346:\tlearn: 0.1150931\ttotal: 7m 37s\tremaining: 49.3s\n",
      "2347:\tlearn: 0.1150328\ttotal: 7m 37s\tremaining: 49.1s\n",
      "2348:\tlearn: 0.1150037\ttotal: 7m 37s\tremaining: 48.9s\n",
      "2349:\tlearn: 0.1149255\ttotal: 7m 37s\tremaining: 48.7s\n",
      "2350:\tlearn: 0.1148726\ttotal: 7m 37s\tremaining: 48.5s\n",
      "2351:\tlearn: 0.1148037\ttotal: 7m 37s\tremaining: 48.3s\n",
      "2352:\tlearn: 0.1147105\ttotal: 7m 38s\tremaining: 48.1s\n",
      "2353:\tlearn: 0.1146325\ttotal: 7m 38s\tremaining: 47.9s\n",
      "2354:\tlearn: 0.1145327\ttotal: 7m 38s\tremaining: 47.7s\n",
      "2355:\tlearn: 0.1144592\ttotal: 7m 38s\tremaining: 47.5s\n",
      "2356:\tlearn: 0.1144109\ttotal: 7m 38s\tremaining: 47.3s\n",
      "2357:\tlearn: 0.1143698\ttotal: 7m 39s\tremaining: 47.1s\n",
      "2358:\tlearn: 0.1143277\ttotal: 7m 39s\tremaining: 46.9s\n",
      "2359:\tlearn: 0.1142766\ttotal: 7m 39s\tremaining: 46.7s\n",
      "2360:\tlearn: 0.1142091\ttotal: 7m 39s\tremaining: 46.5s\n",
      "2361:\tlearn: 0.1141400\ttotal: 7m 39s\tremaining: 46.3s\n",
      "2362:\tlearn: 0.1140978\ttotal: 7m 40s\tremaining: 46.1s\n",
      "2363:\tlearn: 0.1140389\ttotal: 7m 40s\tremaining: 46s\n",
      "2364:\tlearn: 0.1139655\ttotal: 7m 40s\tremaining: 45.8s\n",
      "2365:\tlearn: 0.1139011\ttotal: 7m 40s\tremaining: 45.6s\n",
      "2366:\tlearn: 0.1138437\ttotal: 7m 40s\tremaining: 45.4s\n",
      "2367:\tlearn: 0.1137868\ttotal: 7m 41s\tremaining: 45.2s\n",
      "2368:\tlearn: 0.1136928\ttotal: 7m 41s\tremaining: 45s\n",
      "2369:\tlearn: 0.1136353\ttotal: 7m 41s\tremaining: 44.8s\n",
      "2370:\tlearn: 0.1135825\ttotal: 7m 41s\tremaining: 44.6s\n",
      "2371:\tlearn: 0.1135369\ttotal: 7m 41s\tremaining: 44.4s\n",
      "2372:\tlearn: 0.1134615\ttotal: 7m 42s\tremaining: 44.2s\n",
      "2373:\tlearn: 0.1134022\ttotal: 7m 42s\tremaining: 44s\n",
      "2374:\tlearn: 0.1133342\ttotal: 7m 42s\tremaining: 43.8s\n",
      "2375:\tlearn: 0.1132458\ttotal: 7m 42s\tremaining: 43.6s\n",
      "2376:\tlearn: 0.1132073\ttotal: 7m 42s\tremaining: 43.4s\n",
      "2377:\tlearn: 0.1131532\ttotal: 7m 43s\tremaining: 43.2s\n",
      "2378:\tlearn: 0.1131067\ttotal: 7m 43s\tremaining: 43s\n",
      "2379:\tlearn: 0.1130391\ttotal: 7m 43s\tremaining: 42.8s\n",
      "2380:\tlearn: 0.1129987\ttotal: 7m 43s\tremaining: 42.6s\n",
      "2381:\tlearn: 0.1129133\ttotal: 7m 43s\tremaining: 42.5s\n",
      "2382:\tlearn: 0.1128506\ttotal: 7m 44s\tremaining: 42.3s\n",
      "2383:\tlearn: 0.1127567\ttotal: 7m 44s\tremaining: 42.1s\n",
      "2384:\tlearn: 0.1126726\ttotal: 7m 44s\tremaining: 41.9s\n",
      "2385:\tlearn: 0.1126207\ttotal: 7m 44s\tremaining: 41.7s\n",
      "2386:\tlearn: 0.1125394\ttotal: 7m 44s\tremaining: 41.5s\n",
      "2387:\tlearn: 0.1124836\ttotal: 7m 45s\tremaining: 41.3s\n",
      "2388:\tlearn: 0.1124057\ttotal: 7m 45s\tremaining: 41.1s\n",
      "2389:\tlearn: 0.1123567\ttotal: 7m 45s\tremaining: 40.9s\n",
      "2390:\tlearn: 0.1122893\ttotal: 7m 45s\tremaining: 40.7s\n",
      "2391:\tlearn: 0.1122223\ttotal: 7m 45s\tremaining: 40.5s\n",
      "2392:\tlearn: 0.1121461\ttotal: 7m 45s\tremaining: 40.3s\n",
      "2393:\tlearn: 0.1120941\ttotal: 7m 46s\tremaining: 40.1s\n",
      "2394:\tlearn: 0.1120517\ttotal: 7m 46s\tremaining: 39.9s\n",
      "2395:\tlearn: 0.1119644\ttotal: 7m 46s\tremaining: 39.7s\n",
      "2396:\tlearn: 0.1118846\ttotal: 7m 46s\tremaining: 39.5s\n",
      "2397:\tlearn: 0.1118234\ttotal: 7m 46s\tremaining: 39.3s\n",
      "2398:\tlearn: 0.1117358\ttotal: 7m 47s\tremaining: 39.1s\n",
      "2399:\tlearn: 0.1116792\ttotal: 7m 47s\tremaining: 38.9s\n",
      "2400:\tlearn: 0.1116327\ttotal: 7m 47s\tremaining: 38.8s\n",
      "2401:\tlearn: 0.1115657\ttotal: 7m 47s\tremaining: 38.6s\n",
      "2402:\tlearn: 0.1115115\ttotal: 7m 47s\tremaining: 38.4s\n",
      "2403:\tlearn: 0.1114359\ttotal: 7m 48s\tremaining: 38.2s\n",
      "2404:\tlearn: 0.1113905\ttotal: 7m 48s\tremaining: 38s\n",
      "2405:\tlearn: 0.1113358\ttotal: 7m 48s\tremaining: 37.8s\n",
      "2406:\tlearn: 0.1112859\ttotal: 7m 48s\tremaining: 37.6s\n",
      "2407:\tlearn: 0.1112380\ttotal: 7m 48s\tremaining: 37.4s\n",
      "2408:\tlearn: 0.1111846\ttotal: 7m 49s\tremaining: 37.2s\n",
      "2409:\tlearn: 0.1111230\ttotal: 7m 49s\tremaining: 37s\n",
      "2410:\tlearn: 0.1110468\ttotal: 7m 49s\tremaining: 36.8s\n",
      "2411:\tlearn: 0.1109798\ttotal: 7m 49s\tremaining: 36.6s\n",
      "2412:\tlearn: 0.1109239\ttotal: 7m 49s\tremaining: 36.4s\n",
      "2413:\tlearn: 0.1108850\ttotal: 7m 50s\tremaining: 36.2s\n",
      "2414:\tlearn: 0.1108195\ttotal: 7m 50s\tremaining: 36s\n",
      "2415:\tlearn: 0.1107573\ttotal: 7m 50s\tremaining: 35.8s\n",
      "2416:\tlearn: 0.1106901\ttotal: 7m 50s\tremaining: 35.6s\n",
      "2417:\tlearn: 0.1106192\ttotal: 7m 50s\tremaining: 35.4s\n",
      "2418:\tlearn: 0.1105460\ttotal: 7m 51s\tremaining: 35.2s\n",
      "2419:\tlearn: 0.1105044\ttotal: 7m 51s\tremaining: 35s\n",
      "2420:\tlearn: 0.1104257\ttotal: 7m 51s\tremaining: 34.9s\n",
      "2421:\tlearn: 0.1103687\ttotal: 7m 51s\tremaining: 34.7s\n",
      "2422:\tlearn: 0.1103347\ttotal: 7m 51s\tremaining: 34.5s\n",
      "2423:\tlearn: 0.1102568\ttotal: 7m 51s\tremaining: 34.3s\n",
      "2424:\tlearn: 0.1102080\ttotal: 7m 52s\tremaining: 34.1s\n",
      "2425:\tlearn: 0.1101228\ttotal: 7m 52s\tremaining: 33.9s\n",
      "2426:\tlearn: 0.1100422\ttotal: 7m 52s\tremaining: 33.7s\n",
      "2427:\tlearn: 0.1099744\ttotal: 7m 52s\tremaining: 33.5s\n",
      "2428:\tlearn: 0.1098992\ttotal: 7m 52s\tremaining: 33.3s\n",
      "2429:\tlearn: 0.1098131\ttotal: 7m 53s\tremaining: 33.1s\n",
      "2430:\tlearn: 0.1097392\ttotal: 7m 53s\tremaining: 32.9s\n",
      "2431:\tlearn: 0.1096786\ttotal: 7m 53s\tremaining: 32.7s\n",
      "2432:\tlearn: 0.1096459\ttotal: 7m 53s\tremaining: 32.5s\n",
      "2433:\tlearn: 0.1095656\ttotal: 7m 53s\tremaining: 32.3s\n",
      "2434:\tlearn: 0.1095059\ttotal: 7m 54s\tremaining: 32.1s\n",
      "2435:\tlearn: 0.1094447\ttotal: 7m 54s\tremaining: 31.9s\n",
      "2436:\tlearn: 0.1094070\ttotal: 7m 54s\tremaining: 31.7s\n",
      "2437:\tlearn: 0.1093133\ttotal: 7m 54s\tremaining: 31.5s\n",
      "2438:\tlearn: 0.1092475\ttotal: 7m 54s\tremaining: 31.3s\n",
      "2439:\tlearn: 0.1091917\ttotal: 7m 55s\tremaining: 31.2s\n",
      "2440:\tlearn: 0.1091377\ttotal: 7m 55s\tremaining: 31s\n",
      "2441:\tlearn: 0.1090450\ttotal: 7m 55s\tremaining: 30.8s\n",
      "2442:\tlearn: 0.1089891\ttotal: 7m 55s\tremaining: 30.6s\n",
      "2443:\tlearn: 0.1089290\ttotal: 7m 55s\tremaining: 30.4s\n",
      "2444:\tlearn: 0.1088280\ttotal: 7m 56s\tremaining: 30.2s\n",
      "2445:\tlearn: 0.1087322\ttotal: 7m 56s\tremaining: 30s\n",
      "2446:\tlearn: 0.1086714\ttotal: 7m 56s\tremaining: 29.8s\n",
      "2447:\tlearn: 0.1086045\ttotal: 7m 56s\tremaining: 29.6s\n",
      "2448:\tlearn: 0.1085181\ttotal: 7m 56s\tremaining: 29.4s\n",
      "2449:\tlearn: 0.1084585\ttotal: 7m 57s\tremaining: 29.2s\n",
      "2450:\tlearn: 0.1083923\ttotal: 7m 57s\tremaining: 29s\n",
      "2451:\tlearn: 0.1083118\ttotal: 7m 57s\tremaining: 28.8s\n",
      "2452:\tlearn: 0.1082680\ttotal: 7m 57s\tremaining: 28.6s\n",
      "2453:\tlearn: 0.1081644\ttotal: 7m 57s\tremaining: 28.4s\n",
      "2454:\tlearn: 0.1081076\ttotal: 7m 58s\tremaining: 28.2s\n",
      "2455:\tlearn: 0.1080136\ttotal: 7m 58s\tremaining: 28s\n",
      "2456:\tlearn: 0.1079481\ttotal: 7m 58s\tremaining: 27.8s\n",
      "2457:\tlearn: 0.1078438\ttotal: 7m 58s\tremaining: 27.6s\n",
      "2458:\tlearn: 0.1077858\ttotal: 7m 58s\tremaining: 27.5s\n",
      "2459:\tlearn: 0.1077380\ttotal: 7m 58s\tremaining: 27.3s\n",
      "2460:\tlearn: 0.1076983\ttotal: 7m 59s\tremaining: 27.1s\n",
      "2461:\tlearn: 0.1076641\ttotal: 7m 59s\tremaining: 26.9s\n",
      "2462:\tlearn: 0.1076138\ttotal: 7m 59s\tremaining: 26.7s\n",
      "2463:\tlearn: 0.1075368\ttotal: 7m 59s\tremaining: 26.5s\n",
      "2464:\tlearn: 0.1074939\ttotal: 7m 59s\tremaining: 26.3s\n",
      "2465:\tlearn: 0.1074132\ttotal: 8m\tremaining: 26.1s\n",
      "2466:\tlearn: 0.1073510\ttotal: 8m\tremaining: 25.9s\n",
      "2467:\tlearn: 0.1072736\ttotal: 8m\tremaining: 25.7s\n",
      "2468:\tlearn: 0.1072117\ttotal: 8m\tremaining: 25.5s\n",
      "2469:\tlearn: 0.1071283\ttotal: 8m\tremaining: 25.3s\n",
      "2470:\tlearn: 0.1070548\ttotal: 8m 1s\tremaining: 25.1s\n",
      "2471:\tlearn: 0.1069891\ttotal: 8m 1s\tremaining: 24.9s\n",
      "2472:\tlearn: 0.1069306\ttotal: 8m 1s\tremaining: 24.7s\n",
      "2473:\tlearn: 0.1068356\ttotal: 8m 1s\tremaining: 24.5s\n",
      "2474:\tlearn: 0.1067767\ttotal: 8m 1s\tremaining: 24.3s\n",
      "2475:\tlearn: 0.1067180\ttotal: 8m 2s\tremaining: 24.1s\n",
      "2476:\tlearn: 0.1066748\ttotal: 8m 2s\tremaining: 23.9s\n",
      "2477:\tlearn: 0.1066030\ttotal: 8m 2s\tremaining: 23.8s\n",
      "2478:\tlearn: 0.1065327\ttotal: 8m 2s\tremaining: 23.6s\n",
      "2479:\tlearn: 0.1064533\ttotal: 8m 2s\tremaining: 23.4s\n",
      "2480:\tlearn: 0.1063868\ttotal: 8m 3s\tremaining: 23.2s\n",
      "2481:\tlearn: 0.1063363\ttotal: 8m 3s\tremaining: 23s\n",
      "2482:\tlearn: 0.1062547\ttotal: 8m 3s\tremaining: 22.8s\n",
      "2483:\tlearn: 0.1061864\ttotal: 8m 3s\tremaining: 22.6s\n",
      "2484:\tlearn: 0.1061355\ttotal: 8m 3s\tremaining: 22.4s\n",
      "2485:\tlearn: 0.1060964\ttotal: 8m 4s\tremaining: 22.2s\n",
      "2486:\tlearn: 0.1060319\ttotal: 8m 4s\tremaining: 22s\n",
      "2487:\tlearn: 0.1059499\ttotal: 8m 4s\tremaining: 21.8s\n",
      "2488:\tlearn: 0.1058673\ttotal: 8m 4s\tremaining: 21.6s\n",
      "2489:\tlearn: 0.1057797\ttotal: 8m 4s\tremaining: 21.4s\n",
      "2490:\tlearn: 0.1057319\ttotal: 8m 5s\tremaining: 21.2s\n",
      "2491:\tlearn: 0.1056788\ttotal: 8m 5s\tremaining: 21s\n",
      "2492:\tlearn: 0.1056244\ttotal: 8m 5s\tremaining: 20.8s\n",
      "2493:\tlearn: 0.1055515\ttotal: 8m 5s\tremaining: 20.6s\n",
      "2494:\tlearn: 0.1054744\ttotal: 8m 5s\tremaining: 20.4s\n",
      "2495:\tlearn: 0.1054182\ttotal: 8m 5s\tremaining: 20.2s\n",
      "2496:\tlearn: 0.1053751\ttotal: 8m 6s\tremaining: 20.1s\n",
      "2497:\tlearn: 0.1053043\ttotal: 8m 6s\tremaining: 19.9s\n",
      "2498:\tlearn: 0.1052531\ttotal: 8m 6s\tremaining: 19.7s\n",
      "2499:\tlearn: 0.1051868\ttotal: 8m 6s\tremaining: 19.5s\n",
      "2500:\tlearn: 0.1051361\ttotal: 8m 6s\tremaining: 19.3s\n",
      "2501:\tlearn: 0.1050906\ttotal: 8m 7s\tremaining: 19.1s\n",
      "2502:\tlearn: 0.1050372\ttotal: 8m 7s\tremaining: 18.9s\n",
      "2503:\tlearn: 0.1049691\ttotal: 8m 7s\tremaining: 18.7s\n",
      "2504:\tlearn: 0.1049188\ttotal: 8m 7s\tremaining: 18.5s\n",
      "2505:\tlearn: 0.1048293\ttotal: 8m 7s\tremaining: 18.3s\n",
      "2506:\tlearn: 0.1047646\ttotal: 8m 8s\tremaining: 18.1s\n",
      "2507:\tlearn: 0.1047000\ttotal: 8m 8s\tremaining: 17.9s\n",
      "2508:\tlearn: 0.1046023\ttotal: 8m 8s\tremaining: 17.7s\n",
      "2509:\tlearn: 0.1045259\ttotal: 8m 8s\tremaining: 17.5s\n",
      "2510:\tlearn: 0.1044343\ttotal: 8m 8s\tremaining: 17.3s\n",
      "2511:\tlearn: 0.1043697\ttotal: 8m 9s\tremaining: 17.1s\n",
      "2512:\tlearn: 0.1043184\ttotal: 8m 9s\tremaining: 16.9s\n",
      "2513:\tlearn: 0.1042758\ttotal: 8m 9s\tremaining: 16.7s\n",
      "2514:\tlearn: 0.1042222\ttotal: 8m 9s\tremaining: 16.5s\n",
      "2515:\tlearn: 0.1041748\ttotal: 8m 9s\tremaining: 16.4s\n",
      "2516:\tlearn: 0.1041124\ttotal: 8m 10s\tremaining: 16.2s\n",
      "2517:\tlearn: 0.1040608\ttotal: 8m 10s\tremaining: 16s\n",
      "2518:\tlearn: 0.1039788\ttotal: 8m 10s\tremaining: 15.8s\n",
      "2519:\tlearn: 0.1039184\ttotal: 8m 10s\tremaining: 15.6s\n",
      "2520:\tlearn: 0.1038470\ttotal: 8m 10s\tremaining: 15.4s\n",
      "2521:\tlearn: 0.1038065\ttotal: 8m 11s\tremaining: 15.2s\n",
      "2522:\tlearn: 0.1037378\ttotal: 8m 11s\tremaining: 15s\n",
      "2523:\tlearn: 0.1036945\ttotal: 8m 11s\tremaining: 14.8s\n",
      "2524:\tlearn: 0.1036406\ttotal: 8m 11s\tremaining: 14.6s\n",
      "2525:\tlearn: 0.1036015\ttotal: 8m 11s\tremaining: 14.4s\n",
      "2526:\tlearn: 0.1035527\ttotal: 8m 11s\tremaining: 14.2s\n",
      "2527:\tlearn: 0.1035115\ttotal: 8m 12s\tremaining: 14s\n",
      "2528:\tlearn: 0.1034641\ttotal: 8m 12s\tremaining: 13.8s\n",
      "2529:\tlearn: 0.1033915\ttotal: 8m 12s\tremaining: 13.6s\n",
      "2530:\tlearn: 0.1033313\ttotal: 8m 12s\tremaining: 13.4s\n",
      "2531:\tlearn: 0.1032354\ttotal: 8m 12s\tremaining: 13.2s\n",
      "2532:\tlearn: 0.1031704\ttotal: 8m 13s\tremaining: 13s\n",
      "2533:\tlearn: 0.1030966\ttotal: 8m 13s\tremaining: 12.8s\n",
      "2534:\tlearn: 0.1030439\ttotal: 8m 13s\tremaining: 12.7s\n",
      "2535:\tlearn: 0.1029611\ttotal: 8m 13s\tremaining: 12.5s\n",
      "2536:\tlearn: 0.1028793\ttotal: 8m 13s\tremaining: 12.3s\n",
      "2537:\tlearn: 0.1028068\ttotal: 8m 14s\tremaining: 12.1s\n",
      "2538:\tlearn: 0.1027434\ttotal: 8m 14s\tremaining: 11.9s\n",
      "2539:\tlearn: 0.1026938\ttotal: 8m 14s\tremaining: 11.7s\n",
      "2540:\tlearn: 0.1026319\ttotal: 8m 14s\tremaining: 11.5s\n",
      "2541:\tlearn: 0.1025577\ttotal: 8m 14s\tremaining: 11.3s\n",
      "2542:\tlearn: 0.1025220\ttotal: 8m 15s\tremaining: 11.1s\n",
      "2543:\tlearn: 0.1024765\ttotal: 8m 15s\tremaining: 10.9s\n",
      "2544:\tlearn: 0.1024313\ttotal: 8m 15s\tremaining: 10.7s\n",
      "2545:\tlearn: 0.1024014\ttotal: 8m 15s\tremaining: 10.5s\n",
      "2546:\tlearn: 0.1023377\ttotal: 8m 15s\tremaining: 10.3s\n",
      "2547:\tlearn: 0.1022812\ttotal: 8m 16s\tremaining: 10.1s\n",
      "2548:\tlearn: 0.1022193\ttotal: 8m 16s\tremaining: 9.93s\n",
      "2549:\tlearn: 0.1021723\ttotal: 8m 16s\tremaining: 9.73s\n",
      "2550:\tlearn: 0.1020796\ttotal: 8m 16s\tremaining: 9.54s\n",
      "2551:\tlearn: 0.1020369\ttotal: 8m 16s\tremaining: 9.34s\n",
      "2552:\tlearn: 0.1019615\ttotal: 8m 16s\tremaining: 9.15s\n",
      "2553:\tlearn: 0.1018890\ttotal: 8m 17s\tremaining: 8.95s\n",
      "2554:\tlearn: 0.1018579\ttotal: 8m 17s\tremaining: 8.76s\n",
      "2555:\tlearn: 0.1018041\ttotal: 8m 17s\tremaining: 8.56s\n",
      "2556:\tlearn: 0.1017308\ttotal: 8m 17s\tremaining: 8.37s\n",
      "2557:\tlearn: 0.1016747\ttotal: 8m 17s\tremaining: 8.18s\n",
      "2558:\tlearn: 0.1016200\ttotal: 8m 18s\tremaining: 7.98s\n",
      "2559:\tlearn: 0.1015578\ttotal: 8m 18s\tremaining: 7.79s\n",
      "2560:\tlearn: 0.1014844\ttotal: 8m 18s\tremaining: 7.59s\n",
      "2561:\tlearn: 0.1014217\ttotal: 8m 18s\tremaining: 7.4s\n",
      "2562:\tlearn: 0.1013737\ttotal: 8m 18s\tremaining: 7.2s\n",
      "2563:\tlearn: 0.1013462\ttotal: 8m 19s\tremaining: 7.01s\n",
      "2564:\tlearn: 0.1012773\ttotal: 8m 19s\tremaining: 6.81s\n",
      "2565:\tlearn: 0.1012075\ttotal: 8m 19s\tremaining: 6.62s\n",
      "2566:\tlearn: 0.1011376\ttotal: 8m 19s\tremaining: 6.42s\n",
      "2567:\tlearn: 0.1010758\ttotal: 8m 19s\tremaining: 6.23s\n",
      "2568:\tlearn: 0.1010115\ttotal: 8m 20s\tremaining: 6.03s\n",
      "2569:\tlearn: 0.1009634\ttotal: 8m 20s\tremaining: 5.84s\n",
      "2570:\tlearn: 0.1009070\ttotal: 8m 20s\tremaining: 5.64s\n",
      "2571:\tlearn: 0.1008394\ttotal: 8m 20s\tremaining: 5.45s\n",
      "2572:\tlearn: 0.1007849\ttotal: 8m 20s\tremaining: 5.26s\n",
      "2573:\tlearn: 0.1007029\ttotal: 8m 21s\tremaining: 5.06s\n",
      "2574:\tlearn: 0.1006357\ttotal: 8m 21s\tremaining: 4.87s\n",
      "2575:\tlearn: 0.1005659\ttotal: 8m 21s\tremaining: 4.67s\n",
      "2576:\tlearn: 0.1005009\ttotal: 8m 21s\tremaining: 4.48s\n",
      "2577:\tlearn: 0.1004609\ttotal: 8m 21s\tremaining: 4.28s\n",
      "2578:\tlearn: 0.1004186\ttotal: 8m 22s\tremaining: 4.09s\n",
      "2579:\tlearn: 0.1003602\ttotal: 8m 22s\tremaining: 3.89s\n",
      "2580:\tlearn: 0.1003019\ttotal: 8m 22s\tremaining: 3.7s\n",
      "2581:\tlearn: 0.1002644\ttotal: 8m 22s\tremaining: 3.5s\n",
      "2582:\tlearn: 0.1002190\ttotal: 8m 22s\tremaining: 3.31s\n",
      "2583:\tlearn: 0.1001637\ttotal: 8m 23s\tremaining: 3.11s\n",
      "2584:\tlearn: 0.1001126\ttotal: 8m 23s\tremaining: 2.92s\n",
      "2585:\tlearn: 0.1000668\ttotal: 8m 23s\tremaining: 2.73s\n",
      "2586:\tlearn: 0.1000255\ttotal: 8m 23s\tremaining: 2.53s\n",
      "2587:\tlearn: 0.0999630\ttotal: 8m 23s\tremaining: 2.34s\n",
      "2588:\tlearn: 0.0999031\ttotal: 8m 24s\tremaining: 2.14s\n",
      "2589:\tlearn: 0.0998330\ttotal: 8m 24s\tremaining: 1.95s\n",
      "2590:\tlearn: 0.0997820\ttotal: 8m 24s\tremaining: 1.75s\n",
      "2591:\tlearn: 0.0996791\ttotal: 8m 24s\tremaining: 1.56s\n",
      "2592:\tlearn: 0.0996284\ttotal: 8m 24s\tremaining: 1.36s\n",
      "2593:\tlearn: 0.0995590\ttotal: 8m 24s\tremaining: 1.17s\n",
      "2594:\tlearn: 0.0995189\ttotal: 8m 25s\tremaining: 973ms\n",
      "2595:\tlearn: 0.0994644\ttotal: 8m 25s\tremaining: 779ms\n",
      "2596:\tlearn: 0.0994221\ttotal: 8m 25s\tremaining: 584ms\n",
      "2597:\tlearn: 0.0993563\ttotal: 8m 25s\tremaining: 389ms\n",
      "2598:\tlearn: 0.0993240\ttotal: 8m 25s\tremaining: 195ms\n",
      "2599:\tlearn: 0.0992710\ttotal: 8m 26s\tremaining: 0us\n",
      "En iyi model kaydedildi: Metric score = 0.7957\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "import joblib\n",
    "\n",
    "imu_features = [col for col in features_df.columns if not col.startswith(('thm_','tof_'))]\n",
    "\n",
    "X_imu = features_df[imu_features].drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_imu = features_df['gesture']\n",
    "\n",
    "X_full = features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_full = features_df['gesture']\n",
    "\n",
    "\n",
    "def objective(trial, X, y, sequence_ids):\n",
    "    params = {\n",
    "        # === Temel yap ===\n",
    "        \"task_type\": \"GPU\",\n",
    "        \"devices\": \"0\",\n",
    "        \"depth\":               trial.suggest_int(\"depth\", 6, 10),  # ok derinlik overfit yapar, 68 aras genelde ideal\n",
    "        \"learning_rate\":       trial.suggest_float(\"learning_rate\", 0.03, 0.08, log=True),  # 0.05 civar genelde en iyi\n",
    "\n",
    "        # === Regularization ===\n",
    "        \"l2_leaf_reg\":         trial.suggest_float(\"l2_leaf_reg\", 3.0, 12.0),  # L2 dzenleme\n",
    "        \"random_strength\":     trial.suggest_float(\"random_strength\", 0.5, 3.0),  # Rastgelelik, genel performans arttrr\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.1, 1.5),  # Bayes bagging, stabiliteyi artrr\n",
    "\n",
    "        # === Sampling & byme ===\n",
    "        #\"subsample\":           trial.suggest_float(\"subsample\", 0.8, 1.0),  # Dk alt rnekleme istatistiksel zelliklerde riskli\n",
    "        #\"colsample_bylevel\":   trial.suggest_float(\"colsample_bylevel\", 0.6, 0.95),\n",
    "        \"grow_policy\":         trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\"]),  # Depthwise gereksiz karmaklk katyor\n",
    "\n",
    "        # === Split hassasiyeti ===\n",
    "        \"border_count\":        trial.suggest_int(\"border_count\", 96, 192),  # ToF gibi analog younluklarda yksek deer faydal\n",
    "        \"min_data_in_leaf\":    trial.suggest_int(\"min_data_in_leaf\", 10, 30),  # Leaf overfit'i krar\n",
    "\n",
    "        # === Eitim kontrol ===\n",
    "        \"iterations\":          trial.suggest_int(\"iterations\", 1400, 2800, step = 200),  # 0.05 learning_rate iin 1800+ ideal\n",
    "        \"early_stopping_rounds\": 100,\n",
    "        \"loss_function\":       \"MultiClass\",\n",
    "        \"eval_metric\":         \"TotalF1\",\n",
    "        \"auto_class_weights\":  \"Balanced\",\n",
    "        \"random_seed\":         42,\n",
    "        \"verbose\":             0\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]          # <-- dzeltildi\n",
    "        val_seq_ids    = sequence_ids.iloc[val_idx]\n",
    "\n",
    "        model = CatBoostClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        val_preds_flat = val_preds.flatten() if hasattr(val_preds, 'flatten') else val_preds\n",
    "        score = hierarchical_macro_f1_score(y_val, val_preds_flat, val_seq_ids)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def train_and_save_model_with_optuna(X, y, sequence_ids, model_path, model_name=\"IMU\", n_trials=100):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, X, y, sequence_ids), n_trials=n_trials)\n",
    "\n",
    "    print(f\"Best trial params: {study.best_trial.params}\")\n",
    "    print(f\"Best trial score: {study.best_trial.value:.4f}\")\n",
    "\n",
    "    # En iyi parametrelerle modeli tekrar tm veride eit\n",
    "    best_params = study.best_trial.params\n",
    "    best_params[\"random_state\"] = 42\n",
    "\n",
    "    best_model = CatBoostClassifier(**best_params)\n",
    "    best_model.fit(X, y)\n",
    "    ,\n",
    "\n",
    "    joblib.dump(best_model, f\"{model_path}_{model_name}_{study.best_trial.value:.4f}.pkl\")\n",
    "    print(f\"En iyi model kaydedildi: Metric score = {study.best_trial.value:.4f}\")\n",
    " \n",
    "# Eitim  \n",
    "#print(\"TRAINING IMU MODEL WITH OPTUNA...\")\n",
    "#train_and_save_model_with_optuna(X_imu, y_imu, features_df['sequence_id'], model_path=\"model_cb_optuna\", model_name=\"imu\", n_trials=100)\n",
    "\n",
    "print(\"\\nTRAINING FULL MODEL WITH OPTUNA...\")\n",
    "train_and_save_model_with_optuna(X_full, y_full, features_df['sequence_id'], model_path=\"model_cb_optuna\", model_name=\"full\", n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90d937",
   "metadata": {},
   "source": [
    "## LGBM OPTUNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc6a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-06-14 20:39:52,842] A new study created in memory with name: no-name-80726501-3d92-4c22-b23e-3f05a5084d97\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING IMU MODEL WITH OPTUNA...\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lightgbm import LGBMClassifier\n",
    "import joblib\n",
    "\n",
    "imu_features = [col for col in features_df.columns if not col.startswith(('thm_','tof_'))]\n",
    "\n",
    "X_imu = features_df[imu_features].drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_imu = features_df['gesture']\n",
    "\n",
    "X_full = features_df.drop(columns=['sequence_id', 'gesture', 'subject', 'sequence_type'])\n",
    "y_full = features_df['gesture']\n",
    "\n",
    "\n",
    "def objective(trial, X, y, sequence_ids):\n",
    "    params = {\n",
    "        # --- core tree shape --------------------------------------------------\n",
    "        \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"gbdt\", \"dart\"]),\n",
    "        \"num_leaves\":     trial.suggest_int(\"num_leaves\", 32, 256, step=8),\n",
    "        \"max_depth\":      trial.suggest_int(\"max_depth\", -1, 14),\n",
    "        \"min_data_in_leaf\": trial.suggest_int(\"min_data_in_leaf\", 10, 80),\n",
    "        \"min_sum_hessian_in_leaf\": trial.suggest_float(\n",
    "            \"min_sum_hessian_in_leaf\", 1e-3, 50.0, log=True\n",
    "        ),\n",
    "\n",
    "        # --- regularisation / penalties --------------------------------------\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-3, 5.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-3, 5.0, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.55, 0.95),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.55, 0.95),\n",
    "        \"bagging_freq\":     trial.suggest_int(\"bagging_freq\", 1, 8),\n",
    "\n",
    "        # --- learning dynamics -----------------------------------------------\n",
    "        \"learning_rate\":  trial.suggest_float(\"learning_rate\", 0.02, 0.1, log=True),\n",
    "        \"n_estimators\":   trial.suggest_int(\"n_estimators\", 1000, 3000, step = 200),\n",
    "        # DARTonly drop parameters (ignored for GBDT)\n",
    "        \"drop_rate\":      trial.suggest_float(\"drop_rate\", 0.05, 0.35),\n",
    "        \"skip_drop\":      trial.suggest_float(\"skip_drop\", 0.3, 0.8),\n",
    "\n",
    "        # --- class & loss -----------------------------------------------------\n",
    "        \"objective\":      \"multiclass\",\n",
    "        \"num_class\":      18,\n",
    "        \"metric\":         \"multi_logloss\",   # surrogate during tuning\n",
    "        \"force_row_wise\": True,              # faster on ~8k rows\n",
    "        \"verbosity\":      -1,\n",
    "        \"seed\":           42,\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]          # <-- dzeltildi\n",
    "        val_seq_ids    = sequence_ids.iloc[val_idx]\n",
    "\n",
    "        model = LGBMClassifier(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        val_preds = model.predict(X_val)\n",
    "        score = hierarchical_macro_f1_score(y_val, val_preds, val_seq_ids)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "def train_and_save_model_with_optuna(X, y, sequence_ids, model_path, model_name=\"IMU\", n_trials=100):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, X, y, sequence_ids), n_trials=n_trials)\n",
    "\n",
    "    print(f\"Best trial params: {study.best_trial.params}\")\n",
    "    print(f\"Best trial score: {study.best_trial.value:.4f}\")\n",
    "\n",
    "    # En iyi parametrelerle modeli tekrar tm veride eit\n",
    "    best_params = study.best_trial.params\n",
    "    best_params[\"random_state\"] = 42\n",
    "\n",
    "    best_model = LGBMClassifier(**best_params)\n",
    "    best_model.fit(X, y)\n",
    "\n",
    "    joblib.dump(best_model, f\"{model_path}_{model_name}_{study.best_trial.value:.4f}.pkl\")\n",
    "    print(f\"En iyi model kaydedildi: Metric score = {study.best_trial.value:.4f}\")\n",
    "\n",
    "# Eitim  \n",
    "print(\"TRAINING IMU MODEL WITH OPTUNA...\")\n",
    "train_and_save_model_with_optuna(X_imu, y_imu, features_df['sequence_id'], model_path=\"model_lgbm_optuna\", model_name=\"imu\", n_trials=100)\n",
    "\n",
    "print(\"\\nTRAINING FULL MODEL WITH OPTUNA...\")\n",
    "train_and_save_model_with_optuna(X_full, y_full, features_df['sequence_id'], model_path=\"model_lgbm_optuna\", model_name=\"full\", n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ee12725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8491df6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sequence_id', 'gesture', 'subject', 'sequence_type', 'n_steps', 'max_counter', 'acc_x_mean', 'acc_x_std', 'acc_x_max', 'acc_x_min', 'acc_x_range', 'acc_x_skew', 'acc_x_kurt', 'acc_x_jerk_mean', 'acc_x_jerk_std', 'acc_x_jerk_max', 'acc_x_jerk_min', 'acc_x_energy', 'acc_y_mean', 'acc_y_std', 'acc_y_max', 'acc_y_min', 'acc_y_range', 'acc_y_skew', 'acc_y_kurt', 'acc_y_jerk_mean', 'acc_y_jerk_std', 'acc_y_jerk_max', 'acc_y_jerk_min', 'acc_y_energy', 'acc_z_mean', 'acc_z_std', 'acc_z_max', 'acc_z_min', 'acc_z_range', 'acc_z_skew', 'acc_z_kurt', 'acc_z_jerk_mean', 'acc_z_jerk_std', 'acc_z_jerk_max', 'acc_z_jerk_min', 'acc_z_energy', 'corr_acc_x_y', 'corr_acc_x_z', 'corr_acc_y_z', 'acc_z_momentum_x_range', 'roll_angle_mean', 'roll_angle_std', 'roll_angle_max', 'roll_angle_min', 'yaw_mean', 'yaw_std', 'yaw_min', 'yaw_max', 'yaw_<lambda_0>', 'pitch_mean', 'pitch_std', 'pitch_min', 'pitch_max', 'pitch_<lambda_0>', 'roll_mean', 'roll_std', 'roll_min', 'roll_max', 'roll_<lambda_0>', 'orientation_change_magnitude', 'orientation_delta_yaw', 'orientation_delta_pitch', 'orientation_delta_roll', 'max_rotation_axis_pitch', 'max_rotation_axis_roll', 'max_rotation_axis_yaw', 'yaw_var', 'pitch_var', 'roll_var', 'rot_energy_x', 'rot_energy_y', 'rot_energy_z', 'thm_1_mean', 'thm_1_std', 'thm_1_min', 'thm_1_max', 'thm_1_range', 'thm_1_delta', 'thm_1_activity', 'thm_2_mean', 'thm_2_std', 'thm_2_min', 'thm_2_max', 'thm_2_range', 'thm_2_delta', 'thm_2_activity', 'thm_3_mean', 'thm_3_std', 'thm_3_min', 'thm_3_max', 'thm_3_range', 'thm_3_delta', 'thm_3_activity', 'thm_4_mean', 'thm_4_std', 'thm_4_min', 'thm_4_max', 'thm_4_range', 'thm_4_delta', 'thm_4_activity', 'thm_5_mean', 'thm_5_std', 'thm_5_min', 'thm_5_max', 'thm_5_range', 'thm_5_delta', 'thm_5_activity', 'thm_mean_mean', 'thm_std_mean', 'thm_hotspot_index', 'thm_symmetry_side', 'thm_center_edge_diff', 'tof_1_mean', 'tof_1_std', 'tof_1_min', 'tof_1_max', 'tof_1_range', 'tof_1_valid_ratio', 'tof_1_center_mean', 'tof_1_edge_mean', 'tof_1_center_edge_ratio', 'tof_2_mean', 'tof_2_std', 'tof_2_min', 'tof_2_max', 'tof_2_range', 'tof_2_valid_ratio', 'tof_2_center_mean', 'tof_2_edge_mean', 'tof_2_center_edge_ratio', 'tof_3_mean', 'tof_3_std', 'tof_3_min', 'tof_3_max', 'tof_3_range', 'tof_3_valid_ratio', 'tof_3_center_mean', 'tof_3_edge_mean', 'tof_3_center_edge_ratio', 'tof_4_mean', 'tof_4_std', 'tof_4_min', 'tof_4_max', 'tof_4_range', 'tof_4_valid_ratio', 'tof_4_center_mean', 'tof_4_edge_mean', 'tof_4_center_edge_ratio', 'tof_5_mean', 'tof_5_std', 'tof_5_min', 'tof_5_max', 'tof_5_range', 'tof_5_valid_ratio', 'tof_5_center_mean', 'tof_5_edge_mean', 'tof_5_center_edge_ratio']\n"
     ]
    }
   ],
   "source": [
    "print(features_df.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
