{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:33.153898Z",
     "iopub.status.busy": "2025-07-04T13:28:33.153658Z",
     "iopub.status.idle": "2025-07-04T13:28:51.892980Z",
     "shell.execute_reply": "2025-07-04T13:28:51.892035Z",
     "shell.execute_reply.started": "2025-07-04T13:28:33.153878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 19:39:03.498719: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-07 19:39:03.717490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754584743.788379    5722 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754584743.808864    5722 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-08-07 19:39:03.998867: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, LayerNormalization, Activation, add, MaxPooling1D, Dropout,\n",
    "    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n",
    "    Lambda, Concatenate, GRU, GaussianNoise\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tf.sysconfig.get_build_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU count: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU count:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:51.895049Z",
     "iopub.status.busy": "2025-07-04T13:28:51.894464Z",
     "iopub.status.idle": "2025-07-04T13:28:51.900335Z",
     "shell.execute_reply": "2025-07-04T13:28:51.899463Z",
     "shell.execute_reply.started": "2025-07-04T13:28:51.895023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "state = 1\n",
    "import random\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.experimental.numpy.random.seed(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "seed_everything(seed=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:51.901740Z",
     "iopub.status.busy": "2025-07-04T13:28:51.901434Z",
     "iopub.status.idle": "2025-07-04T13:28:51.938388Z",
     "shell.execute_reply": "2025-07-04T13:28:51.937661Z",
     "shell.execute_reply.started": "2025-07-04T13:28:51.901713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · tensorflow 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# (Competition metric will only be imported when TRAINing)\n",
    "TRAIN = True                \n",
    "DEBUG_GATE = False  \n",
    "                     \n",
    "RAW_DIR = Path(\"\")\n",
    "PRETRAINED_DIR = Path(\"new_model_10_fold\")\n",
    "EXPORT_DIR = Path(\"transformer_imu_only_5folds\")\n",
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 95 \n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "MIXUP_ALPHA = 0.4 \n",
    "EPOCHS = 160\n",
    "PATIENCE = 40\n",
    "N_SPLITS = 5\n",
    "MASKING_PROB = 0.25\n",
    "GATE_LOSS_WEIGHT = 0.20 # 0.20 \n",
    "\n",
    "print(\"▶ imports ready · tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:51.939603Z",
     "iopub.status.busy": "2025-07-04T13:28:51.939338Z",
     "iopub.status.idle": "2025-07-04T13:28:51.959963Z",
     "shell.execute_reply": "2025-07-04T13:28:51.959030Z",
     "shell.execute_reply.started": "2025-07-04T13:28:51.939575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "    acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "    for i in range(len(acc_values)):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :]\n",
    "            continue\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200):\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    angular_vel = np.zeros((len(quat_values), 3))\n",
    "    for i in range(len(quat_values) - 1):\n",
    "        q_t, q_t_plus_dt = quat_values[i], quat_values[i+1]\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isnan(q_t_plus_dt)): continue\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError: pass\n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    angular_dist = np.zeros(len(quat_values))\n",
    "    for i in range(len(quat_values) - 1):\n",
    "        q1, q2 = quat_values[i], quat_values[i+1]\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isnan(q2)): continue\n",
    "        try:\n",
    "            r1, r2 = R.from_quat(q1), R.from_quat(q2)\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            angular_dist[i] = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "        except ValueError: pass\n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:51.961299Z",
     "iopub.status.busy": "2025-07-04T13:28:51.960998Z",
     "iopub.status.idle": "2025-07-04T13:28:51.986618Z",
     "shell.execute_reply": "2025-07-04T13:28:51.985673Z",
     "shell.execute_reply.started": "2025-07-04T13:28:51.961260Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tensor Manipulations\n",
    "def time_sum(x): return K.sum(x, axis=1)\n",
    "def squeeze_last_axis(x): return tf.squeeze(x, axis=-1)\n",
    "def expand_last_axis(x): return tf.expand_dims(x, axis=-1)\n",
    "\n",
    "def se_block(x, reduction=8):\n",
    "    ch = x.shape[-1]\n",
    "    se = GlobalAveragePooling1D()(x)\n",
    "    se = Dense(ch // reduction, activation='relu')(se)\n",
    "    se = Dense(ch, activation='sigmoid')(se)\n",
    "    se = Reshape((1, ch))(se)\n",
    "    return Multiply()([x, se])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T07:56:04.785466Z",
     "iopub.status.busy": "2025-07-04T07:56:04.784809Z",
     "iopub.status.idle": "2025-07-04T07:56:04.803532Z",
     "shell.execute_reply": "2025-07-04T07:56:04.802817Z",
     "shell.execute_reply.started": "2025-07-04T07:56:04.785437Z"
    }
   },
   "outputs": [],
   "source": [
    "class GatedMixupGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size, class_weight=None, alpha=0.2):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch = batch_size\n",
    "        self.class_weight = class_weight\n",
    "        self.alpha = alpha\n",
    "        self.indices = np.arange(len(X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i*self.batch:(i+1)*self.batch]\n",
    "        Xb, yb = self.X[idx].copy(), self.y[idx].copy()\n",
    "        \n",
    "        sample_weights = np.ones(len(Xb), dtype='float32')\n",
    "        if self.class_weight:\n",
    "            y_integers = yb.argmax(axis=1)\n",
    "            sample_weights = np.array([self.class_weight[i] for i in y_integers])\n",
    "        \n",
    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            perm = np.random.permutation(len(Xb))\n",
    "            X_mix = lam * Xb + (1 - lam) * Xb[perm]\n",
    "            y_mix = lam * yb + (1 - lam) * yb[perm]\n",
    "            sample_weights_mix = lam * sample_weights + (1 - lam) * sample_weights[perm]\n",
    "            return X_mix, y_mix, sample_weights_mix\n",
    "\n",
    "        return Xb, yb, sample_weights\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:52.013491Z",
     "iopub.status.busy": "2025-07-04T13:28:52.013231Z",
     "iopub.status.idle": "2025-07-04T13:28:52.034252Z",
     "shell.execute_reply": "2025-07-04T13:28:52.033394Z",
     "shell.execute_reply.started": "2025-07-04T13:28:52.013470Z"
    },
    "trusted": true
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Utility functions and custom layers should be defined or imported here\n",
    "# (As provided in your previous prompts)\n",
    "\n",
    "def residual_se_cnn_block(x, filters, kernel_size, drop, wd):\n",
    "    y = Conv1D(filters, kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "    y = Dropout(drop)(y)\n",
    "    y = Conv1D(filters, kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(wd))(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    # Eğer input channels ile filters farklıysa 1x1 Conv ile eşleştir\n",
    "    if x.shape[-1] != filters:\n",
    "        x = Conv1D(filters, 1, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "    return Activation('relu')(Add()([x, y]))\n",
    "\n",
    "class TransformerEncoderBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.25, wd=1e-3, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.rate = rate\n",
    "        self.wd = wd\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads)\n",
    "        self.ffn = tf.keras.Sequential(\n",
    "            [Dense(ff_dim, activation=\"relu\", kernel_regularizer=l2(wd)),\n",
    "             Dense(embed_dim, kernel_regularizer=l2(wd)),]\n",
    "        )\n",
    "        # LayerNormalization, BatchNormalization'dan daha yaygın Transformer'larda\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(inputs + attn_output) # Add & Norm\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        return self.norm2(out1 + ffn_output) # Add & Norm\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"ff_dim\": self.ff_dim,\n",
    "            \"rate\": self.rate,\n",
    "            \"wd\": self.wd,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "class PositionalEmbedding(Layer):\n",
    "    def __init__(self, sequence_length, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.output_dim = output_dim\n",
    "        self.position_embeddings = Embedding(input_dim=sequence_length, output_dim=output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        return inputs + self.position_embeddings(positions)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"output_dim\": self.output_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "def build_imu_only_transformer_model(pad_len, imu_dim, n_classes, wd=5e-4): # wd slightly increased\n",
    "    inp = Input(shape=(pad_len, imu_dim), name='imu_input')\n",
    "\n",
    "    # --- IMU Feature Extraction Branch (Daha Derin) ---\n",
    "    x = residual_se_cnn_block(inp, 64, 3, drop=0.2, wd=wd) \n",
    "    x = residual_se_cnn_block(x, 128, 5, drop=0.25, wd=wd) \n",
    "    x = residual_se_cnn_block(x, 256, 7, drop=0.3, wd=wd) \n",
    "    x = residual_se_cnn_block(x, 256, 3, drop=0.3, wd=wd) # Ek bir residual block\n",
    "    \n",
    "    x = MaxPooling1D(2, name='imu_pool_1')(x)\n",
    "    x = Dropout(0.35)(x) # Dropout artırıldı\n",
    "\n",
    "    x = Conv1D(384, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x) # Filtre sayısı artırıldı\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(2, name='imu_pool_2')(x)\n",
    "    x = Dropout(0.4)(x) # Dropout artırıldı\n",
    "\n",
    "    # Gerekirse bir Conv1D daha eklenebilir\n",
    "    x = Conv1D(512, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # --- Transformer Encoder Stack (Daha Güçlü) ---\n",
    "    current_timesteps = K.int_shape(x)[1]\n",
    "    embed_dim = K.int_shape(x)[-1] # Burası 512 olmalı\n",
    "\n",
    "    x = PositionalEmbedding(current_timesteps, embed_dim)(x)\n",
    "    \n",
    "    # Daha fazla Transformer Encoder bloğu ve artırılmış kapasite\n",
    "    x = TransformerEncoderBlock(embed_dim=embed_dim, num_heads=12, ff_dim=1024, rate=0.35, wd=wd, name='imu_transformer_1')(x)\n",
    "    x = TransformerEncoderBlock(embed_dim=embed_dim, num_heads=12, ff_dim=1024, rate=0.4, wd=wd, name='imu_transformer_2')(x)\n",
    "    x = TransformerEncoderBlock(embed_dim=embed_dim, num_heads=12, ff_dim=1024, rate=0.45, wd=wd, name='imu_transformer_3')(x) # Üçüncü Transformer\n",
    "    x = TransformerEncoderBlock(embed_dim=embed_dim, num_heads=12, ff_dim=1024, rate=0.45, wd=wd, name='imu_transformer_4')(x) # Dördüncü Transformer\n",
    "\n",
    "    # --- Global Context and Classification (Çift Pooling) ---\n",
    "    # Hem GlobalAveragePooling hem de GlobalMaxPooling kullanarak daha zengin bir temsil\n",
    "    avg_pool = GlobalAveragePooling1D(name='global_avg_pooling')(x)\n",
    "    max_pool = GlobalMaxPooling1D(name='global_max_pooling')(x)\n",
    "    x = Concatenate(name='combined_pooling')([avg_pool, max_pool]) # İki pooling çıktısı birleştirilir\n",
    "\n",
    "    # --- Dense Layers for Classification (Agresif Dropout) ---\n",
    "    # Özellik vektörünün boyutu 2 * embed_dim oldu (örn: 2 * 512 = 1024)\n",
    "    x = Dense(512, use_bias=False, kernel_regularizer=l2(wd))(x) # İlk Dense katmanı artırıldı\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.5)(x) # Daha yüksek dropout\n",
    "\n",
    "    x = Dense(256, use_bias=False, kernel_regularizer=l2(wd))(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(0.45)(x) # Dropout ayarı\n",
    "\n",
    "    main_output = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=main_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def squeeze_last_axis(x):\n",
    "    return tf.squeeze(x, axis=-1)\n",
    "\n",
    "def expand_last_axis(x):\n",
    "    return tf.expand_dims(x, axis=-1)\n",
    "\n",
    "def attention_block(inputs):\n",
    "    score = Dense(1, activation='tanh')(inputs)\n",
    "    score = Lambda(squeeze_last_axis)(score)\n",
    "    weights = Activation('softmax')(score)\n",
    "    weights = Lambda(expand_last_axis)(weights)\n",
    "    weighted = Multiply()([inputs, weights])\n",
    "    return Lambda(lambda x: K.sum(x, axis=1))(weighted)\n",
    "\n",
    "class SEBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, reduction_ratio=8, **kwargs):\n",
    "        super(SEBlock, self).__init__(**kwargs)\n",
    "        self.reduction_ratio = reduction_ratio\n",
    "        \n",
    "        # Katmanları burada tanımlayın\n",
    "        self.avg_pool = GlobalAveragePooling1D()\n",
    "        self.dense1 = Dense(None, activation='relu') # output_shape, call içinde belirlenecek\n",
    "        self.dense2 = Dense(None, activation='sigmoid') # output_shape, call içinde belirlenecek\n",
    "        self.reshape = Reshape((1, None))\n",
    "        self.multiply = Multiply()\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        channel = input_shape[-1]\n",
    "        # Katmanların output_shape'ini build metodunda belirleyin\n",
    "        self.dense1.units = channel // self.reduction_ratio\n",
    "        self.dense2.units = channel\n",
    "        self.reshape.target_shape = (1, channel)\n",
    "        super(SEBlock, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        se = self.avg_pool(inputs)\n",
    "        se = self.dense1(se)\n",
    "        se = self.dense2(se)\n",
    "        se = self.reshape(se)\n",
    "        return self.multiply([inputs, se])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(SEBlock, self).get_config()\n",
    "        config.update({\"reduction_ratio\": self.reduction_ratio})\n",
    "        return config\n",
    "\n",
    "class TransformerBlock(Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.25, wd=1e-3):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"gelu\", kernel_regularizer=l2(wd)),\n",
    "            Dense(embed_dim, kernel_regularizer=l2(wd)),\n",
    "        ])\n",
    "        self.norm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.norm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        out1 = self.norm1(inputs + self.dropout1(attn_output, training=training))\n",
    "        ffn_output = self.ffn(out1)\n",
    "        return self.norm2(out1 + self.dropout2(ffn_output, training=training))\n",
    "\n",
    "def build_competition_ready_transformer(pad_len, imu_dim, n_classes, wd=2e-3):\n",
    "    inp = Input(shape=(pad_len, imu_dim), name=\"imu_input\")\n",
    "\n",
    "    # --- BiGRU + Residual LSTM ---\n",
    "    x = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(inp)\n",
    "    lstm = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(x)\n",
    "    x = Add()([x, lstm])\n",
    "    x = SEBlock()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # --- Transformer Katmanları ---\n",
    "    for rate in [0.25, 0.3]:\n",
    "        x = TransformerBlock(embed_dim=256, num_heads=4, ff_dim=384, rate=rate, wd=wd)(x)\n",
    "\n",
    "    # --- Attention ve Pooling ---\n",
    "    attn = attention_block(x)\n",
    "    avg_pool = GlobalAveragePooling1D()(x)\n",
    "    max_pool = GlobalMaxPooling1D()(x)\n",
    "    x = Concatenate()([attn, avg_pool, max_pool])\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # --- Final Dense Katmanlar ---\n",
    "    x = Dense(512, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.45)(x)\n",
    "\n",
    "    x = Dense(256, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax', name=\"main_output\", kernel_regularizer=l2(wd))(x)\n",
    "    return Model(inputs=inp, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:52.036653Z",
     "iopub.status.busy": "2025-07-04T13:28:52.036359Z",
     "iopub.status.idle": "2025-07-04T13:28:52.058098Z",
     "shell.execute_reply": "2025-07-04T13:28:52.057140Z",
     "shell.execute_reply.started": "2025-07-04T13:28:52.036628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import sobel\n",
    "\n",
    "# ToF için spatial gradyan (sobel) temelli özellikler\n",
    "def calculate_spatial_tof_features(seq_df, sensor_id):\n",
    "    # 1D 64-pikseli 8x8'e reshape edip sobel gradyanı alacağız\n",
    "    pixel_cols = [f\"tof_{sensor_id}_v{p}\" for p in range(64)]\n",
    "    tof_data = seq_df[pixel_cols].replace(-1, np.nan).ffill().bfill().fillna(0).values\n",
    "    \n",
    "    # Frame sayısı x 64 → (N x 8 x 8)\n",
    "    N = len(seq_df)\n",
    "    reshaped = tof_data.reshape(N, 8, 8)\n",
    "    \n",
    "    # Spatial gradyanları hesapla (sobel x ve y)\n",
    "    sobel_x = sobel(reshaped, axis=1)\n",
    "    sobel_y = sobel(reshaped, axis=2)\n",
    "    grad_mag = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "\n",
    "    # Özet istatistikleri hesapla\n",
    "    grad_mean = grad_mag.mean(axis=(1, 2))\n",
    "    grad_std  = grad_mag.std(axis=(1, 2))\n",
    "    grad_max  = grad_mag.max(axis=(1, 2))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        f'tof_{sensor_id}_grad_mean': grad_mean,\n",
    "        f'tof_{sensor_id}_grad_std': grad_std,\n",
    "        f'tof_{sensor_id}_grad_max': grad_max\n",
    "    }, index=seq_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T14:37:28.597398Z",
     "iopub.status.busy": "2025-07-04T14:37:28.597100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset ...\n",
      "acc_y ortalaması negatif olan subject'ler: ['SUBJ_019262', 'SUBJ_045235']\n",
      "  Removing gravity and calculating linear acceleration features...\n",
      "  Calculating angular velocity and distance from quaternions...\n",
      "  IMU (phys-based + enhanced) 31 | THM + Aggregated TOF 40 | total 31 features\n",
      "  Building sequences...\n",
      "  Fitting StandardScaler...\n",
      "  Scaling and padding sequences...\n",
      "  Starting training with Stratified Group K-Fold CV...\n",
      "\n",
      "===== FOLD 1/5 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754584889.083112    5722 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1754584895.899342    6322 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 87ms/step - accuracy: 0.1066 - loss: 8.9270 - val_accuracy: 0.2812 - val_loss: 7.2245 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.2161 - loss: 7.2885 - val_accuracy: 0.3415 - val_loss: 6.3368 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.2707 - loss: 6.3137 - val_accuracy: 0.3877 - val_loss: 5.5803 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.3300 - loss: 5.6232 - val_accuracy: 0.4240 - val_loss: 5.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.3596 - loss: 5.0067 - val_accuracy: 0.4437 - val_loss: 4.5907 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.3850 - loss: 4.6067 - val_accuracy: 0.4289 - val_loss: 4.1495 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4127 - loss: 4.1361 - val_accuracy: 0.4277 - val_loss: 3.8840 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4005 - loss: 3.8244 - val_accuracy: 0.4665 - val_loss: 3.5076 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4236 - loss: 3.5331 - val_accuracy: 0.4603 - val_loss: 3.3151 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4688 - loss: 3.1900 - val_accuracy: 0.4942 - val_loss: 3.0105 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4795 - loss: 3.0492 - val_accuracy: 0.4751 - val_loss: 2.8951 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.4721 - loss: 2.9638 - val_accuracy: 0.4726 - val_loss: 2.7917 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4823 - loss: 2.7903 - val_accuracy: 0.4585 - val_loss: 2.7761 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4974 - loss: 2.5340 - val_accuracy: 0.4837 - val_loss: 2.5306 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.4990 - loss: 2.5269 - val_accuracy: 0.5194 - val_loss: 2.3324 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5280 - loss: 2.3938 - val_accuracy: 0.5089 - val_loss: 2.3384 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5085 - loss: 2.3406 - val_accuracy: 0.5028 - val_loss: 2.3430 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5217 - loss: 2.2626 - val_accuracy: 0.5077 - val_loss: 2.2404 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5458 - loss: 2.1598 - val_accuracy: 0.5071 - val_loss: 2.1994 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5143 - loss: 2.2627 - val_accuracy: 0.5120 - val_loss: 2.1860 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5685 - loss: 2.0167 - val_accuracy: 0.5058 - val_loss: 2.1813 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5599 - loss: 2.0546 - val_accuracy: 0.5415 - val_loss: 2.0494 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5647 - loss: 2.0433 - val_accuracy: 0.5378 - val_loss: 2.0719 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5565 - loss: 2.1305 - val_accuracy: 0.5212 - val_loss: 2.0161 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5679 - loss: 2.0226 - val_accuracy: 0.5182 - val_loss: 2.0748 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5362 - loss: 2.0896 - val_accuracy: 0.5286 - val_loss: 2.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5795 - loss: 1.9760 - val_accuracy: 0.5489 - val_loss: 1.9428 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5884 - loss: 1.9615 - val_accuracy: 0.5446 - val_loss: 1.9916 - learning_rate: 5.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5669 - loss: 2.0401 - val_accuracy: 0.5292 - val_loss: 1.9995 - learning_rate: 5.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5884 - loss: 1.9581 - val_accuracy: 0.5428 - val_loss: 1.9812 - learning_rate: 5.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5661 - loss: 2.0295 - val_accuracy: 0.5378 - val_loss: 2.0476 - learning_rate: 5.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5916 - loss: 1.9092 - val_accuracy: 0.5526 - val_loss: 1.9466 - learning_rate: 5.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5763 - loss: 1.9573 - val_accuracy: 0.5317 - val_loss: 1.9792 - learning_rate: 5.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6075 - loss: 1.8706 - val_accuracy: 0.5434 - val_loss: 1.9727 - learning_rate: 5.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6051 - loss: 1.8877 - val_accuracy: 0.5138 - val_loss: 2.1337 - learning_rate: 5.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5942 - loss: 1.8886 - val_accuracy: 0.5557 - val_loss: 1.9005 - learning_rate: 5.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6366 - loss: 1.7600 - val_accuracy: 0.5409 - val_loss: 1.9182 - learning_rate: 5.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6349 - loss: 1.8043 - val_accuracy: 0.5538 - val_loss: 1.9001 - learning_rate: 5.0000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6270 - loss: 1.8084 - val_accuracy: 0.5729 - val_loss: 1.9080 - learning_rate: 5.0000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6248 - loss: 1.8294 - val_accuracy: 0.5502 - val_loss: 1.9081 - learning_rate: 5.0000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6358 - loss: 1.7681 - val_accuracy: 0.5655 - val_loss: 1.8948 - learning_rate: 5.0000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6249 - loss: 1.8383 - val_accuracy: 0.5311 - val_loss: 1.9902 - learning_rate: 5.0000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6441 - loss: 1.7640 - val_accuracy: 0.5563 - val_loss: 1.9178 - learning_rate: 5.0000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6246 - loss: 1.8322 - val_accuracy: 0.5360 - val_loss: 1.9981 - learning_rate: 5.0000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6193 - loss: 1.8310 - val_accuracy: 0.5477 - val_loss: 2.0300 - learning_rate: 5.0000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6345 - loss: 1.8077 - val_accuracy: 0.5760 - val_loss: 1.8194 - learning_rate: 5.0000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6676 - loss: 1.7318 - val_accuracy: 0.5532 - val_loss: 1.9837 - learning_rate: 5.0000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6485 - loss: 1.7903 - val_accuracy: 0.5545 - val_loss: 1.9749 - learning_rate: 5.0000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6478 - loss: 1.8433 - val_accuracy: 0.5477 - val_loss: 1.9339 - learning_rate: 5.0000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6538 - loss: 1.8285 - val_accuracy: 0.5194 - val_loss: 2.0994 - learning_rate: 5.0000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6463 - loss: 1.7850 - val_accuracy: 0.5612 - val_loss: 1.9645 - learning_rate: 5.0000e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6450 - loss: 1.8276 - val_accuracy: 0.5557 - val_loss: 1.9877 - learning_rate: 5.0000e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6583 - loss: 1.7504 - val_accuracy: 0.5545 - val_loss: 1.9204 - learning_rate: 5.0000e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6404 - loss: 1.8414\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6405 - loss: 1.8411 - val_accuracy: 0.5742 - val_loss: 1.9450 - learning_rate: 5.0000e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6623 - loss: 1.8023 - val_accuracy: 0.5735 - val_loss: 1.9020 - learning_rate: 2.5000e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6595 - loss: 1.7364 - val_accuracy: 0.5908 - val_loss: 1.8579 - learning_rate: 2.5000e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6689 - loss: 1.7447 - val_accuracy: 0.5766 - val_loss: 1.8856 - learning_rate: 2.5000e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6993 - loss: 1.7250 - val_accuracy: 0.5809 - val_loss: 1.8831 - learning_rate: 2.5000e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7228 - loss: 1.6286 - val_accuracy: 0.6012 - val_loss: 1.7817 - learning_rate: 2.5000e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6919 - loss: 1.7183 - val_accuracy: 0.5711 - val_loss: 1.8873 - learning_rate: 2.5000e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7353 - loss: 1.5283 - val_accuracy: 0.6055 - val_loss: 1.8022 - learning_rate: 2.5000e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7315 - loss: 1.5916 - val_accuracy: 0.5828 - val_loss: 1.9142 - learning_rate: 2.5000e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6862 - loss: 1.7296 - val_accuracy: 0.5908 - val_loss: 1.8719 - learning_rate: 2.5000e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7230 - loss: 1.5892 - val_accuracy: 0.5354 - val_loss: 1.9931 - learning_rate: 2.5000e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6737 - loss: 1.7512 - val_accuracy: 0.5809 - val_loss: 1.9058 - learning_rate: 2.5000e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7301 - loss: 1.6377 - val_accuracy: 0.5698 - val_loss: 1.8426 - learning_rate: 2.5000e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7090 - loss: 1.6777 - val_accuracy: 0.5582 - val_loss: 1.9163 - learning_rate: 2.5000e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6993 - loss: 1.7100 - val_accuracy: 0.5766 - val_loss: 1.8807 - learning_rate: 2.5000e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6930 - loss: 1.7031\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6931 - loss: 1.7028 - val_accuracy: 0.5865 - val_loss: 1.8581 - learning_rate: 2.5000e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7154 - loss: 1.6200 - val_accuracy: 0.5975 - val_loss: 1.7983 - learning_rate: 1.2500e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7363 - loss: 1.6503 - val_accuracy: 0.5963 - val_loss: 1.8803 - learning_rate: 1.2500e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7580 - loss: 1.5564 - val_accuracy: 0.5809 - val_loss: 1.8672 - learning_rate: 1.2500e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7346 - loss: 1.5951 - val_accuracy: 0.6240 - val_loss: 1.7855 - learning_rate: 1.2500e-04\n",
      "Epoch 74/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7748 - loss: 1.4839 - val_accuracy: 0.5889 - val_loss: 1.8435 - learning_rate: 1.2500e-04\n",
      "Epoch 75/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8025 - loss: 1.3834 - val_accuracy: 0.5865 - val_loss: 1.8509 - learning_rate: 1.2500e-04\n",
      "Epoch 76/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7615 - loss: 1.5431 - val_accuracy: 0.5908 - val_loss: 1.8572 - learning_rate: 1.2500e-04\n",
      "Epoch 77/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7647 - loss: 1.5862 - val_accuracy: 0.5982 - val_loss: 1.8081 - learning_rate: 1.2500e-04\n",
      "Epoch 78/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7717 - loss: 1.4984 - val_accuracy: 0.6000 - val_loss: 1.7788 - learning_rate: 1.2500e-04\n",
      "Epoch 79/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7980 - loss: 1.4200 - val_accuracy: 0.5840 - val_loss: 1.8550 - learning_rate: 1.2500e-04\n",
      "Epoch 80/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7579 - loss: 1.5768 - val_accuracy: 0.6006 - val_loss: 1.7593 - learning_rate: 1.2500e-04\n",
      "Epoch 81/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7802 - loss: 1.5076\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7801 - loss: 1.5076 - val_accuracy: 0.5889 - val_loss: 1.8413 - learning_rate: 1.2500e-04\n",
      "Epoch 82/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7794 - loss: 1.4691 - val_accuracy: 0.6123 - val_loss: 1.7442 - learning_rate: 6.2500e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7400 - loss: 1.6130 - val_accuracy: 0.6092 - val_loss: 1.7451 - learning_rate: 6.2500e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8029 - loss: 1.4445 - val_accuracy: 0.6049 - val_loss: 1.7806 - learning_rate: 6.2500e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7741 - loss: 1.5288 - val_accuracy: 0.5797 - val_loss: 1.9313 - learning_rate: 6.2500e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8077 - loss: 1.3860 - val_accuracy: 0.5926 - val_loss: 1.8490 - learning_rate: 6.2500e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7733 - loss: 1.5246 - val_accuracy: 0.5945 - val_loss: 1.8669 - learning_rate: 6.2500e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7706 - loss: 1.5230 - val_accuracy: 0.6203 - val_loss: 1.7789 - learning_rate: 6.2500e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7720 - loss: 1.4666 - val_accuracy: 0.5945 - val_loss: 1.8887 - learning_rate: 6.2500e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8008 - loss: 1.5004\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8007 - loss: 1.5004 - val_accuracy: 0.6037 - val_loss: 1.8161 - learning_rate: 6.2500e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7742 - loss: 1.5623 - val_accuracy: 0.5852 - val_loss: 1.8144 - learning_rate: 3.1250e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8288 - loss: 1.4226 - val_accuracy: 0.5945 - val_loss: 1.8564 - learning_rate: 3.1250e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7835 - loss: 1.5200 - val_accuracy: 0.5994 - val_loss: 1.7967 - learning_rate: 3.1250e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7875 - loss: 1.5246 - val_accuracy: 0.6111 - val_loss: 1.7608 - learning_rate: 3.1250e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7737 - loss: 1.5466 - val_accuracy: 0.6166 - val_loss: 1.7728 - learning_rate: 3.1250e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8224 - loss: 1.3816 - val_accuracy: 0.6031 - val_loss: 1.8399 - learning_rate: 3.1250e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8148 - loss: 1.3957 - val_accuracy: 0.5742 - val_loss: 1.8619 - learning_rate: 3.1250e-05\n",
      "Epoch 98/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7796 - loss: 1.5014 - val_accuracy: 0.5969 - val_loss: 1.8212 - learning_rate: 3.1250e-05\n",
      "Epoch 99/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7797 - loss: 1.5279\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7797 - loss: 1.5276 - val_accuracy: 0.6062 - val_loss: 1.7769 - learning_rate: 3.1250e-05\n",
      "Epoch 100/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8142 - loss: 1.4196 - val_accuracy: 0.6240 - val_loss: 1.7278 - learning_rate: 1.5625e-05\n",
      "Epoch 101/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8140 - loss: 1.4450 - val_accuracy: 0.6025 - val_loss: 1.8118 - learning_rate: 1.5625e-05\n",
      "Epoch 102/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8016 - loss: 1.4931 - val_accuracy: 0.6277 - val_loss: 1.7493 - learning_rate: 1.5625e-05\n",
      "Epoch 103/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7805 - loss: 1.5122 - val_accuracy: 0.6018 - val_loss: 1.8437 - learning_rate: 1.5625e-05\n",
      "Epoch 104/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7677 - loss: 1.5304 - val_accuracy: 0.5797 - val_loss: 1.8412 - learning_rate: 1.5625e-05\n",
      "Epoch 105/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7695 - loss: 1.5676 - val_accuracy: 0.5828 - val_loss: 1.8578 - learning_rate: 1.5625e-05\n",
      "Epoch 106/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7540 - loss: 1.5397 - val_accuracy: 0.6074 - val_loss: 1.8245 - learning_rate: 1.5625e-05\n",
      "Epoch 107/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8087 - loss: 1.4346 - val_accuracy: 0.5975 - val_loss: 1.7994 - learning_rate: 1.5625e-05\n",
      "Epoch 108/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8012 - loss: 1.4499 - val_accuracy: 0.5815 - val_loss: 1.9126 - learning_rate: 1.5625e-05\n",
      "Epoch 109/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7769 - loss: 1.4819 - val_accuracy: 0.6018 - val_loss: 1.8546 - learning_rate: 1.5625e-05\n",
      "Epoch 110/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8160 - loss: 1.4579\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8159 - loss: 1.4580 - val_accuracy: 0.6240 - val_loss: 1.7257 - learning_rate: 1.5625e-05\n",
      "Epoch 111/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7798 - loss: 1.5965 - val_accuracy: 0.5926 - val_loss: 1.8463 - learning_rate: 7.8125e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7655 - loss: 1.5257 - val_accuracy: 0.5926 - val_loss: 1.8469 - learning_rate: 7.8125e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7911 - loss: 1.4931 - val_accuracy: 0.6006 - val_loss: 1.8169 - learning_rate: 7.8125e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8409 - loss: 1.3415 - val_accuracy: 0.6049 - val_loss: 1.8228 - learning_rate: 7.8125e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8057 - loss: 1.3872 - val_accuracy: 0.6025 - val_loss: 1.8257 - learning_rate: 7.8125e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8034 - loss: 1.4922 - val_accuracy: 0.6166 - val_loss: 1.7663 - learning_rate: 7.8125e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8389 - loss: 1.3088 - val_accuracy: 0.6049 - val_loss: 1.7837 - learning_rate: 7.8125e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.8085 - loss: 1.4343 - val_accuracy: 0.6117 - val_loss: 1.8127 - learning_rate: 7.8125e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8190 - loss: 1.3885\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8188 - loss: 1.3891 - val_accuracy: 0.5914 - val_loss: 1.8609 - learning_rate: 7.8125e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7919 - loss: 1.6062 - val_accuracy: 0.6049 - val_loss: 1.8311 - learning_rate: 3.9063e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8068 - loss: 1.4543 - val_accuracy: 0.6043 - val_loss: 1.7733 - learning_rate: 3.9063e-06\n",
      "Epoch 122/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7837 - loss: 1.5227 - val_accuracy: 0.6277 - val_loss: 1.7844 - learning_rate: 3.9063e-06\n",
      "Epoch 123/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7756 - loss: 1.5683 - val_accuracy: 0.6031 - val_loss: 1.8501 - learning_rate: 3.9063e-06\n",
      "Epoch 124/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8119 - loss: 1.4696 - val_accuracy: 0.6031 - val_loss: 1.8562 - learning_rate: 3.9063e-06\n",
      "Epoch 125/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8170 - loss: 1.4140 - val_accuracy: 0.5969 - val_loss: 1.8688 - learning_rate: 3.9063e-06\n",
      "Epoch 126/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8089 - loss: 1.4695 - val_accuracy: 0.6123 - val_loss: 1.8164 - learning_rate: 3.9063e-06\n",
      "Epoch 127/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7864 - loss: 1.5039 - val_accuracy: 0.6111 - val_loss: 1.7754 - learning_rate: 3.9063e-06\n",
      "Epoch 128/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7695 - loss: 1.5457\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7694 - loss: 1.5459 - val_accuracy: 0.6055 - val_loss: 1.7886 - learning_rate: 3.9063e-06\n",
      "Epoch 129/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7824 - loss: 1.4924 - val_accuracy: 0.6055 - val_loss: 1.8516 - learning_rate: 3.0000e-06\n",
      "Epoch 130/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.7632 - loss: 1.5738 - val_accuracy: 0.6012 - val_loss: 1.8091 - learning_rate: 3.0000e-06\n",
      "Epoch 131/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.7920 - loss: 1.4772 - val_accuracy: 0.6043 - val_loss: 1.8407 - learning_rate: 3.0000e-06\n",
      "Epoch 132/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7911 - loss: 1.4504 - val_accuracy: 0.6012 - val_loss: 1.8168 - learning_rate: 3.0000e-06\n",
      "Epoch 133/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.7938 - loss: 1.4856 - val_accuracy: 0.5865 - val_loss: 1.9190 - learning_rate: 3.0000e-06\n",
      "Epoch 134/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - accuracy: 0.8344 - loss: 1.3976 - val_accuracy: 0.6160 - val_loss: 1.8118 - learning_rate: 3.0000e-06\n",
      "Epoch 135/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7982 - loss: 1.4707 - val_accuracy: 0.6086 - val_loss: 1.8036 - learning_rate: 3.0000e-06\n",
      "Epoch 136/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8346 - loss: 1.3157 - val_accuracy: 0.5846 - val_loss: 1.8871 - learning_rate: 3.0000e-06\n",
      "Epoch 137/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7501 - loss: 1.6670 - val_accuracy: 0.6191 - val_loss: 1.7553 - learning_rate: 3.0000e-06\n",
      "Epoch 138/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8024 - loss: 1.4848 - val_accuracy: 0.6129 - val_loss: 1.7780 - learning_rate: 3.0000e-06\n",
      "Epoch 139/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.8075 - loss: 1.4608 - val_accuracy: 0.5902 - val_loss: 1.8341 - learning_rate: 3.0000e-06\n",
      "Epoch 140/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8236 - loss: 1.3500 - val_accuracy: 0.5692 - val_loss: 1.8838 - learning_rate: 3.0000e-06\n",
      "Epoch 141/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8148 - loss: 1.4425 - val_accuracy: 0.5877 - val_loss: 1.8603 - learning_rate: 3.0000e-06\n",
      "Epoch 142/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7778 - loss: 1.5145 - val_accuracy: 0.5988 - val_loss: 1.8363 - learning_rate: 3.0000e-06\n",
      "Epoch 142: early stopping\n",
      "Restoring model weights from the end of the best epoch: 102.\n",
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_0/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_0/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi: transformer_imu_only_5folds/gesture_model_fold_0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 20:03:00.585778: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\n",
      "===== FOLD 2/5 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 97ms/step - accuracy: 0.0968 - loss: 8.9341 - val_accuracy: 0.2745 - val_loss: 7.3079 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.2086 - loss: 7.2832 - val_accuracy: 0.2990 - val_loss: 6.5007 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.2561 - loss: 6.3680 - val_accuracy: 0.4093 - val_loss: 5.6829 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.3067 - loss: 5.7113 - val_accuracy: 0.3952 - val_loss: 5.1024 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.3478 - loss: 5.1164 - val_accuracy: 0.4430 - val_loss: 4.6606 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.3972 - loss: 4.5430 - val_accuracy: 0.4350 - val_loss: 4.2495 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.4161 - loss: 4.2759 - val_accuracy: 0.4277 - val_loss: 3.9306 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.4306 - loss: 3.8061 - val_accuracy: 0.4596 - val_loss: 3.5426 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.4627 - loss: 3.4885 - val_accuracy: 0.4455 - val_loss: 3.3539 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.4441 - loss: 3.2597 - val_accuracy: 0.4498 - val_loss: 3.1882 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.4544 - loss: 3.1562 - val_accuracy: 0.4675 - val_loss: 2.9584 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.4998 - loss: 2.8058 - val_accuracy: 0.4896 - val_loss: 2.7879 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.4906 - loss: 2.7191 - val_accuracy: 0.4810 - val_loss: 2.6737 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.4792 - loss: 2.6950 - val_accuracy: 0.4798 - val_loss: 2.6465 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.4953 - loss: 2.6427 - val_accuracy: 0.5037 - val_loss: 2.4070 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.5178 - loss: 2.4275 - val_accuracy: 0.5055 - val_loss: 2.3531 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5133 - loss: 2.4325 - val_accuracy: 0.4939 - val_loss: 2.4017 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.5283 - loss: 2.3043 - val_accuracy: 0.5208 - val_loss: 2.2893 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5493 - loss: 2.2326 - val_accuracy: 0.5012 - val_loss: 2.2595 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5332 - loss: 2.2235 - val_accuracy: 0.4908 - val_loss: 2.2481 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5389 - loss: 2.1561 - val_accuracy: 0.5178 - val_loss: 2.2290 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.5588 - loss: 2.1569 - val_accuracy: 0.5472 - val_loss: 2.0771 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.5379 - loss: 2.1551 - val_accuracy: 0.5221 - val_loss: 2.0965 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.5716 - loss: 2.0196 - val_accuracy: 0.5270 - val_loss: 2.0890 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.5747 - loss: 2.0104 - val_accuracy: 0.5398 - val_loss: 2.0075 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5761 - loss: 2.0726 - val_accuracy: 0.5208 - val_loss: 2.0493 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5890 - loss: 1.9613 - val_accuracy: 0.5325 - val_loss: 2.0298 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5987 - loss: 1.9582 - val_accuracy: 0.5398 - val_loss: 2.0231 - learning_rate: 5.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5863 - loss: 1.9186 - val_accuracy: 0.5729 - val_loss: 1.9104 - learning_rate: 5.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6005 - loss: 1.9353 - val_accuracy: 0.5423 - val_loss: 1.9761 - learning_rate: 5.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5591 - loss: 2.0337 - val_accuracy: 0.5447 - val_loss: 2.0136 - learning_rate: 5.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5964 - loss: 1.9219 - val_accuracy: 0.5355 - val_loss: 2.0155 - learning_rate: 5.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6174 - loss: 1.8070 - val_accuracy: 0.5576 - val_loss: 1.9376 - learning_rate: 5.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5762 - loss: 1.9928 - val_accuracy: 0.5300 - val_loss: 1.9799 - learning_rate: 5.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5912 - loss: 1.9075 - val_accuracy: 0.5472 - val_loss: 1.9604 - learning_rate: 5.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5854 - loss: 1.9775 - val_accuracy: 0.5699 - val_loss: 1.9704 - learning_rate: 5.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.6080 - loss: 1.9026\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6080 - loss: 1.9025 - val_accuracy: 0.5545 - val_loss: 1.9661 - learning_rate: 5.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6055 - loss: 1.9360 - val_accuracy: 0.5502 - val_loss: 2.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.6343 - loss: 1.7983 - val_accuracy: 0.5558 - val_loss: 2.0009 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6758 - loss: 1.6782 - val_accuracy: 0.5656 - val_loss: 1.9270 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6613 - loss: 1.7530 - val_accuracy: 0.5502 - val_loss: 1.9799 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6771 - loss: 1.7250 - val_accuracy: 0.5582 - val_loss: 1.9442 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6200 - loss: 1.8485 - val_accuracy: 0.5527 - val_loss: 1.9264 - learning_rate: 2.5000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6662 - loss: 1.7650 - val_accuracy: 0.5931 - val_loss: 1.8320 - learning_rate: 2.5000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6446 - loss: 1.7954 - val_accuracy: 0.5686 - val_loss: 1.9120 - learning_rate: 2.5000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6447 - loss: 1.7734 - val_accuracy: 0.5686 - val_loss: 1.9129 - learning_rate: 2.5000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.6836 - loss: 1.7591 - val_accuracy: 0.5717 - val_loss: 1.8891 - learning_rate: 2.5000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6938 - loss: 1.6306 - val_accuracy: 0.5564 - val_loss: 1.9241 - learning_rate: 2.5000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6691 - loss: 1.7439 - val_accuracy: 0.5699 - val_loss: 1.8838 - learning_rate: 2.5000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7071 - loss: 1.6178 - val_accuracy: 0.5564 - val_loss: 1.9836 - learning_rate: 2.5000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.7025 - loss: 1.6526 - val_accuracy: 0.5815 - val_loss: 1.8602 - learning_rate: 2.5000e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.6812 - loss: 1.7124\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6812 - loss: 1.7120 - val_accuracy: 0.5858 - val_loss: 1.8548 - learning_rate: 2.5000e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6703 - loss: 1.7539 - val_accuracy: 0.5962 - val_loss: 1.8639 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6664 - loss: 1.7260 - val_accuracy: 0.5938 - val_loss: 1.8333 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7253 - loss: 1.5819 - val_accuracy: 0.5797 - val_loss: 1.8821 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6705 - loss: 1.7654 - val_accuracy: 0.5729 - val_loss: 1.8951 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7010 - loss: 1.6288 - val_accuracy: 0.5864 - val_loss: 1.8779 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7184 - loss: 1.6587 - val_accuracy: 0.5705 - val_loss: 1.9121 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7129 - loss: 1.6442 - val_accuracy: 0.5772 - val_loss: 1.8719 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6588 - loss: 1.7579 - val_accuracy: 0.6097 - val_loss: 1.8121 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.7051 - loss: 1.6548 - val_accuracy: 0.5521 - val_loss: 1.9572 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.7144 - loss: 1.5583 - val_accuracy: 0.5766 - val_loss: 1.8499 - learning_rate: 1.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7101 - loss: 1.6266 - val_accuracy: 0.5888 - val_loss: 1.8679 - learning_rate: 1.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7339 - loss: 1.6282 - val_accuracy: 0.5925 - val_loss: 1.8756 - learning_rate: 1.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7136 - loss: 1.6813 - val_accuracy: 0.5766 - val_loss: 1.9371 - learning_rate: 1.2500e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.7675 - loss: 1.4836 - val_accuracy: 0.5876 - val_loss: 1.8709 - learning_rate: 1.2500e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.6997 - loss: 1.6107 - val_accuracy: 0.5821 - val_loss: 1.8765 - learning_rate: 1.2500e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.7449 - loss: 1.5348\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.7448 - loss: 1.5348 - val_accuracy: 0.5980 - val_loss: 1.8105 - learning_rate: 1.2500e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7369 - loss: 1.5267 - val_accuracy: 0.6115 - val_loss: 1.7828 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7411 - loss: 1.5362 - val_accuracy: 0.5839 - val_loss: 1.8900 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7733 - loss: 1.4284 - val_accuracy: 0.5907 - val_loss: 1.9002 - learning_rate: 6.2500e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7425 - loss: 1.5719 - val_accuracy: 0.5754 - val_loss: 1.9619 - learning_rate: 6.2500e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7419 - loss: 1.5974 - val_accuracy: 0.5913 - val_loss: 1.8567 - learning_rate: 6.2500e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7640 - loss: 1.5594 - val_accuracy: 0.5968 - val_loss: 1.8430 - learning_rate: 6.2500e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7829 - loss: 1.4021 - val_accuracy: 0.5882 - val_loss: 1.8273 - learning_rate: 6.2500e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7538 - loss: 1.5638 - val_accuracy: 0.6042 - val_loss: 1.8102 - learning_rate: 6.2500e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7563 - loss: 1.5088\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7564 - loss: 1.5087 - val_accuracy: 0.5950 - val_loss: 1.8081 - learning_rate: 6.2500e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7639 - loss: 1.4964 - val_accuracy: 0.5950 - val_loss: 1.8426 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7563 - loss: 1.4990 - val_accuracy: 0.5950 - val_loss: 1.8335 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7522 - loss: 1.5233 - val_accuracy: 0.5858 - val_loss: 1.8741 - learning_rate: 3.1250e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7291 - loss: 1.6310 - val_accuracy: 0.5754 - val_loss: 1.8633 - learning_rate: 3.1250e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7553 - loss: 1.5452 - val_accuracy: 0.5827 - val_loss: 1.8071 - learning_rate: 3.1250e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.7627 - loss: 1.5627 - val_accuracy: 0.5839 - val_loss: 1.8646 - learning_rate: 3.1250e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7598 - loss: 1.5699 - val_accuracy: 0.5858 - val_loss: 1.8851 - learning_rate: 3.1250e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7565 - loss: 1.5341 - val_accuracy: 0.5993 - val_loss: 1.8433 - learning_rate: 3.1250e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7470 - loss: 1.6119\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7471 - loss: 1.6113 - val_accuracy: 0.5729 - val_loss: 1.9014 - learning_rate: 3.1250e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7416 - loss: 1.5791 - val_accuracy: 0.6054 - val_loss: 1.8079 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7472 - loss: 1.5400 - val_accuracy: 0.5839 - val_loss: 1.8706 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7610 - loss: 1.5016 - val_accuracy: 0.6048 - val_loss: 1.7878 - learning_rate: 1.5625e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7794 - loss: 1.4703 - val_accuracy: 0.6115 - val_loss: 1.7630 - learning_rate: 1.5625e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7474 - loss: 1.5796 - val_accuracy: 0.5723 - val_loss: 1.9111 - learning_rate: 1.5625e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7122 - loss: 1.6559 - val_accuracy: 0.5919 - val_loss: 1.8089 - learning_rate: 1.5625e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7839 - loss: 1.4618 - val_accuracy: 0.5901 - val_loss: 1.8503 - learning_rate: 1.5625e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7326 - loss: 1.5594 - val_accuracy: 0.5925 - val_loss: 1.7734 - learning_rate: 1.5625e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7510 - loss: 1.5233\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7509 - loss: 1.5239 - val_accuracy: 0.5876 - val_loss: 1.8336 - learning_rate: 1.5625e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7907 - loss: 1.4637 - val_accuracy: 0.6029 - val_loss: 1.8414 - learning_rate: 7.8125e-06\n",
      "Epoch 97/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7563 - loss: 1.5382 - val_accuracy: 0.5993 - val_loss: 1.8496 - learning_rate: 7.8125e-06\n",
      "Epoch 98/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7731 - loss: 1.5437 - val_accuracy: 0.5790 - val_loss: 1.8743 - learning_rate: 7.8125e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7517 - loss: 1.5857 - val_accuracy: 0.5754 - val_loss: 1.9065 - learning_rate: 7.8125e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7883 - loss: 1.4498 - val_accuracy: 0.5950 - val_loss: 1.8593 - learning_rate: 7.8125e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7439 - loss: 1.5979 - val_accuracy: 0.5754 - val_loss: 1.8942 - learning_rate: 7.8125e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 86ms/step - accuracy: 0.7894 - loss: 1.4246 - val_accuracy: 0.6005 - val_loss: 1.7949 - learning_rate: 7.8125e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7573 - loss: 1.5390 - val_accuracy: 0.5797 - val_loss: 1.8803 - learning_rate: 7.8125e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.7323 - loss: 1.6167\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7325 - loss: 1.6160 - val_accuracy: 0.6091 - val_loss: 1.8021 - learning_rate: 7.8125e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7848 - loss: 1.4720 - val_accuracy: 0.6060 - val_loss: 1.8504 - learning_rate: 3.9063e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7768 - loss: 1.4927 - val_accuracy: 0.5784 - val_loss: 1.9015 - learning_rate: 3.9063e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7735 - loss: 1.5230 - val_accuracy: 0.5882 - val_loss: 1.8508 - learning_rate: 3.9063e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7612 - loss: 1.5017 - val_accuracy: 0.6048 - val_loss: 1.8677 - learning_rate: 3.9063e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7570 - loss: 1.5473 - val_accuracy: 0.5852 - val_loss: 1.8923 - learning_rate: 3.9063e-06\n",
      "Epoch 109: early stopping\n",
      "Restoring model weights from the end of the best epoch: 69.\n",
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi: transformer_imu_only_5folds/gesture_model_fold_1\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "\n",
      "===== FOLD 3/5 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 96ms/step - accuracy: 0.0989 - loss: 8.9514 - val_accuracy: 0.2323 - val_loss: 7.4300 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.1962 - loss: 7.3499 - val_accuracy: 0.3251 - val_loss: 6.4620 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.2799 - loss: 6.3925 - val_accuracy: 0.3699 - val_loss: 5.6310 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.3160 - loss: 5.7554 - val_accuracy: 0.3876 - val_loss: 5.0982 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.3588 - loss: 5.1258 - val_accuracy: 0.4280 - val_loss: 4.6079 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.3850 - loss: 4.6618 - val_accuracy: 0.4268 - val_loss: 4.2655 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.3921 - loss: 4.1831 - val_accuracy: 0.4350 - val_loss: 3.9577 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.4400 - loss: 3.8430 - val_accuracy: 0.4381 - val_loss: 3.6136 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.4320 - loss: 3.5735 - val_accuracy: 0.4659 - val_loss: 3.3365 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4470 - loss: 3.3161 - val_accuracy: 0.4621 - val_loss: 3.1506 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4672 - loss: 3.0438 - val_accuracy: 0.4836 - val_loss: 2.9392 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.4769 - loss: 2.9171 - val_accuracy: 0.5006 - val_loss: 2.7671 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.4793 - loss: 2.7425 - val_accuracy: 0.4628 - val_loss: 2.7284 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4892 - loss: 2.6835 - val_accuracy: 0.4886 - val_loss: 2.5043 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5212 - loss: 2.4345 - val_accuracy: 0.5082 - val_loss: 2.4354 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5062 - loss: 2.4277 - val_accuracy: 0.5082 - val_loss: 2.3796 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.4996 - loss: 2.3851 - val_accuracy: 0.5183 - val_loss: 2.3342 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5395 - loss: 2.2821 - val_accuracy: 0.5189 - val_loss: 2.2431 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5358 - loss: 2.2087 - val_accuracy: 0.5044 - val_loss: 2.2973 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5080 - loss: 2.2864 - val_accuracy: 0.5335 - val_loss: 2.0914 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.5651 - loss: 2.0439 - val_accuracy: 0.5208 - val_loss: 2.1789 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5553 - loss: 2.1485 - val_accuracy: 0.5372 - val_loss: 2.1323 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5528 - loss: 2.0703 - val_accuracy: 0.5436 - val_loss: 2.0508 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5675 - loss: 2.0197 - val_accuracy: 0.5246 - val_loss: 2.1165 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5538 - loss: 2.1266 - val_accuracy: 0.5372 - val_loss: 2.0888 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5793 - loss: 1.9462 - val_accuracy: 0.5499 - val_loss: 2.0169 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5661 - loss: 1.9766 - val_accuracy: 0.5442 - val_loss: 2.0155 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5902 - loss: 1.9477 - val_accuracy: 0.5290 - val_loss: 2.0208 - learning_rate: 5.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6010 - loss: 1.9031 - val_accuracy: 0.5663 - val_loss: 2.0191 - learning_rate: 5.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5663 - loss: 1.9311 - val_accuracy: 0.5530 - val_loss: 1.9675 - learning_rate: 5.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5683 - loss: 1.9859 - val_accuracy: 0.5619 - val_loss: 1.9728 - learning_rate: 5.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5980 - loss: 1.9127 - val_accuracy: 0.5354 - val_loss: 2.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6105 - loss: 1.8179 - val_accuracy: 0.5650 - val_loss: 1.9919 - learning_rate: 5.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6102 - loss: 1.8383 - val_accuracy: 0.5663 - val_loss: 1.8968 - learning_rate: 5.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5925 - loss: 1.9493 - val_accuracy: 0.5707 - val_loss: 1.8994 - learning_rate: 5.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6099 - loss: 1.8770 - val_accuracy: 0.5436 - val_loss: 2.0022 - learning_rate: 5.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6083 - loss: 1.9614 - val_accuracy: 0.5492 - val_loss: 1.9996 - learning_rate: 5.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6128 - loss: 1.8716 - val_accuracy: 0.5499 - val_loss: 1.9587 - learning_rate: 5.0000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5913 - loss: 1.9311 - val_accuracy: 0.5625 - val_loss: 1.9496 - learning_rate: 5.0000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6177 - loss: 1.8733 - val_accuracy: 0.5669 - val_loss: 1.9247 - learning_rate: 5.0000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6160 - loss: 1.8965 - val_accuracy: 0.5543 - val_loss: 1.9562 - learning_rate: 5.0000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6221 - loss: 1.8143 - val_accuracy: 0.5783 - val_loss: 1.8662 - learning_rate: 5.0000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6166 - loss: 1.8729 - val_accuracy: 0.5802 - val_loss: 1.9037 - learning_rate: 5.0000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.6269 - loss: 1.8289 - val_accuracy: 0.5846 - val_loss: 1.9059 - learning_rate: 5.0000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6261 - loss: 1.8582 - val_accuracy: 0.5688 - val_loss: 1.9349 - learning_rate: 5.0000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6173 - loss: 1.8401 - val_accuracy: 0.5827 - val_loss: 1.9573 - learning_rate: 5.0000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6418 - loss: 1.8278 - val_accuracy: 0.5814 - val_loss: 1.9084 - learning_rate: 5.0000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6605 - loss: 1.7420 - val_accuracy: 0.5890 - val_loss: 1.8982 - learning_rate: 5.0000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6425 - loss: 1.8206 - val_accuracy: 0.5663 - val_loss: 1.9160 - learning_rate: 5.0000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6322 - loss: 1.8751 - val_accuracy: 0.5518 - val_loss: 2.0234 - learning_rate: 5.0000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6890 - loss: 1.7336 - val_accuracy: 0.5972 - val_loss: 1.9012 - learning_rate: 5.0000e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6554 - loss: 1.7397 - val_accuracy: 0.5758 - val_loss: 1.9156 - learning_rate: 5.0000e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6667 - loss: 1.7610 - val_accuracy: 0.5859 - val_loss: 1.9000 - learning_rate: 5.0000e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6580 - loss: 1.8300 - val_accuracy: 0.6067 - val_loss: 1.7859 - learning_rate: 5.0000e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6469 - loss: 1.8472 - val_accuracy: 0.5777 - val_loss: 1.8973 - learning_rate: 5.0000e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6704 - loss: 1.7509 - val_accuracy: 0.5878 - val_loss: 1.8582 - learning_rate: 5.0000e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6609 - loss: 1.7795 - val_accuracy: 0.5606 - val_loss: 2.0110 - learning_rate: 5.0000e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6882 - loss: 1.7051 - val_accuracy: 0.5688 - val_loss: 1.9430 - learning_rate: 5.0000e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.6575 - loss: 1.7613 - val_accuracy: 0.6181 - val_loss: 1.7737 - learning_rate: 5.0000e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6707 - loss: 1.8037 - val_accuracy: 0.5739 - val_loss: 1.9177 - learning_rate: 5.0000e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6756 - loss: 1.7651 - val_accuracy: 0.5732 - val_loss: 1.9631 - learning_rate: 5.0000e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6963 - loss: 1.7082 - val_accuracy: 0.5985 - val_loss: 1.8460 - learning_rate: 5.0000e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.6579 - loss: 1.8544 - val_accuracy: 0.5966 - val_loss: 1.8618 - learning_rate: 5.0000e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6688 - loss: 1.7950 - val_accuracy: 0.5770 - val_loss: 1.9295 - learning_rate: 5.0000e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6835 - loss: 1.7214 - val_accuracy: 0.5581 - val_loss: 2.0071 - learning_rate: 5.0000e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6919 - loss: 1.7171 - val_accuracy: 0.5972 - val_loss: 1.9150 - learning_rate: 5.0000e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6974 - loss: 1.6441\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6973 - loss: 1.6446 - val_accuracy: 0.5638 - val_loss: 1.9467 - learning_rate: 5.0000e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7026 - loss: 1.7513 - val_accuracy: 0.5903 - val_loss: 1.9729 - learning_rate: 2.5000e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7086 - loss: 1.6862 - val_accuracy: 0.6174 - val_loss: 1.8033 - learning_rate: 2.5000e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7322 - loss: 1.6478 - val_accuracy: 0.6073 - val_loss: 1.8998 - learning_rate: 2.5000e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7313 - loss: 1.6259 - val_accuracy: 0.6054 - val_loss: 1.8064 - learning_rate: 2.5000e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7083 - loss: 1.7273 - val_accuracy: 0.6250 - val_loss: 1.7879 - learning_rate: 2.5000e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7612 - loss: 1.5246 - val_accuracy: 0.6326 - val_loss: 1.7552 - learning_rate: 2.5000e-04\n",
      "Epoch 74/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7452 - loss: 1.5993 - val_accuracy: 0.6004 - val_loss: 1.9321 - learning_rate: 2.5000e-04\n",
      "Epoch 75/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.7576 - loss: 1.5335 - val_accuracy: 0.5694 - val_loss: 1.9744 - learning_rate: 2.5000e-04\n",
      "Epoch 76/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7291 - loss: 1.6792 - val_accuracy: 0.6035 - val_loss: 1.8620 - learning_rate: 2.5000e-04\n",
      "Epoch 77/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7397 - loss: 1.5640 - val_accuracy: 0.5928 - val_loss: 1.8485 - learning_rate: 2.5000e-04\n",
      "Epoch 78/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7467 - loss: 1.6279 - val_accuracy: 0.5934 - val_loss: 1.8765 - learning_rate: 2.5000e-04\n",
      "Epoch 79/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7258 - loss: 1.6233 - val_accuracy: 0.5764 - val_loss: 1.9280 - learning_rate: 2.5000e-04\n",
      "Epoch 80/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7760 - loss: 1.5296 - val_accuracy: 0.5922 - val_loss: 1.8837 - learning_rate: 2.5000e-04\n",
      "Epoch 81/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7544 - loss: 1.6469\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7542 - loss: 1.6469 - val_accuracy: 0.5997 - val_loss: 1.8516 - learning_rate: 2.5000e-04\n",
      "Epoch 82/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7564 - loss: 1.5259 - val_accuracy: 0.5960 - val_loss: 1.9079 - learning_rate: 1.2500e-04\n",
      "Epoch 83/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7978 - loss: 1.4657 - val_accuracy: 0.5972 - val_loss: 1.8858 - learning_rate: 1.2500e-04\n",
      "Epoch 84/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.7815 - loss: 1.5193 - val_accuracy: 0.5972 - val_loss: 1.9108 - learning_rate: 1.2500e-04\n",
      "Epoch 85/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7776 - loss: 1.5166 - val_accuracy: 0.6206 - val_loss: 1.8053 - learning_rate: 1.2500e-04\n",
      "Epoch 86/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7798 - loss: 1.5425 - val_accuracy: 0.5947 - val_loss: 1.8012 - learning_rate: 1.2500e-04\n",
      "Epoch 87/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7401 - loss: 1.6362 - val_accuracy: 0.6067 - val_loss: 1.8177 - learning_rate: 1.2500e-04\n",
      "Epoch 88/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7712 - loss: 1.5654 - val_accuracy: 0.6023 - val_loss: 1.8403 - learning_rate: 1.2500e-04\n",
      "Epoch 89/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7622 - loss: 1.5535 - val_accuracy: 0.5852 - val_loss: 1.8437 - learning_rate: 1.2500e-04\n",
      "Epoch 90/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7847 - loss: 1.4818\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7845 - loss: 1.4822 - val_accuracy: 0.5739 - val_loss: 1.8830 - learning_rate: 1.2500e-04\n",
      "Epoch 91/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8091 - loss: 1.4689 - val_accuracy: 0.5972 - val_loss: 1.8568 - learning_rate: 6.2500e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.7757 - loss: 1.4871 - val_accuracy: 0.5739 - val_loss: 1.9794 - learning_rate: 6.2500e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8270 - loss: 1.3945 - val_accuracy: 0.6294 - val_loss: 1.7483 - learning_rate: 6.2500e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.7964 - loss: 1.5013 - val_accuracy: 0.6364 - val_loss: 1.7492 - learning_rate: 6.2500e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8007 - loss: 1.5313 - val_accuracy: 0.6080 - val_loss: 1.8520 - learning_rate: 6.2500e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.8195 - loss: 1.4664 - val_accuracy: 0.6004 - val_loss: 1.9012 - learning_rate: 6.2500e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.8260 - loss: 1.3810 - val_accuracy: 0.5840 - val_loss: 1.9290 - learning_rate: 6.2500e-05\n",
      "Epoch 98/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.7769 - loss: 1.5149 - val_accuracy: 0.6067 - val_loss: 1.7845 - learning_rate: 6.2500e-05\n",
      "Epoch 99/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.8198 - loss: 1.4400 - val_accuracy: 0.6162 - val_loss: 1.7760 - learning_rate: 6.2500e-05\n",
      "Epoch 100/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.7633 - loss: 1.5496 - val_accuracy: 0.6004 - val_loss: 1.8656 - learning_rate: 6.2500e-05\n",
      "Epoch 101/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.8014 - loss: 1.4012 - val_accuracy: 0.6383 - val_loss: 1.7051 - learning_rate: 6.2500e-05\n",
      "Epoch 102/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8127 - loss: 1.4594 - val_accuracy: 0.5878 - val_loss: 1.8561 - learning_rate: 6.2500e-05\n",
      "Epoch 103/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.8179 - loss: 1.4518 - val_accuracy: 0.5953 - val_loss: 1.8886 - learning_rate: 6.2500e-05\n",
      "Epoch 104/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8375 - loss: 1.3854 - val_accuracy: 0.6080 - val_loss: 1.8270 - learning_rate: 6.2500e-05\n",
      "Epoch 105/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.8321 - loss: 1.3784 - val_accuracy: 0.6218 - val_loss: 1.7126 - learning_rate: 6.2500e-05\n",
      "Epoch 106/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.8542 - loss: 1.2950 - val_accuracy: 0.5966 - val_loss: 1.8883 - learning_rate: 6.2500e-05\n",
      "Epoch 107/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7917 - loss: 1.5488 - val_accuracy: 0.6054 - val_loss: 1.8604 - learning_rate: 6.2500e-05\n",
      "Epoch 108/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8426 - loss: 1.3446 - val_accuracy: 0.6231 - val_loss: 1.8794 - learning_rate: 6.2500e-05\n",
      "Epoch 109/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8712 - loss: 1.2370\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8708 - loss: 1.2385 - val_accuracy: 0.6098 - val_loss: 1.8356 - learning_rate: 6.2500e-05\n",
      "Epoch 110/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8018 - loss: 1.4671 - val_accuracy: 0.5953 - val_loss: 1.9214 - learning_rate: 3.1250e-05\n",
      "Epoch 111/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8533 - loss: 1.3779 - val_accuracy: 0.6244 - val_loss: 1.7388 - learning_rate: 3.1250e-05\n",
      "Epoch 112/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7925 - loss: 1.4922 - val_accuracy: 0.5871 - val_loss: 1.9142 - learning_rate: 3.1250e-05\n",
      "Epoch 113/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.8051 - loss: 1.5019 - val_accuracy: 0.5928 - val_loss: 1.8789 - learning_rate: 3.1250e-05\n",
      "Epoch 114/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7909 - loss: 1.5338 - val_accuracy: 0.6187 - val_loss: 1.7668 - learning_rate: 3.1250e-05\n",
      "Epoch 115/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8386 - loss: 1.3691 - val_accuracy: 0.5941 - val_loss: 1.8765 - learning_rate: 3.1250e-05\n",
      "Epoch 116/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.8303 - loss: 1.3791 - val_accuracy: 0.6086 - val_loss: 1.8213 - learning_rate: 3.1250e-05\n",
      "Epoch 117/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.8260 - loss: 1.4146 - val_accuracy: 0.6181 - val_loss: 1.8227 - learning_rate: 3.1250e-05\n",
      "Epoch 118/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8303 - loss: 1.3761\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.8301 - loss: 1.3771 - val_accuracy: 0.6010 - val_loss: 1.8883 - learning_rate: 3.1250e-05\n",
      "Epoch 119/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.8368 - loss: 1.4254 - val_accuracy: 0.6130 - val_loss: 1.7844 - learning_rate: 1.5625e-05\n",
      "Epoch 120/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8234 - loss: 1.4454 - val_accuracy: 0.6035 - val_loss: 1.9116 - learning_rate: 1.5625e-05\n",
      "Epoch 121/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8523 - loss: 1.3055 - val_accuracy: 0.6054 - val_loss: 1.8804 - learning_rate: 1.5625e-05\n",
      "Epoch 122/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8341 - loss: 1.4098 - val_accuracy: 0.6111 - val_loss: 1.7872 - learning_rate: 1.5625e-05\n",
      "Epoch 123/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8104 - loss: 1.5203 - val_accuracy: 0.6117 - val_loss: 1.8052 - learning_rate: 1.5625e-05\n",
      "Epoch 124/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8334 - loss: 1.3759 - val_accuracy: 0.5808 - val_loss: 1.9265 - learning_rate: 1.5625e-05\n",
      "Epoch 125/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8222 - loss: 1.4312 - val_accuracy: 0.6162 - val_loss: 1.8224 - learning_rate: 1.5625e-05\n",
      "Epoch 126/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8293 - loss: 1.3965 - val_accuracy: 0.6414 - val_loss: 1.7181 - learning_rate: 1.5625e-05\n",
      "Epoch 127/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.8414 - loss: 1.3368 - val_accuracy: 0.5991 - val_loss: 1.8604 - learning_rate: 1.5625e-05\n",
      "Epoch 128/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.8079 - loss: 1.5073 - val_accuracy: 0.5922 - val_loss: 1.8907 - learning_rate: 1.5625e-05\n",
      "Epoch 129/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.8550 - loss: 1.3276 - val_accuracy: 0.6376 - val_loss: 1.7492 - learning_rate: 1.5625e-05\n",
      "Epoch 130/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8137 - loss: 1.4439 - val_accuracy: 0.6269 - val_loss: 1.7960 - learning_rate: 1.5625e-05\n",
      "Epoch 131/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.8249 - loss: 1.3858 - val_accuracy: 0.6256 - val_loss: 1.7415 - learning_rate: 1.5625e-05\n",
      "Epoch 132/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8289 - loss: 1.3966 - val_accuracy: 0.6080 - val_loss: 1.8007 - learning_rate: 1.5625e-05\n",
      "Epoch 133/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8378 - loss: 1.3345 - val_accuracy: 0.5833 - val_loss: 1.9007 - learning_rate: 1.5625e-05\n",
      "Epoch 134/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8227 - loss: 1.4146\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8228 - loss: 1.4144 - val_accuracy: 0.6155 - val_loss: 1.8565 - learning_rate: 1.5625e-05\n",
      "Epoch 135/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8395 - loss: 1.4046 - val_accuracy: 0.6149 - val_loss: 1.8075 - learning_rate: 7.8125e-06\n",
      "Epoch 136/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8254 - loss: 1.5038 - val_accuracy: 0.5997 - val_loss: 1.8457 - learning_rate: 7.8125e-06\n",
      "Epoch 137/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8343 - loss: 1.3739 - val_accuracy: 0.6193 - val_loss: 1.7908 - learning_rate: 7.8125e-06\n",
      "Epoch 138/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8364 - loss: 1.4005 - val_accuracy: 0.6162 - val_loss: 1.7769 - learning_rate: 7.8125e-06\n",
      "Epoch 139/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7958 - loss: 1.5698 - val_accuracy: 0.6231 - val_loss: 1.7654 - learning_rate: 7.8125e-06\n",
      "Epoch 140/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8245 - loss: 1.4194 - val_accuracy: 0.6282 - val_loss: 1.7137 - learning_rate: 7.8125e-06\n",
      "Epoch 141/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.7976 - loss: 1.5695 - val_accuracy: 0.5852 - val_loss: 1.9366 - learning_rate: 7.8125e-06\n",
      "Epoch 142/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8433 - loss: 1.4325 - val_accuracy: 0.6307 - val_loss: 1.7441 - learning_rate: 7.8125e-06\n",
      "Epoch 143/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8207 - loss: 1.4485\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8206 - loss: 1.4488 - val_accuracy: 0.5997 - val_loss: 1.8893 - learning_rate: 7.8125e-06\n",
      "Epoch 144/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8404 - loss: 1.4275 - val_accuracy: 0.6269 - val_loss: 1.7919 - learning_rate: 3.9063e-06\n",
      "Epoch 145/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8301 - loss: 1.3754 - val_accuracy: 0.6149 - val_loss: 1.8106 - learning_rate: 3.9063e-06\n",
      "Epoch 146/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8023 - loss: 1.4706 - val_accuracy: 0.6282 - val_loss: 1.7454 - learning_rate: 3.9063e-06\n",
      "Epoch 147/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.8276 - loss: 1.4071 - val_accuracy: 0.6313 - val_loss: 1.7361 - learning_rate: 3.9063e-06\n",
      "Epoch 148/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.8443 - loss: 1.4200 - val_accuracy: 0.5676 - val_loss: 1.9155 - learning_rate: 3.9063e-06\n",
      "Epoch 149/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8310 - loss: 1.4118 - val_accuracy: 0.5934 - val_loss: 1.8839 - learning_rate: 3.9063e-06\n",
      "Epoch 150/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8396 - loss: 1.4191 - val_accuracy: 0.6086 - val_loss: 1.7931 - learning_rate: 3.9063e-06\n",
      "Epoch 151/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8466 - loss: 1.4244 - val_accuracy: 0.6376 - val_loss: 1.7564 - learning_rate: 3.9063e-06\n",
      "Epoch 152/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8272 - loss: 1.4440\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8271 - loss: 1.4441 - val_accuracy: 0.5947 - val_loss: 1.8836 - learning_rate: 3.9063e-06\n",
      "Epoch 153/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.8222 - loss: 1.4441 - val_accuracy: 0.6136 - val_loss: 1.7983 - learning_rate: 3.0000e-06\n",
      "Epoch 154/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.8557 - loss: 1.3010 - val_accuracy: 0.6054 - val_loss: 1.8451 - learning_rate: 3.0000e-06\n",
      "Epoch 155/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8498 - loss: 1.4137 - val_accuracy: 0.6054 - val_loss: 1.9069 - learning_rate: 3.0000e-06\n",
      "Epoch 156/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8491 - loss: 1.3764 - val_accuracy: 0.5846 - val_loss: 1.8850 - learning_rate: 3.0000e-06\n",
      "Epoch 157/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8508 - loss: 1.3515 - val_accuracy: 0.5859 - val_loss: 1.8628 - learning_rate: 3.0000e-06\n",
      "Epoch 158/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.8617 - loss: 1.3612 - val_accuracy: 0.5966 - val_loss: 1.9006 - learning_rate: 3.0000e-06\n",
      "Epoch 159/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.8642 - loss: 1.2797 - val_accuracy: 0.6162 - val_loss: 1.8154 - learning_rate: 3.0000e-06\n",
      "Epoch 160/160\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 95ms/step - accuracy: 0.8364 - loss: 1.4018 - val_accuracy: 0.6181 - val_loss: 1.7951 - learning_rate: 3.0000e-06\n",
      "Restoring model weights from the end of the best epoch: 126.\n",
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi: transformer_imu_only_5folds/gesture_model_fold_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 20:43:06.084278: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "\n",
      "===== FOLD 4/5 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 92ms/step - accuracy: 0.0948 - loss: 8.8590 - val_accuracy: 0.2914 - val_loss: 7.2420 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.1994 - loss: 7.3525 - val_accuracy: 0.3225 - val_loss: 6.4124 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.2545 - loss: 6.5076 - val_accuracy: 0.3665 - val_loss: 5.7767 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.3104 - loss: 5.7603 - val_accuracy: 0.4016 - val_loss: 5.1747 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.3335 - loss: 5.1738 - val_accuracy: 0.3685 - val_loss: 4.8568 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.3572 - loss: 4.7481 - val_accuracy: 0.4070 - val_loss: 4.3481 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.3936 - loss: 4.3289 - val_accuracy: 0.4300 - val_loss: 4.0753 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.3977 - loss: 4.1159 - val_accuracy: 0.4483 - val_loss: 3.7071 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.4420 - loss: 3.6692 - val_accuracy: 0.4415 - val_loss: 3.5547 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.4368 - loss: 3.4200 - val_accuracy: 0.4415 - val_loss: 3.3822 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.4568 - loss: 3.2530 - val_accuracy: 0.4679 - val_loss: 3.0782 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.4628 - loss: 3.0694 - val_accuracy: 0.4219 - val_loss: 3.0623 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.4680 - loss: 2.8736 - val_accuracy: 0.4726 - val_loss: 2.7953 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.4734 - loss: 2.7672 - val_accuracy: 0.4868 - val_loss: 2.6536 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.4826 - loss: 2.6907 - val_accuracy: 0.5172 - val_loss: 2.5624 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.4803 - loss: 2.6339 - val_accuracy: 0.5132 - val_loss: 2.4928 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5079 - loss: 2.4209 - val_accuracy: 0.5044 - val_loss: 2.4001 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.5316 - loss: 2.3741 - val_accuracy: 0.4699 - val_loss: 2.5214 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.4853 - loss: 2.4468 - val_accuracy: 0.5085 - val_loss: 2.3762 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.5134 - loss: 2.3736 - val_accuracy: 0.5051 - val_loss: 2.2392 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5286 - loss: 2.2589 - val_accuracy: 0.4577 - val_loss: 2.4001 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5147 - loss: 2.2285 - val_accuracy: 0.4963 - val_loss: 2.2644 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.5224 - loss: 2.2595\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5225 - loss: 2.2590 - val_accuracy: 0.5118 - val_loss: 2.2196 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5583 - loss: 2.1452 - val_accuracy: 0.5314 - val_loss: 2.1139 - learning_rate: 2.5000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5598 - loss: 2.1520 - val_accuracy: 0.5375 - val_loss: 2.0995 - learning_rate: 2.5000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.5569 - loss: 2.0856 - val_accuracy: 0.5456 - val_loss: 2.1405 - learning_rate: 2.5000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.5553 - loss: 2.0986 - val_accuracy: 0.5274 - val_loss: 2.0922 - learning_rate: 2.5000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5591 - loss: 2.0747 - val_accuracy: 0.5517 - val_loss: 1.9866 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5806 - loss: 2.0084 - val_accuracy: 0.5538 - val_loss: 2.0206 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5858 - loss: 1.9518 - val_accuracy: 0.5429 - val_loss: 1.9669 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.5819 - loss: 1.9971 - val_accuracy: 0.5179 - val_loss: 2.1508 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5803 - loss: 2.0170 - val_accuracy: 0.5416 - val_loss: 2.0209 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.5955 - loss: 1.8791 - val_accuracy: 0.5227 - val_loss: 2.1012 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5941 - loss: 1.9543 - val_accuracy: 0.5423 - val_loss: 2.0278 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.5974 - loss: 1.9221 - val_accuracy: 0.5463 - val_loss: 1.9875 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6108 - loss: 1.8691 - val_accuracy: 0.5612 - val_loss: 1.9433 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6066 - loss: 1.9525 - val_accuracy: 0.5652 - val_loss: 1.9089 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6314 - loss: 1.8141 - val_accuracy: 0.5666 - val_loss: 1.9675 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6247 - loss: 1.8531 - val_accuracy: 0.5436 - val_loss: 2.0222 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6281 - loss: 1.7680 - val_accuracy: 0.5862 - val_loss: 1.8906 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.6317 - loss: 1.7801 - val_accuracy: 0.5463 - val_loss: 2.0044 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.5896 - loss: 1.9568 - val_accuracy: 0.5517 - val_loss: 1.8901 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6232 - loss: 1.8581 - val_accuracy: 0.5646 - val_loss: 1.9382 - learning_rate: 2.5000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6558 - loss: 1.7529 - val_accuracy: 0.5734 - val_loss: 1.9389 - learning_rate: 2.5000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.6392 - loss: 1.8346 - val_accuracy: 0.5727 - val_loss: 1.9520 - learning_rate: 2.5000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.6523 - loss: 1.7524 - val_accuracy: 0.5348 - val_loss: 1.9447 - learning_rate: 2.5000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6592 - loss: 1.7666 - val_accuracy: 0.5402 - val_loss: 1.9798 - learning_rate: 2.5000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.6258 - loss: 1.8709\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6259 - loss: 1.8704 - val_accuracy: 0.5632 - val_loss: 1.8821 - learning_rate: 2.5000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6352 - loss: 1.8799 - val_accuracy: 0.5767 - val_loss: 1.9513 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6520 - loss: 1.7752 - val_accuracy: 0.5808 - val_loss: 1.8760 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6341 - loss: 1.8273 - val_accuracy: 0.5889 - val_loss: 1.8920 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.6556 - loss: 1.7630 - val_accuracy: 0.6004 - val_loss: 1.8758 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6555 - loss: 1.7912 - val_accuracy: 0.6099 - val_loss: 1.8066 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6437 - loss: 1.8043 - val_accuracy: 0.5862 - val_loss: 1.8732 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.6454 - loss: 1.7899 - val_accuracy: 0.5490 - val_loss: 1.9619 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6615 - loss: 1.7372 - val_accuracy: 0.5761 - val_loss: 1.8665 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.6564 - loss: 1.8228 - val_accuracy: 0.5882 - val_loss: 1.8349 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.7020 - loss: 1.6767 - val_accuracy: 0.5707 - val_loss: 1.8710 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6799 - loss: 1.7049 - val_accuracy: 0.5734 - val_loss: 1.9179 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.6411 - loss: 1.8542 - val_accuracy: 0.6099 - val_loss: 1.7792 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.6715 - loss: 1.7404\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6714 - loss: 1.7406 - val_accuracy: 0.5625 - val_loss: 1.9688 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6592 - loss: 1.7745 - val_accuracy: 0.5673 - val_loss: 1.9559 - learning_rate: 6.2500e-05\n",
      "Epoch 63/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6496 - loss: 1.8409 - val_accuracy: 0.5997 - val_loss: 1.8016 - learning_rate: 6.2500e-05\n",
      "Epoch 64/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6763 - loss: 1.7500 - val_accuracy: 0.5720 - val_loss: 1.9098 - learning_rate: 6.2500e-05\n",
      "Epoch 65/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7005 - loss: 1.6398 - val_accuracy: 0.5963 - val_loss: 1.7820 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7111 - loss: 1.6329 - val_accuracy: 0.5727 - val_loss: 1.9661 - learning_rate: 6.2500e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7012 - loss: 1.6832 - val_accuracy: 0.5930 - val_loss: 1.8172 - learning_rate: 6.2500e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7070 - loss: 1.6360 - val_accuracy: 0.6153 - val_loss: 1.7559 - learning_rate: 6.2500e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7073 - loss: 1.6228 - val_accuracy: 0.5896 - val_loss: 1.8242 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6934 - loss: 1.6478 - val_accuracy: 0.5788 - val_loss: 1.9287 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6997 - loss: 1.6452 - val_accuracy: 0.5916 - val_loss: 1.8457 - learning_rate: 6.2500e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.6847 - loss: 1.7368 - val_accuracy: 0.5984 - val_loss: 1.8650 - learning_rate: 6.2500e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7076 - loss: 1.6818 - val_accuracy: 0.5869 - val_loss: 1.8293 - learning_rate: 6.2500e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7213 - loss: 1.5964 - val_accuracy: 0.5680 - val_loss: 1.8935 - learning_rate: 6.2500e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7028 - loss: 1.5966 - val_accuracy: 0.5761 - val_loss: 1.8875 - learning_rate: 6.2500e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7064 - loss: 1.7034\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7063 - loss: 1.7032 - val_accuracy: 0.6058 - val_loss: 1.7791 - learning_rate: 6.2500e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.6670 - loss: 1.7574 - val_accuracy: 0.6004 - val_loss: 1.7952 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.6879 - loss: 1.6833 - val_accuracy: 0.6160 - val_loss: 1.7374 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7046 - loss: 1.7214 - val_accuracy: 0.5835 - val_loss: 1.8345 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.7163 - loss: 1.6237 - val_accuracy: 0.5903 - val_loss: 1.8772 - learning_rate: 3.1250e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7113 - loss: 1.6505 - val_accuracy: 0.5903 - val_loss: 1.8132 - learning_rate: 3.1250e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.6989 - loss: 1.7062 - val_accuracy: 0.5619 - val_loss: 1.9017 - learning_rate: 3.1250e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6856 - loss: 1.7278 - val_accuracy: 0.5734 - val_loss: 1.8982 - learning_rate: 3.1250e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.7038 - loss: 1.6698 - val_accuracy: 0.5612 - val_loss: 1.9113 - learning_rate: 3.1250e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7457 - loss: 1.5805 - val_accuracy: 0.5794 - val_loss: 1.8533 - learning_rate: 3.1250e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7275 - loss: 1.5497\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 81ms/step - accuracy: 0.7275 - loss: 1.5501 - val_accuracy: 0.6065 - val_loss: 1.8501 - learning_rate: 3.1250e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7301 - loss: 1.5672 - val_accuracy: 0.5903 - val_loss: 1.8016 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.7359 - loss: 1.5316 - val_accuracy: 0.6045 - val_loss: 1.7666 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7325 - loss: 1.5421 - val_accuracy: 0.5828 - val_loss: 1.8191 - learning_rate: 1.5625e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7102 - loss: 1.6608 - val_accuracy: 0.5822 - val_loss: 1.8872 - learning_rate: 1.5625e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7391 - loss: 1.5385 - val_accuracy: 0.6072 - val_loss: 1.7773 - learning_rate: 1.5625e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7291 - loss: 1.5800 - val_accuracy: 0.6099 - val_loss: 1.7737 - learning_rate: 1.5625e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7390 - loss: 1.5371 - val_accuracy: 0.5835 - val_loss: 1.8754 - learning_rate: 1.5625e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7200 - loss: 1.6256 - val_accuracy: 0.5747 - val_loss: 1.8861 - learning_rate: 1.5625e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7587 - loss: 1.4725\n",
      "Epoch 95: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7585 - loss: 1.4732 - val_accuracy: 0.5903 - val_loss: 1.8697 - learning_rate: 1.5625e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7222 - loss: 1.6077 - val_accuracy: 0.6024 - val_loss: 1.7383 - learning_rate: 7.8125e-06\n",
      "Epoch 97/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7403 - loss: 1.5735 - val_accuracy: 0.5815 - val_loss: 1.8388 - learning_rate: 7.8125e-06\n",
      "Epoch 98/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7443 - loss: 1.5522 - val_accuracy: 0.5957 - val_loss: 1.8316 - learning_rate: 7.8125e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7261 - loss: 1.5946 - val_accuracy: 0.5882 - val_loss: 1.8476 - learning_rate: 7.8125e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7505 - loss: 1.5078 - val_accuracy: 0.6004 - val_loss: 1.7933 - learning_rate: 7.8125e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7366 - loss: 1.5657 - val_accuracy: 0.6004 - val_loss: 1.7878 - learning_rate: 7.8125e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7157 - loss: 1.6392 - val_accuracy: 0.5808 - val_loss: 1.9136 - learning_rate: 7.8125e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7239 - loss: 1.6016 - val_accuracy: 0.5984 - val_loss: 1.8007 - learning_rate: 7.8125e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7236 - loss: 1.6263\n",
      "Epoch 104: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7236 - loss: 1.6263 - val_accuracy: 0.5930 - val_loss: 1.8274 - learning_rate: 7.8125e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7107 - loss: 1.6391 - val_accuracy: 0.6078 - val_loss: 1.7510 - learning_rate: 3.9063e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7068 - loss: 1.6734 - val_accuracy: 0.5991 - val_loss: 1.7926 - learning_rate: 3.9063e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7152 - loss: 1.6464 - val_accuracy: 0.6112 - val_loss: 1.7764 - learning_rate: 3.9063e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7240 - loss: 1.6109 - val_accuracy: 0.5693 - val_loss: 1.9038 - learning_rate: 3.9063e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7224 - loss: 1.5794 - val_accuracy: 0.6092 - val_loss: 1.7907 - learning_rate: 3.9063e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7260 - loss: 1.5765 - val_accuracy: 0.5896 - val_loss: 1.8236 - learning_rate: 3.9063e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7559 - loss: 1.4916 - val_accuracy: 0.5984 - val_loss: 1.8162 - learning_rate: 3.9063e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7141 - loss: 1.5702 - val_accuracy: 0.5963 - val_loss: 1.8852 - learning_rate: 3.9063e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7235 - loss: 1.6109\n",
      "Epoch 113: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7237 - loss: 1.6104 - val_accuracy: 0.5970 - val_loss: 1.7946 - learning_rate: 3.9063e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 85ms/step - accuracy: 0.7258 - loss: 1.6035 - val_accuracy: 0.6214 - val_loss: 1.7631 - learning_rate: 3.0000e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7316 - loss: 1.5772 - val_accuracy: 0.6099 - val_loss: 1.7498 - learning_rate: 3.0000e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7046 - loss: 1.6391 - val_accuracy: 0.5835 - val_loss: 1.8394 - learning_rate: 3.0000e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7084 - loss: 1.7163 - val_accuracy: 0.6200 - val_loss: 1.7495 - learning_rate: 3.0000e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7187 - loss: 1.6265 - val_accuracy: 0.6024 - val_loss: 1.7659 - learning_rate: 3.0000e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7164 - loss: 1.6052 - val_accuracy: 0.5943 - val_loss: 1.8227 - learning_rate: 3.0000e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7562 - loss: 1.5126 - val_accuracy: 0.6038 - val_loss: 1.7907 - learning_rate: 3.0000e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7403 - loss: 1.5691 - val_accuracy: 0.5855 - val_loss: 1.8112 - learning_rate: 3.0000e-06\n",
      "Epoch 122/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7598 - loss: 1.4409 - val_accuracy: 0.5909 - val_loss: 1.8965 - learning_rate: 3.0000e-06\n",
      "Epoch 123/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7085 - loss: 1.6701 - val_accuracy: 0.5903 - val_loss: 1.8250 - learning_rate: 3.0000e-06\n",
      "Epoch 124/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7552 - loss: 1.5241 - val_accuracy: 0.5936 - val_loss: 1.8733 - learning_rate: 3.0000e-06\n",
      "Epoch 125/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7292 - loss: 1.5210 - val_accuracy: 0.5896 - val_loss: 1.8124 - learning_rate: 3.0000e-06\n",
      "Epoch 126/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - accuracy: 0.7172 - loss: 1.6340 - val_accuracy: 0.5916 - val_loss: 1.8181 - learning_rate: 3.0000e-06\n",
      "Epoch 127/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.7163 - loss: 1.7133 - val_accuracy: 0.6051 - val_loss: 1.8429 - learning_rate: 3.0000e-06\n",
      "Epoch 128/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7520 - loss: 1.4996 - val_accuracy: 0.5869 - val_loss: 1.8530 - learning_rate: 3.0000e-06\n",
      "Epoch 129/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7032 - loss: 1.6715 - val_accuracy: 0.5923 - val_loss: 1.7920 - learning_rate: 3.0000e-06\n",
      "Epoch 130/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7509 - loss: 1.5663 - val_accuracy: 0.5930 - val_loss: 1.8155 - learning_rate: 3.0000e-06\n",
      "Epoch 131/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7409 - loss: 1.5340 - val_accuracy: 0.5916 - val_loss: 1.8158 - learning_rate: 3.0000e-06\n",
      "Epoch 132/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7174 - loss: 1.6277 - val_accuracy: 0.5963 - val_loss: 1.7968 - learning_rate: 3.0000e-06\n",
      "Epoch 133/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7528 - loss: 1.5108 - val_accuracy: 0.5754 - val_loss: 1.8497 - learning_rate: 3.0000e-06\n",
      "Epoch 134/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7066 - loss: 1.6187 - val_accuracy: 0.5970 - val_loss: 1.7910 - learning_rate: 3.0000e-06\n",
      "Epoch 135/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7306 - loss: 1.5899 - val_accuracy: 0.5734 - val_loss: 1.8474 - learning_rate: 3.0000e-06\n",
      "Epoch 136/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7088 - loss: 1.6553 - val_accuracy: 0.6045 - val_loss: 1.7527 - learning_rate: 3.0000e-06\n",
      "Epoch 137/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7455 - loss: 1.5170 - val_accuracy: 0.5916 - val_loss: 1.8407 - learning_rate: 3.0000e-06\n",
      "Epoch 138/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7286 - loss: 1.6155 - val_accuracy: 0.6065 - val_loss: 1.7693 - learning_rate: 3.0000e-06\n",
      "Epoch 139/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.7127 - loss: 1.6595 - val_accuracy: 0.5774 - val_loss: 1.8687 - learning_rate: 3.0000e-06\n",
      "Epoch 140/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7279 - loss: 1.5878 - val_accuracy: 0.5896 - val_loss: 1.8281 - learning_rate: 3.0000e-06\n",
      "Epoch 141/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7362 - loss: 1.5839 - val_accuracy: 0.5666 - val_loss: 1.8180 - learning_rate: 3.0000e-06\n",
      "Epoch 142/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7356 - loss: 1.5513 - val_accuracy: 0.5923 - val_loss: 1.8230 - learning_rate: 3.0000e-06\n",
      "Epoch 143/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7352 - loss: 1.5494 - val_accuracy: 0.5957 - val_loss: 1.8276 - learning_rate: 3.0000e-06\n",
      "Epoch 144/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7358 - loss: 1.5682 - val_accuracy: 0.6051 - val_loss: 1.8434 - learning_rate: 3.0000e-06\n",
      "Epoch 145/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.7235 - loss: 1.5980 - val_accuracy: 0.5720 - val_loss: 1.8519 - learning_rate: 3.0000e-06\n",
      "Epoch 146/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 91ms/step - accuracy: 0.7005 - loss: 1.6522 - val_accuracy: 0.5849 - val_loss: 1.8721 - learning_rate: 3.0000e-06\n",
      "Epoch 147/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7149 - loss: 1.5966 - val_accuracy: 0.5963 - val_loss: 1.8297 - learning_rate: 3.0000e-06\n",
      "Epoch 148/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7236 - loss: 1.5805 - val_accuracy: 0.5754 - val_loss: 1.8595 - learning_rate: 3.0000e-06\n",
      "Epoch 149/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7181 - loss: 1.6739 - val_accuracy: 0.5930 - val_loss: 1.8317 - learning_rate: 3.0000e-06\n",
      "Epoch 150/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.7256 - loss: 1.5951 - val_accuracy: 0.5855 - val_loss: 1.8759 - learning_rate: 3.0000e-06\n",
      "Epoch 151/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.7257 - loss: 1.6738 - val_accuracy: 0.5652 - val_loss: 1.8850 - learning_rate: 3.0000e-06\n",
      "Epoch 152/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.7324 - loss: 1.5326 - val_accuracy: 0.5855 - val_loss: 1.8489 - learning_rate: 3.0000e-06\n",
      "Epoch 153/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 83ms/step - accuracy: 0.7231 - loss: 1.6174 - val_accuracy: 0.5977 - val_loss: 1.8154 - learning_rate: 3.0000e-06\n",
      "Epoch 154/160\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7143 - loss: 1.6321 - val_accuracy: 0.5855 - val_loss: 1.8177 - learning_rate: 3.0000e-06\n",
      "Epoch 154: early stopping\n",
      "Restoring model weights from the end of the best epoch: 114.\n",
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_3/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_3/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi: transformer_imu_only_5folds/gesture_model_fold_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 21:06:11.896877: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "\n",
      "===== FOLD 5/5 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 94ms/step - accuracy: 0.0948 - loss: 8.9606 - val_accuracy: 0.2963 - val_loss: 7.3285 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.1950 - loss: 7.3250 - val_accuracy: 0.3331 - val_loss: 6.3673 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.2745 - loss: 6.3656 - val_accuracy: 0.3731 - val_loss: 5.6704 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.3318 - loss: 5.5974 - val_accuracy: 0.3970 - val_loss: 5.1652 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.3592 - loss: 5.2036 - val_accuracy: 0.4216 - val_loss: 4.5709 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.3810 - loss: 4.6457 - val_accuracy: 0.4241 - val_loss: 4.2727 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.4186 - loss: 4.1645 - val_accuracy: 0.4333 - val_loss: 3.9490 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.4321 - loss: 3.7977 - val_accuracy: 0.4339 - val_loss: 3.6444 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.4439 - loss: 3.5611 - val_accuracy: 0.4616 - val_loss: 3.2716 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 92ms/step - accuracy: 0.4558 - loss: 3.2663 - val_accuracy: 0.4518 - val_loss: 3.1224 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.4838 - loss: 3.0039 - val_accuracy: 0.4794 - val_loss: 2.9379 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.4898 - loss: 2.8457 - val_accuracy: 0.4751 - val_loss: 2.7169 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.5177 - loss: 2.6679 - val_accuracy: 0.4819 - val_loss: 2.6667 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.4731 - loss: 2.7252 - val_accuracy: 0.4923 - val_loss: 2.5182 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 90ms/step - accuracy: 0.5139 - loss: 2.4479 - val_accuracy: 0.5126 - val_loss: 2.4414 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.5413 - loss: 2.3265 - val_accuracy: 0.5034 - val_loss: 2.3453 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.5482 - loss: 2.3436 - val_accuracy: 0.5249 - val_loss: 2.2755 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.5407 - loss: 2.2418 - val_accuracy: 0.5083 - val_loss: 2.2169 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.5253 - loss: 2.2856 - val_accuracy: 0.5310 - val_loss: 2.1191 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.5197 - loss: 2.2346 - val_accuracy: 0.5144 - val_loss: 2.2184 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.5399 - loss: 2.1523 - val_accuracy: 0.5255 - val_loss: 2.1280 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 85ms/step - accuracy: 0.5393 - loss: 2.0691 - val_accuracy: 0.5144 - val_loss: 2.0719 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.5512 - loss: 2.0471 - val_accuracy: 0.5126 - val_loss: 2.0703 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.5660 - loss: 1.9825 - val_accuracy: 0.4929 - val_loss: 2.1221 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 87ms/step - accuracy: 0.5874 - loss: 1.9280 - val_accuracy: 0.5163 - val_loss: 2.0845 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.5611 - loss: 2.0408 - val_accuracy: 0.5052 - val_loss: 2.1121 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.5833 - loss: 1.9544\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.5833 - loss: 1.9545 - val_accuracy: 0.5206 - val_loss: 1.9769 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 88ms/step - accuracy: 0.5771 - loss: 1.9972 - val_accuracy: 0.5421 - val_loss: 2.0186 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.5759 - loss: 1.9742 - val_accuracy: 0.5464 - val_loss: 2.0214 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.5913 - loss: 1.9537 - val_accuracy: 0.5569 - val_loss: 1.9353 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6196 - loss: 1.8927 - val_accuracy: 0.5347 - val_loss: 1.9748 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6244 - loss: 1.8424 - val_accuracy: 0.5409 - val_loss: 2.0062 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6545 - loss: 1.7087 - val_accuracy: 0.5513 - val_loss: 1.9742 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6470 - loss: 1.7199 - val_accuracy: 0.5433 - val_loss: 1.9615 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6219 - loss: 1.8874 - val_accuracy: 0.5495 - val_loss: 1.9801 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6089 - loss: 1.8623 - val_accuracy: 0.5274 - val_loss: 1.9702 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6448 - loss: 1.7549 - val_accuracy: 0.5581 - val_loss: 1.9571 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6160 - loss: 1.8562 - val_accuracy: 0.5655 - val_loss: 1.9171 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6172 - loss: 1.8704 - val_accuracy: 0.5458 - val_loss: 1.9653 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6555 - loss: 1.7595 - val_accuracy: 0.5384 - val_loss: 1.9868 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6437 - loss: 1.7582 - val_accuracy: 0.5323 - val_loss: 1.9303 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6686 - loss: 1.6712 - val_accuracy: 0.5612 - val_loss: 1.8788 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 86ms/step - accuracy: 0.6404 - loss: 1.7502 - val_accuracy: 0.5415 - val_loss: 1.9853 - learning_rate: 2.5000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6398 - loss: 1.7799 - val_accuracy: 0.5476 - val_loss: 1.9573 - learning_rate: 2.5000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6424 - loss: 1.7807 - val_accuracy: 0.5894 - val_loss: 1.7956 - learning_rate: 2.5000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6692 - loss: 1.6481 - val_accuracy: 0.5538 - val_loss: 1.9696 - learning_rate: 2.5000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6490 - loss: 1.7517 - val_accuracy: 0.5409 - val_loss: 1.9964 - learning_rate: 2.5000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6520 - loss: 1.7086 - val_accuracy: 0.5470 - val_loss: 1.9251 - learning_rate: 2.5000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6413 - loss: 1.7846 - val_accuracy: 0.5753 - val_loss: 1.8436 - learning_rate: 2.5000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6558 - loss: 1.7061 - val_accuracy: 0.5802 - val_loss: 1.8392 - learning_rate: 2.5000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6475 - loss: 1.7961 - val_accuracy: 0.5747 - val_loss: 1.8721 - learning_rate: 2.5000e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6556 - loss: 1.7818 - val_accuracy: 0.5403 - val_loss: 1.9354 - learning_rate: 2.5000e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6779 - loss: 1.7095\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6778 - loss: 1.7097 - val_accuracy: 0.5605 - val_loss: 1.9059 - learning_rate: 2.5000e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6778 - loss: 1.7430 - val_accuracy: 0.5839 - val_loss: 1.8355 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6990 - loss: 1.6666 - val_accuracy: 0.5728 - val_loss: 1.9157 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7131 - loss: 1.5985 - val_accuracy: 0.5704 - val_loss: 1.8832 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6978 - loss: 1.6908 - val_accuracy: 0.5821 - val_loss: 1.8299 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6817 - loss: 1.6906 - val_accuracy: 0.5765 - val_loss: 1.9031 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7376 - loss: 1.5586 - val_accuracy: 0.5950 - val_loss: 1.8535 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7484 - loss: 1.5141 - val_accuracy: 0.5704 - val_loss: 1.9012 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7056 - loss: 1.6593 - val_accuracy: 0.5716 - val_loss: 1.8643 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7354 - loss: 1.5649 - val_accuracy: 0.5747 - val_loss: 1.8754 - learning_rate: 1.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7064 - loss: 1.6484 - val_accuracy: 0.5925 - val_loss: 1.8240 - learning_rate: 1.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.6883 - loss: 1.6689 - val_accuracy: 0.6036 - val_loss: 1.7781 - learning_rate: 1.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7217 - loss: 1.5863 - val_accuracy: 0.5802 - val_loss: 1.8496 - learning_rate: 1.2500e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7144 - loss: 1.6373 - val_accuracy: 0.5587 - val_loss: 1.8793 - learning_rate: 1.2500e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7179 - loss: 1.6419 - val_accuracy: 0.5778 - val_loss: 1.8581 - learning_rate: 1.2500e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7002 - loss: 1.6206 - val_accuracy: 0.5808 - val_loss: 1.8687 - learning_rate: 1.2500e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7465 - loss: 1.5288 - val_accuracy: 0.5808 - val_loss: 1.8399 - learning_rate: 1.2500e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7255 - loss: 1.5489 - val_accuracy: 0.5747 - val_loss: 1.8889 - learning_rate: 1.2500e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7498 - loss: 1.5430 - val_accuracy: 0.5612 - val_loss: 1.8734 - learning_rate: 1.2500e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7158 - loss: 1.6060\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7158 - loss: 1.6057 - val_accuracy: 0.5771 - val_loss: 1.9101 - learning_rate: 1.2500e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.6962 - loss: 1.6873 - val_accuracy: 0.5741 - val_loss: 1.8614 - learning_rate: 6.2500e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7455 - loss: 1.5723 - val_accuracy: 0.5538 - val_loss: 1.9847 - learning_rate: 6.2500e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7474 - loss: 1.4714 - val_accuracy: 0.5661 - val_loss: 1.9261 - learning_rate: 6.2500e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7215 - loss: 1.6457 - val_accuracy: 0.5882 - val_loss: 1.8492 - learning_rate: 6.2500e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7345 - loss: 1.6038 - val_accuracy: 0.6042 - val_loss: 1.8113 - learning_rate: 6.2500e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7569 - loss: 1.5505 - val_accuracy: 0.5931 - val_loss: 1.8072 - learning_rate: 6.2500e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7443 - loss: 1.6257 - val_accuracy: 0.6091 - val_loss: 1.7607 - learning_rate: 6.2500e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7581 - loss: 1.4521 - val_accuracy: 0.5618 - val_loss: 1.9421 - learning_rate: 6.2500e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7543 - loss: 1.5305 - val_accuracy: 0.5913 - val_loss: 1.8951 - learning_rate: 6.2500e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7710 - loss: 1.4990 - val_accuracy: 0.5808 - val_loss: 1.8977 - learning_rate: 6.2500e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7495 - loss: 1.5924 - val_accuracy: 0.5839 - val_loss: 1.8566 - learning_rate: 6.2500e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7191 - loss: 1.5836 - val_accuracy: 0.5993 - val_loss: 1.8237 - learning_rate: 6.2500e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7702 - loss: 1.4950 - val_accuracy: 0.6103 - val_loss: 1.7550 - learning_rate: 6.2500e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7063 - loss: 1.6905 - val_accuracy: 0.5759 - val_loss: 1.9054 - learning_rate: 6.2500e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7608 - loss: 1.5107 - val_accuracy: 0.5894 - val_loss: 1.8135 - learning_rate: 6.2500e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7762 - loss: 1.4723 - val_accuracy: 0.5821 - val_loss: 1.8971 - learning_rate: 6.2500e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7695 - loss: 1.4851 - val_accuracy: 0.5673 - val_loss: 1.9479 - learning_rate: 6.2500e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7498 - loss: 1.5514 - val_accuracy: 0.5747 - val_loss: 1.9124 - learning_rate: 6.2500e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7683 - loss: 1.4914 - val_accuracy: 0.5962 - val_loss: 1.8209 - learning_rate: 6.2500e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7549 - loss: 1.5422 - val_accuracy: 0.5888 - val_loss: 1.8210 - learning_rate: 6.2500e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7431 - loss: 1.5701\n",
      "Epoch 93: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7431 - loss: 1.5705 - val_accuracy: 0.5974 - val_loss: 1.8562 - learning_rate: 6.2500e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7699 - loss: 1.4660 - val_accuracy: 0.5907 - val_loss: 1.8406 - learning_rate: 3.1250e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7731 - loss: 1.5150 - val_accuracy: 0.5802 - val_loss: 1.8559 - learning_rate: 3.1250e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7442 - loss: 1.5645 - val_accuracy: 0.5716 - val_loss: 1.9507 - learning_rate: 3.1250e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7885 - loss: 1.4447 - val_accuracy: 0.6220 - val_loss: 1.7717 - learning_rate: 3.1250e-05\n",
      "Epoch 98/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7588 - loss: 1.5397 - val_accuracy: 0.5857 - val_loss: 1.8344 - learning_rate: 3.1250e-05\n",
      "Epoch 99/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7272 - loss: 1.5934 - val_accuracy: 0.5734 - val_loss: 1.8908 - learning_rate: 3.1250e-05\n",
      "Epoch 100/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7728 - loss: 1.4778 - val_accuracy: 0.5636 - val_loss: 1.9379 - learning_rate: 3.1250e-05\n",
      "Epoch 101/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7802 - loss: 1.4615 - val_accuracy: 0.5962 - val_loss: 1.8730 - learning_rate: 3.1250e-05\n",
      "Epoch 102/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7576 - loss: 1.5603 - val_accuracy: 0.5950 - val_loss: 1.8277 - learning_rate: 3.1250e-05\n",
      "Epoch 103/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7958 - loss: 1.4097 - val_accuracy: 0.6171 - val_loss: 1.7251 - learning_rate: 3.1250e-05\n",
      "Epoch 104/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.8043 - loss: 1.3492 - val_accuracy: 0.5876 - val_loss: 1.9353 - learning_rate: 3.1250e-05\n",
      "Epoch 105/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7603 - loss: 1.5335\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7603 - loss: 1.5335 - val_accuracy: 0.5845 - val_loss: 1.8688 - learning_rate: 3.1250e-05\n",
      "Epoch 106/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7913 - loss: 1.4879 - val_accuracy: 0.5507 - val_loss: 2.0146 - learning_rate: 1.5625e-05\n",
      "Epoch 107/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7865 - loss: 1.4630 - val_accuracy: 0.5900 - val_loss: 1.8229 - learning_rate: 1.5625e-05\n",
      "Epoch 108/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7735 - loss: 1.4550 - val_accuracy: 0.6073 - val_loss: 1.7879 - learning_rate: 1.5625e-05\n",
      "Epoch 109/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7852 - loss: 1.4342 - val_accuracy: 0.5734 - val_loss: 1.9542 - learning_rate: 1.5625e-05\n",
      "Epoch 110/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7625 - loss: 1.5557 - val_accuracy: 0.5648 - val_loss: 1.9358 - learning_rate: 1.5625e-05\n",
      "Epoch 111/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7725 - loss: 1.5216 - val_accuracy: 0.5950 - val_loss: 1.8599 - learning_rate: 1.5625e-05\n",
      "Epoch 112/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7654 - loss: 1.4912 - val_accuracy: 0.5943 - val_loss: 1.8316 - learning_rate: 1.5625e-05\n",
      "Epoch 113/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7868 - loss: 1.4664 - val_accuracy: 0.5790 - val_loss: 1.8529 - learning_rate: 1.5625e-05\n",
      "Epoch 114/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7744 - loss: 1.5177\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7746 - loss: 1.5170 - val_accuracy: 0.6030 - val_loss: 1.8295 - learning_rate: 1.5625e-05\n",
      "Epoch 115/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7781 - loss: 1.5159 - val_accuracy: 0.5698 - val_loss: 1.8869 - learning_rate: 7.8125e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7500 - loss: 1.5432 - val_accuracy: 0.6171 - val_loss: 1.7377 - learning_rate: 7.8125e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.8122 - loss: 1.4347 - val_accuracy: 0.5943 - val_loss: 1.8467 - learning_rate: 7.8125e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7810 - loss: 1.5309 - val_accuracy: 0.5993 - val_loss: 1.8250 - learning_rate: 7.8125e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7996 - loss: 1.4102 - val_accuracy: 0.5833 - val_loss: 1.9030 - learning_rate: 7.8125e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.8175 - loss: 1.3953 - val_accuracy: 0.5943 - val_loss: 1.8180 - learning_rate: 7.8125e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7712 - loss: 1.4589 - val_accuracy: 0.6030 - val_loss: 1.8274 - learning_rate: 7.8125e-06\n",
      "Epoch 122/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.8284 - loss: 1.3776 - val_accuracy: 0.5894 - val_loss: 1.8506 - learning_rate: 7.8125e-06\n",
      "Epoch 123/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7593 - loss: 1.5470\n",
      "Epoch 123: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7592 - loss: 1.5472 - val_accuracy: 0.5851 - val_loss: 1.8230 - learning_rate: 7.8125e-06\n",
      "Epoch 124/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7479 - loss: 1.6124 - val_accuracy: 0.5882 - val_loss: 1.8757 - learning_rate: 3.9063e-06\n",
      "Epoch 125/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7910 - loss: 1.4271 - val_accuracy: 0.5796 - val_loss: 1.8935 - learning_rate: 3.9063e-06\n",
      "Epoch 126/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.8225 - loss: 1.3568 - val_accuracy: 0.5833 - val_loss: 1.8566 - learning_rate: 3.9063e-06\n",
      "Epoch 127/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7518 - loss: 1.6009 - val_accuracy: 0.6011 - val_loss: 1.7868 - learning_rate: 3.9063e-06\n",
      "Epoch 128/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7563 - loss: 1.5369 - val_accuracy: 0.5919 - val_loss: 1.9022 - learning_rate: 3.9063e-06\n",
      "Epoch 129/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7706 - loss: 1.4647 - val_accuracy: 0.5943 - val_loss: 1.8399 - learning_rate: 3.9063e-06\n",
      "Epoch 130/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7865 - loss: 1.5074 - val_accuracy: 0.5691 - val_loss: 1.9563 - learning_rate: 3.9063e-06\n",
      "Epoch 131/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.8055 - loss: 1.4327 - val_accuracy: 0.5864 - val_loss: 1.8513 - learning_rate: 3.9063e-06\n",
      "Epoch 132/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7855 - loss: 1.5267\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7854 - loss: 1.5267 - val_accuracy: 0.5728 - val_loss: 1.8884 - learning_rate: 3.9063e-06\n",
      "Epoch 133/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7748 - loss: 1.5048 - val_accuracy: 0.5747 - val_loss: 1.9636 - learning_rate: 3.0000e-06\n",
      "Epoch 134/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 82ms/step - accuracy: 0.7694 - loss: 1.5155 - val_accuracy: 0.5741 - val_loss: 1.9170 - learning_rate: 3.0000e-06\n",
      "Epoch 135/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7771 - loss: 1.5539 - val_accuracy: 0.5808 - val_loss: 1.8394 - learning_rate: 3.0000e-06\n",
      "Epoch 136/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 83ms/step - accuracy: 0.7825 - loss: 1.4872 - val_accuracy: 0.6079 - val_loss: 1.8213 - learning_rate: 3.0000e-06\n",
      "Epoch 137/160\n",
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 84ms/step - accuracy: 0.7834 - loss: 1.4978 - val_accuracy: 0.5784 - val_loss: 1.8759 - learning_rate: 3.0000e-06\n",
      "Epoch 137: early stopping\n",
      "Restoring model weights from the end of the best epoch: 97.\n",
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: transformer_imu_only_5folds/gesture_model_fold_4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model kaydedildi: transformer_imu_only_5folds/gesture_model_fold_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-07 21:25:21.475544: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "\n",
      "✔ Training done.\n",
      "Overall OOF H‑F1 Score = 0.7522\n"
     ]
    }
   ],
   "source": [
    "if TRAIN: \n",
    "    print(\"▶ TRAIN MODE – loading dataset ...\")\n",
    "    df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "    \n",
    "    train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df['gesture_int'] = le.fit_transform(df['gesture'])\n",
    "    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "\n",
    "    acc_y_neg_subjects = (\n",
    "        df.groupby('subject')['acc_y']\n",
    "        .mean()\n",
    "        .loc[lambda x: x < 0]\n",
    "        .index\n",
    "        .tolist()\n",
    "    )\n",
    "\n",
    "    print(\"acc_y ortalaması negatif olan subject'ler:\", acc_y_neg_subjects)\n",
    "    df = df[~df['subject'].isin(acc_y_neg_subjects)].reset_index(drop=True)\n",
    "    \n",
    "    print(\"  Removing gravity and calculating linear acceleration features...\")\n",
    "    linear_accel_list = [pd.DataFrame(remove_gravity_from_acc(group[['acc_x', 'acc_y', 'acc_z']], group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "    df = pd.concat([df, pd.concat(linear_accel_list)], axis=1)\n",
    "    \n",
    "    df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n",
    "    df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0)\n",
    "    \n",
    "    print(\"  Calculating angular velocity and distance from quaternions...\")\n",
    "    angular_vel_list = [pd.DataFrame(calculate_angular_velocity_from_quat(group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "    df = pd.concat([df, pd.concat(angular_vel_list)], axis=1)\n",
    "    angular_dist_list = [pd.DataFrame(calculate_angular_distance(group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['angular_distance'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "    df = pd.concat([df, pd.concat(angular_dist_list)], axis=1)\n",
    "\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z',  'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z']:\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_diff'] = df.groupby('sequence_id')[col].diff().fillna(0)\n",
    "            df[f'{col}_abs_diff'] = np.abs(df.groupby('sequence_id')[col].diff()).fillna(0)\n",
    "\n",
    "    imu_cols_base = ['acc_x', 'acc_y', 'acc_z'] + [c for c in df.columns if c.startswith('rot_')]\n",
    "    imu_engineered = [\n",
    "    'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance'\n",
    "    ]\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z']:\n",
    "        if col in df.columns:\n",
    "            imu_engineered.append(f'{col}_diff')\n",
    "            imu_engineered.append(f'{col}_abs_diff')\n",
    "    imu_cols = list(dict.fromkeys(imu_cols_base + imu_engineered))\n",
    "    \n",
    "    thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n",
    "    \n",
    "    tof_aggregated_cols_template = []\n",
    "    for i in range(1, 6): tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        tof_aggregated_cols_template.extend([\n",
    "            f'tof_{i}_grad_mean', f'tof_{i}_grad_std', f'tof_{i}_grad_max'\n",
    "        ])\n",
    "    \n",
    "    final_feature_cols = imu_cols\n",
    "\n",
    "    imu_dim_final = len(imu_cols)\n",
    "    tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n",
    "    \n",
    "    print(f\"  IMU (phys-based + enhanced) {imu_dim_final} | THM + Aggregated TOF {tof_thm_aggregated_dim_final} | total {len(final_feature_cols)} features\")\n",
    "    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n",
    "\n",
    "    print(\"  Building sequences...\")\n",
    "    seq_gp = df.groupby('sequence_id')\n",
    "    X_list_unscaled, y_list_int, groups_list, lens = [], [], [], []\n",
    "    for seq_id, seq_df in seq_gp:\n",
    "        seq_df_copy = seq_df.copy()\n",
    "        for i in range(1, 6):\n",
    "            pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]; tof_data = seq_df_copy[pixel_cols].replace(-1, np.nan)\n",
    "            seq_df_copy[f'tof_{i}_mean'], seq_df_copy[f'tof_{i}_std'], seq_df_copy[f'tof_{i}_min'], seq_df_copy[f'tof_{i}_max'] = tof_data.mean(axis=1), tof_data.std(axis=1), tof_data.min(axis=1), tof_data.max(axis=1)\n",
    "            \n",
    "            spatial_feats = calculate_spatial_tof_features(seq_df_copy, i)\n",
    "            seq_df_copy = pd.concat([seq_df_copy, spatial_feats], axis=1)\n",
    "        \n",
    "        X_list_unscaled.append(seq_df_copy[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32'))\n",
    "        y_list_int.append(seq_df_copy['gesture_int'].iloc[0])\n",
    "        groups_list.append(seq_df_copy['subject'].iloc[0])\n",
    "        lens.append(len(seq_df_copy))\n",
    "\n",
    "    print(\"  Fitting StandardScaler...\")\n",
    "    all_steps_concatenated = np.concatenate(X_list_unscaled, axis=0)\n",
    "    scaler = StandardScaler().fit(all_steps_concatenated)\n",
    "    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n",
    "    \n",
    "    print(\"  Scaling and padding sequences...\")\n",
    "    X_scaled_list = [scaler.transform(x_seq) for x_seq in X_list_unscaled]\n",
    "    pad_len = int(np.percentile(lens, PAD_PERCENTILE)); np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n",
    "    X = pad_sequences(X_scaled_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "    subject_acc_x_mean_global = df.groupby('subject')['acc_x'].mean()\n",
    "    subject_is_acc_x_mean_negative = (subject_acc_x_mean_global < 0).astype(str)\n",
    "    \n",
    "    y_stratify = np.array([f\"{gesture_label}_{subject_is_acc_x_mean_negative.loc[sub_id]}\"\n",
    "                           for gesture_label, sub_id in zip(y_list_int, groups_list)])\n",
    "    \n",
    "    groups, y = np.array(groups_list), to_categorical(y_list_int, num_classes=len(le.classes_))\n",
    "    print(\"  Starting training with Stratified Group K-Fold CV...\")\n",
    "    sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=state) # state_num yerine state kullanıldı\n",
    "    oof_preds = np.zeros_like(y, dtype='float32')\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y_stratify, groups)):\n",
    "        print(f\"\\n===== FOLD {fold+1}/{N_SPLITS} =====\")\n",
    "        X_tr, X_val, y_tr, y_val = X[train_idx], X[val_idx], y[train_idx], y[val_idx]# y_val düzeltildi\n",
    "        \n",
    "        # --- DEĞİŞİKLİK BAŞLANGICI ---\n",
    "        # Modelinizi burada çağırın\n",
    "        model = build_competition_ready_transformer(\n",
    "            pad_len, imu_dim_final, len(le.classes_)\n",
    "        )\n",
    "\n",
    "        # Custom katmanları compile ve save/load için kaydet.\n",
    "        # Bu custom_objects, model.save() ve tf.keras.models.load_model() için gereklidir.\n",
    "        # custom_objects_for_model = {\n",
    "        #     'TransformerEncoderBlock': TransformerEncoderBlock,\n",
    "        #     'PositionalEmbedding': PositionalEmbedding,\n",
    "        #     # Eğer residual_se_cnn_block ve attention_layer custom Layer ise, onları da ekleyin.\n",
    "        #     # Şu anki tanımlarınız Layer sınıfından kalıtım almadığı için gerekmez,\n",
    "        #     # ancak Layer olarak yeniden yazarsanız eklersiniz.\n",
    "        # }\n",
    "        # --- DEĞİŞİKLİK SONU ---\n",
    "\n",
    "        lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=8,\n",
    "            cooldown=2,\n",
    "            min_lr=3e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        model.compile(optimizer=Adam(learning_rate=LR_INIT), # learning_rate argümanı kullanıldı\n",
    "                      loss={'main_output': tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)},\n",
    "                      loss_weights={'main_output': 1.0},\n",
    "                      metrics={'main_output': 'accuracy'})\n",
    "        \n",
    "        class_weight_dict = dict(enumerate(compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_tr.argmax(1))))\n",
    "        \n",
    "        train_gen = GatedMixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, class_weight=class_weight_dict, alpha=MIXUP_ALPHA)\n",
    "        val_gen = GatedMixupGenerator(X_val, y_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "        cb = [\n",
    "            EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1, monitor='val_accuracy', mode='max'),\n",
    "            lr_scheduler\n",
    "        ]\n",
    "        \n",
    "        model.fit(train_gen, epochs=EPOCHS, validation_data=val_gen, callbacks=cb, verbose=1)\n",
    "        \n",
    "        # --- DEĞİŞİKLİK BAŞLANGICI ---\n",
    "        # Modeli custom_objects ile kaydedin\n",
    "        model_save_path = EXPORT_DIR / f\"gesture_model_fold_{fold}\" # .h5 uzantısı olmadan bir dizin adı\n",
    "        tf.saved_model.save(model, str(model_save_path)) # SavedModel formatında kaydet\n",
    "        print(f\"Model kaydedildi: {model_save_path}\")\n",
    "        # --- DEĞİŞİKLİK SONU ---\n",
    "\n",
    "        preds_val = model.predict(X_val)\n",
    "        oof_preds[val_idx] = preds_val\n",
    "\n",
    "    print(\"\\n✔ Training done.\")\n",
    "    \n",
    "    from metric import CompetitionMetric # Import path needs to be correct\n",
    "    true_oof_int = y.argmax(1)\n",
    "    pred_oof_int = oof_preds.argmax(1)\n",
    "        \n",
    "    h_f1_oof = CompetitionMetric().calculate_hierarchical_f1(\n",
    "        pd.DataFrame({'gesture': le.classes_[true_oof_int]}),\n",
    "        pd.DataFrame({'gesture': le.classes_[pred_oof_int]}))\n",
    "    print(f\"Overall OOF H‑F1 Score = {h_f1_oof:.4f}\")\n",
    " \n",
    "# --- INFERENCE KODU ENTEGRASYONU ---\n",
    "else: # INFERENCE bloğu\n",
    "    print(\"▶ INFERENCE MODE – loading artefacts from\", PRETRAINED_DIR)\n",
    "    final_feature_cols = np.load(PRETRAINED_DIR / \"feature_cols.npy\", allow_pickle=True).tolist()\n",
    "    pad_len             = int(np.load(PRETRAINED_DIR / \"sequence_maxlen.npy\"))\n",
    "    scaler              = joblib.load(PRETRAINED_DIR / \"scaler.pkl\")\n",
    "    gesture_classes = np.load(PRETRAINED_DIR / \"gesture_classes.npy\", allow_pickle=True)\n",
    "    \n",
    "    # --- DEĞİŞİKLİK BAŞLANGICI ---\n",
    "    # Inference kısmındaki custom_objs'u güncelleyin\n",
    "    custom_objs = {\n",
    "        'TransformerEncoderBlock': TransformerEncoderBlock,\n",
    "        'PositionalEmbedding': PositionalEmbedding,\n",
    "        # 'time_sum', 'squeeze_last_axis', 'expand_last_axis', 'se_block' ve 'attention_layer'\n",
    "        # eğer sizin tarafınızdan custom Layer olarak tanımlanmışlarsa buraya eklenmeli.\n",
    "        # Örneğin, residual_se_cnn_block içinde Layer değilse, dışarıda kalabilir.\n",
    "        # Şu anki iskeletimde onları da Layer olarak düşündüm.\n",
    "        'residual_se_cnn_block': residual_se_cnn_block, # Eğer Layer kalıtımı alıyorsa\n",
    "        'attention_layer': attention_layer, # Eğer Layer kalıtımı alıyorsa\n",
    "    }\n",
    "    # --- DEĞİŞİKLİK SONU ---\n",
    "    \n",
    "    models = []\n",
    "    # print(f\"  Loading {N_SPLITS} models for ensemble inference...\")\n",
    "    # Sizin döngüdeki 5 katı model yükleme mantığınızı korudum, kendi path'lerinizi güncelleyin\n",
    "    for model_set_path in [\n",
    "        PRETRAINED_DIR, # Bu sizin kendi eğittiğiniz modeller için\n",
    "       # \"/kaggle/input/n-kg42-5folds-wtaccy-handsplit-8329\",\n",
    "       # \"/kaggle/input/n-kg83-5folds-8383-wtaccy-hs\",\n",
    "       # \"/kaggle/input/o-ls17-5folds-wtaccy-handsplit-8351\",\n",
    "       # \"/kaggle/input/om-ls38-5folds-8339-wtacc-y\"\n",
    "    ]:\n",
    "        for fold in range(N_SPLITS):\n",
    "            model_path = Path(model_set_path) / f\"gesture_model_fold_{fold}.h5\"\n",
    "            if model_path.exists(): # Modelin varlığını kontrol edin\n",
    "                model = tf.keras.models.load_model(model_path, compile=False, custom_objects = custom_objs)\n",
    "                models.append(model)\n",
    "            else:\n",
    "                print(f\"Warning: Model not found at {model_path}. Skipping.\")\n",
    "\n",
    "    print(f\"Models, scaler, feature_cols, pad_len loaded – ready for evaluation - MODEL LENGTH: {len(models)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T19:54:16.507523Z",
     "iopub.status.busy": "2025-07-03T19:54:16.507315Z",
     "iopub.status.idle": "2025-07-03T19:54:16.518619Z",
     "shell.execute_reply": "2025-07-03T19:54:16.517884Z",
     "shell.execute_reply.started": "2025-07-03T19:54:16.507508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    df_seq = sequence.to_pandas()\n",
    "    seq_df_copy = df_seq.copy() \n",
    "\n",
    "\n",
    "    linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "    df_seq['linear_acc_x'], df_seq['linear_acc_y'], df_seq['linear_acc_z'] = linear_accel[:, 0], linear_accel[:, 1], linear_accel[:, 2]\n",
    "    df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + df_seq['linear_acc_y']**2 + df_seq['linear_acc_z']**2)\n",
    "    df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0)\n",
    "    angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "    df_seq['angular_vel_x'], df_seq['angular_vel_y'], df_seq['angular_vel_z'] = angular_vel[:, 0], angular_vel[:, 1], angular_vel[:, 2]\n",
    "    df_seq['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z']:\n",
    "        if col in df_seq.columns:\n",
    "            df_seq[f'{col}_diff'] = df_seq.groupby('sequence_id')[col].diff().fillna(0)\n",
    "            df_seq[f'{col}_abs_diff'] = np.abs(df_seq.groupby('sequence_id')[col].diff()).fillna(0) # Mutlak fark\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]; tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "        df_seq[f'tof_{i}_mean'], df_seq[f'tof_{i}_std'], df_seq[f'tof_{i}_min'], df_seq[f'tof_{i}_max'] = tof_data.mean(axis=1), tof_data.std(axis=1), tof_data.min(axis=1), tof_data.max(axis=1)\n",
    "        spatial_feats = calculate_spatial_tof_features(seq_df_copy, i)\n",
    "        df_seq = pd.concat([df_seq, spatial_feats], axis=1)\n",
    "        \n",
    "        \n",
    "    mat_unscaled = df_seq[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "    mat_scaled = scaler.transform(mat_unscaled)\n",
    "    pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "   \n",
    "    all_preds = [model.predict(pad_input, verbose=0)[0] for model in models] # 主出力のみ取得\n",
    "    avg_pred = np.mean(all_preds, axis=0)\n",
    "    print(str(gesture_classes[avg_pred.argmax()]))\n",
    "    return str(gesture_classes[avg_pred.argmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T19:54:16.519668Z",
     "iopub.status.busy": "2025-07-03T19:54:16.519431Z",
     "iopub.status.idle": "2025-07-03T19:54:30.810934Z",
     "shell.execute_reply": "2025-07-03T19:54:30.810174Z",
     "shell.execute_reply.started": "2025-07-03T19:54:16.519652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not TRAIN:\n",
    "    import kaggle_evaluation.cmi_inference_server\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway(\n",
    "            data_paths=(\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7713851,
     "sourceId": 12274546,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7782242,
     "sourceId": 12344631,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 242954653,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
