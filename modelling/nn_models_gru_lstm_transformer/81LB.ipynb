{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:33.153898Z",
     "iopub.status.busy": "2025-07-04T13:28:33.153658Z",
     "iopub.status.idle": "2025-07-04T13:28:51.892980Z",
     "shell.execute_reply": "2025-07-04T13:28:51.892035Z",
     "shell.execute_reply.started": "2025-07-04T13:28:33.153878Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-02 09:28:43.800486: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-02 09:28:41.235839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756794521.316467  281726 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756794521.340551  281726 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-09-02 09:28:41.560687: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os, json, joblib, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "from tensorflow.keras.utils import Sequence, to_categorical, pad_sequences\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv1D, BatchNormalization, LayerNormalization, Activation, add, MaxPooling1D, Dropout,\n",
    "    Bidirectional, LSTM, GlobalAveragePooling1D, Dense, Multiply, Reshape,\n",
    "    Lambda, Concatenate, GRU, GaussianNoise\n",
    ")\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import polars as pl\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n",
      "3.8.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices(\"GPU\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('cpu_compiler', '/usr/lib/llvm-18/bin/clang'), ('cuda_compute_capabilities', ['sm_60', 'sm_70', 'sm_80', 'sm_89', 'compute_90']), ('cuda_version', '12.5.1'), ('cudnn_version', '9'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.sysconfig.get_build_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU sayısı: 1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"GPU sayısı:\", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:51.895049Z",
     "iopub.status.busy": "2025-07-04T13:28:51.894464Z",
     "iopub.status.idle": "2025-07-04T13:28:51.900335Z",
     "shell.execute_reply": "2025-07-04T13:28:51.899463Z",
     "shell.execute_reply.started": "2025-07-04T13:28:51.895023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "state_num = 25\n",
    "import random\n",
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.experimental.numpy.random.seed(seed)\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "seed_everything(seed=state_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:51.901740Z",
     "iopub.status.busy": "2025-07-04T13:28:51.901434Z",
     "iopub.status.idle": "2025-07-04T13:28:51.938388Z",
     "shell.execute_reply": "2025-07-04T13:28:51.937661Z",
     "shell.execute_reply.started": "2025-07-04T13:28:51.901713Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ imports ready · tensorflow 2.18.0\n"
     ]
    }
   ],
   "source": [
    "# (Competition metric will only be imported when TRAINing)\n",
    "TRAIN = True                \n",
    "DEBUG_GATE = False\n",
    "                     \n",
    "RAW_DIR = Path(\"\")\n",
    "PRETRAINED_DIR = Path(\"new_model_10_fold\")\n",
    "EXPORT_DIR = Path(\"10folds_new\")\n",
    "BATCH_SIZE = 64\n",
    "PAD_PERCENTILE = 95\n",
    "LR_INIT = 5e-4\n",
    "WD = 3e-3\n",
    "MIXUP_ALPHA = 0.4 \n",
    "EPOCHS = 160\n",
    "PATIENCE = 40\n",
    "N_SPLITS = 10\n",
    "MASKING_PROB = 0.25\n",
    "GATE_LOSS_WEIGHT = 0.20     # 0.20\n",
    "\n",
    "print(\"▶ imports ready · tensorflow\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:51.939603Z",
     "iopub.status.busy": "2025-07-04T13:28:51.939338Z",
     "iopub.status.idle": "2025-07-04T13:28:51.959963Z",
     "shell.execute_reply": "2025-07-04T13:28:51.959030Z",
     "shell.execute_reply.started": "2025-07-04T13:28:51.939575Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_gravity_from_acc(acc_data, rot_data):\n",
    "    acc_values = acc_data[['acc_x', 'acc_y', 'acc_z']].values\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    linear_accel = np.zeros_like(acc_values)\n",
    "    gravity_world = np.array([0, 0, 9.81])\n",
    "    for i in range(len(acc_values)):\n",
    "        if np.all(np.isnan(quat_values[i])) or np.all(np.isclose(quat_values[i], 0)):\n",
    "            linear_accel[i, :] = acc_values[i, :]\n",
    "            continue\n",
    "        try:\n",
    "            rotation = R.from_quat(quat_values[i])\n",
    "            gravity_sensor_frame = rotation.apply(gravity_world, inverse=True)\n",
    "            linear_accel[i, :] = acc_values[i, :] - gravity_sensor_frame\n",
    "        except ValueError:\n",
    "             linear_accel[i, :] = acc_values[i, :]\n",
    "    return linear_accel\n",
    "\n",
    "def calculate_angular_velocity_from_quat(rot_data, time_delta=1/200):\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    angular_vel = np.zeros((len(quat_values), 3))\n",
    "    for i in range(len(quat_values) - 1):\n",
    "        q_t, q_t_plus_dt = quat_values[i], quat_values[i+1]\n",
    "        if np.all(np.isnan(q_t)) or np.all(np.isnan(q_t_plus_dt)): continue\n",
    "        try:\n",
    "            rot_t = R.from_quat(q_t)\n",
    "            rot_t_plus_dt = R.from_quat(q_t_plus_dt)\n",
    "            delta_rot = rot_t.inv() * rot_t_plus_dt\n",
    "            angular_vel[i, :] = delta_rot.as_rotvec() / time_delta\n",
    "        except ValueError: pass\n",
    "    return angular_vel\n",
    "\n",
    "def calculate_angular_distance(rot_data):\n",
    "    quat_values = rot_data[['rot_x', 'rot_y', 'rot_z', 'rot_w']].values\n",
    "    angular_dist = np.zeros(len(quat_values))\n",
    "    for i in range(len(quat_values) - 1):\n",
    "        q1, q2 = quat_values[i], quat_values[i+1]\n",
    "        if np.all(np.isnan(q1)) or np.all(np.isnan(q2)): continue\n",
    "        try:\n",
    "            r1, r2 = R.from_quat(q1), R.from_quat(q2)\n",
    "            relative_rotation = r1.inv() * r2\n",
    "            angular_dist[i] = np.linalg.norm(relative_rotation.as_rotvec())\n",
    "        except ValueError: pass\n",
    "    return angular_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Manipulations\n",
    "def time_sum(x): return K.sum(x, axis=1) \n",
    "def squeeze_last_axis(x): return tf.squeeze(x, axis=-1)\n",
    "def expand_last_axis(x): return tf.expand_dims(x, axis=-1)\n",
    "\n",
    "def se_block(x, reduction=8):\n",
    "    ch = x.shape[-1]\n",
    "    se = GlobalAveragePooling1D()(x)\n",
    "    se = Dense(ch // reduction, activation='relu')(se)\n",
    "    se = Dense(ch, activation='sigmoid')(se)\n",
    "    se = Reshape((1, ch))(se)\n",
    "    return Multiply()([x, se])\n",
    "\n",
    "def residual_se_cnn_block(x, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4):\n",
    "    shortcut = x\n",
    "    for _ in range(2):\n",
    "        x = Conv1D(filters, kernel_size, padding='same', use_bias=False,\n",
    "                   kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "    x = se_block(x)\n",
    "    if shortcut.shape[-1] != filters:\n",
    "        shortcut = Conv1D(filters, 1, padding='same', use_bias=False,\n",
    "                          kernel_regularizer=l2(wd))(shortcut)\n",
    "        shortcut = BatchNormalization()(shortcut)\n",
    "    x = add([x, shortcut])\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling1D(pool_size)(x)\n",
    "    x = Dropout(drop)(x)\n",
    "    return x\n",
    "\n",
    "def attention_layer(inputs):\n",
    "    score = Dense(1, activation='tanh')(inputs)\n",
    "    score = Lambda(squeeze_last_axis)(score)\n",
    "    weights = Activation('softmax')(score)\n",
    "    weights = Lambda(expand_last_axis)(weights)\n",
    "    context = Multiply()([inputs, weights])\n",
    "    context = Lambda(time_sum)(context)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T07:56:04.785466Z",
     "iopub.status.busy": "2025-07-04T07:56:04.784809Z",
     "iopub.status.idle": "2025-07-04T07:56:04.803532Z",
     "shell.execute_reply": "2025-07-04T07:56:04.802817Z",
     "shell.execute_reply.started": "2025-07-04T07:56:04.785437Z"
    }
   },
   "outputs": [],
   "source": [
    "class GatedMixupGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size, imu_dim, class_weight=None, alpha=0.2, masking_prob=0.0):\n",
    "        self.X, self.y = X, y\n",
    "        self.batch = batch_size\n",
    "        self.imu_dim = imu_dim\n",
    "        self.class_weight = class_weight\n",
    "        self.alpha = alpha\n",
    "        self.masking_prob = masking_prob\n",
    "        self.indices = np.arange(len(X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X) / self.batch))\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        idx = self.indices[i*self.batch:(i+1)*self.batch]\n",
    "        Xb, yb = self.X[idx].copy(), self.y[idx].copy()\n",
    "        \n",
    "        \n",
    "        sample_weights = np.ones(len(Xb), dtype='float32')\n",
    "        if self.class_weight:\n",
    "            y_integers = yb.argmax(axis=1)\n",
    "            sample_weights = np.array([self.class_weight[i] for i in y_integers])\n",
    "        \n",
    "        gate_target = np.ones(len(Xb), dtype='float32')\n",
    "        if self.masking_prob > 0:\n",
    "            for i in range(len(Xb)):\n",
    "                if np.random.rand() < self.masking_prob:\n",
    "                    Xb[i, :, self.imu_dim:] = 0\n",
    "                    gate_target[i] = 0.0\n",
    "\n",
    "        if self.alpha > 0:\n",
    "            lam = np.random.beta(self.alpha, self.alpha)\n",
    "            perm = np.random.permutation(len(Xb))\n",
    "            X_mix = lam * Xb + (1 - lam) * Xb[perm]\n",
    "            y_mix = lam * yb + (1 - lam) * yb[perm]\n",
    "            gate_target_mix = lam * gate_target + (1 - lam) * gate_target[perm]\n",
    "            sample_weights_mix = lam * sample_weights + (1 - lam) * sample_weights[perm]\n",
    "            return X_mix, {'main_output': y_mix, 'tof_gate': gate_target_mix}, sample_weights_mix\n",
    "\n",
    "        return Xb, {'main_output': yb, 'tof_gate': gate_target}, sample_weights\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        #if self.shuffle:\n",
    "        np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def build_gated_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n",
    "\n",
    "    x2_base = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n",
    "    x2_base = LayerNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n",
    "    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n",
    "    x2_base = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2_base)\n",
    "    x2_base = LayerNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n",
    "    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n",
    "    \n",
    "    gate_input = GlobalAveragePooling1D()(tof)\n",
    "    gate_input = Dense(16, activation='relu')(gate_input)\n",
    "    \n",
    "    gate = Dense(1, activation='sigmoid', name='tof_gate')(gate_input)\n",
    "    \n",
    "    x2 = Multiply()([x2_base, gate])\n",
    "\n",
    "    merged = Concatenate()([x1, x2])\n",
    "    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xc = GaussianNoise(0.09)(merged)\n",
    "    xc = Dense(16, activation='elu')(xc)\n",
    "    x = Concatenate()([xa, xb, xc])\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "        x = Dropout(drop)(x)\n",
    "    \n",
    "    out = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=inp, outputs=[out, gate])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMER - (LS'den 0.816LB 0.8359 CV)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, BatchNormalization, Conv1D, MaxPooling1D,\n",
    "    Activation, Multiply, Bidirectional, LSTM, GRU, Concatenate,\n",
    "    GlobalAveragePooling1D, Lambda, RepeatVector, Reshape, add,\n",
    "    LayerNormalization, MultiHeadAttention, Flatten\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# -----------------\n",
    "# SE Block\n",
    "# -----------------\n",
    "class SEBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, reduction=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        ch = input_shape[-1]\n",
    "        self.gap = GlobalAveragePooling1D()\n",
    "        self.fc1 = Dense(ch // self.reduction, activation='relu')\n",
    "        self.fc2 = Dense(ch, activation='sigmoid')\n",
    "        self.reshape = Reshape((1, ch))\n",
    "        self.multiply = Multiply()\n",
    "\n",
    "    def call(self, x):\n",
    "        se = self.gap(x)\n",
    "        se = self.fc1(se)\n",
    "        se = self.fc2(se)\n",
    "        se = self.reshape(se)\n",
    "        return self.multiply([x, se])\n",
    "\n",
    "# -----------------\n",
    "# Residual SE CNN Block\n",
    "# -----------------\n",
    "class ResidualSEBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, pool_size=2, drop=0.3, wd=1e-4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.drop = drop\n",
    "        self.wd = wd\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv_layers = []\n",
    "        for _ in range(2):\n",
    "            self.conv_layers.append(Conv1D(self.filters, self.kernel_size, padding='same',\n",
    "                                           use_bias=False, kernel_regularizer=l2(self.wd)))\n",
    "            self.conv_layers.append(BatchNormalization())\n",
    "            self.conv_layers.append(Activation('relu'))\n",
    "\n",
    "        self.se_block = SEBlock()\n",
    "\n",
    "        self.shortcut_conv = None\n",
    "        if input_shape[-1] != self.filters:\n",
    "            self.shortcut_conv = Conv1D(self.filters, 1, padding='same',\n",
    "                                        use_bias=False, kernel_regularizer=l2(self.wd))\n",
    "            self.shortcut_bn = BatchNormalization()\n",
    "\n",
    "        self.add_layer = add\n",
    "        self.relu = Activation('relu')\n",
    "        self.pool = MaxPooling1D(self.pool_size)\n",
    "        self.dropout = Dropout(self.drop)\n",
    "\n",
    "    def call(self, x):\n",
    "        shortcut = x\n",
    "        for layer in self.conv_layers:\n",
    "            x = layer(x)\n",
    "        x = self.se_block(x)\n",
    "\n",
    "        if self.shortcut_conv is not None:\n",
    "            shortcut = self.shortcut_conv(shortcut)\n",
    "            shortcut = self.shortcut_bn(shortcut)\n",
    "\n",
    "        x = self.add_layer([x, shortcut])\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "# -----------------\n",
    "# Attention Layer\n",
    "# -----------------\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.score_dense = Dense(1, activation='tanh')\n",
    "        self.softmax = Activation('softmax')\n",
    "        self.multiply = Multiply()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        score = self.score_dense(inputs)\n",
    "        score = tf.squeeze(score, axis=-1)\n",
    "        weights = self.softmax(score)\n",
    "        weights = tf.expand_dims(weights, axis=-1)\n",
    "        context = self.multiply([inputs, weights])\n",
    "        return tf.reduce_sum(context, axis=1)\n",
    "\n",
    "# -----------------\n",
    "# Transformer Encoder Block\n",
    "# -----------------\n",
    "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, head_num=4, ff_dim=256, dropout=0.2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.head_num = head_num\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.ln1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.attn = MultiHeadAttention(num_heads=self.head_num, key_dim=input_shape[-1] // self.head_num)\n",
    "        self.drop1 = Dropout(self.dropout_rate)\n",
    "\n",
    "        self.ln2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn_dense1 = Dense(self.ff_dim, activation='relu')\n",
    "        self.ffn_dense2 = Dense(input_shape[-1])\n",
    "        self.drop2 = Dropout(self.dropout_rate)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x_norm = self.ln1(inputs)\n",
    "        attn_out = self.attn(x_norm, x_norm)\n",
    "        attn_out = self.drop1(attn_out)\n",
    "        out1 = attn_out + inputs\n",
    "\n",
    "        x_norm2 = self.ln2(out1)\n",
    "        x_ff = self.ffn_dense1(x_norm2)\n",
    "        x_ff = self.ffn_dense2(x_ff)\n",
    "        x_ff = self.drop2(x_ff)\n",
    "        return x_ff + out1\n",
    "\n",
    "# -----------------\n",
    "# Model Builder\n",
    "# -----------------\n",
    "def build_competition_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "    inp = Input(shape=(pad_len, imu_dim + tof_dim), name='input_all')\n",
    "\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim], name='imu_slice')(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:], name='tof_slice')(inp)\n",
    "\n",
    "    x_imu = ResidualSEBlock(64, 3, pool_size=2, drop=0.1, wd=wd)(imu)\n",
    "    x_imu = ResidualSEBlock(128, 5, pool_size=2, drop=0.1, wd=wd)(x_imu)\n",
    "\n",
    "    x_tof = Conv1D(64, 3, padding='same', kernel_regularizer=l2(wd), use_bias=False)(tof)\n",
    "    x_tof = BatchNormalization()(x_tof)\n",
    "    x_tof = Activation('relu')(x_tof)\n",
    "    x_tof = MaxPooling1D(2)(x_tof)\n",
    "\n",
    "    x_tof = Conv1D(128, 3, padding='same', kernel_regularizer=l2(wd), use_bias=False)(x_tof)\n",
    "    x_tof = BatchNormalization()(x_tof)\n",
    "    x_tof = Activation('relu')(x_tof)\n",
    "    x_tof = MaxPooling1D(2)(x_tof)\n",
    "\n",
    "    x_tof = Bidirectional(GRU(64, return_sequences=True, kernel_regularizer=l2(wd)))(x_tof)\n",
    "    x_tof = Dropout(0.2)(x_tof)\n",
    "\n",
    "    gate_input = GlobalAveragePooling1D()(tof)\n",
    "    gate_dense = Dense(16, activation='relu')(gate_input)\n",
    "    gate = Dense(1, activation='sigmoid', name='tof_gate')(gate_dense)\n",
    "\n",
    "    gate_timesteps = K.int_shape(x_tof)[1]\n",
    "    gate_expanded = RepeatVector(gate_timesteps)(gate)\n",
    "    x_tof = Multiply(name='gated_tof_output')([x_tof, gate_expanded])\n",
    "\n",
    "    merged = Concatenate(name='merged_features')([x_imu, x_tof])\n",
    "\n",
    "    #x_lstm = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    #x_gru = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    x_lstm = Bidirectional(LSTM(160, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    x_gru = Bidirectional(GRU(160, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    x_rnn_concat = Concatenate()([x_lstm, x_gru])\n",
    "\n",
    "    #x_trans = TransformerEncoderBlock(head_num=8, ff_dim=512, dropout=0.3)(x_rnn_concat)\n",
    "    x_trans = TransformerEncoderBlock(head_num=12, ff_dim=768, dropout=0.3)(x_rnn_concat)\n",
    "    x_trans = TransformerEncoderBlock(head_num=8, ff_dim=512, dropout=0.3)(x_trans)\n",
    "\n",
    "    attn_out = AttentionLayer()(x_trans)\n",
    "\n",
    "    x = attn_out\n",
    "    for units, drop_rate in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, kernel_regularizer=l2(wd), use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(drop_rate)(x)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=[out, gate])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORMER OPTIMIZE (Lambda fix for H5) 0.8429 CV - 0.826 LB -------------- BEST TRANSFORMER\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    BatchNormalization,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    Activation,\n",
    "    Multiply,\n",
    "    Bidirectional,\n",
    "    LSTM,\n",
    "    GRU,\n",
    "    Concatenate,\n",
    "    GlobalAveragePooling1D,\n",
    "    Lambda,\n",
    "    RepeatVector,\n",
    "    Reshape,\n",
    "    add,\n",
    "    LayerNormalization,\n",
    "    MultiHeadAttention\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# -----------------\n",
    "# SE Block\n",
    "# -----------------\n",
    "class SEBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, reduction=8, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        ch = int(input_shape[-1])\n",
    "        self.gap = GlobalAveragePooling1D()\n",
    "        self.fc1 = Dense(max(ch // self.reduction, 4), activation='relu')\n",
    "        self.fc2 = Dense(ch, activation='sigmoid')\n",
    "        self.reshape = Reshape((1, ch))\n",
    "\n",
    "    def call(self, x):\n",
    "        se = self.gap(x)\n",
    "        se = self.fc1(se)\n",
    "        se = self.fc2(se)\n",
    "        se = self.reshape(se)\n",
    "        return x * se\n",
    "\n",
    "# -----------------\n",
    "# Residual SE Block (with pooling)\n",
    "# -----------------\n",
    "class ResidualSEBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, pool_size=2, drop=0.25, wd=1e-4, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_size = pool_size\n",
    "        self.drop = drop\n",
    "        self.wd = wd\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.conv1 = Conv1D(self.filters, self.kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(self.wd))\n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.act1 = Activation('relu')\n",
    "        self.conv2 = Conv1D(self.filters, self.kernel_size, padding='same', use_bias=False, kernel_regularizer=l2(self.wd))\n",
    "        self.bn2 = BatchNormalization()\n",
    "        self.act2 = Activation('relu')\n",
    "        self.se = SEBlock(reduction=8)\n",
    "        self.shortcut_conv = None\n",
    "        if int(input_shape[-1]) != self.filters:\n",
    "            self.shortcut_conv = Conv1D(self.filters, 1, padding='same', use_bias=False, kernel_regularizer=l2(self.wd))\n",
    "            self.shortcut_bn = BatchNormalization()\n",
    "        self.pool = MaxPooling1D(self.pool_size)\n",
    "        self.dropout = Dropout(self.drop)\n",
    "        self.add = add\n",
    "        self.relu = Activation('relu')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        shortcut = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x, training=training)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x, training=training)\n",
    "        x = self.act2(x)\n",
    "        x = self.se(x)\n",
    "        if self.shortcut_conv is not None:\n",
    "            shortcut = self.shortcut_conv(shortcut)\n",
    "            shortcut = self.shortcut_bn(shortcut, training=training)\n",
    "        x = self.add([x, shortcut])\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        return x\n",
    "\n",
    "# -----------------\n",
    "# Attention pooling (time-wise)\n",
    "# -----------------\n",
    "class AttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.score_dense = Dense(1, activation='tanh')\n",
    "        self.softmax = tf.keras.layers.Softmax(axis=1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        score = self.score_dense(inputs)  # (B, T, 1)\n",
    "        score = tf.squeeze(score, axis=-1)  # (B, T)\n",
    "        weights = self.softmax(score)  # (B, T)\n",
    "        weights = tf.expand_dims(weights, axis=-1)  # (B, T, 1)\n",
    "        context = inputs * weights  # (B, T, C)\n",
    "        return tf.reduce_sum(context, axis=1)  # (B, C)\n",
    "\n",
    "# -----------------\n",
    "# Transformer Encoder (pre-LN)\n",
    "# -----------------\n",
    "class TransformerEncoderBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self, head_num=8, ff_dim=512, dropout=0.2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.head_num = head_num\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        d_model = int(input_shape[-1])\n",
    "        self.ln1 = LayerNormalization(epsilon=1e-6)\n",
    "        # key_dim must be >=1 and typically d_model // head_num\n",
    "        self.mha = MultiHeadAttention(num_heads=self.head_num, key_dim=max(1, d_model // self.head_num))\n",
    "        self.dropout1 = Dropout(self.dropout_rate)\n",
    "        self.ln2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.ffn_dense1 = Dense(self.ff_dim, activation='relu', kernel_regularizer=l2(1e-4))\n",
    "        self.ffn_dense2 = Dense(d_model, kernel_regularizer=l2(1e-4))\n",
    "        self.dropout2 = Dropout(self.dropout_rate)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        # Pre-LN\n",
    "        x_norm = self.ln1(x)\n",
    "        attn_out = self.mha(x_norm, x_norm)\n",
    "        attn_out = self.dropout1(attn_out, training=training)\n",
    "        x = attn_out + x\n",
    "        x_norm2 = self.ln2(x)\n",
    "        x_ff = self.ffn_dense1(x_norm2)\n",
    "        x_ff = self.ffn_dense2(x_ff)\n",
    "        x_ff = self.dropout2(x_ff, training=training)\n",
    "        return x + x_ff\n",
    "\n",
    "# -----------------\n",
    "# Model builder (Lambda-safe)\n",
    "# -----------------\n",
    "def build_competition_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "    inp = Input(shape=(pad_len, imu_dim + tof_dim), name='input_all')\n",
    "\n",
    "    # Dilimleme Lambda'larına output_shape verildi (H5 yüklemesi güvenli)\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim], output_shape=(pad_len, imu_dim), name='imu_slice')(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:], output_shape=(pad_len, tof_dim), name='tof_slice')(inp)\n",
    "\n",
    "    # IMU path\n",
    "    x_imu = ResidualSEBlock(64, 3, pool_size=2, drop=0.12, wd=wd)(imu)\n",
    "    x_imu = ResidualSEBlock(128, 5, pool_size=2, drop=0.12, wd=wd)(x_imu)\n",
    "\n",
    "    # ToF path\n",
    "    x_tof = Conv1D(64, 3, padding='same', kernel_regularizer=l2(wd), use_bias=False)(tof)\n",
    "    x_tof = BatchNormalization()(x_tof)\n",
    "    x_tof = Activation('relu')(x_tof)\n",
    "    x_tof = MaxPooling1D(2)(x_tof)\n",
    "    x_tof = Conv1D(128, 3, padding='same', kernel_regularizer=l2(wd), use_bias=False)(x_tof)\n",
    "    x_tof = BatchNormalization()(x_tof)\n",
    "    x_tof = Activation('relu')(x_tof)\n",
    "    x_tof = MaxPooling1D(2)(x_tof)\n",
    "    x_tof = Bidirectional(GRU(64, return_sequences=True, kernel_regularizer=l2(wd)))(x_tof)\n",
    "    x_tof = Dropout(0.22)(x_tof)\n",
    "\n",
    "    # --- Channel-wise ToF gate (Lambda -> RepeatVector ile değiştirildi) ---\n",
    "    gate_feat = GlobalAveragePooling1D()(x_tof)  # (B, C)\n",
    "    gate_chan = Dense(int(x_tof.shape[-1]), activation='sigmoid', name='tof_gate_chan')(gate_feat)  # (B, C)\n",
    "    gate_chan_expand = RepeatVector(1, name='tof_gate_chan_expand')(gate_chan)  # (B, 1, C) — shape belirgin\n",
    "    x_tof = Multiply(name='tof_channel_gate')([x_tof, gate_chan_expand])  # (B, T, C) * (B, 1, C)\n",
    "\n",
    "    # Scalar aux gate (aynı kaldı)\n",
    "    gate_scalar = Dense(1, activation='sigmoid', name='tof_gate')(gate_feat)  # (B, 1)\n",
    "\n",
    "    # Merge\n",
    "    merged = Concatenate(name='merged_features')([x_imu, x_tof])\n",
    "\n",
    "    # RNN katmanı\n",
    "    x_lstm = Bidirectional(LSTM(160, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    x_gru = Bidirectional(GRU(160, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    x_rnn_concat = Concatenate(name='rnn_concat')([x_lstm, x_gru])\n",
    "\n",
    "    # Transformer stack\n",
    "    x_trans = TransformerEncoderBlock(head_num=12, ff_dim=768, dropout=0.28)(x_rnn_concat)\n",
    "    x_trans = TransformerEncoderBlock(head_num=8, ff_dim=512, dropout=0.28)(x_trans)\n",
    "\n",
    "    # Temporal attention pooling\n",
    "    attn_out = AttentionLayer()(x_trans)\n",
    "\n",
    "    # Dense head\n",
    "    x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(attn_out)\n",
    "    for units, drop_rate in [(256, 0.48), (128, 0.32)]:\n",
    "        x = Dense(units, kernel_regularizer=l2(wd), use_bias=False)(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(drop_rate)(x)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n",
    "\n",
    "    return Model(inputs=inp, outputs=[out, gate_scalar])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def build_gated_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "    inp = Input(shape=(pad_len, imu_dim+tof_dim))\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim])(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:])(inp)\n",
    "\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n",
    "\n",
    "    x2_base = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n",
    "    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n",
    "    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n",
    "    x2_base = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2_base)\n",
    "    x2_base = BatchNormalization()(x2_base); x2_base = Activation('relu')(x2_base)\n",
    "    x2_base = MaxPooling1D(2)(x2_base); x2_base = Dropout(0.2)(x2_base)\n",
    "    \n",
    "    gate_input = GlobalAveragePooling1D()(tof)\n",
    "    gate_input = Dense(16, activation='relu')(gate_input)\n",
    "    \n",
    "    gate = Dense(1, activation='sigmoid', name='tof_gate')(gate_input)\n",
    "    \n",
    "    x2 = Multiply()([x2_base, gate])\n",
    "\n",
    "    merged = Concatenate()([x1, x2])\n",
    "    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xc = GaussianNoise(0.09)(merged)\n",
    "    xc = Dense(16, activation='elu')(xc)\n",
    "    x = Concatenate()([xa, xb, xc])\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = attention_layer(x)\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x); x = Activation('relu')(x)\n",
    "        x = Dropout(drop)(x)\n",
    "    \n",
    "    out = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n",
    "    \n",
    "    \n",
    "    return Model(inputs=inp, outputs=[out, gate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW 0.825\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def build_gated_two_branch_model(pad_len, imu_dim, tof_dim, n_classes, wd=1e-4):\n",
    "    inp = Input(shape=(pad_len, imu_dim + tof_dim))\n",
    "\n",
    "    # --- Branch split ---\n",
    "    imu = Lambda(lambda t: t[:, :, :imu_dim], name='imu_input_slice')(inp)\n",
    "    tof = Lambda(lambda t: t[:, :, imu_dim:], name='tof_input_slice')(inp)\n",
    "\n",
    "    # --- IMU branch (residual_se_cnn_block'ların zaman boyutunu koruduğunu varsayarak) ---\n",
    "    # Eğer bu bloklar downsampling yapmıyorsa, x1'in boyutu (None, pad_len, 128) civarında olacaktır.\n",
    "    # Ancak hata mesajı (None, 31, 128) olduğuna göre, IMU dalının zaten downsampled olduğu varsayılıyor.\n",
    "    # Bu durumda, x1'in zaman boyutu 31 olarak kabul ediliyor.\n",
    "    x1 = residual_se_cnn_block(imu, 64, 3, drop=0.1, wd=wd)\n",
    "    x1 = residual_se_cnn_block(x1, 128, 5, drop=0.1, wd=wd)\n",
    "    # Hata mesajına göre (None, 31, 128) şekline ulaştığı varsayılıyor.\n",
    "    # Eğer residual_se_cnn_block iç yapısında MaxPooling yoksa, bu satıra bir MaxPooling1D(2) veya (4) eklemek gerekebilir.\n",
    "\n",
    "    # --- ToF branch: CNN + BiGRU ---\n",
    "    x2 = Conv1D(64, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(tof)\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling1D(2, name='tof_pool_1')(x2) # İlk MaxPooling: (None, pad_len/2, 64)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "\n",
    "    # Hata mesajı (None, 63, 128) olduğuna göre, x2'nin şu anki boyutu 63.\n",
    "    # x1'in boyutu 31 olduğuna göre, x2'yi de 31'e düşürmek için BİR KEZ DAHA MaxPooling uygulamalıyız.\n",
    "    # Önceki modelinizde iki kez MaxPooling kullanılıyordu, bu da uyumluluğu artırır.\n",
    "    x2 = Conv1D(128, 3, padding='same', use_bias=False, kernel_regularizer=l2(wd))(x2) # İkinci Conv1D\n",
    "    x2 = BatchNormalization()(x2)\n",
    "    x2 = Activation('relu')(x2)\n",
    "    x2 = MaxPooling1D(2, name='tof_pool_2')(x2) # İkinci MaxPooling: (None, pad_len/4, 128)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "\n",
    "    x2 = Bidirectional(GRU(64, return_sequences=True, kernel_regularizer=l2(wd)))(x2)\n",
    "    x2 = Dropout(0.2)(x2)\n",
    "    # GRU katmanı çıktı boyutunu (None, pad_len/4, 128) veya (None, pad_len/4, 2*64) yapar, yani 128.\n",
    "\n",
    "    # --- Gate mekanizması korunuyor ---\n",
    "    # Gate hala orijinal ToF verisinden beslenmeli (downsampling yapılmamış `tof` girdisinden).\n",
    "    gate_input = GlobalAveragePooling1D()(tof)\n",
    "    gate_input = Dense(16, activation='relu')(gate_input)\n",
    "    gate = Dense(1, activation='sigmoid', name='tof_gate')(gate_input)\n",
    "    \n",
    "    # Gate'i Multiply katmanında kullanmak için x2'nin mevcut zaman boyutuna göre RepeatVector ile genişletiyoruz.\n",
    "    # K.int_shape(x2)[1] ile x2'nin dinamik zaman boyutunu alıyoruz.\n",
    "    current_tof_timesteps = K.int_shape(x2)[1] # Burası şimdi 31 (pad_len / 4) olmalı\n",
    "    gate_expanded = RepeatVector(current_tof_timesteps)(gate) # (None, current_tof_timesteps, 1)\n",
    "    \n",
    "    x2 = Multiply(name='gated_tof_output')([x2, gate_expanded]) # Gate, x2'nin her zaman adımına uygulanır  \n",
    "    \n",
    "    # --- Merge ---\n",
    "    # Şimdi x1 ve x2'nin zaman boyutları (None, 31, features) şeklinde olmalı\n",
    "    merged = Concatenate(name='merged_branches')([x1, x2])\n",
    "\n",
    "    # --- Temporal Encoder (GRU + LSTM) + Transformer block mantığı ---\n",
    "    xa = Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "    xb = Bidirectional(GRU(128, return_sequences=True, kernel_regularizer=l2(wd)))(merged)\n",
    "\n",
    "    # --- Lightweight Transformer-style attention block ---\n",
    "    attn_input = Concatenate(name='attention_input')([xa, xb])\n",
    "    attn_output = attention_layer(attn_input)  # Global attention pooling (output: (None, features))\n",
    "\n",
    "    # --- Dense layers ---\n",
    "    x = attn_output # `attention_layer` çıktısı (batch_size, features) olduğu için artık zaman boyutu yok.\n",
    "    for units, drop in [(256, 0.5), (128, 0.3)]:\n",
    "        x = Dense(units, use_bias=False, kernel_regularizer=l2(wd))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = Dropout(drop)(x)\n",
    "\n",
    "    out = Dense(n_classes, activation='softmax', name='main_output', kernel_regularizer=l2(wd))(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=[out, gate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:52.036653Z",
     "iopub.status.busy": "2025-07-04T13:28:52.036359Z",
     "iopub.status.idle": "2025-07-04T13:28:52.058098Z",
     "shell.execute_reply": "2025-07-04T13:28:52.057140Z",
     "shell.execute_reply.started": "2025-07-04T13:28:52.036628Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage import sobel\n",
    "\n",
    "# ToF için spatial gradyan (sobel) temelli özellikler\n",
    "def calculate_spatial_tof_features(seq_df, sensor_id):\n",
    "    # 1D 64-pikseli 8x8'e reshape edip sobel gradyanı alacağız\n",
    "    pixel_cols = [f\"tof_{sensor_id}_v{p}\" for p in range(64)]\n",
    "    tof_data = seq_df[pixel_cols].replace(-1, np.nan).ffill().bfill().fillna(0).values\n",
    "    \n",
    "    # Frame sayısı x 64 → (N x 8 x 8)\n",
    "    N = len(seq_df)\n",
    "    reshaped = tof_data.reshape(N, 8, 8)\n",
    "    \n",
    "    # Spatial gradyanları hesapla (sobel x ve y)\n",
    "    sobel_x = sobel(reshaped, axis=1)\n",
    "    sobel_y = sobel(reshaped, axis=2)\n",
    "    grad_mag = np.sqrt(sobel_x ** 2 + sobel_y ** 2)\n",
    "\n",
    "    # Özet istatistikleri hesapla\n",
    "    grad_mean = grad_mag.mean(axis=(1, 2))\n",
    "    grad_std  = grad_mag.std(axis=(1, 2))\n",
    "    grad_max  = grad_mag.max(axis=(1, 2))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        f'tof_{sensor_id}_grad_mean': grad_mean,\n",
    "        f'tof_{sensor_id}_grad_std': grad_std,\n",
    "        f'tof_{sensor_id}_grad_max': grad_max\n",
    "    }, index=seq_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T13:28:52.059207Z",
     "iopub.status.busy": "2025-07-04T13:28:52.058943Z",
     "iopub.status.idle": "2025-07-04T13:28:52.234783Z",
     "shell.execute_reply": "2025-07-04T13:28:52.233780Z",
     "shell.execute_reply.started": "2025-07-04T13:28:52.059187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "def count_peaks(series):\n",
    "    peaks, _ = find_peaks(series, height=np.mean(series))\n",
    "    return len(peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-04T14:37:28.597398Z",
     "iopub.status.busy": "2025-07-04T14:37:28.597100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ TRAIN MODE – loading dataset ...\n",
      "  Removing gravity and calculating linear acceleration features...\n",
      "  Calculating angular velocity and distance from quaternions...\n",
      "  IMU (phys-based + enhanced) 31 | THM + Aggregated TOF 40 | total 71 features\n",
      "  Building sequences...\n",
      "  Fitting StandardScaler...\n",
      "  Scaling and padding sequences...\n",
      "  Starting training with Stratified Group K-Fold CV...\n",
      "\n",
      "===== FOLD 1/10 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756794673.536956  281726 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21770 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756794681.708970  282413 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 113ms/step - loss: 10.5365 - main_output_accuracy: 0.1453 - main_output_loss: 2.9460 - tof_gate_loss: 0.6921 - val_loss: 8.0983 - val_main_output_accuracy: 0.4451 - val_main_output_loss: 2.3980 - val_tof_gate_loss: 0.5082 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - loss: 7.5242 - main_output_accuracy: 0.3704 - main_output_loss: 2.2490 - tof_gate_loss: 0.4948 - val_loss: 6.1467 - val_main_output_accuracy: 0.5462 - val_main_output_loss: 1.9125 - val_tof_gate_loss: 0.3711 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 6.0707 - main_output_accuracy: 0.4618 - main_output_loss: 2.0821 - tof_gate_loss: 0.3650 - val_loss: 5.0113 - val_main_output_accuracy: 0.5709 - val_main_output_loss: 1.6615 - val_tof_gate_loss: 0.2700 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 5.1813 - main_output_accuracy: 0.4826 - main_output_loss: 2.0018 - tof_gate_loss: 0.2673 - val_loss: 4.2515 - val_main_output_accuracy: 0.6202 - val_main_output_loss: 1.5378 - val_tof_gate_loss: 0.1917 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - loss: 4.4290 - main_output_accuracy: 0.5318 - main_output_loss: 1.8347 - tof_gate_loss: 0.1876 - val_loss: 3.8005 - val_main_output_accuracy: 0.6091 - val_main_output_loss: 1.5575 - val_tof_gate_loss: 0.1373 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 4.0309 - main_output_accuracy: 0.5510 - main_output_loss: 1.8812 - tof_gate_loss: 0.1379 - val_loss: 3.4068 - val_main_output_accuracy: 0.5906 - val_main_output_loss: 1.5267 - val_tof_gate_loss: 0.1013 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - loss: 3.6209 - main_output_accuracy: 0.5794 - main_output_loss: 1.8145 - tof_gate_loss: 0.1011 - val_loss: 3.0645 - val_main_output_accuracy: 0.6387 - val_main_output_loss: 1.4802 - val_tof_gate_loss: 0.0765 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 3.2596 - main_output_accuracy: 0.6051 - main_output_loss: 1.7320 - tof_gate_loss: 0.0768 - val_loss: 2.9213 - val_main_output_accuracy: 0.6054 - val_main_output_loss: 1.5695 - val_tof_gate_loss: 0.0586 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.9686 - main_output_accuracy: 0.6188 - main_output_loss: 1.6690 - tof_gate_loss: 0.0579 - val_loss: 2.7190 - val_main_output_accuracy: 0.6079 - val_main_output_loss: 1.5600 - val_tof_gate_loss: 0.0464 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 2.8708 - main_output_accuracy: 0.6252 - main_output_loss: 1.7494 - tof_gate_loss: 0.0490 - val_loss: 2.5004 - val_main_output_accuracy: 0.6338 - val_main_output_loss: 1.4927 - val_tof_gate_loss: 0.0375 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - loss: 2.7102 - main_output_accuracy: 0.6256 - main_output_loss: 1.7349 - tof_gate_loss: 0.0400 - val_loss: 2.3463 - val_main_output_accuracy: 0.6510 - val_main_output_loss: 1.4657 - val_tof_gate_loss: 0.0312 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.4908 - main_output_accuracy: 0.6441 - main_output_loss: 1.6332 - tof_gate_loss: 0.0310 - val_loss: 2.3061 - val_main_output_accuracy: 0.6239 - val_main_output_loss: 1.5269 - val_tof_gate_loss: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.4391 - main_output_accuracy: 0.6483 - main_output_loss: 1.6845 - tof_gate_loss: 0.0263 - val_loss: 2.1723 - val_main_output_accuracy: 0.6671 - val_main_output_loss: 1.4824 - val_tof_gate_loss: 0.0214 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 81ms/step - loss: 2.3278 - main_output_accuracy: 0.6509 - main_output_loss: 1.6539 - tof_gate_loss: 0.0223 - val_loss: 2.0581 - val_main_output_accuracy: 0.6560 - val_main_output_loss: 1.4350 - val_tof_gate_loss: 0.0184 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.3267 - main_output_accuracy: 0.6496 - main_output_loss: 1.7213 - tof_gate_loss: 0.0206 - val_loss: 2.0933 - val_main_output_accuracy: 0.6313 - val_main_output_loss: 1.5373 - val_tof_gate_loss: 0.0156 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 2.1882 - main_output_accuracy: 0.6491 - main_output_loss: 1.6373 - tof_gate_loss: 0.0167 - val_loss: 2.0947 - val_main_output_accuracy: 0.6042 - val_main_output_loss: 1.5873 - val_tof_gate_loss: 0.0136 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - loss: 2.0734 - main_output_accuracy: 0.6754 - main_output_loss: 1.5708 - tof_gate_loss: 0.0133 - val_loss: 1.9602 - val_main_output_accuracy: 0.6375 - val_main_output_loss: 1.4900 - val_tof_gate_loss: 0.0118 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 2.1284 - main_output_accuracy: 0.6600 - main_output_loss: 1.6691 - tof_gate_loss: 0.0129 - val_loss: 1.8287 - val_main_output_accuracy: 0.6695 - val_main_output_loss: 1.3957 - val_tof_gate_loss: 0.0102 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.0685 - main_output_accuracy: 0.6575 - main_output_loss: 1.6402 - tof_gate_loss: 0.0115 - val_loss: 1.8091 - val_main_output_accuracy: 0.6757 - val_main_output_loss: 1.3969 - val_tof_gate_loss: 0.0089 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - loss: 1.9855 - main_output_accuracy: 0.6881 - main_output_loss: 1.5838 - tof_gate_loss: 0.0095 - val_loss: 1.9169 - val_main_output_accuracy: 0.6276 - val_main_output_loss: 1.5277 - val_tof_gate_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.0842 - main_output_accuracy: 0.6598 - main_output_loss: 1.7039 - tof_gate_loss: 0.0092 - val_loss: 1.8790 - val_main_output_accuracy: 0.6141 - val_main_output_loss: 1.5148 - val_tof_gate_loss: 0.0071 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.8827 - main_output_accuracy: 0.6899 - main_output_loss: 1.5224 - tof_gate_loss: 0.0071 - val_loss: 1.9017 - val_main_output_accuracy: 0.6042 - val_main_output_loss: 1.5633 - val_tof_gate_loss: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - loss: 1.8855 - main_output_accuracy: 0.6989 - main_output_loss: 1.5415 - tof_gate_loss: 0.0063 - val_loss: 1.8600 - val_main_output_accuracy: 0.5993 - val_main_output_loss: 1.5228 - val_tof_gate_loss: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.9717 - main_output_accuracy: 0.6671 - main_output_loss: 1.6409 - tof_gate_loss: 0.0061 - val_loss: 1.8603 - val_main_output_accuracy: 0.5980 - val_main_output_loss: 1.5488 - val_tof_gate_loss: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 79ms/step - loss: 1.8793 - main_output_accuracy: 0.7120 - main_output_loss: 1.5700 - tof_gate_loss: 0.0054 - val_loss: 1.6674 - val_main_output_accuracy: 0.6991 - val_main_output_loss: 1.3635 - val_tof_gate_loss: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.8604 - main_output_accuracy: 0.7123 - main_output_loss: 1.5572 - tof_gate_loss: 0.0048 - val_loss: 1.7896 - val_main_output_accuracy: 0.6609 - val_main_output_loss: 1.4929 - val_tof_gate_loss: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.8783 - main_output_accuracy: 0.7089 - main_output_loss: 1.5852 - tof_gate_loss: 0.0044 - val_loss: 1.8359 - val_main_output_accuracy: 0.6165 - val_main_output_loss: 1.5455 - val_tof_gate_loss: 0.0037 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 1.8252 - main_output_accuracy: 0.6939 - main_output_loss: 1.5360 - tof_gate_loss: 0.0037 - val_loss: 1.8977 - val_main_output_accuracy: 0.6178 - val_main_output_loss: 1.6143 - val_tof_gate_loss: 0.0034 - learning_rate: 5.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.8326 - main_output_accuracy: 0.7020 - main_output_loss: 1.5454 - tof_gate_loss: 0.0037 - val_loss: 1.7913 - val_main_output_accuracy: 0.6400 - val_main_output_loss: 1.5195 - val_tof_gate_loss: 0.0030 - learning_rate: 5.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.6863 - main_output_accuracy: 0.7443 - main_output_loss: 1.4105 - tof_gate_loss: 0.0029 - val_loss: 1.8106 - val_main_output_accuracy: 0.6153 - val_main_output_loss: 1.5412 - val_tof_gate_loss: 0.0028 - learning_rate: 5.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - loss: 1.8615 - main_output_accuracy: 0.7042 - main_output_loss: 1.5931 - tof_gate_loss: 0.0031 - val_loss: 1.7530 - val_main_output_accuracy: 0.6289 - val_main_output_loss: 1.4867 - val_tof_gate_loss: 0.0025 - learning_rate: 5.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - loss: 1.8830 - main_output_accuracy: 0.6991 - main_output_loss: 1.6181 - tof_gate_loss: 0.0028 - val_loss: 1.8596 - val_main_output_accuracy: 0.6091 - val_main_output_loss: 1.5996 - val_tof_gate_loss: 0.0023 - learning_rate: 5.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.8483 - main_output_accuracy: 0.7212 - main_output_loss: 1.5881 - tof_gate_loss: 0.0025\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.8482 - main_output_accuracy: 0.7211 - main_output_loss: 1.5880 - tof_gate_loss: 0.0025 - val_loss: 1.7454 - val_main_output_accuracy: 0.6708 - val_main_output_loss: 1.4952 - val_tof_gate_loss: 0.0021 - learning_rate: 5.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 1.7359 - main_output_accuracy: 0.7482 - main_output_loss: 1.4852 - tof_gate_loss: 0.0023 - val_loss: 1.5241 - val_main_output_accuracy: 0.7213 - val_main_output_loss: 1.2814 - val_tof_gate_loss: 0.0020 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.6561 - main_output_accuracy: 0.7740 - main_output_loss: 1.4135 - tof_gate_loss: 0.0022 - val_loss: 1.5737 - val_main_output_accuracy: 0.7152 - val_main_output_loss: 1.3389 - val_tof_gate_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.6867 - main_output_accuracy: 0.7579 - main_output_loss: 1.4505 - tof_gate_loss: 0.0022 - val_loss: 1.6299 - val_main_output_accuracy: 0.6782 - val_main_output_loss: 1.3959 - val_tof_gate_loss: 0.0018 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 1.7411 - main_output_accuracy: 0.7691 - main_output_loss: 1.5164 - tof_gate_loss: 0.0021 - val_loss: 1.5937 - val_main_output_accuracy: 0.6880 - val_main_output_loss: 1.3667 - val_tof_gate_loss: 0.0017 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.6276 - main_output_accuracy: 0.7891 - main_output_loss: 1.4025 - tof_gate_loss: 0.0018 - val_loss: 1.6514 - val_main_output_accuracy: 0.6535 - val_main_output_loss: 1.4268 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.7624 - main_output_accuracy: 0.7213 - main_output_loss: 1.5371 - tof_gate_loss: 0.0018 - val_loss: 1.5593 - val_main_output_accuracy: 0.6880 - val_main_output_loss: 1.3395 - val_tof_gate_loss: 0.0015 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 1.6235 - main_output_accuracy: 0.7794 - main_output_loss: 1.4080 - tof_gate_loss: 0.0016 - val_loss: 1.6404 - val_main_output_accuracy: 0.6695 - val_main_output_loss: 1.4226 - val_tof_gate_loss: 0.0015 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.6493 - main_output_accuracy: 0.7577 - main_output_loss: 1.4350 - tof_gate_loss: 0.0016 - val_loss: 1.5563 - val_main_output_accuracy: 0.6991 - val_main_output_loss: 1.3448 - val_tof_gate_loss: 0.0014 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.6946 - main_output_accuracy: 0.7639 - main_output_loss: 1.4824 - tof_gate_loss: 0.0015\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.6946 - main_output_accuracy: 0.7639 - main_output_loss: 1.4824 - tof_gate_loss: 0.0015 - val_loss: 1.6442 - val_main_output_accuracy: 0.7016 - val_main_output_loss: 1.4343 - val_tof_gate_loss: 0.0013 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.5799 - main_output_accuracy: 0.7972 - main_output_loss: 1.3699 - tof_gate_loss: 0.0014 - val_loss: 1.4832 - val_main_output_accuracy: 0.7139 - val_main_output_loss: 1.2774 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - loss: 1.5425 - main_output_accuracy: 0.8104 - main_output_loss: 1.3398 - tof_gate_loss: 0.0014 - val_loss: 1.4965 - val_main_output_accuracy: 0.6991 - val_main_output_loss: 1.2915 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.4705 - main_output_accuracy: 0.8182 - main_output_loss: 1.2686 - tof_gate_loss: 0.0013 - val_loss: 1.4391 - val_main_output_accuracy: 0.7176 - val_main_output_loss: 1.2388 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.4832 - main_output_accuracy: 0.8228 - main_output_loss: 1.2847 - tof_gate_loss: 0.0012 - val_loss: 1.4891 - val_main_output_accuracy: 0.7226 - val_main_output_loss: 1.2948 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 1.5534 - main_output_accuracy: 0.8122 - main_output_loss: 1.3568 - tof_gate_loss: 0.0012 - val_loss: 1.4566 - val_main_output_accuracy: 0.7263 - val_main_output_loss: 1.2588 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.5912 - main_output_accuracy: 0.7941 - main_output_loss: 1.3889 - tof_gate_loss: 0.0013 - val_loss: 1.4672 - val_main_output_accuracy: 0.7139 - val_main_output_loss: 1.2768 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.5609 - main_output_accuracy: 0.8053 - main_output_loss: 1.3678 - tof_gate_loss: 0.0012 - val_loss: 1.4724 - val_main_output_accuracy: 0.7152 - val_main_output_loss: 1.2828 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 1.4635 - main_output_accuracy: 0.8513 - main_output_loss: 1.2754 - tof_gate_loss: 0.0011 - val_loss: 1.4437 - val_main_output_accuracy: 0.7213 - val_main_output_loss: 1.2583 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.4906 - main_output_accuracy: 0.8304 - main_output_loss: 1.3011 - tof_gate_loss: 0.0011 - val_loss: 1.4894 - val_main_output_accuracy: 0.7139 - val_main_output_loss: 1.3057 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.6064 - main_output_accuracy: 0.7848 - main_output_loss: 1.4189 - tof_gate_loss: 0.0012 - val_loss: 1.4503 - val_main_output_accuracy: 0.7213 - val_main_output_loss: 1.2690 - val_tof_gate_loss: 9.8144e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - loss: 1.4644 - main_output_accuracy: 0.8274 - main_output_loss: 1.2810 - tof_gate_loss: 0.0010 - val_loss: 1.4883 - val_main_output_accuracy: 0.7016 - val_main_output_loss: 1.3041 - val_tof_gate_loss: 9.8067e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.5711 - main_output_accuracy: 0.8024 - main_output_loss: 1.3877 - tof_gate_loss: 0.0011 - val_loss: 1.4543 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2707 - val_tof_gate_loss: 9.1300e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.4502 - main_output_accuracy: 0.8308 - main_output_loss: 1.2677 - tof_gate_loss: 9.3474e-04 - val_loss: 1.4700 - val_main_output_accuracy: 0.6942 - val_main_output_loss: 1.2885 - val_tof_gate_loss: 8.8098e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 1.5513 - main_output_accuracy: 0.7949 - main_output_loss: 1.3714 - tof_gate_loss: 0.0010 - val_loss: 1.4387 - val_main_output_accuracy: 0.7324 - val_main_output_loss: 1.2596 - val_tof_gate_loss: 8.4783e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.6230 - main_output_accuracy: 0.7995 - main_output_loss: 1.4427 - tof_gate_loss: 9.2015e-04 - val_loss: 1.4633 - val_main_output_accuracy: 0.7164 - val_main_output_loss: 1.2817 - val_tof_gate_loss: 8.1552e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.6052 - main_output_accuracy: 0.7762 - main_output_loss: 1.4266 - tof_gate_loss: 9.8827e-04 - val_loss: 1.4490 - val_main_output_accuracy: 0.7226 - val_main_output_loss: 1.2745 - val_tof_gate_loss: 7.8746e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - loss: 1.5244 - main_output_accuracy: 0.8241 - main_output_loss: 1.3449 - tof_gate_loss: 8.6099e-04 - val_loss: 1.5061 - val_main_output_accuracy: 0.7090 - val_main_output_loss: 1.3339 - val_tof_gate_loss: 7.5574e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 128ms/step - loss: 1.5660 - main_output_accuracy: 0.8293 - main_output_loss: 1.3907 - tof_gate_loss: 7.8156e-04 - val_loss: 1.4762 - val_main_output_accuracy: 0.7016 - val_main_output_loss: 1.2997 - val_tof_gate_loss: 7.2544e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.4259 - main_output_accuracy: 0.8522 - main_output_loss: 1.2510 - tof_gate_loss: 7.3393e-04 - val_loss: 1.4652 - val_main_output_accuracy: 0.7152 - val_main_output_loss: 1.2884 - val_tof_gate_loss: 6.9697e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - loss: 1.5130 - main_output_accuracy: 0.8249 - main_output_loss: 1.3393 - tof_gate_loss: 7.7992e-04 - val_loss: 1.5400 - val_main_output_accuracy: 0.7004 - val_main_output_loss: 1.3683 - val_tof_gate_loss: 6.6952e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - loss: 1.4906 - main_output_accuracy: 0.8346 - main_output_loss: 1.3143 - tof_gate_loss: 6.9804e-04 - val_loss: 1.4879 - val_main_output_accuracy: 0.7176 - val_main_output_loss: 1.3144 - val_tof_gate_loss: 6.4790e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 1.3889 - main_output_accuracy: 0.8533 - main_output_loss: 1.2174 - tof_gate_loss: 6.1879e-04\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 1.3895 - main_output_accuracy: 0.8531 - main_output_loss: 1.2180 - tof_gate_loss: 6.1894e-04 - val_loss: 1.5028 - val_main_output_accuracy: 0.7028 - val_main_output_loss: 1.3304 - val_tof_gate_loss: 6.2844e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 1.5721 - main_output_accuracy: 0.8161 - main_output_loss: 1.4018 - tof_gate_loss: 6.7202e-04 - val_loss: 1.4364 - val_main_output_accuracy: 0.7201 - val_main_output_loss: 1.2702 - val_tof_gate_loss: 6.0099e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5117 - main_output_accuracy: 0.8311 - main_output_loss: 1.3451 - tof_gate_loss: 6.4125e-04 - val_loss: 1.4066 - val_main_output_accuracy: 0.7300 - val_main_output_loss: 1.2349 - val_tof_gate_loss: 5.9074e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - loss: 1.5338 - main_output_accuracy: 0.8278 - main_output_loss: 1.3659 - tof_gate_loss: 6.4662e-04 - val_loss: 1.4402 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2767 - val_tof_gate_loss: 5.7121e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.3936 - main_output_accuracy: 0.8722 - main_output_loss: 1.2264 - tof_gate_loss: 5.7127e-04 - val_loss: 1.4160 - val_main_output_accuracy: 0.7176 - val_main_output_loss: 1.2511 - val_tof_gate_loss: 5.6212e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - loss: 1.2907 - main_output_accuracy: 0.8900 - main_output_loss: 1.1244 - tof_gate_loss: 5.4349e-04 - val_loss: 1.4694 - val_main_output_accuracy: 0.7115 - val_main_output_loss: 1.3073 - val_tof_gate_loss: 5.6531e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - loss: 1.4719 - main_output_accuracy: 0.8462 - main_output_loss: 1.3042 - tof_gate_loss: 6.0976e-04 - val_loss: 1.4360 - val_main_output_accuracy: 0.7201 - val_main_output_loss: 1.2632 - val_tof_gate_loss: 5.3901e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4279 - main_output_accuracy: 0.8647 - main_output_loss: 1.2633 - tof_gate_loss: 6.0021e-04 - val_loss: 1.4471 - val_main_output_accuracy: 0.7028 - val_main_output_loss: 1.2861 - val_tof_gate_loss: 5.2604e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 133ms/step - loss: 1.3986 - main_output_accuracy: 0.8667 - main_output_loss: 1.2365 - tof_gate_loss: 5.6960e-04 - val_loss: 1.4060 - val_main_output_accuracy: 0.7263 - val_main_output_loss: 1.2408 - val_tof_gate_loss: 5.0364e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.4270 - main_output_accuracy: 0.8502 - main_output_loss: 1.2648 - tof_gate_loss: 5.3873e-04\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.4269 - main_output_accuracy: 0.8502 - main_output_loss: 1.2647 - tof_gate_loss: 5.3856e-04 - val_loss: 1.4147 - val_main_output_accuracy: 0.7164 - val_main_output_loss: 1.2490 - val_tof_gate_loss: 4.9325e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - loss: 1.4626 - main_output_accuracy: 0.8422 - main_output_loss: 1.3023 - tof_gate_loss: 5.6079e-04 - val_loss: 1.4294 - val_main_output_accuracy: 0.7102 - val_main_output_loss: 1.2682 - val_tof_gate_loss: 4.7995e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4488 - main_output_accuracy: 0.8488 - main_output_loss: 1.2866 - tof_gate_loss: 5.5340e-04 - val_loss: 1.3988 - val_main_output_accuracy: 0.7275 - val_main_output_loss: 1.2390 - val_tof_gate_loss: 4.7302e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 133ms/step - loss: 1.5032 - main_output_accuracy: 0.8391 - main_output_loss: 1.3391 - tof_gate_loss: 5.2529e-04 - val_loss: 1.4077 - val_main_output_accuracy: 0.7312 - val_main_output_loss: 1.2512 - val_tof_gate_loss: 4.7429e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.4939 - main_output_accuracy: 0.8403 - main_output_loss: 1.3334 - tof_gate_loss: 5.3997e-04 - val_loss: 1.3908 - val_main_output_accuracy: 0.7386 - val_main_output_loss: 1.2367 - val_tof_gate_loss: 4.6418e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - loss: 1.4025 - main_output_accuracy: 0.8550 - main_output_loss: 1.2424 - tof_gate_loss: 5.2007e-04 - val_loss: 1.4349 - val_main_output_accuracy: 0.7127 - val_main_output_loss: 1.2767 - val_tof_gate_loss: 4.5326e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - loss: 1.3915 - main_output_accuracy: 0.8733 - main_output_loss: 1.2343 - tof_gate_loss: 4.7377e-04 - val_loss: 1.3999 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2342 - val_tof_gate_loss: 4.4982e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3632 - main_output_accuracy: 0.8756 - main_output_loss: 1.2046 - tof_gate_loss: 4.6187e-04 - val_loss: 1.4229 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2676 - val_tof_gate_loss: 4.4181e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 134ms/step - loss: 1.4395 - main_output_accuracy: 0.8707 - main_output_loss: 1.2858 - tof_gate_loss: 5.1329e-04 - val_loss: 1.3790 - val_main_output_accuracy: 0.7386 - val_main_output_loss: 1.2157 - val_tof_gate_loss: 4.4121e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5130 - main_output_accuracy: 0.8301 - main_output_loss: 1.3581 - tof_gate_loss: 5.0957e-04 - val_loss: 1.4115 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2532 - val_tof_gate_loss: 4.3010e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - loss: 1.3617 - main_output_accuracy: 0.8916 - main_output_loss: 1.2039 - tof_gate_loss: 4.3818e-04 - val_loss: 1.4245 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2722 - val_tof_gate_loss: 4.2112e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4577 - main_output_accuracy: 0.8669 - main_output_loss: 1.3116 - tof_gate_loss: 4.3842e-04 - val_loss: 1.4053 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2483 - val_tof_gate_loss: 4.0719e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 1.3921 - main_output_accuracy: 0.8566 - main_output_loss: 1.2345 - tof_gate_loss: 4.3331e-04\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - loss: 1.3926 - main_output_accuracy: 0.8566 - main_output_loss: 1.2350 - tof_gate_loss: 4.3338e-04 - val_loss: 1.4212 - val_main_output_accuracy: 0.7152 - val_main_output_loss: 1.2667 - val_tof_gate_loss: 4.1074e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4525 - main_output_accuracy: 0.8654 - main_output_loss: 1.2994 - tof_gate_loss: 4.4365e-04 - val_loss: 1.3866 - val_main_output_accuracy: 0.7361 - val_main_output_loss: 1.2329 - val_tof_gate_loss: 3.9518e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - loss: 1.4231 - main_output_accuracy: 0.8741 - main_output_loss: 1.2675 - tof_gate_loss: 4.2324e-04 - val_loss: 1.3947 - val_main_output_accuracy: 0.7337 - val_main_output_loss: 1.2378 - val_tof_gate_loss: 3.8968e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.2726 - main_output_accuracy: 0.9019 - main_output_loss: 1.1152 - tof_gate_loss: 3.7757e-04 - val_loss: 1.3902 - val_main_output_accuracy: 0.7386 - val_main_output_loss: 1.2299 - val_tof_gate_loss: 3.9756e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - loss: 1.4108 - main_output_accuracy: 0.8599 - main_output_loss: 1.2575 - tof_gate_loss: 4.4192e-04 - val_loss: 1.4095 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2506 - val_tof_gate_loss: 3.8514e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 128ms/step - loss: 1.3027 - main_output_accuracy: 0.9005 - main_output_loss: 1.1478 - tof_gate_loss: 3.9071e-04 - val_loss: 1.3947 - val_main_output_accuracy: 0.7312 - val_main_output_loss: 1.2349 - val_tof_gate_loss: 3.7790e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.3291 - main_output_accuracy: 0.8913 - main_output_loss: 1.1715 - tof_gate_loss: 3.9259e-04 - val_loss: 1.3833 - val_main_output_accuracy: 0.7312 - val_main_output_loss: 1.2255 - val_tof_gate_loss: 3.7980e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - loss: 1.4010 - main_output_accuracy: 0.8650 - main_output_loss: 1.2453 - tof_gate_loss: 4.0859e-04 - val_loss: 1.3742 - val_main_output_accuracy: 0.7411 - val_main_output_loss: 1.2193 - val_tof_gate_loss: 3.6954e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4415 - main_output_accuracy: 0.8701 - main_output_loss: 1.2895 - tof_gate_loss: 4.0363e-04 - val_loss: 1.3901 - val_main_output_accuracy: 0.7324 - val_main_output_loss: 1.2377 - val_tof_gate_loss: 3.6637e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - loss: 1.2831 - main_output_accuracy: 0.9077 - main_output_loss: 1.1345 - tof_gate_loss: 3.5978e-04 - val_loss: 1.3812 - val_main_output_accuracy: 0.7337 - val_main_output_loss: 1.2267 - val_tof_gate_loss: 3.6051e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.4214 - main_output_accuracy: 0.8688 - main_output_loss: 1.2630 - tof_gate_loss: 3.8660e-04 - val_loss: 1.3830 - val_main_output_accuracy: 0.7386 - val_main_output_loss: 1.2263 - val_tof_gate_loss: 3.5432e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - loss: 1.4193 - main_output_accuracy: 0.8746 - main_output_loss: 1.2648 - tof_gate_loss: 3.7727e-04 - val_loss: 1.3877 - val_main_output_accuracy: 0.7275 - val_main_output_loss: 1.2334 - val_tof_gate_loss: 3.5524e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4012 - main_output_accuracy: 0.8681 - main_output_loss: 1.2513 - tof_gate_loss: 3.9683e-04 - val_loss: 1.3925 - val_main_output_accuracy: 0.7374 - val_main_output_loss: 1.2358 - val_tof_gate_loss: 3.4607e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 98/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - loss: 1.3761 - main_output_accuracy: 0.8769 - main_output_loss: 1.2225 - tof_gate_loss: 3.6644e-04 - val_loss: 1.3903 - val_main_output_accuracy: 0.7226 - val_main_output_loss: 1.2336 - val_tof_gate_loss: 3.4058e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 99/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - loss: 1.4272 - main_output_accuracy: 0.8698 - main_output_loss: 1.2735 - tof_gate_loss: 3.8909e-04 - val_loss: 1.3929 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2437 - val_tof_gate_loss: 3.3523e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 100/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.2296 - main_output_accuracy: 0.9145 - main_output_loss: 1.0735 - tof_gate_loss: 3.2103e-04\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.2305 - main_output_accuracy: 0.9144 - main_output_loss: 1.0744 - tof_gate_loss: 3.2122e-04 - val_loss: 1.4083 - val_main_output_accuracy: 0.7201 - val_main_output_loss: 1.2557 - val_tof_gate_loss: 3.3288e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 101/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 133ms/step - loss: 1.4195 - main_output_accuracy: 0.8623 - main_output_loss: 1.2660 - tof_gate_loss: 3.7251e-04 - val_loss: 1.3879 - val_main_output_accuracy: 0.7312 - val_main_output_loss: 1.2303 - val_tof_gate_loss: 3.2796e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - loss: 1.3636 - main_output_accuracy: 0.8871 - main_output_loss: 1.2101 - tof_gate_loss: 3.4025e-04 - val_loss: 1.3914 - val_main_output_accuracy: 0.7201 - val_main_output_loss: 1.2471 - val_tof_gate_loss: 3.2529e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 84ms/step - loss: 1.3492 - main_output_accuracy: 0.8874 - main_output_loss: 1.1937 - tof_gate_loss: 3.4077e-04 - val_loss: 1.3891 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2386 - val_tof_gate_loss: 3.2572e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - loss: 1.4135 - main_output_accuracy: 0.8725 - main_output_loss: 1.2574 - tof_gate_loss: 3.5463e-04 - val_loss: 1.3913 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2429 - val_tof_gate_loss: 3.2369e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3195 - main_output_accuracy: 0.8903 - main_output_loss: 1.1637 - tof_gate_loss: 3.4725e-04 - val_loss: 1.3935 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2387 - val_tof_gate_loss: 3.2341e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 128ms/step - loss: 1.3199 - main_output_accuracy: 0.8888 - main_output_loss: 1.1670 - tof_gate_loss: 3.2307e-04 - val_loss: 1.3883 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2324 - val_tof_gate_loss: 3.1755e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3826 - main_output_accuracy: 0.8809 - main_output_loss: 1.2287 - tof_gate_loss: 3.3268e-04 - val_loss: 1.3908 - val_main_output_accuracy: 0.7361 - val_main_output_loss: 1.2395 - val_tof_gate_loss: 3.1435e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - loss: 1.4188 - main_output_accuracy: 0.8613 - main_output_loss: 1.2675 - tof_gate_loss: 3.4309e-04 - val_loss: 1.3889 - val_main_output_accuracy: 0.7324 - val_main_output_loss: 1.2327 - val_tof_gate_loss: 3.1382e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 1.4837 - main_output_accuracy: 0.8632 - main_output_loss: 1.3333 - tof_gate_loss: 3.5676e-04\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - loss: 1.4837 - main_output_accuracy: 0.8631 - main_output_loss: 1.3332 - tof_gate_loss: 3.5679e-04 - val_loss: 1.3920 - val_main_output_accuracy: 0.7226 - val_main_output_loss: 1.2378 - val_tof_gate_loss: 3.1604e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3213 - main_output_accuracy: 0.8985 - main_output_loss: 1.1719 - tof_gate_loss: 3.3415e-04 - val_loss: 1.3864 - val_main_output_accuracy: 0.7324 - val_main_output_loss: 1.2327 - val_tof_gate_loss: 3.0886e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - loss: 1.2988 - main_output_accuracy: 0.8969 - main_output_loss: 1.1455 - tof_gate_loss: 3.4629e-04 - val_loss: 1.3846 - val_main_output_accuracy: 0.7312 - val_main_output_loss: 1.2299 - val_tof_gate_loss: 3.0714e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.4705 - main_output_accuracy: 0.8564 - main_output_loss: 1.3183 - tof_gate_loss: 3.4771e-04 - val_loss: 1.3829 - val_main_output_accuracy: 0.7300 - val_main_output_loss: 1.2320 - val_tof_gate_loss: 3.0186e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - loss: 1.4654 - main_output_accuracy: 0.8539 - main_output_loss: 1.3133 - tof_gate_loss: 3.4982e-04 - val_loss: 1.3847 - val_main_output_accuracy: 0.7349 - val_main_output_loss: 1.2320 - val_tof_gate_loss: 3.0712e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3736 - main_output_accuracy: 0.8844 - main_output_loss: 1.2221 - tof_gate_loss: 3.3030e-04 - val_loss: 1.3889 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2397 - val_tof_gate_loss: 2.9904e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - loss: 1.4349 - main_output_accuracy: 0.8611 - main_output_loss: 1.2852 - tof_gate_loss: 3.3038e-04 - val_loss: 1.3891 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2418 - val_tof_gate_loss: 3.0185e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5424 - main_output_accuracy: 0.8316 - main_output_loss: 1.3906 - tof_gate_loss: 3.7745e-04 - val_loss: 1.3875 - val_main_output_accuracy: 0.7213 - val_main_output_loss: 1.2371 - val_tof_gate_loss: 3.0055e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - loss: 1.4548 - main_output_accuracy: 0.8610 - main_output_loss: 1.3030 - tof_gate_loss: 3.2919e-04 - val_loss: 1.3911 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2392 - val_tof_gate_loss: 2.9807e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 1.4505 - main_output_accuracy: 0.8693 - main_output_loss: 1.3011 - tof_gate_loss: 3.4509e-04\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4504 - main_output_accuracy: 0.8693 - main_output_loss: 1.3011 - tof_gate_loss: 3.4502e-04 - val_loss: 1.3884 - val_main_output_accuracy: 0.7189 - val_main_output_loss: 1.2371 - val_tof_gate_loss: 2.9781e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 130ms/step - loss: 1.3712 - main_output_accuracy: 0.8895 - main_output_loss: 1.2207 - tof_gate_loss: 3.0687e-04 - val_loss: 1.3886 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2466 - val_tof_gate_loss: 2.9655e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 131ms/step - loss: 1.2747 - main_output_accuracy: 0.9141 - main_output_loss: 1.1220 - tof_gate_loss: 3.0628e-04 - val_loss: 1.3894 - val_main_output_accuracy: 0.7226 - val_main_output_loss: 1.2408 - val_tof_gate_loss: 2.9650e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.3099 - main_output_accuracy: 0.8868 - main_output_loss: 1.1568 - tof_gate_loss: 2.9513e-04 - val_loss: 1.3887 - val_main_output_accuracy: 0.7250 - val_main_output_loss: 1.2362 - val_tof_gate_loss: 2.9669e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 122/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - loss: 1.4256 - main_output_accuracy: 0.8521 - main_output_loss: 1.2695 - tof_gate_loss: 3.2750e-04 - val_loss: 1.3875 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2327 - val_tof_gate_loss: 2.9191e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 123/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.3423 - main_output_accuracy: 0.8970 - main_output_loss: 1.1865 - tof_gate_loss: 2.9593e-04 - val_loss: 1.3896 - val_main_output_accuracy: 0.7213 - val_main_output_loss: 1.2435 - val_tof_gate_loss: 2.9192e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 124/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 135ms/step - loss: 1.4185 - main_output_accuracy: 0.8847 - main_output_loss: 1.2688 - tof_gate_loss: 3.1500e-04 - val_loss: 1.3867 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2308 - val_tof_gate_loss: 2.9041e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 125/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.4242 - main_output_accuracy: 0.8739 - main_output_loss: 1.2736 - tof_gate_loss: 3.2041e-04 - val_loss: 1.3874 - val_main_output_accuracy: 0.7275 - val_main_output_loss: 1.2373 - val_tof_gate_loss: 2.9079e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 126/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 133ms/step - loss: 1.3155 - main_output_accuracy: 0.8969 - main_output_loss: 1.1652 - tof_gate_loss: 2.9992e-04 - val_loss: 1.3851 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2318 - val_tof_gate_loss: 2.9039e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 127/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3895 - main_output_accuracy: 0.8776 - main_output_loss: 1.2366 - tof_gate_loss: 3.2118e-04 - val_loss: 1.3866 - val_main_output_accuracy: 0.7263 - val_main_output_loss: 1.2358 - val_tof_gate_loss: 2.8391e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 128/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 136ms/step - loss: 1.3668 - main_output_accuracy: 0.8931 - main_output_loss: 1.2150 - tof_gate_loss: 3.0903e-04 - val_loss: 1.3871 - val_main_output_accuracy: 0.7226 - val_main_output_loss: 1.2307 - val_tof_gate_loss: 2.8517e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 129/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3820 - main_output_accuracy: 0.8823 - main_output_loss: 1.2283 - tof_gate_loss: 3.1242e-04 - val_loss: 1.3809 - val_main_output_accuracy: 0.7287 - val_main_output_loss: 1.2273 - val_tof_gate_loss: 2.8584e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 130/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 134ms/step - loss: 1.3100 - main_output_accuracy: 0.8994 - main_output_loss: 1.1573 - tof_gate_loss: 2.9013e-04 - val_loss: 1.3836 - val_main_output_accuracy: 0.7275 - val_main_output_loss: 1.2320 - val_tof_gate_loss: 2.8252e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 131/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 137ms/step - loss: 1.3690 - main_output_accuracy: 0.8783 - main_output_loss: 1.2189 - tof_gate_loss: 3.1284e-04 - val_loss: 1.3847 - val_main_output_accuracy: 0.7300 - val_main_output_loss: 1.2359 - val_tof_gate_loss: 2.8145e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 132/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3958 - main_output_accuracy: 0.8760 - main_output_loss: 1.2445 - tof_gate_loss: 3.1047e-04 - val_loss: 1.3869 - val_main_output_accuracy: 0.7238 - val_main_output_loss: 1.2351 - val_tof_gate_loss: 2.7744e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 132: early stopping\n",
      "Restoring model weights from the end of the best epoch: 92.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 09:57:52.986498: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\n",
      "===== FOLD 2/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 113ms/step - loss: 10.5236 - main_output_accuracy: 0.1619 - main_output_loss: 2.9204 - tof_gate_loss: 1.0983 - val_loss: 8.1123 - val_main_output_accuracy: 0.3958 - val_main_output_loss: 2.5085 - val_tof_gate_loss: 0.8378 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 129ms/step - loss: 7.3647 - main_output_accuracy: 0.3733 - main_output_loss: 2.1936 - tof_gate_loss: 0.7557 - val_loss: 6.1826 - val_main_output_accuracy: 0.4939 - val_main_output_loss: 2.0317 - val_tof_gate_loss: 0.6550 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 5.9744 - main_output_accuracy: 0.4635 - main_output_loss: 2.0665 - tof_gate_loss: 0.6104 - val_loss: 5.0771 - val_main_output_accuracy: 0.5172 - val_main_output_loss: 1.7901 - val_tof_gate_loss: 0.5331 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 134ms/step - loss: 5.0676 - main_output_accuracy: 0.5046 - main_output_loss: 1.9516 - tof_gate_loss: 0.5010 - val_loss: 4.4390 - val_main_output_accuracy: 0.5196 - val_main_output_loss: 1.7646 - val_tof_gate_loss: 0.4428 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 4.3463 - main_output_accuracy: 0.5517 - main_output_loss: 1.7989 - tof_gate_loss: 0.4022 - val_loss: 3.9116 - val_main_output_accuracy: 0.5404 - val_main_output_loss: 1.7056 - val_tof_gate_loss: 0.3482 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 3.9668 - main_output_accuracy: 0.5726 - main_output_loss: 1.8638 - tof_gate_loss: 0.3260 - val_loss: 3.4667 - val_main_output_accuracy: 0.5821 - val_main_output_loss: 1.6298 - val_tof_gate_loss: 0.2639 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 3.6019 - main_output_accuracy: 0.5760 - main_output_loss: 1.8424 - tof_gate_loss: 0.2473 - val_loss: 3.2224 - val_main_output_accuracy: 0.5441 - val_main_output_loss: 1.6738 - val_tof_gate_loss: 0.1985 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 3.1994 - main_output_accuracy: 0.6057 - main_output_loss: 1.7121 - tof_gate_loss: 0.1844 - val_loss: 2.9307 - val_main_output_accuracy: 0.5870 - val_main_output_loss: 1.6169 - val_tof_gate_loss: 0.1512 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 3.0451 - main_output_accuracy: 0.6196 - main_output_loss: 1.7783 - tof_gate_loss: 0.1432 - val_loss: 2.8297 - val_main_output_accuracy: 0.5625 - val_main_output_loss: 1.6986 - val_tof_gate_loss: 0.1197 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.8192 - main_output_accuracy: 0.6266 - main_output_loss: 1.7284 - tof_gate_loss: 0.1134 - val_loss: 2.5895 - val_main_output_accuracy: 0.5809 - val_main_output_loss: 1.6102 - val_tof_gate_loss: 0.0964 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 2.6566 - main_output_accuracy: 0.6278 - main_output_loss: 1.7090 - tof_gate_loss: 0.0891 - val_loss: 2.4297 - val_main_output_accuracy: 0.6005 - val_main_output_loss: 1.5703 - val_tof_gate_loss: 0.0794 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 2.5704 - main_output_accuracy: 0.6102 - main_output_loss: 1.7394 - tof_gate_loss: 0.0735 - val_loss: 2.4030 - val_main_output_accuracy: 0.5613 - val_main_output_loss: 1.6474 - val_tof_gate_loss: 0.0676 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 2.4037 - main_output_accuracy: 0.6380 - main_output_loss: 1.6648 - tof_gate_loss: 0.0625 - val_loss: 2.2765 - val_main_output_accuracy: 0.5944 - val_main_output_loss: 1.6021 - val_tof_gate_loss: 0.0572 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - loss: 2.2555 - main_output_accuracy: 0.6632 - main_output_loss: 1.6029 - tof_gate_loss: 0.0496 - val_loss: 2.1368 - val_main_output_accuracy: 0.6225 - val_main_output_loss: 1.5327 - val_tof_gate_loss: 0.0499 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 2.2628 - main_output_accuracy: 0.6393 - main_output_loss: 1.6741 - tof_gate_loss: 0.0435 - val_loss: 2.1338 - val_main_output_accuracy: 0.6115 - val_main_output_loss: 1.5879 - val_tof_gate_loss: 0.0434 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 128ms/step - loss: 2.1341 - main_output_accuracy: 0.6840 - main_output_loss: 1.6054 - tof_gate_loss: 0.0367 - val_loss: 2.0669 - val_main_output_accuracy: 0.6275 - val_main_output_loss: 1.5664 - val_tof_gate_loss: 0.0384 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 128ms/step - loss: 2.1427 - main_output_accuracy: 0.6650 - main_output_loss: 1.6571 - tof_gate_loss: 0.0328 - val_loss: 1.9730 - val_main_output_accuracy: 0.6238 - val_main_output_loss: 1.5130 - val_tof_gate_loss: 0.0345 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 2.1051 - main_output_accuracy: 0.6735 - main_output_loss: 1.6542 - tof_gate_loss: 0.0286 - val_loss: 2.0516 - val_main_output_accuracy: 0.5809 - val_main_output_loss: 1.6228 - val_tof_gate_loss: 0.0311 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 125ms/step - loss: 1.9635 - main_output_accuracy: 0.6929 - main_output_loss: 1.5421 - tof_gate_loss: 0.0233 - val_loss: 2.1412 - val_main_output_accuracy: 0.5637 - val_main_output_loss: 1.7322 - val_tof_gate_loss: 0.0283 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - loss: 2.0563 - main_output_accuracy: 0.6853 - main_output_loss: 1.6604 - tof_gate_loss: 0.0221 - val_loss: 2.0468 - val_main_output_accuracy: 0.5490 - val_main_output_loss: 1.6656 - val_tof_gate_loss: 0.0251 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.9914 - main_output_accuracy: 0.6768 - main_output_loss: 1.6183 - tof_gate_loss: 0.0198 - val_loss: 2.0318 - val_main_output_accuracy: 0.5760 - val_main_output_loss: 1.6740 - val_tof_gate_loss: 0.0231 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.9290 - main_output_accuracy: 0.6875 - main_output_loss: 1.5773 - tof_gate_loss: 0.0173 - val_loss: 1.9122 - val_main_output_accuracy: 0.5907 - val_main_output_loss: 1.5719 - val_tof_gate_loss: 0.0218 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.0341 - main_output_accuracy: 0.6630 - main_output_loss: 1.7000 - tof_gate_loss: 0.0171 - val_loss: 1.8558 - val_main_output_accuracy: 0.6189 - val_main_output_loss: 1.5314 - val_tof_gate_loss: 0.0195 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 2.0023 - main_output_accuracy: 0.6782 - main_output_loss: 1.6767 - tof_gate_loss: 0.0141\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.0020 - main_output_accuracy: 0.6782 - main_output_loss: 1.6765 - tof_gate_loss: 0.0141 - val_loss: 1.9630 - val_main_output_accuracy: 0.6115 - val_main_output_loss: 1.6515 - val_tof_gate_loss: 0.0183 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.8804 - main_output_accuracy: 0.7229 - main_output_loss: 1.5740 - tof_gate_loss: 0.0126 - val_loss: 1.7572 - val_main_output_accuracy: 0.6483 - val_main_output_loss: 1.4617 - val_tof_gate_loss: 0.0176 - learning_rate: 2.5000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.7993 - main_output_accuracy: 0.7302 - main_output_loss: 1.5034 - tof_gate_loss: 0.0120 - val_loss: 1.7018 - val_main_output_accuracy: 0.6483 - val_main_output_loss: 1.4133 - val_tof_gate_loss: 0.0165 - learning_rate: 2.5000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - loss: 1.7313 - main_output_accuracy: 0.7491 - main_output_loss: 1.4420 - tof_gate_loss: 0.0111 - val_loss: 1.7192 - val_main_output_accuracy: 0.6458 - val_main_output_loss: 1.4423 - val_tof_gate_loss: 0.0159 - learning_rate: 2.5000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.7394 - main_output_accuracy: 0.7322 - main_output_loss: 1.4660 - tof_gate_loss: 0.0105 - val_loss: 1.7907 - val_main_output_accuracy: 0.6213 - val_main_output_loss: 1.5171 - val_tof_gate_loss: 0.0151 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.7474 - main_output_accuracy: 0.7491 - main_output_loss: 1.4795 - tof_gate_loss: 0.0107 - val_loss: 1.6825 - val_main_output_accuracy: 0.6679 - val_main_output_loss: 1.4162 - val_tof_gate_loss: 0.0145 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.6901 - main_output_accuracy: 0.7652 - main_output_loss: 1.4304 - tof_gate_loss: 0.0090 - val_loss: 1.7640 - val_main_output_accuracy: 0.6373 - val_main_output_loss: 1.5053 - val_tof_gate_loss: 0.0141 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.6613 - main_output_accuracy: 0.7534 - main_output_loss: 1.4040 - tof_gate_loss: 0.0086 - val_loss: 1.6749 - val_main_output_accuracy: 0.6642 - val_main_output_loss: 1.4229 - val_tof_gate_loss: 0.0133 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.7705 - main_output_accuracy: 0.7516 - main_output_loss: 1.5209 - tof_gate_loss: 0.0088 - val_loss: 1.6842 - val_main_output_accuracy: 0.6605 - val_main_output_loss: 1.4364 - val_tof_gate_loss: 0.0129 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - loss: 1.6553 - main_output_accuracy: 0.7595 - main_output_loss: 1.4118 - tof_gate_loss: 0.0077 - val_loss: 1.7581 - val_main_output_accuracy: 0.6458 - val_main_output_loss: 1.5141 - val_tof_gate_loss: 0.0121 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.6857 - main_output_accuracy: 0.7542 - main_output_loss: 1.4413 - tof_gate_loss: 0.0073 - val_loss: 1.7386 - val_main_output_accuracy: 0.6483 - val_main_output_loss: 1.4942 - val_tof_gate_loss: 0.0116 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 1.7041 - main_output_accuracy: 0.7692 - main_output_loss: 1.4658 - tof_gate_loss: 0.0069 - val_loss: 1.6477 - val_main_output_accuracy: 0.6703 - val_main_output_loss: 1.4089 - val_tof_gate_loss: 0.0114 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.7480 - main_output_accuracy: 0.7333 - main_output_loss: 1.5120 - tof_gate_loss: 0.0071 - val_loss: 1.7177 - val_main_output_accuracy: 0.6250 - val_main_output_loss: 1.4849 - val_tof_gate_loss: 0.0106 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - loss: 1.8154 - main_output_accuracy: 0.7317 - main_output_loss: 1.5885 - tof_gate_loss: 0.0067 - val_loss: 1.6506 - val_main_output_accuracy: 0.6728 - val_main_output_loss: 1.4178 - val_tof_gate_loss: 0.0101 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.6318 - main_output_accuracy: 0.7839 - main_output_loss: 1.4015 - tof_gate_loss: 0.0059 - val_loss: 1.7157 - val_main_output_accuracy: 0.6201 - val_main_output_loss: 1.4880 - val_tof_gate_loss: 0.0096 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.6046 - main_output_accuracy: 0.7877 - main_output_loss: 1.3790 - tof_gate_loss: 0.0053 - val_loss: 1.6669 - val_main_output_accuracy: 0.6544 - val_main_output_loss: 1.4429 - val_tof_gate_loss: 0.0094 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 132ms/step - loss: 1.6336 - main_output_accuracy: 0.7823 - main_output_loss: 1.4116 - tof_gate_loss: 0.0053 - val_loss: 1.6424 - val_main_output_accuracy: 0.6667 - val_main_output_loss: 1.4210 - val_tof_gate_loss: 0.0088 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7065 - main_output_accuracy: 0.7664 - main_output_loss: 1.4839 - tof_gate_loss: 0.0052 - val_loss: 1.8111 - val_main_output_accuracy: 0.5907 - val_main_output_loss: 1.5955 - val_tof_gate_loss: 0.0085 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.6688 - main_output_accuracy: 0.7656 - main_output_loss: 1.4519 - tof_gate_loss: 0.0045 - val_loss: 1.7247 - val_main_output_accuracy: 0.6176 - val_main_output_loss: 1.5099 - val_tof_gate_loss: 0.0080 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7041 - main_output_accuracy: 0.7590 - main_output_loss: 1.4782 - tof_gate_loss: 0.0043 - val_loss: 1.7724 - val_main_output_accuracy: 0.6336 - val_main_output_loss: 1.5591 - val_tof_gate_loss: 0.0079 - learning_rate: 2.5000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - loss: 1.6560 - main_output_accuracy: 0.7737 - main_output_loss: 1.4414 - tof_gate_loss: 0.0040 - val_loss: 1.6960 - val_main_output_accuracy: 0.6483 - val_main_output_loss: 1.4820 - val_tof_gate_loss: 0.0073 - learning_rate: 2.5000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.6121 - main_output_accuracy: 0.7914 - main_output_loss: 1.3998 - tof_gate_loss: 0.0038 - val_loss: 1.6204 - val_main_output_accuracy: 0.6740 - val_main_output_loss: 1.4060 - val_tof_gate_loss: 0.0070 - learning_rate: 2.5000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.6206 - main_output_accuracy: 0.7764 - main_output_loss: 1.4044 - tof_gate_loss: 0.0038 - val_loss: 1.6319 - val_main_output_accuracy: 0.6716 - val_main_output_loss: 1.4226 - val_tof_gate_loss: 0.0067 - learning_rate: 2.5000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7011 - main_output_accuracy: 0.7610 - main_output_loss: 1.4925 - tof_gate_loss: 0.0033 - val_loss: 1.6549 - val_main_output_accuracy: 0.6495 - val_main_output_loss: 1.4463 - val_tof_gate_loss: 0.0066 - learning_rate: 2.5000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.6879 - main_output_accuracy: 0.7619 - main_output_loss: 1.4855 - tof_gate_loss: 0.0037 - val_loss: 1.6871 - val_main_output_accuracy: 0.6679 - val_main_output_loss: 1.4796 - val_tof_gate_loss: 0.0061 - learning_rate: 2.5000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - loss: 1.5710 - main_output_accuracy: 0.8025 - main_output_loss: 1.3644 - tof_gate_loss: 0.0031 - val_loss: 1.6425 - val_main_output_accuracy: 0.6532 - val_main_output_loss: 1.4378 - val_tof_gate_loss: 0.0059 - learning_rate: 2.5000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.7515 - main_output_accuracy: 0.7408 - main_output_loss: 1.5476 - tof_gate_loss: 0.0029 - val_loss: 1.6489 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.4429 - val_tof_gate_loss: 0.0056 - learning_rate: 2.5000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - loss: 1.7128 - main_output_accuracy: 0.7612 - main_output_loss: 1.5094 - tof_gate_loss: 0.0027 - val_loss: 1.7368 - val_main_output_accuracy: 0.6434 - val_main_output_loss: 1.5325 - val_tof_gate_loss: 0.0056 - learning_rate: 2.5000e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.5813 - main_output_accuracy: 0.7909 - main_output_loss: 1.3784 - tof_gate_loss: 0.0025 - val_loss: 1.6223 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.4221 - val_tof_gate_loss: 0.0054 - learning_rate: 2.5000e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.6792 - main_output_accuracy: 0.7723 - main_output_loss: 1.4795 - tof_gate_loss: 0.0023 - val_loss: 1.6521 - val_main_output_accuracy: 0.6556 - val_main_output_loss: 1.4567 - val_tof_gate_loss: 0.0050 - learning_rate: 2.5000e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 1.6536 - main_output_accuracy: 0.7729 - main_output_loss: 1.4528 - tof_gate_loss: 0.0022 - val_loss: 1.6023 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.4023 - val_tof_gate_loss: 0.0048 - learning_rate: 2.5000e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.5668 - main_output_accuracy: 0.7953 - main_output_loss: 1.3691 - tof_gate_loss: 0.0020 - val_loss: 1.6581 - val_main_output_accuracy: 0.6532 - val_main_output_loss: 1.4591 - val_tof_gate_loss: 0.0046 - learning_rate: 2.5000e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.4812 - main_output_accuracy: 0.8321 - main_output_loss: 1.2822 - tof_gate_loss: 0.0017 - val_loss: 1.6099 - val_main_output_accuracy: 0.6716 - val_main_output_loss: 1.4085 - val_tof_gate_loss: 0.0046 - learning_rate: 2.5000e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.5719 - main_output_accuracy: 0.8034 - main_output_loss: 1.3773 - tof_gate_loss: 0.0018 - val_loss: 1.6942 - val_main_output_accuracy: 0.6373 - val_main_output_loss: 1.5052 - val_tof_gate_loss: 0.0043 - learning_rate: 2.5000e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 1.5207 - main_output_accuracy: 0.8068 - main_output_loss: 1.3315 - tof_gate_loss: 0.0017\n",
      "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.5209 - main_output_accuracy: 0.8068 - main_output_loss: 1.3317 - tof_gate_loss: 0.0017 - val_loss: 1.6538 - val_main_output_accuracy: 0.6569 - val_main_output_loss: 1.4602 - val_tof_gate_loss: 0.0041 - learning_rate: 2.5000e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.5680 - main_output_accuracy: 0.8010 - main_output_loss: 1.3749 - tof_gate_loss: 0.0015 - val_loss: 1.5635 - val_main_output_accuracy: 0.6863 - val_main_output_loss: 1.3773 - val_tof_gate_loss: 0.0042 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.5427 - main_output_accuracy: 0.8138 - main_output_loss: 1.3515 - tof_gate_loss: 0.0016 - val_loss: 1.5760 - val_main_output_accuracy: 0.6777 - val_main_output_loss: 1.3881 - val_tof_gate_loss: 0.0041 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - loss: 1.5074 - main_output_accuracy: 0.8169 - main_output_loss: 1.3208 - tof_gate_loss: 0.0015 - val_loss: 1.5420 - val_main_output_accuracy: 0.6887 - val_main_output_loss: 1.3522 - val_tof_gate_loss: 0.0038 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.4881 - main_output_accuracy: 0.8263 - main_output_loss: 1.3032 - tof_gate_loss: 0.0014 - val_loss: 1.5730 - val_main_output_accuracy: 0.6826 - val_main_output_loss: 1.3896 - val_tof_gate_loss: 0.0039 - learning_rate: 1.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.5819 - main_output_accuracy: 0.8108 - main_output_loss: 1.3985 - tof_gate_loss: 0.0014 - val_loss: 1.5833 - val_main_output_accuracy: 0.6703 - val_main_output_loss: 1.4036 - val_tof_gate_loss: 0.0037 - learning_rate: 1.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - loss: 1.4575 - main_output_accuracy: 0.8400 - main_output_loss: 1.2756 - tof_gate_loss: 0.0013 - val_loss: 1.5363 - val_main_output_accuracy: 0.6863 - val_main_output_loss: 1.3529 - val_tof_gate_loss: 0.0036 - learning_rate: 1.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.4671 - main_output_accuracy: 0.8246 - main_output_loss: 1.2839 - tof_gate_loss: 0.0012 - val_loss: 1.5194 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3474 - val_tof_gate_loss: 0.0035 - learning_rate: 1.2500e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.4584 - main_output_accuracy: 0.8474 - main_output_loss: 1.2841 - tof_gate_loss: 0.0012 - val_loss: 1.5330 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3537 - val_tof_gate_loss: 0.0034 - learning_rate: 1.2500e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - loss: 1.5087 - main_output_accuracy: 0.8286 - main_output_loss: 1.3329 - tof_gate_loss: 0.0012 - val_loss: 1.5977 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.4185 - val_tof_gate_loss: 0.0033 - learning_rate: 1.2500e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.5370 - main_output_accuracy: 0.8216 - main_output_loss: 1.3644 - tof_gate_loss: 0.0012 - val_loss: 1.6413 - val_main_output_accuracy: 0.6507 - val_main_output_loss: 1.4708 - val_tof_gate_loss: 0.0034 - learning_rate: 1.2500e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.5027 - main_output_accuracy: 0.8192 - main_output_loss: 1.3291 - tof_gate_loss: 0.0011 - val_loss: 1.5508 - val_main_output_accuracy: 0.6826 - val_main_output_loss: 1.3744 - val_tof_gate_loss: 0.0032 - learning_rate: 1.2500e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 1.4591 - main_output_accuracy: 0.8281 - main_output_loss: 1.2858 - tof_gate_loss: 0.0011 - val_loss: 1.6013 - val_main_output_accuracy: 0.6801 - val_main_output_loss: 1.4261 - val_tof_gate_loss: 0.0033 - learning_rate: 1.2500e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.4904 - main_output_accuracy: 0.8415 - main_output_loss: 1.3168 - tof_gate_loss: 0.0010 - val_loss: 1.6083 - val_main_output_accuracy: 0.6593 - val_main_output_loss: 1.4345 - val_tof_gate_loss: 0.0031 - learning_rate: 1.2500e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.3786 - main_output_accuracy: 0.8764 - main_output_loss: 1.2060 - tof_gate_loss: 9.3902e-04 - val_loss: 1.6359 - val_main_output_accuracy: 0.6679 - val_main_output_loss: 1.4600 - val_tof_gate_loss: 0.0029 - learning_rate: 1.2500e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 1.4421 - main_output_accuracy: 0.8426 - main_output_loss: 1.2714 - tof_gate_loss: 9.5027e-04\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.4425 - main_output_accuracy: 0.8425 - main_output_loss: 1.2718 - tof_gate_loss: 9.5021e-04 - val_loss: 1.5718 - val_main_output_accuracy: 0.6838 - val_main_output_loss: 1.4006 - val_tof_gate_loss: 0.0030 - learning_rate: 1.2500e-04\n",
      "Epoch 74/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - loss: 1.4293 - main_output_accuracy: 0.8427 - main_output_loss: 1.2585 - tof_gate_loss: 8.9754e-04 - val_loss: 1.5331 - val_main_output_accuracy: 0.6998 - val_main_output_loss: 1.3667 - val_tof_gate_loss: 0.0029 - learning_rate: 6.2500e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.4850 - main_output_accuracy: 0.8418 - main_output_loss: 1.3161 - tof_gate_loss: 9.0046e-04 - val_loss: 1.5445 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3785 - val_tof_gate_loss: 0.0028 - learning_rate: 6.2500e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4859 - main_output_accuracy: 0.8234 - main_output_loss: 1.3184 - tof_gate_loss: 9.2227e-04 - val_loss: 1.5142 - val_main_output_accuracy: 0.6985 - val_main_output_loss: 1.3449 - val_tof_gate_loss: 0.0028 - learning_rate: 6.2500e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 76ms/step - loss: 1.5977 - main_output_accuracy: 0.7919 - main_output_loss: 1.4336 - tof_gate_loss: 9.4124e-04 - val_loss: 1.5303 - val_main_output_accuracy: 0.6936 - val_main_output_loss: 1.3601 - val_tof_gate_loss: 0.0027 - learning_rate: 6.2500e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.4792 - main_output_accuracy: 0.8522 - main_output_loss: 1.3119 - tof_gate_loss: 8.4479e-04 - val_loss: 1.5270 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3582 - val_tof_gate_loss: 0.0028 - learning_rate: 6.2500e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 75ms/step - loss: 1.3766 - main_output_accuracy: 0.8620 - main_output_loss: 1.2122 - tof_gate_loss: 7.9987e-04 - val_loss: 1.5461 - val_main_output_accuracy: 0.6838 - val_main_output_loss: 1.3836 - val_tof_gate_loss: 0.0026 - learning_rate: 6.2500e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.4203 - main_output_accuracy: 0.8537 - main_output_loss: 1.2554 - tof_gate_loss: 8.0999e-04 - val_loss: 1.5527 - val_main_output_accuracy: 0.6850 - val_main_output_loss: 1.3845 - val_tof_gate_loss: 0.0027 - learning_rate: 6.2500e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.4385 - main_output_accuracy: 0.8517 - main_output_loss: 1.2753 - tof_gate_loss: 7.8307e-04 - val_loss: 1.5315 - val_main_output_accuracy: 0.6936 - val_main_output_loss: 1.3693 - val_tof_gate_loss: 0.0025 - learning_rate: 6.2500e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 1.3764 - main_output_accuracy: 0.8746 - main_output_loss: 1.2141 - tof_gate_loss: 7.5836e-04\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - loss: 1.3763 - main_output_accuracy: 0.8746 - main_output_loss: 1.2140 - tof_gate_loss: 7.5825e-04 - val_loss: 1.5520 - val_main_output_accuracy: 0.6789 - val_main_output_loss: 1.3952 - val_tof_gate_loss: 0.0025 - learning_rate: 6.2500e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.4154 - main_output_accuracy: 0.8679 - main_output_loss: 1.2538 - tof_gate_loss: 7.9504e-04 - val_loss: 1.5180 - val_main_output_accuracy: 0.7157 - val_main_output_loss: 1.3520 - val_tof_gate_loss: 0.0025 - learning_rate: 3.1250e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.3531 - main_output_accuracy: 0.8588 - main_output_loss: 1.1918 - tof_gate_loss: 6.9496e-04 - val_loss: 1.5354 - val_main_output_accuracy: 0.6973 - val_main_output_loss: 1.3831 - val_tof_gate_loss: 0.0025 - learning_rate: 3.1250e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - loss: 1.3628 - main_output_accuracy: 0.8736 - main_output_loss: 1.2030 - tof_gate_loss: 7.1622e-04 - val_loss: 1.5357 - val_main_output_accuracy: 0.6998 - val_main_output_loss: 1.3810 - val_tof_gate_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4038 - main_output_accuracy: 0.8783 - main_output_loss: 1.2437 - tof_gate_loss: 7.1167e-04 - val_loss: 1.5446 - val_main_output_accuracy: 0.6875 - val_main_output_loss: 1.3809 - val_tof_gate_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4527 - main_output_accuracy: 0.8708 - main_output_loss: 1.2933 - tof_gate_loss: 7.2467e-04 - val_loss: 1.5195 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3617 - val_tof_gate_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - loss: 1.4261 - main_output_accuracy: 0.8549 - main_output_loss: 1.2683 - tof_gate_loss: 7.1973e-04 - val_loss: 1.5249 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3673 - val_tof_gate_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.5131 - main_output_accuracy: 0.8448 - main_output_loss: 1.3553 - tof_gate_loss: 7.4262e-04 - val_loss: 1.5506 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.3884 - val_tof_gate_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.3806 - main_output_accuracy: 0.8914 - main_output_loss: 1.2221 - tof_gate_loss: 6.7371e-04 - val_loss: 1.5190 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3610 - val_tof_gate_loss: 0.0024 - learning_rate: 3.1250e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 1.4272 - main_output_accuracy: 0.8623 - main_output_loss: 1.2708 - tof_gate_loss: 6.5038e-04\n",
      "Epoch 91: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 69ms/step - loss: 1.4274 - main_output_accuracy: 0.8622 - main_output_loss: 1.2710 - tof_gate_loss: 6.5078e-04 - val_loss: 1.5407 - val_main_output_accuracy: 0.6850 - val_main_output_loss: 1.3844 - val_tof_gate_loss: 0.0023 - learning_rate: 3.1250e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.4068 - main_output_accuracy: 0.8809 - main_output_loss: 1.2488 - tof_gate_loss: 6.9795e-04 - val_loss: 1.5211 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3691 - val_tof_gate_loss: 0.0025 - learning_rate: 1.5625e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.4315 - main_output_accuracy: 0.8555 - main_output_loss: 1.2728 - tof_gate_loss: 6.8529e-04 - val_loss: 1.5240 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3680 - val_tof_gate_loss: 0.0024 - learning_rate: 1.5625e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - loss: 1.3612 - main_output_accuracy: 0.8740 - main_output_loss: 1.2050 - tof_gate_loss: 6.2775e-04 - val_loss: 1.5044 - val_main_output_accuracy: 0.7047 - val_main_output_loss: 1.3483 - val_tof_gate_loss: 0.0023 - learning_rate: 1.5625e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.3219 - main_output_accuracy: 0.9004 - main_output_loss: 1.1710 - tof_gate_loss: 5.9581e-04 - val_loss: 1.5029 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3550 - val_tof_gate_loss: 0.0023 - learning_rate: 1.5625e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - loss: 1.2899 - main_output_accuracy: 0.8984 - main_output_loss: 1.1355 - tof_gate_loss: 6.2208e-04 - val_loss: 1.5134 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.3609 - val_tof_gate_loss: 0.0023 - learning_rate: 1.5625e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.4649 - main_output_accuracy: 0.8407 - main_output_loss: 1.3054 - tof_gate_loss: 6.5206e-04 - val_loss: 1.5238 - val_main_output_accuracy: 0.7034 - val_main_output_loss: 1.3739 - val_tof_gate_loss: 0.0023 - learning_rate: 1.5625e-05\n",
      "Epoch 98/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.3373 - main_output_accuracy: 0.8837 - main_output_loss: 1.1819 - tof_gate_loss: 6.4696e-04 - val_loss: 1.5262 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3685 - val_tof_gate_loss: 0.0022 - learning_rate: 1.5625e-05\n",
      "Epoch 99/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 1.3793 - main_output_accuracy: 0.8678 - main_output_loss: 1.2208 - tof_gate_loss: 6.6044e-04 - val_loss: 1.5186 - val_main_output_accuracy: 0.7047 - val_main_output_loss: 1.3649 - val_tof_gate_loss: 0.0024 - learning_rate: 1.5625e-05\n",
      "Epoch 100/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.2672 - main_output_accuracy: 0.9097 - main_output_loss: 1.1134 - tof_gate_loss: 6.0447e-04\n",
      "Epoch 100: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.2676 - main_output_accuracy: 0.9095 - main_output_loss: 1.1138 - tof_gate_loss: 6.0444e-04 - val_loss: 1.5143 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3554 - val_tof_gate_loss: 0.0022 - learning_rate: 1.5625e-05\n",
      "Epoch 101/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.3351 - main_output_accuracy: 0.8980 - main_output_loss: 1.1792 - tof_gate_loss: 6.2676e-04 - val_loss: 1.5087 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.3572 - val_tof_gate_loss: 0.0023 - learning_rate: 7.8125e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - loss: 1.3326 - main_output_accuracy: 0.8962 - main_output_loss: 1.1781 - tof_gate_loss: 6.0519e-04 - val_loss: 1.5050 - val_main_output_accuracy: 0.7047 - val_main_output_loss: 1.3526 - val_tof_gate_loss: 0.0022 - learning_rate: 7.8125e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.3250 - main_output_accuracy: 0.8901 - main_output_loss: 1.1723 - tof_gate_loss: 5.9186e-04 - val_loss: 1.5165 - val_main_output_accuracy: 0.6998 - val_main_output_loss: 1.3626 - val_tof_gate_loss: 0.0022 - learning_rate: 7.8125e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.3294 - main_output_accuracy: 0.8915 - main_output_loss: 1.1748 - tof_gate_loss: 5.6830e-04 - val_loss: 1.5171 - val_main_output_accuracy: 0.7059 - val_main_output_loss: 1.3594 - val_tof_gate_loss: 0.0022 - learning_rate: 7.8125e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 1.3512 - main_output_accuracy: 0.8695 - main_output_loss: 1.1950 - tof_gate_loss: 5.9610e-04 - val_loss: 1.5162 - val_main_output_accuracy: 0.6985 - val_main_output_loss: 1.3569 - val_tof_gate_loss: 0.0022 - learning_rate: 7.8125e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.5064 - main_output_accuracy: 0.8502 - main_output_loss: 1.3593 - tof_gate_loss: 6.2498e-04 - val_loss: 1.5193 - val_main_output_accuracy: 0.6985 - val_main_output_loss: 1.3657 - val_tof_gate_loss: 0.0021 - learning_rate: 7.8125e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.4122 - main_output_accuracy: 0.8616 - main_output_loss: 1.2612 - tof_gate_loss: 6.1845e-04 - val_loss: 1.5224 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3700 - val_tof_gate_loss: 0.0021 - learning_rate: 7.8125e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 77ms/step - loss: 1.3951 - main_output_accuracy: 0.8749 - main_output_loss: 1.2399 - tof_gate_loss: 5.9762e-04 - val_loss: 1.5191 - val_main_output_accuracy: 0.7059 - val_main_output_loss: 1.3606 - val_tof_gate_loss: 0.0023 - learning_rate: 7.8125e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.4409 - main_output_accuracy: 0.8666 - main_output_loss: 1.2904 - tof_gate_loss: 5.8676e-04\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4405 - main_output_accuracy: 0.8667 - main_output_loss: 1.2900 - tof_gate_loss: 5.8665e-04 - val_loss: 1.5225 - val_main_output_accuracy: 0.6998 - val_main_output_loss: 1.3700 - val_tof_gate_loss: 0.0021 - learning_rate: 7.8125e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.3939 - main_output_accuracy: 0.8767 - main_output_loss: 1.2377 - tof_gate_loss: 5.8531e-04 - val_loss: 1.5192 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3617 - val_tof_gate_loss: 0.0021 - learning_rate: 3.9063e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 1.4497 - main_output_accuracy: 0.8707 - main_output_loss: 1.3027 - tof_gate_loss: 5.9691e-04 - val_loss: 1.5210 - val_main_output_accuracy: 0.7059 - val_main_output_loss: 1.3661 - val_tof_gate_loss: 0.0021 - learning_rate: 3.9063e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.2850 - main_output_accuracy: 0.9054 - main_output_loss: 1.1388 - tof_gate_loss: 5.6013e-04 - val_loss: 1.5205 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.3683 - val_tof_gate_loss: 0.0021 - learning_rate: 3.9063e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.2872 - main_output_accuracy: 0.9203 - main_output_loss: 1.1347 - tof_gate_loss: 5.5448e-04 - val_loss: 1.5216 - val_main_output_accuracy: 0.6985 - val_main_output_loss: 1.3719 - val_tof_gate_loss: 0.0021 - learning_rate: 3.9063e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - loss: 1.4796 - main_output_accuracy: 0.8439 - main_output_loss: 1.3241 - tof_gate_loss: 6.7939e-04 - val_loss: 1.5177 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.3671 - val_tof_gate_loss: 0.0021 - learning_rate: 3.9063e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.4151 - main_output_accuracy: 0.8762 - main_output_loss: 1.2608 - tof_gate_loss: 6.5781e-04 - val_loss: 1.5265 - val_main_output_accuracy: 0.7108 - val_main_output_loss: 1.3756 - val_tof_gate_loss: 0.0021 - learning_rate: 3.9063e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.3623 - main_output_accuracy: 0.8814 - main_output_loss: 1.2099 - tof_gate_loss: 5.8870e-04 - val_loss: 1.5189 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3685 - val_tof_gate_loss: 0.0021 - learning_rate: 3.9063e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 73ms/step - loss: 1.3689 - main_output_accuracy: 0.8869 - main_output_loss: 1.2145 - tof_gate_loss: 5.8375e-04 - val_loss: 1.5183 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3677 - val_tof_gate_loss: 0.0022 - learning_rate: 3.9063e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.3003 - main_output_accuracy: 0.9040 - main_output_loss: 1.1487 - tof_gate_loss: 5.2256e-04\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.3006 - main_output_accuracy: 0.9039 - main_output_loss: 1.1490 - tof_gate_loss: 5.2272e-04 - val_loss: 1.5186 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.3722 - val_tof_gate_loss: 0.0022 - learning_rate: 3.9063e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.2660 - main_output_accuracy: 0.9058 - main_output_loss: 1.1113 - tof_gate_loss: 5.6098e-04 - val_loss: 1.5193 - val_main_output_accuracy: 0.7034 - val_main_output_loss: 1.3662 - val_tof_gate_loss: 0.0022 - learning_rate: 3.0000e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 1.3239 - main_output_accuracy: 0.9078 - main_output_loss: 1.1716 - tof_gate_loss: 5.5104e-04 - val_loss: 1.5180 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3673 - val_tof_gate_loss: 0.0021 - learning_rate: 3.0000e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.3955 - main_output_accuracy: 0.8692 - main_output_loss: 1.2448 - tof_gate_loss: 5.8769e-04 - val_loss: 1.5205 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3699 - val_tof_gate_loss: 0.0021 - learning_rate: 3.0000e-06\n",
      "Epoch 122/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 1.3510 - main_output_accuracy: 0.8878 - main_output_loss: 1.2021 - tof_gate_loss: 5.4727e-04 - val_loss: 1.5189 - val_main_output_accuracy: 0.7034 - val_main_output_loss: 1.3660 - val_tof_gate_loss: 0.0021 - learning_rate: 3.0000e-06\n",
      "Epoch 123/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.4247 - main_output_accuracy: 0.8727 - main_output_loss: 1.2761 - tof_gate_loss: 5.7684e-04 - val_loss: 1.5180 - val_main_output_accuracy: 0.7034 - val_main_output_loss: 1.3632 - val_tof_gate_loss: 0.0021 - learning_rate: 3.0000e-06\n",
      "Epoch 123: early stopping\n",
      "Restoring model weights from the end of the best epoch: 83.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 10:21:08.649346: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "\n",
      "===== FOLD 3/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 107ms/step - loss: 10.4253 - main_output_accuracy: 0.1550 - main_output_loss: 2.8531 - tof_gate_loss: 0.6897 - val_loss: 7.9601 - val_main_output_accuracy: 0.4718 - val_main_output_loss: 2.3275 - val_tof_gate_loss: 0.5100 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - loss: 7.4474 - main_output_accuracy: 0.3390 - main_output_loss: 2.2523 - tof_gate_loss: 0.4563 - val_loss: 5.9903 - val_main_output_accuracy: 0.5699 - val_main_output_loss: 1.8509 - val_tof_gate_loss: 0.3461 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 5.9769 - main_output_accuracy: 0.4452 - main_output_loss: 2.0874 - tof_gate_loss: 0.3181 - val_loss: 4.8962 - val_main_output_accuracy: 0.5931 - val_main_output_loss: 1.6474 - val_tof_gate_loss: 0.2381 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 5.0691 - main_output_accuracy: 0.4932 - main_output_loss: 1.9932 - tof_gate_loss: 0.2239 - val_loss: 4.1649 - val_main_output_accuracy: 0.6042 - val_main_output_loss: 1.5424 - val_tof_gate_loss: 0.1633 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - loss: 4.3156 - main_output_accuracy: 0.5378 - main_output_loss: 1.8149 - tof_gate_loss: 0.1519 - val_loss: 3.6283 - val_main_output_accuracy: 0.6152 - val_main_output_loss: 1.4691 - val_tof_gate_loss: 0.1171 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 3.9952 - main_output_accuracy: 0.5292 - main_output_loss: 1.9271 - tof_gate_loss: 0.1171 - val_loss: 3.2512 - val_main_output_accuracy: 0.6544 - val_main_output_loss: 1.4497 - val_tof_gate_loss: 0.0860 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 75ms/step - loss: 3.5859 - main_output_accuracy: 0.5665 - main_output_loss: 1.8592 - tof_gate_loss: 0.0881 - val_loss: 2.9456 - val_main_output_accuracy: 0.6544 - val_main_output_loss: 1.4326 - val_tof_gate_loss: 0.0654 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 3.1762 - main_output_accuracy: 0.6074 - main_output_loss: 1.7198 - tof_gate_loss: 0.0624 - val_loss: 2.7114 - val_main_output_accuracy: 0.6532 - val_main_output_loss: 1.4231 - val_tof_gate_loss: 0.0504 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 2.9888 - main_output_accuracy: 0.6061 - main_output_loss: 1.7473 - tof_gate_loss: 0.0511 - val_loss: 2.5283 - val_main_output_accuracy: 0.6691 - val_main_output_loss: 1.4228 - val_tof_gate_loss: 0.0396 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 2.7697 - main_output_accuracy: 0.6013 - main_output_loss: 1.7065 - tof_gate_loss: 0.0404 - val_loss: 2.3996 - val_main_output_accuracy: 0.6373 - val_main_output_loss: 1.4393 - val_tof_gate_loss: 0.0321 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 2.7085 - main_output_accuracy: 0.6104 - main_output_loss: 1.7790 - tof_gate_loss: 0.0351 - val_loss: 2.2336 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3934 - val_tof_gate_loss: 0.0262 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 2.5487 - main_output_accuracy: 0.6080 - main_output_loss: 1.7344 - tof_gate_loss: 0.0294 - val_loss: 2.3143 - val_main_output_accuracy: 0.5956 - val_main_output_loss: 1.5769 - val_tof_gate_loss: 0.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 2.4126 - main_output_accuracy: 0.6422 - main_output_loss: 1.6957 - tof_gate_loss: 0.0235 - val_loss: 2.0920 - val_main_output_accuracy: 0.6581 - val_main_output_loss: 1.4360 - val_tof_gate_loss: 0.0183 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 2.3144 - main_output_accuracy: 0.6411 - main_output_loss: 1.6717 - tof_gate_loss: 0.0197 - val_loss: 1.9133 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.3206 - val_tof_gate_loss: 0.0155 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 127ms/step - loss: 2.3062 - main_output_accuracy: 0.6258 - main_output_loss: 1.7285 - tof_gate_loss: 0.0171 - val_loss: 1.9291 - val_main_output_accuracy: 0.6703 - val_main_output_loss: 1.3977 - val_tof_gate_loss: 0.0133 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 2.1958 - main_output_accuracy: 0.6492 - main_output_loss: 1.6706 - tof_gate_loss: 0.0149 - val_loss: 1.9211 - val_main_output_accuracy: 0.6397 - val_main_output_loss: 1.4308 - val_tof_gate_loss: 0.0114 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 126ms/step - loss: 2.0757 - main_output_accuracy: 0.6750 - main_output_loss: 1.5967 - tof_gate_loss: 0.0123 - val_loss: 1.8432 - val_main_output_accuracy: 0.6581 - val_main_output_loss: 1.3948 - val_tof_gate_loss: 0.0098 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 2.0385 - main_output_accuracy: 0.6821 - main_output_loss: 1.5916 - tof_gate_loss: 0.0107 - val_loss: 1.8004 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.3800 - val_tof_gate_loss: 0.0086 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 2.0792 - main_output_accuracy: 0.6566 - main_output_loss: 1.6712 - tof_gate_loss: 0.0097 - val_loss: 1.7341 - val_main_output_accuracy: 0.7169 - val_main_output_loss: 1.3395 - val_tof_gate_loss: 0.0076 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - loss: 1.9866 - main_output_accuracy: 0.6944 - main_output_loss: 1.5950 - tof_gate_loss: 0.0081 - val_loss: 1.7339 - val_main_output_accuracy: 0.6985 - val_main_output_loss: 1.3626 - val_tof_gate_loss: 0.0068 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.9635 - main_output_accuracy: 0.6743 - main_output_loss: 1.6023 - tof_gate_loss: 0.0078 - val_loss: 1.7582 - val_main_output_accuracy: 0.6826 - val_main_output_loss: 1.4121 - val_tof_gate_loss: 0.0060 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.0050 - main_output_accuracy: 0.6692 - main_output_loss: 1.6619 - tof_gate_loss: 0.0071 - val_loss: 1.6903 - val_main_output_accuracy: 0.6887 - val_main_output_loss: 1.3520 - val_tof_gate_loss: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 2.0332 - main_output_accuracy: 0.6542 - main_output_loss: 1.7107 - tof_gate_loss: 0.0067 - val_loss: 1.6651 - val_main_output_accuracy: 0.6875 - val_main_output_loss: 1.3505 - val_tof_gate_loss: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.8119 - main_output_accuracy: 0.7189 - main_output_loss: 1.4964 - tof_gate_loss: 0.0052 - val_loss: 1.8419 - val_main_output_accuracy: 0.6225 - val_main_output_loss: 1.5330 - val_tof_gate_loss: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 95ms/step - loss: 1.8585 - main_output_accuracy: 0.6947 - main_output_loss: 1.5519 - tof_gate_loss: 0.0047 - val_loss: 1.6391 - val_main_output_accuracy: 0.6850 - val_main_output_loss: 1.3388 - val_tof_gate_loss: 0.0038 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.8182 - main_output_accuracy: 0.7027 - main_output_loss: 1.5221 - tof_gate_loss: 0.0041 - val_loss: 1.6726 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3831 - val_tof_gate_loss: 0.0034 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.8107 - main_output_accuracy: 0.7080 - main_output_loss: 1.5210 - tof_gate_loss: 0.0038 - val_loss: 1.5780 - val_main_output_accuracy: 0.7194 - val_main_output_loss: 1.2939 - val_tof_gate_loss: 0.0031 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.8114 - main_output_accuracy: 0.7033 - main_output_loss: 1.5310 - tof_gate_loss: 0.0034 - val_loss: 1.5720 - val_main_output_accuracy: 0.7132 - val_main_output_loss: 1.2942 - val_tof_gate_loss: 0.0028 - learning_rate: 5.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.8337 - main_output_accuracy: 0.6965 - main_output_loss: 1.5592 - tof_gate_loss: 0.0032 - val_loss: 1.6727 - val_main_output_accuracy: 0.6863 - val_main_output_loss: 1.3990 - val_tof_gate_loss: 0.0026 - learning_rate: 5.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.8119 - main_output_accuracy: 0.6857 - main_output_loss: 1.5382 - tof_gate_loss: 0.0029 - val_loss: 1.6508 - val_main_output_accuracy: 0.7132 - val_main_output_loss: 1.3826 - val_tof_gate_loss: 0.0023 - learning_rate: 5.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.8141 - main_output_accuracy: 0.7152 - main_output_loss: 1.5529 - tof_gate_loss: 0.0027 - val_loss: 1.5831 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3259 - val_tof_gate_loss: 0.0021 - learning_rate: 5.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.8345 - main_output_accuracy: 0.6985 - main_output_loss: 1.5767 - tof_gate_loss: 0.0025 - val_loss: 1.6390 - val_main_output_accuracy: 0.6863 - val_main_output_loss: 1.3845 - val_tof_gate_loss: 0.0019 - learning_rate: 5.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.6694 - main_output_accuracy: 0.7334 - main_output_loss: 1.4138 - tof_gate_loss: 0.0020 - val_loss: 1.6578 - val_main_output_accuracy: 0.6998 - val_main_output_loss: 1.4042 - val_tof_gate_loss: 0.0018 - learning_rate: 5.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.8532 - main_output_accuracy: 0.6981 - main_output_loss: 1.6033 - tof_gate_loss: 0.0022 - val_loss: 1.6342 - val_main_output_accuracy: 0.7206 - val_main_output_loss: 1.3919 - val_tof_gate_loss: 0.0016 - learning_rate: 5.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.8379 - main_output_accuracy: 0.7169 - main_output_loss: 1.5906 - tof_gate_loss: 0.0019 - val_loss: 1.6014 - val_main_output_accuracy: 0.6912 - val_main_output_loss: 1.3519 - val_tof_gate_loss: 0.0015 - learning_rate: 5.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.6933 - main_output_accuracy: 0.7435 - main_output_loss: 1.4537 - tof_gate_loss: 0.0018 - val_loss: 1.6326 - val_main_output_accuracy: 0.6752 - val_main_output_loss: 1.3942 - val_tof_gate_loss: 0.0014 - learning_rate: 5.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.7337 - main_output_accuracy: 0.7374 - main_output_loss: 1.4916 - tof_gate_loss: 0.0016 - val_loss: 1.5559 - val_main_output_accuracy: 0.7120 - val_main_output_loss: 1.3208 - val_tof_gate_loss: 0.0013 - learning_rate: 5.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.7176 - main_output_accuracy: 0.7425 - main_output_loss: 1.4832 - tof_gate_loss: 0.0014 - val_loss: 1.6074 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.3696 - val_tof_gate_loss: 0.0012 - learning_rate: 5.0000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.7891 - main_output_accuracy: 0.7228 - main_output_loss: 1.5545 - tof_gate_loss: 0.0015 - val_loss: 1.5475 - val_main_output_accuracy: 0.7267 - val_main_output_loss: 1.3098 - val_tof_gate_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.7695 - main_output_accuracy: 0.7355 - main_output_loss: 1.5344 - tof_gate_loss: 0.0013 - val_loss: 1.5448 - val_main_output_accuracy: 0.7145 - val_main_output_loss: 1.3101 - val_tof_gate_loss: 9.8557e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.7791 - main_output_accuracy: 0.7128 - main_output_loss: 1.5467 - tof_gate_loss: 0.0011 - val_loss: 1.5990 - val_main_output_accuracy: 0.7108 - val_main_output_loss: 1.3702 - val_tof_gate_loss: 9.0772e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7671 - main_output_accuracy: 0.7439 - main_output_loss: 1.5349 - tof_gate_loss: 0.0011 - val_loss: 1.5400 - val_main_output_accuracy: 0.7181 - val_main_output_loss: 1.3153 - val_tof_gate_loss: 8.4523e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.6489 - main_output_accuracy: 0.7402 - main_output_loss: 1.4271 - tof_gate_loss: 9.3922e-04 - val_loss: 1.5831 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3527 - val_tof_gate_loss: 7.8109e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.7411 - main_output_accuracy: 0.7463 - main_output_loss: 1.5227 - tof_gate_loss: 9.1157e-04 - val_loss: 1.6200 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3937 - val_tof_gate_loss: 7.2291e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.7325 - main_output_accuracy: 0.7543 - main_output_loss: 1.5068 - tof_gate_loss: 8.5379e-04 - val_loss: 1.5393 - val_main_output_accuracy: 0.7145 - val_main_output_loss: 1.3162 - val_tof_gate_loss: 6.6609e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.6447 - main_output_accuracy: 0.7681 - main_output_loss: 1.4191 - tof_gate_loss: 8.2838e-04 - val_loss: 1.7068 - val_main_output_accuracy: 0.6691 - val_main_output_loss: 1.4752 - val_tof_gate_loss: 6.1633e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 1.7027 - main_output_accuracy: 0.7432 - main_output_loss: 1.4740 - tof_gate_loss: 7.2270e-04\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.7024 - main_output_accuracy: 0.7432 - main_output_loss: 1.4737 - tof_gate_loss: 7.2248e-04 - val_loss: 1.5248 - val_main_output_accuracy: 0.7157 - val_main_output_loss: 1.3022 - val_tof_gate_loss: 5.7893e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.7269 - main_output_accuracy: 0.7470 - main_output_loss: 1.5034 - tof_gate_loss: 7.4231e-04 - val_loss: 1.4205 - val_main_output_accuracy: 0.7488 - val_main_output_loss: 1.2100 - val_tof_gate_loss: 5.5869e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.5787 - main_output_accuracy: 0.7911 - main_output_loss: 1.3659 - tof_gate_loss: 6.6442e-04 - val_loss: 1.4465 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2380 - val_tof_gate_loss: 5.2818e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.5816 - main_output_accuracy: 0.8017 - main_output_loss: 1.3802 - tof_gate_loss: 6.0486e-04 - val_loss: 1.4217 - val_main_output_accuracy: 0.7488 - val_main_output_loss: 1.2215 - val_tof_gate_loss: 5.0947e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.5967 - main_output_accuracy: 0.7807 - main_output_loss: 1.3950 - tof_gate_loss: 6.1220e-04 - val_loss: 1.5126 - val_main_output_accuracy: 0.6973 - val_main_output_loss: 1.3171 - val_tof_gate_loss: 4.9094e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7692 - main_output_accuracy: 0.7676 - main_output_loss: 1.5697 - tof_gate_loss: 6.4577e-04 - val_loss: 1.4165 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.2230 - val_tof_gate_loss: 4.6636e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 114ms/step - loss: 1.5479 - main_output_accuracy: 0.8162 - main_output_loss: 1.3549 - tof_gate_loss: 5.5575e-04 - val_loss: 1.4892 - val_main_output_accuracy: 0.7292 - val_main_output_loss: 1.2935 - val_tof_gate_loss: 4.4945e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.5254 - main_output_accuracy: 0.8016 - main_output_loss: 1.3352 - tof_gate_loss: 5.0776e-04 - val_loss: 1.4136 - val_main_output_accuracy: 0.7488 - val_main_output_loss: 1.2261 - val_tof_gate_loss: 4.3335e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.6324 - main_output_accuracy: 0.7953 - main_output_loss: 1.4427 - tof_gate_loss: 5.1532e-04 - val_loss: 1.4746 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.2864 - val_tof_gate_loss: 4.1296e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.5638 - main_output_accuracy: 0.7951 - main_output_loss: 1.3735 - tof_gate_loss: 4.9860e-04 - val_loss: 1.4559 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2721 - val_tof_gate_loss: 3.9656e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.5916 - main_output_accuracy: 0.7770 - main_output_loss: 1.3994 - tof_gate_loss: 4.6476e-04 - val_loss: 1.4454 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2575 - val_tof_gate_loss: 3.8083e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.4499 - main_output_accuracy: 0.8171 - main_output_loss: 1.2662 - tof_gate_loss: 4.0644e-04 - val_loss: 1.4558 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2762 - val_tof_gate_loss: 3.5793e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.5527 - main_output_accuracy: 0.7881 - main_output_loss: 1.3665 - tof_gate_loss: 4.3354e-04 - val_loss: 1.4963 - val_main_output_accuracy: 0.7243 - val_main_output_loss: 1.3164 - val_tof_gate_loss: 3.4831e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 1.5366 - main_output_accuracy: 0.8006 - main_output_loss: 1.3547 - tof_gate_loss: 4.0336e-04\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.5365 - main_output_accuracy: 0.8006 - main_output_loss: 1.3546 - tof_gate_loss: 4.0340e-04 - val_loss: 1.5178 - val_main_output_accuracy: 0.7059 - val_main_output_loss: 1.3382 - val_tof_gate_loss: 3.2889e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.5289 - main_output_accuracy: 0.8292 - main_output_loss: 1.3496 - tof_gate_loss: 4.0134e-04 - val_loss: 1.4066 - val_main_output_accuracy: 0.7451 - val_main_output_loss: 1.2313 - val_tof_gate_loss: 3.1875e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.4272 - main_output_accuracy: 0.8500 - main_output_loss: 1.2520 - tof_gate_loss: 3.6452e-04 - val_loss: 1.3590 - val_main_output_accuracy: 0.7598 - val_main_output_loss: 1.1883 - val_tof_gate_loss: 3.1121e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.4338 - main_output_accuracy: 0.8504 - main_output_loss: 1.2582 - tof_gate_loss: 3.4094e-04 - val_loss: 1.3706 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.1956 - val_tof_gate_loss: 3.0500e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.4078 - main_output_accuracy: 0.8616 - main_output_loss: 1.2351 - tof_gate_loss: 3.4570e-04 - val_loss: 1.4033 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.2330 - val_tof_gate_loss: 2.9527e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.5080 - main_output_accuracy: 0.8155 - main_output_loss: 1.3396 - tof_gate_loss: 3.7028e-04 - val_loss: 1.3605 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1949 - val_tof_gate_loss: 2.8870e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 1.4984 - main_output_accuracy: 0.8286 - main_output_loss: 1.3308 - tof_gate_loss: 3.5201e-04 - val_loss: 1.3623 - val_main_output_accuracy: 0.7794 - val_main_output_loss: 1.1952 - val_tof_gate_loss: 2.7868e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.5418 - main_output_accuracy: 0.8092 - main_output_loss: 1.3728 - tof_gate_loss: 3.3543e-04 - val_loss: 1.3972 - val_main_output_accuracy: 0.7475 - val_main_output_loss: 1.2361 - val_tof_gate_loss: 2.7337e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.5789 - main_output_accuracy: 0.8056 - main_output_loss: 1.4085 - tof_gate_loss: 3.2335e-04 - val_loss: 1.3874 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.2247 - val_tof_gate_loss: 2.6283e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.5408 - main_output_accuracy: 0.8149 - main_output_loss: 1.3773 - tof_gate_loss: 3.2909e-04 - val_loss: 1.4021 - val_main_output_accuracy: 0.7426 - val_main_output_loss: 1.2377 - val_tof_gate_loss: 2.5550e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 1.6100 - main_output_accuracy: 0.8125 - main_output_loss: 1.4483 - tof_gate_loss: 3.5813e-04 - val_loss: 1.4687 - val_main_output_accuracy: 0.7243 - val_main_output_loss: 1.3101 - val_tof_gate_loss: 2.4578e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.3840 - main_output_accuracy: 0.8404 - main_output_loss: 1.2235 - tof_gate_loss: 2.8781e-04 - val_loss: 1.3710 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.2100 - val_tof_gate_loss: 2.4323e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - loss: 1.4914 - main_output_accuracy: 0.8354 - main_output_loss: 1.3323 - tof_gate_loss: 3.1912e-04 - val_loss: 1.3968 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.2350 - val_tof_gate_loss: 2.3266e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.3991 - main_output_accuracy: 0.8501 - main_output_loss: 1.2409 - tof_gate_loss: 2.6756e-04 - val_loss: 1.3761 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.2198 - val_tof_gate_loss: 2.2329e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 74/160\n",
      "\u001b[1m107/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 1.4603 - main_output_accuracy: 0.8203 - main_output_loss: 1.3028 - tof_gate_loss: 2.6359e-04\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.4612 - main_output_accuracy: 0.8202 - main_output_loss: 1.3037 - tof_gate_loss: 2.6366e-04 - val_loss: 1.3749 - val_main_output_accuracy: 0.7757 - val_main_output_loss: 1.2176 - val_tof_gate_loss: 2.1692e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 75/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.4699 - main_output_accuracy: 0.8417 - main_output_loss: 1.3130 - tof_gate_loss: 2.6275e-04 - val_loss: 1.3945 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.2414 - val_tof_gate_loss: 2.1149e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.4650 - main_output_accuracy: 0.8254 - main_output_loss: 1.3113 - tof_gate_loss: 2.5871e-04 - val_loss: 1.3305 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1747 - val_tof_gate_loss: 2.0865e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.3490 - main_output_accuracy: 0.8621 - main_output_loss: 1.1989 - tof_gate_loss: 2.3408e-04 - val_loss: 1.3593 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.2036 - val_tof_gate_loss: 2.0193e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.4017 - main_output_accuracy: 0.8547 - main_output_loss: 1.2507 - tof_gate_loss: 2.4175e-04 - val_loss: 1.3576 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.2066 - val_tof_gate_loss: 1.9885e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.3830 - main_output_accuracy: 0.8625 - main_output_loss: 1.2307 - tof_gate_loss: 2.4277e-04 - val_loss: 1.3511 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.2005 - val_tof_gate_loss: 1.9679e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.4704 - main_output_accuracy: 0.8663 - main_output_loss: 1.3168 - tof_gate_loss: 2.5756e-04 - val_loss: 1.3519 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.2058 - val_tof_gate_loss: 1.8952e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.4749 - main_output_accuracy: 0.8314 - main_output_loss: 1.3219 - tof_gate_loss: 2.3757e-04 - val_loss: 1.3192 - val_main_output_accuracy: 0.7806 - val_main_output_loss: 1.1705 - val_tof_gate_loss: 1.8583e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.4712 - main_output_accuracy: 0.8447 - main_output_loss: 1.3244 - tof_gate_loss: 2.3417e-04 - val_loss: 1.3289 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1822 - val_tof_gate_loss: 1.8247e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.4699 - main_output_accuracy: 0.8469 - main_output_loss: 1.3181 - tof_gate_loss: 2.1883e-04 - val_loss: 1.3573 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.2102 - val_tof_gate_loss: 1.7880e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.4514 - main_output_accuracy: 0.8450 - main_output_loss: 1.3018 - tof_gate_loss: 2.2748e-04 - val_loss: 1.3301 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1829 - val_tof_gate_loss: 1.7354e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - loss: 1.4609 - main_output_accuracy: 0.8436 - main_output_loss: 1.3104 - tof_gate_loss: 2.2103e-04 - val_loss: 1.3215 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.1736 - val_tof_gate_loss: 1.6730e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.3555 - main_output_accuracy: 0.8803 - main_output_loss: 1.2070 - tof_gate_loss: 1.8945e-04 - val_loss: 1.3823 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.2364 - val_tof_gate_loss: 1.6473e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 1.3568 - main_output_accuracy: 0.8837 - main_output_loss: 1.2073 - tof_gate_loss: 1.8357e-04 - val_loss: 1.3414 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.1945 - val_tof_gate_loss: 1.5988e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.2980 - main_output_accuracy: 0.8669 - main_output_loss: 1.1497 - tof_gate_loss: 1.8643e-04 - val_loss: 1.3212 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1787 - val_tof_gate_loss: 1.5681e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 1.4284 - main_output_accuracy: 0.8578 - main_output_loss: 1.2829 - tof_gate_loss: 1.9481e-04\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.4283 - main_output_accuracy: 0.8579 - main_output_loss: 1.2828 - tof_gate_loss: 1.9477e-04 - val_loss: 1.3448 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.2009 - val_tof_gate_loss: 1.5057e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.4862 - main_output_accuracy: 0.8470 - main_output_loss: 1.3428 - tof_gate_loss: 1.9282e-04 - val_loss: 1.3508 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.2058 - val_tof_gate_loss: 1.4823e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.3248 - main_output_accuracy: 0.8792 - main_output_loss: 1.1770 - tof_gate_loss: 1.7480e-04 - val_loss: 1.3291 - val_main_output_accuracy: 0.7745 - val_main_output_loss: 1.1828 - val_tof_gate_loss: 1.4573e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.3234 - main_output_accuracy: 0.8884 - main_output_loss: 1.1796 - tof_gate_loss: 1.7120e-04 - val_loss: 1.3402 - val_main_output_accuracy: 0.7598 - val_main_output_loss: 1.2033 - val_tof_gate_loss: 1.4349e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 1.3218 - main_output_accuracy: 0.8970 - main_output_loss: 1.1830 - tof_gate_loss: 1.6192e-04 - val_loss: 1.3312 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1874 - val_tof_gate_loss: 1.4176e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.3715 - main_output_accuracy: 0.8742 - main_output_loss: 1.2288 - tof_gate_loss: 1.6746e-04 - val_loss: 1.3109 - val_main_output_accuracy: 0.7782 - val_main_output_loss: 1.1682 - val_tof_gate_loss: 1.3925e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.4749 - main_output_accuracy: 0.8451 - main_output_loss: 1.3327 - tof_gate_loss: 1.7926e-04 - val_loss: 1.3418 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1984 - val_tof_gate_loss: 1.3571e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.4097 - main_output_accuracy: 0.8886 - main_output_loss: 1.2693 - tof_gate_loss: 1.7112e-04 - val_loss: 1.3382 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.1993 - val_tof_gate_loss: 1.3312e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.3924 - main_output_accuracy: 0.8774 - main_output_loss: 1.2492 - tof_gate_loss: 1.6121e-04 - val_loss: 1.3509 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.2160 - val_tof_gate_loss: 1.3143e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 98/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 1.3618 - main_output_accuracy: 0.8690 - main_output_loss: 1.2206 - tof_gate_loss: 1.5218e-04\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.3620 - main_output_accuracy: 0.8691 - main_output_loss: 1.2209 - tof_gate_loss: 1.5224e-04 - val_loss: 1.3355 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1969 - val_tof_gate_loss: 1.3022e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 99/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.4094 - main_output_accuracy: 0.8865 - main_output_loss: 1.2684 - tof_gate_loss: 1.6482e-04 - val_loss: 1.3187 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1786 - val_tof_gate_loss: 1.2702e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 100/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 1.4938 - main_output_accuracy: 0.8543 - main_output_loss: 1.3529 - tof_gate_loss: 1.7398e-04 - val_loss: 1.3361 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1945 - val_tof_gate_loss: 1.2642e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 101/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.3373 - main_output_accuracy: 0.8763 - main_output_loss: 1.1987 - tof_gate_loss: 1.4900e-04 - val_loss: 1.3259 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1871 - val_tof_gate_loss: 1.2646e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 102/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.4162 - main_output_accuracy: 0.8888 - main_output_loss: 1.2727 - tof_gate_loss: 1.5489e-04 - val_loss: 1.3361 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1976 - val_tof_gate_loss: 1.2450e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 103/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 1.3263 - main_output_accuracy: 0.8977 - main_output_loss: 1.1864 - tof_gate_loss: 1.4859e-04 - val_loss: 1.3346 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1912 - val_tof_gate_loss: 1.2312e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 104/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.4223 - main_output_accuracy: 0.8669 - main_output_loss: 1.2798 - tof_gate_loss: 1.5205e-04 - val_loss: 1.3413 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.2019 - val_tof_gate_loss: 1.2230e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 105/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.2986 - main_output_accuracy: 0.8962 - main_output_loss: 1.1558 - tof_gate_loss: 1.4029e-04 - val_loss: 1.3331 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1942 - val_tof_gate_loss: 1.1888e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 106/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.2976 - main_output_accuracy: 0.8897 - main_output_loss: 1.1593 - tof_gate_loss: 1.4123e-04 - val_loss: 1.3395 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1990 - val_tof_gate_loss: 1.1693e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 107/160\n",
      "\u001b[1m 79/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 115ms/step - loss: 1.3570 - main_output_accuracy: 0.8998 - main_output_loss: 1.2193 - tof_gate_loss: 1.4045e-04\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 82ms/step - loss: 1.3482 - main_output_accuracy: 0.8983 - main_output_loss: 1.2111 - tof_gate_loss: 1.3966e-04 - val_loss: 1.3405 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.2007 - val_tof_gate_loss: 1.1619e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 108/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.3553 - main_output_accuracy: 0.8712 - main_output_loss: 1.2163 - tof_gate_loss: 1.4033e-04 - val_loss: 1.3376 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.1964 - val_tof_gate_loss: 1.1572e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.3441 - main_output_accuracy: 0.8806 - main_output_loss: 1.2064 - tof_gate_loss: 1.4762e-04 - val_loss: 1.3292 - val_main_output_accuracy: 0.7598 - val_main_output_loss: 1.1890 - val_tof_gate_loss: 1.1419e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 68ms/step - loss: 1.3520 - main_output_accuracy: 0.8957 - main_output_loss: 1.2203 - tof_gate_loss: 1.3651e-04 - val_loss: 1.3317 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.1910 - val_tof_gate_loss: 1.1380e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.4314 - main_output_accuracy: 0.8641 - main_output_loss: 1.2927 - tof_gate_loss: 1.4157e-04 - val_loss: 1.3317 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1942 - val_tof_gate_loss: 1.1271e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.3507 - main_output_accuracy: 0.8959 - main_output_loss: 1.2071 - tof_gate_loss: 1.3667e-04 - val_loss: 1.3265 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1848 - val_tof_gate_loss: 1.1211e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - loss: 1.3860 - main_output_accuracy: 0.8993 - main_output_loss: 1.2486 - tof_gate_loss: 1.4466e-04 - val_loss: 1.3397 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.2008 - val_tof_gate_loss: 1.1258e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.3288 - main_output_accuracy: 0.8736 - main_output_loss: 1.1884 - tof_gate_loss: 1.3827e-04 - val_loss: 1.3364 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1971 - val_tof_gate_loss: 1.0968e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 1.3635 - main_output_accuracy: 0.8891 - main_output_loss: 1.2294 - tof_gate_loss: 1.2699e-04 - val_loss: 1.3262 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1861 - val_tof_gate_loss: 1.0877e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 1.2971 - main_output_accuracy: 0.8951 - main_output_loss: 1.1587 - tof_gate_loss: 1.2603e-04\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - loss: 1.2972 - main_output_accuracy: 0.8951 - main_output_loss: 1.1588 - tof_gate_loss: 1.2605e-04 - val_loss: 1.3366 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1957 - val_tof_gate_loss: 1.0781e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.3198 - main_output_accuracy: 0.9032 - main_output_loss: 1.1818 - tof_gate_loss: 1.3096e-04 - val_loss: 1.3325 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1935 - val_tof_gate_loss: 1.0771e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.3559 - main_output_accuracy: 0.8584 - main_output_loss: 1.2174 - tof_gate_loss: 1.3219e-04 - val_loss: 1.3261 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1873 - val_tof_gate_loss: 1.0753e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - loss: 1.3718 - main_output_accuracy: 0.8702 - main_output_loss: 1.2330 - tof_gate_loss: 1.3203e-04 - val_loss: 1.3240 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1871 - val_tof_gate_loss: 1.0714e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.3767 - main_output_accuracy: 0.8738 - main_output_loss: 1.2384 - tof_gate_loss: 1.3618e-04 - val_loss: 1.3261 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1856 - val_tof_gate_loss: 1.0640e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 1.3731 - main_output_accuracy: 0.8804 - main_output_loss: 1.2345 - tof_gate_loss: 1.2959e-04 - val_loss: 1.3273 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1912 - val_tof_gate_loss: 1.0543e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 121: early stopping\n",
      "Restoring model weights from the end of the best epoch: 81.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 10:44:37.887870: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\n",
      "===== FOLD 4/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 107ms/step - loss: 10.5569 - main_output_accuracy: 0.1513 - main_output_loss: 2.9312 - tof_gate_loss: 0.6637 - val_loss: 8.2552 - val_main_output_accuracy: 0.3974 - val_main_output_loss: 2.4529 - val_tof_gate_loss: 0.5224 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 7.6868 - main_output_accuracy: 0.3574 - main_output_loss: 2.3133 - tof_gate_loss: 0.4755 - val_loss: 6.2857 - val_main_output_accuracy: 0.4745 - val_main_output_loss: 1.9460 - val_tof_gate_loss: 0.3700 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - loss: 6.1100 - main_output_accuracy: 0.4552 - main_output_loss: 2.0228 - tof_gate_loss: 0.3259 - val_loss: 5.1714 - val_main_output_accuracy: 0.5608 - val_main_output_loss: 1.7370 - val_tof_gate_loss: 0.2582 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 5.2716 - main_output_accuracy: 0.4858 - main_output_loss: 2.0114 - tof_gate_loss: 0.2327 - val_loss: 4.3421 - val_main_output_accuracy: 0.6105 - val_main_output_loss: 1.5456 - val_tof_gate_loss: 0.1792 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 96ms/step - loss: 4.5370 - main_output_accuracy: 0.5135 - main_output_loss: 1.8723 - tof_gate_loss: 0.1557 - val_loss: 3.9094 - val_main_output_accuracy: 0.5935 - val_main_output_loss: 1.5940 - val_tof_gate_loss: 0.1284 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 70ms/step - loss: 4.0738 - main_output_accuracy: 0.5406 - main_output_loss: 1.8575 - tof_gate_loss: 0.1165 - val_loss: 3.4589 - val_main_output_accuracy: 0.6131 - val_main_output_loss: 1.5230 - val_tof_gate_loss: 0.0941 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 3.6996 - main_output_accuracy: 0.5878 - main_output_loss: 1.8450 - tof_gate_loss: 0.0851 - val_loss: 3.1912 - val_main_output_accuracy: 0.6366 - val_main_output_loss: 1.5574 - val_tof_gate_loss: 0.0712 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 3.4057 - main_output_accuracy: 0.5826 - main_output_loss: 1.8348 - tof_gate_loss: 0.0641 - val_loss: 2.9427 - val_main_output_accuracy: 0.6118 - val_main_output_loss: 1.5497 - val_tof_gate_loss: 0.0553 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - loss: 3.1788 - main_output_accuracy: 0.5780 - main_output_loss: 1.8389 - tof_gate_loss: 0.0522 - val_loss: 2.6363 - val_main_output_accuracy: 0.6301 - val_main_output_loss: 1.4435 - val_tof_gate_loss: 0.0440 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 3.0096 - main_output_accuracy: 0.5738 - main_output_loss: 1.8586 - tof_gate_loss: 0.0406 - val_loss: 2.5425 - val_main_output_accuracy: 0.5974 - val_main_output_loss: 1.5099 - val_tof_gate_loss: 0.0359 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 97ms/step - loss: 2.6939 - main_output_accuracy: 0.6343 - main_output_loss: 1.6992 - tof_gate_loss: 0.0308 - val_loss: 2.3822 - val_main_output_accuracy: 0.6510 - val_main_output_loss: 1.4805 - val_tof_gate_loss: 0.0296 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - loss: 2.6340 - main_output_accuracy: 0.6152 - main_output_loss: 1.7629 - tof_gate_loss: 0.0273 - val_loss: 2.2479 - val_main_output_accuracy: 0.6418 - val_main_output_loss: 1.4557 - val_tof_gate_loss: 0.0245 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 2.4471 - main_output_accuracy: 0.6635 - main_output_loss: 1.6836 - tof_gate_loss: 0.0219 - val_loss: 2.1969 - val_main_output_accuracy: 0.6523 - val_main_output_loss: 1.4943 - val_tof_gate_loss: 0.0207 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 2.3185 - main_output_accuracy: 0.6448 - main_output_loss: 1.6391 - tof_gate_loss: 0.0181 - val_loss: 2.0485 - val_main_output_accuracy: 0.6771 - val_main_output_loss: 1.4184 - val_tof_gate_loss: 0.0179 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 71ms/step - loss: 2.2959 - main_output_accuracy: 0.6512 - main_output_loss: 1.6950 - tof_gate_loss: 0.0163 - val_loss: 1.9358 - val_main_output_accuracy: 0.6967 - val_main_output_loss: 1.3696 - val_tof_gate_loss: 0.0154 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 2.1924 - main_output_accuracy: 0.6635 - main_output_loss: 1.6419 - tof_gate_loss: 0.0132 - val_loss: 1.9508 - val_main_output_accuracy: 0.6562 - val_main_output_loss: 1.4374 - val_tof_gate_loss: 0.0134 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 98ms/step - loss: 2.1107 - main_output_accuracy: 0.6518 - main_output_loss: 1.6025 - tof_gate_loss: 0.0113 - val_loss: 1.9032 - val_main_output_accuracy: 0.6680 - val_main_output_loss: 1.4283 - val_tof_gate_loss: 0.0117 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 78ms/step - loss: 2.1628 - main_output_accuracy: 0.6431 - main_output_loss: 1.6922 - tof_gate_loss: 0.0100 - val_loss: 1.8740 - val_main_output_accuracy: 0.6680 - val_main_output_loss: 1.4366 - val_tof_gate_loss: 0.0103 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 2.0224 - main_output_accuracy: 0.6822 - main_output_loss: 1.5928 - tof_gate_loss: 0.0087 - val_loss: 1.8838 - val_main_output_accuracy: 0.6144 - val_main_output_loss: 1.4767 - val_tof_gate_loss: 0.0091 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 93ms/step - loss: 1.9585 - main_output_accuracy: 0.6732 - main_output_loss: 1.5580 - tof_gate_loss: 0.0074 - val_loss: 1.8771 - val_main_output_accuracy: 0.6314 - val_main_output_loss: 1.4947 - val_tof_gate_loss: 0.0081 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.9936 - main_output_accuracy: 0.6665 - main_output_loss: 1.6161 - tof_gate_loss: 0.0072 - val_loss: 1.7143 - val_main_output_accuracy: 0.7046 - val_main_output_loss: 1.3527 - val_tof_gate_loss: 0.0072 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.9610 - main_output_accuracy: 0.6793 - main_output_loss: 1.6045 - tof_gate_loss: 0.0061 - val_loss: 1.7635 - val_main_output_accuracy: 0.6575 - val_main_output_loss: 1.4217 - val_tof_gate_loss: 0.0065 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 86ms/step - loss: 1.9339 - main_output_accuracy: 0.6723 - main_output_loss: 1.5897 - tof_gate_loss: 0.0055 - val_loss: 1.7581 - val_main_output_accuracy: 0.6784 - val_main_output_loss: 1.4288 - val_tof_gate_loss: 0.0058 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.9844 - main_output_accuracy: 0.6680 - main_output_loss: 1.6540 - tof_gate_loss: 0.0054 - val_loss: 1.6951 - val_main_output_accuracy: 0.6941 - val_main_output_loss: 1.3807 - val_tof_gate_loss: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.8437 - main_output_accuracy: 0.6974 - main_output_loss: 1.5333 - tof_gate_loss: 0.0044 - val_loss: 1.6659 - val_main_output_accuracy: 0.6928 - val_main_output_loss: 1.3622 - val_tof_gate_loss: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.9122 - main_output_accuracy: 0.6814 - main_output_loss: 1.6078 - tof_gate_loss: 0.0041 - val_loss: 1.6966 - val_main_output_accuracy: 0.6863 - val_main_output_loss: 1.4012 - val_tof_gate_loss: 0.0043 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 2.0143 - main_output_accuracy: 0.6648 - main_output_loss: 1.7200 - tof_gate_loss: 0.0038 - val_loss: 1.7062 - val_main_output_accuracy: 0.6510 - val_main_output_loss: 1.4197 - val_tof_gate_loss: 0.0039 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 93ms/step - loss: 1.8390 - main_output_accuracy: 0.6773 - main_output_loss: 1.5549 - tof_gate_loss: 0.0032 - val_loss: 1.7185 - val_main_output_accuracy: 0.6876 - val_main_output_loss: 1.4395 - val_tof_gate_loss: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9134 - main_output_accuracy: 0.6955 - main_output_loss: 1.6338 - tof_gate_loss: 0.0029\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.9135 - main_output_accuracy: 0.6955 - main_output_loss: 1.6339 - tof_gate_loss: 0.0029 - val_loss: 1.7467 - val_main_output_accuracy: 0.6392 - val_main_output_loss: 1.4731 - val_tof_gate_loss: 0.0032 - learning_rate: 5.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.7455 - main_output_accuracy: 0.7273 - main_output_loss: 1.4757 - tof_gate_loss: 0.0026 - val_loss: 1.6295 - val_main_output_accuracy: 0.7111 - val_main_output_loss: 1.3688 - val_tof_gate_loss: 0.0031 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.7250 - main_output_accuracy: 0.7479 - main_output_loss: 1.4657 - tof_gate_loss: 0.0025 - val_loss: 1.5504 - val_main_output_accuracy: 0.7320 - val_main_output_loss: 1.2999 - val_tof_gate_loss: 0.0029 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.7798 - main_output_accuracy: 0.7228 - main_output_loss: 1.5309 - tof_gate_loss: 0.0025 - val_loss: 1.5761 - val_main_output_accuracy: 0.7098 - val_main_output_loss: 1.3321 - val_tof_gate_loss: 0.0028 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 100ms/step - loss: 1.7656 - main_output_accuracy: 0.7378 - main_output_loss: 1.5215 - tof_gate_loss: 0.0023 - val_loss: 1.5523 - val_main_output_accuracy: 0.7268 - val_main_output_loss: 1.3137 - val_tof_gate_loss: 0.0027 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6709 - main_output_accuracy: 0.7628 - main_output_loss: 1.4336 - tof_gate_loss: 0.0022 - val_loss: 1.5670 - val_main_output_accuracy: 0.7137 - val_main_output_loss: 1.3329 - val_tof_gate_loss: 0.0026 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.7226 - main_output_accuracy: 0.7356 - main_output_loss: 1.4951 - tof_gate_loss: 0.0021 - val_loss: 1.5627 - val_main_output_accuracy: 0.7137 - val_main_output_loss: 1.3323 - val_tof_gate_loss: 0.0024 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6816 - main_output_accuracy: 0.7441 - main_output_loss: 1.4568 - tof_gate_loss: 0.0019 - val_loss: 1.4985 - val_main_output_accuracy: 0.7229 - val_main_output_loss: 1.2730 - val_tof_gate_loss: 0.0023 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6934 - main_output_accuracy: 0.7611 - main_output_loss: 1.4656 - tof_gate_loss: 0.0018 - val_loss: 1.4926 - val_main_output_accuracy: 0.7464 - val_main_output_loss: 1.2699 - val_tof_gate_loss: 0.0022 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6497 - main_output_accuracy: 0.7577 - main_output_loss: 1.4287 - tof_gate_loss: 0.0018 - val_loss: 1.5263 - val_main_output_accuracy: 0.7268 - val_main_output_loss: 1.3059 - val_tof_gate_loss: 0.0021 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6422 - main_output_accuracy: 0.7609 - main_output_loss: 1.4187 - tof_gate_loss: 0.0016 - val_loss: 1.5836 - val_main_output_accuracy: 0.6980 - val_main_output_loss: 1.3661 - val_tof_gate_loss: 0.0020 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.6732 - main_output_accuracy: 0.7861 - main_output_loss: 1.4580 - tof_gate_loss: 0.0015 - val_loss: 1.5256 - val_main_output_accuracy: 0.7229 - val_main_output_loss: 1.3119 - val_tof_gate_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - loss: 1.6963 - main_output_accuracy: 0.7521 - main_output_loss: 1.4849 - tof_gate_loss: 0.0015 - val_loss: 1.5228 - val_main_output_accuracy: 0.7294 - val_main_output_loss: 1.3107 - val_tof_gate_loss: 0.0018 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.5742 - main_output_accuracy: 0.7839 - main_output_loss: 1.3641 - tof_gate_loss: 0.0013 - val_loss: 1.5193 - val_main_output_accuracy: 0.7007 - val_main_output_loss: 1.3093 - val_tof_gate_loss: 0.0017 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6895 - main_output_accuracy: 0.7383 - main_output_loss: 1.4750 - tof_gate_loss: 0.0013 - val_loss: 1.4712 - val_main_output_accuracy: 0.7294 - val_main_output_loss: 1.2626 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.5212 - main_output_accuracy: 0.8009 - main_output_loss: 1.3129 - tof_gate_loss: 0.0012 - val_loss: 1.5228 - val_main_output_accuracy: 0.7216 - val_main_output_loss: 1.3163 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.5497 - main_output_accuracy: 0.7868 - main_output_loss: 1.3440 - tof_gate_loss: 0.0011\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5499 - main_output_accuracy: 0.7867 - main_output_loss: 1.3442 - tof_gate_loss: 0.0011 - val_loss: 1.5253 - val_main_output_accuracy: 0.7203 - val_main_output_loss: 1.3207 - val_tof_gate_loss: 0.0015 - learning_rate: 2.5000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.6939 - main_output_accuracy: 0.7723 - main_output_loss: 1.4904 - tof_gate_loss: 0.0012 - val_loss: 1.4536 - val_main_output_accuracy: 0.7359 - val_main_output_loss: 1.2528 - val_tof_gate_loss: 0.0014 - learning_rate: 1.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5065 - main_output_accuracy: 0.8111 - main_output_loss: 1.3024 - tof_gate_loss: 0.0010 - val_loss: 1.4608 - val_main_output_accuracy: 0.7425 - val_main_output_loss: 1.2627 - val_tof_gate_loss: 0.0014 - learning_rate: 1.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5651 - main_output_accuracy: 0.7944 - main_output_loss: 1.3714 - tof_gate_loss: 0.0010 - val_loss: 1.4263 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.2314 - val_tof_gate_loss: 0.0014 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4862 - main_output_accuracy: 0.8189 - main_output_loss: 1.2917 - tof_gate_loss: 9.5988e-04 - val_loss: 1.4615 - val_main_output_accuracy: 0.7359 - val_main_output_loss: 1.2684 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5781 - main_output_accuracy: 0.7927 - main_output_loss: 1.3859 - tof_gate_loss: 9.7070e-04 - val_loss: 1.4492 - val_main_output_accuracy: 0.7451 - val_main_output_loss: 1.2574 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5316 - main_output_accuracy: 0.8216 - main_output_loss: 1.3420 - tof_gate_loss: 9.8731e-04 - val_loss: 1.4621 - val_main_output_accuracy: 0.7359 - val_main_output_loss: 1.2729 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5329 - main_output_accuracy: 0.8025 - main_output_loss: 1.3439 - tof_gate_loss: 8.5166e-04 - val_loss: 1.4753 - val_main_output_accuracy: 0.7294 - val_main_output_loss: 1.2874 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4435 - main_output_accuracy: 0.8406 - main_output_loss: 1.2604 - tof_gate_loss: 8.6125e-04 - val_loss: 1.4151 - val_main_output_accuracy: 0.7464 - val_main_output_loss: 1.2290 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5224 - main_output_accuracy: 0.8080 - main_output_loss: 1.3363 - tof_gate_loss: 8.5581e-04 - val_loss: 1.4300 - val_main_output_accuracy: 0.7542 - val_main_output_loss: 1.2461 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5489 - main_output_accuracy: 0.8018 - main_output_loss: 1.3654 - tof_gate_loss: 8.5112e-04 - val_loss: 1.3916 - val_main_output_accuracy: 0.7739 - val_main_output_loss: 1.2093 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5498 - main_output_accuracy: 0.8203 - main_output_loss: 1.3718 - tof_gate_loss: 8.1511e-04 - val_loss: 1.4715 - val_main_output_accuracy: 0.7477 - val_main_output_loss: 1.2900 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.6481 - main_output_accuracy: 0.7750 - main_output_loss: 1.4674 - tof_gate_loss: 8.3530e-04 - val_loss: 1.4318 - val_main_output_accuracy: 0.7490 - val_main_output_loss: 1.2526 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4924 - main_output_accuracy: 0.8131 - main_output_loss: 1.3111 - tof_gate_loss: 7.5040e-04 - val_loss: 1.4043 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.2257 - val_tof_gate_loss: 9.8355e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5594 - main_output_accuracy: 0.7910 - main_output_loss: 1.3803 - tof_gate_loss: 6.8787e-04 - val_loss: 1.4398 - val_main_output_accuracy: 0.7399 - val_main_output_loss: 1.2624 - val_tof_gate_loss: 9.4938e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4916 - main_output_accuracy: 0.7968 - main_output_loss: 1.3083 - tof_gate_loss: 6.6328e-04 - val_loss: 1.4556 - val_main_output_accuracy: 0.7438 - val_main_output_loss: 1.2786 - val_tof_gate_loss: 9.2045e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4426 - main_output_accuracy: 0.8475 - main_output_loss: 1.2693 - tof_gate_loss: 5.8094e-04 - val_loss: 1.4378 - val_main_output_accuracy: 0.7359 - val_main_output_loss: 1.2619 - val_tof_gate_loss: 8.8481e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4277 - main_output_accuracy: 0.8594 - main_output_loss: 1.2518 - tof_gate_loss: 5.7139e-04 - val_loss: 1.4173 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.2430 - val_tof_gate_loss: 8.5375e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.4382 - main_output_accuracy: 0.8425 - main_output_loss: 1.2624 - tof_gate_loss: 5.8420e-04\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4380 - main_output_accuracy: 0.8426 - main_output_loss: 1.2622 - tof_gate_loss: 5.8396e-04 - val_loss: 1.4338 - val_main_output_accuracy: 0.7333 - val_main_output_loss: 1.2606 - val_tof_gate_loss: 8.2639e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4298 - main_output_accuracy: 0.8472 - main_output_loss: 1.2556 - tof_gate_loss: 5.9050e-04 - val_loss: 1.3743 - val_main_output_accuracy: 0.7686 - val_main_output_loss: 1.2017 - val_tof_gate_loss: 8.0572e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 65/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.4029 - main_output_accuracy: 0.8580 - main_output_loss: 1.2298 - tof_gate_loss: 5.1752e-04 - val_loss: 1.4040 - val_main_output_accuracy: 0.7660 - val_main_output_loss: 1.2326 - val_tof_gate_loss: 7.9042e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5204 - main_output_accuracy: 0.8301 - main_output_loss: 1.3656 - tof_gate_loss: 5.2297e-04 - val_loss: 1.3965 - val_main_output_accuracy: 0.7608 - val_main_output_loss: 1.2275 - val_tof_gate_loss: 7.7319e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4388 - main_output_accuracy: 0.8550 - main_output_loss: 1.2699 - tof_gate_loss: 5.1217e-04 - val_loss: 1.3831 - val_main_output_accuracy: 0.7634 - val_main_output_loss: 1.2143 - val_tof_gate_loss: 7.5821e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4241 - main_output_accuracy: 0.8448 - main_output_loss: 1.2578 - tof_gate_loss: 4.8598e-04 - val_loss: 1.3661 - val_main_output_accuracy: 0.7725 - val_main_output_loss: 1.1974 - val_tof_gate_loss: 7.4338e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4306 - main_output_accuracy: 0.8375 - main_output_loss: 1.2682 - tof_gate_loss: 4.9189e-04 - val_loss: 1.3919 - val_main_output_accuracy: 0.7582 - val_main_output_loss: 1.2247 - val_tof_gate_loss: 7.2703e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4628 - main_output_accuracy: 0.8573 - main_output_loss: 1.2946 - tof_gate_loss: 5.0148e-04 - val_loss: 1.4014 - val_main_output_accuracy: 0.7529 - val_main_output_loss: 1.2348 - val_tof_gate_loss: 7.1176e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5221 - main_output_accuracy: 0.8205 - main_output_loss: 1.3833 - tof_gate_loss: 5.0606e-04 - val_loss: 1.4012 - val_main_output_accuracy: 0.7595 - val_main_output_loss: 1.2362 - val_tof_gate_loss: 6.9271e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.4383 - main_output_accuracy: 0.8468 - main_output_loss: 1.2836 - tof_gate_loss: 4.7818e-04\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4387 - main_output_accuracy: 0.8466 - main_output_loss: 1.2839 - tof_gate_loss: 4.7810e-04 - val_loss: 1.4338 - val_main_output_accuracy: 0.7477 - val_main_output_loss: 1.2689 - val_tof_gate_loss: 6.7660e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3715 - main_output_accuracy: 0.8652 - main_output_loss: 1.2046 - tof_gate_loss: 4.3609e-04 - val_loss: 1.3833 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.2187 - val_tof_gate_loss: 6.6849e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5345 - main_output_accuracy: 0.8211 - main_output_loss: 1.3716 - tof_gate_loss: 4.5428e-04 - val_loss: 1.3869 - val_main_output_accuracy: 0.7634 - val_main_output_loss: 1.2240 - val_tof_gate_loss: 6.6148e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4586 - main_output_accuracy: 0.8494 - main_output_loss: 1.2945 - tof_gate_loss: 4.5757e-04 - val_loss: 1.3644 - val_main_output_accuracy: 0.7660 - val_main_output_loss: 1.2016 - val_tof_gate_loss: 6.5111e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3648 - main_output_accuracy: 0.8842 - main_output_loss: 1.2010 - tof_gate_loss: 4.1602e-04 - val_loss: 1.3663 - val_main_output_accuracy: 0.7621 - val_main_output_loss: 1.2041 - val_tof_gate_loss: 6.4439e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4499 - main_output_accuracy: 0.8636 - main_output_loss: 1.2925 - tof_gate_loss: 4.2255e-04 - val_loss: 1.3793 - val_main_output_accuracy: 0.7608 - val_main_output_loss: 1.2165 - val_tof_gate_loss: 6.3222e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3850 - main_output_accuracy: 0.8632 - main_output_loss: 1.2229 - tof_gate_loss: 4.0255e-04 - val_loss: 1.3844 - val_main_output_accuracy: 0.7556 - val_main_output_loss: 1.2231 - val_tof_gate_loss: 6.2356e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3324 - main_output_accuracy: 0.8943 - main_output_loss: 1.1694 - tof_gate_loss: 3.8109e-04 - val_loss: 1.3696 - val_main_output_accuracy: 0.7673 - val_main_output_loss: 1.2088 - val_tof_gate_loss: 6.1400e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4348 - main_output_accuracy: 0.8635 - main_output_loss: 1.2743 - tof_gate_loss: 4.1315e-04 - val_loss: 1.3892 - val_main_output_accuracy: 0.7542 - val_main_output_loss: 1.2284 - val_tof_gate_loss: 6.0618e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.3677 - main_output_accuracy: 0.8605 - main_output_loss: 1.2071 - tof_gate_loss: 3.9309e-04\n",
      "Epoch 81: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3678 - main_output_accuracy: 0.8605 - main_output_loss: 1.2072 - tof_gate_loss: 3.9307e-04 - val_loss: 1.3793 - val_main_output_accuracy: 0.7699 - val_main_output_loss: 1.2188 - val_tof_gate_loss: 5.9498e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4632 - main_output_accuracy: 0.8496 - main_output_loss: 1.3046 - tof_gate_loss: 4.1269e-04 - val_loss: 1.3719 - val_main_output_accuracy: 0.7621 - val_main_output_loss: 1.2120 - val_tof_gate_loss: 5.8991e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4616 - main_output_accuracy: 0.8504 - main_output_loss: 1.3011 - tof_gate_loss: 4.0396e-04 - val_loss: 1.3703 - val_main_output_accuracy: 0.7673 - val_main_output_loss: 1.2114 - val_tof_gate_loss: 5.8427e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4110 - main_output_accuracy: 0.8662 - main_output_loss: 1.2532 - tof_gate_loss: 3.7615e-04 - val_loss: 1.3656 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2063 - val_tof_gate_loss: 5.7846e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3865 - main_output_accuracy: 0.8764 - main_output_loss: 1.2283 - tof_gate_loss: 3.5480e-04 - val_loss: 1.3677 - val_main_output_accuracy: 0.7660 - val_main_output_loss: 1.2089 - val_tof_gate_loss: 5.7303e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.3211 - main_output_accuracy: 0.8769 - main_output_loss: 1.1636 - tof_gate_loss: 3.6273e-04 - val_loss: 1.3753 - val_main_output_accuracy: 0.7608 - val_main_output_loss: 1.2166 - val_tof_gate_loss: 5.6966e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4616 - main_output_accuracy: 0.8636 - main_output_loss: 1.3036 - tof_gate_loss: 3.8179e-04 - val_loss: 1.3718 - val_main_output_accuracy: 0.7686 - val_main_output_loss: 1.2139 - val_tof_gate_loss: 5.6297e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3570 - main_output_accuracy: 0.8772 - main_output_loss: 1.1979 - tof_gate_loss: 3.4253e-04 - val_loss: 1.3641 - val_main_output_accuracy: 0.7791 - val_main_output_loss: 1.2055 - val_tof_gate_loss: 5.5727e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4396 - main_output_accuracy: 0.8661 - main_output_loss: 1.2822 - tof_gate_loss: 3.7317e-04 - val_loss: 1.3728 - val_main_output_accuracy: 0.7634 - val_main_output_loss: 1.2145 - val_tof_gate_loss: 5.5134e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4658 - main_output_accuracy: 0.8381 - main_output_loss: 1.3110 - tof_gate_loss: 3.8929e-04 - val_loss: 1.3792 - val_main_output_accuracy: 0.7725 - val_main_output_loss: 1.2212 - val_tof_gate_loss: 5.4540e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3623 - main_output_accuracy: 0.8785 - main_output_loss: 1.2114 - tof_gate_loss: 3.9765e-04 - val_loss: 1.3708 - val_main_output_accuracy: 0.7778 - val_main_output_loss: 1.2132 - val_tof_gate_loss: 5.3841e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3274 - main_output_accuracy: 0.8835 - main_output_loss: 1.1708 - tof_gate_loss: 3.3717e-04 - val_loss: 1.3690 - val_main_output_accuracy: 0.7725 - val_main_output_loss: 1.2116 - val_tof_gate_loss: 5.3355e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4468 - main_output_accuracy: 0.8573 - main_output_loss: 1.3000 - tof_gate_loss: 3.4906e-04 - val_loss: 1.3754 - val_main_output_accuracy: 0.7699 - val_main_output_loss: 1.2181 - val_tof_gate_loss: 5.2814e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.2628 - main_output_accuracy: 0.9062 - main_output_loss: 1.1045 - tof_gate_loss: 3.0739e-04 - val_loss: 1.3778 - val_main_output_accuracy: 0.7621 - val_main_output_loss: 1.2203 - val_tof_gate_loss: 5.2011e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3350 - main_output_accuracy: 0.8874 - main_output_loss: 1.1765 - tof_gate_loss: 3.2917e-04 - val_loss: 1.3672 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2097 - val_tof_gate_loss: 5.1608e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.3181 - main_output_accuracy: 0.8967 - main_output_loss: 1.1625 - tof_gate_loss: 3.0777e-04\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3187 - main_output_accuracy: 0.8966 - main_output_loss: 1.1631 - tof_gate_loss: 3.0787e-04 - val_loss: 1.3755 - val_main_output_accuracy: 0.7673 - val_main_output_loss: 1.2181 - val_tof_gate_loss: 5.0828e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4096 - main_output_accuracy: 0.8745 - main_output_loss: 1.2689 - tof_gate_loss: 3.2988e-04 - val_loss: 1.3681 - val_main_output_accuracy: 0.7660 - val_main_output_loss: 1.2109 - val_tof_gate_loss: 5.0518e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 98/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4434 - main_output_accuracy: 0.8722 - main_output_loss: 1.2873 - tof_gate_loss: 3.2585e-04 - val_loss: 1.3744 - val_main_output_accuracy: 0.7634 - val_main_output_loss: 1.2181 - val_tof_gate_loss: 5.0330e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.2637 - main_output_accuracy: 0.9007 - main_output_loss: 1.1131 - tof_gate_loss: 3.0491e-04 - val_loss: 1.3784 - val_main_output_accuracy: 0.7621 - val_main_output_loss: 1.2220 - val_tof_gate_loss: 5.0059e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3232 - main_output_accuracy: 0.8862 - main_output_loss: 1.1695 - tof_gate_loss: 3.0453e-04 - val_loss: 1.3703 - val_main_output_accuracy: 0.7686 - val_main_output_loss: 1.2145 - val_tof_gate_loss: 4.9601e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3849 - main_output_accuracy: 0.8995 - main_output_loss: 1.2285 - tof_gate_loss: 3.2242e-04 - val_loss: 1.3688 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2132 - val_tof_gate_loss: 4.9431e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4341 - main_output_accuracy: 0.8568 - main_output_loss: 1.2792 - tof_gate_loss: 3.3093e-04 - val_loss: 1.3670 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2106 - val_tof_gate_loss: 4.8878e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4631 - main_output_accuracy: 0.8643 - main_output_loss: 1.3086 - tof_gate_loss: 3.0468e-04 - val_loss: 1.3676 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2124 - val_tof_gate_loss: 4.8657e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3952 - main_output_accuracy: 0.8779 - main_output_loss: 1.2533 - tof_gate_loss: 3.1415e-04 - val_loss: 1.3689 - val_main_output_accuracy: 0.7725 - val_main_output_loss: 1.2134 - val_tof_gate_loss: 4.8282e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.3680 - main_output_accuracy: 0.8789 - main_output_loss: 1.2168 - tof_gate_loss: 3.3096e-04\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3678 - main_output_accuracy: 0.8790 - main_output_loss: 1.2166 - tof_gate_loss: 3.3077e-04 - val_loss: 1.3712 - val_main_output_accuracy: 0.7699 - val_main_output_loss: 1.2157 - val_tof_gate_loss: 4.7864e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3914 - main_output_accuracy: 0.8848 - main_output_loss: 1.2333 - tof_gate_loss: 3.0366e-04 - val_loss: 1.3727 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2183 - val_tof_gate_loss: 4.7609e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3494 - main_output_accuracy: 0.8836 - main_output_loss: 1.1944 - tof_gate_loss: 2.9377e-04 - val_loss: 1.3708 - val_main_output_accuracy: 0.7778 - val_main_output_loss: 1.2165 - val_tof_gate_loss: 4.7496e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4129 - main_output_accuracy: 0.8683 - main_output_loss: 1.2575 - tof_gate_loss: 3.1506e-04 - val_loss: 1.3723 - val_main_output_accuracy: 0.7686 - val_main_output_loss: 1.2168 - val_tof_gate_loss: 4.7372e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3146 - main_output_accuracy: 0.8983 - main_output_loss: 1.1687 - tof_gate_loss: 2.9835e-04 - val_loss: 1.3754 - val_main_output_accuracy: 0.7673 - val_main_output_loss: 1.2194 - val_tof_gate_loss: 4.7037e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3452 - main_output_accuracy: 0.8852 - main_output_loss: 1.1918 - tof_gate_loss: 2.8452e-04 - val_loss: 1.3743 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2198 - val_tof_gate_loss: 4.6838e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3862 - main_output_accuracy: 0.8885 - main_output_loss: 1.2302 - tof_gate_loss: 2.8733e-04 - val_loss: 1.3734 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2194 - val_tof_gate_loss: 4.6672e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4342 - main_output_accuracy: 0.8517 - main_output_loss: 1.2795 - tof_gate_loss: 3.0704e-04 - val_loss: 1.3754 - val_main_output_accuracy: 0.7725 - val_main_output_loss: 1.2198 - val_tof_gate_loss: 4.6429e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.4022 - main_output_accuracy: 0.8715 - main_output_loss: 1.2498 - tof_gate_loss: 2.9705e-04 - val_loss: 1.3739 - val_main_output_accuracy: 0.7699 - val_main_output_loss: 1.2191 - val_tof_gate_loss: 4.6209e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.3971 - main_output_accuracy: 0.8609 - main_output_loss: 1.2418 - tof_gate_loss: 3.0012e-04\n",
      "Epoch 114: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3967 - main_output_accuracy: 0.8611 - main_output_loss: 1.2414 - tof_gate_loss: 2.9994e-04 - val_loss: 1.3699 - val_main_output_accuracy: 0.7686 - val_main_output_loss: 1.2141 - val_tof_gate_loss: 4.6085e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4869 - main_output_accuracy: 0.8461 - main_output_loss: 1.3319 - tof_gate_loss: 2.9080e-04 - val_loss: 1.3724 - val_main_output_accuracy: 0.7725 - val_main_output_loss: 1.2175 - val_tof_gate_loss: 4.5812e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3954 - main_output_accuracy: 0.8836 - main_output_loss: 1.2408 - tof_gate_loss: 2.8154e-04 - val_loss: 1.3730 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2183 - val_tof_gate_loss: 4.5716e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3692 - main_output_accuracy: 0.8764 - main_output_loss: 1.2283 - tof_gate_loss: 2.9175e-04 - val_loss: 1.3704 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2156 - val_tof_gate_loss: 4.5595e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3465 - main_output_accuracy: 0.8825 - main_output_loss: 1.1943 - tof_gate_loss: 2.7224e-04 - val_loss: 1.3689 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2146 - val_tof_gate_loss: 4.5425e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4160 - main_output_accuracy: 0.8741 - main_output_loss: 1.2663 - tof_gate_loss: 2.8918e-04 - val_loss: 1.3674 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2130 - val_tof_gate_loss: 4.5223e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4247 - main_output_accuracy: 0.8773 - main_output_loss: 1.2704 - tof_gate_loss: 2.8673e-04 - val_loss: 1.3654 - val_main_output_accuracy: 0.7739 - val_main_output_loss: 1.2107 - val_tof_gate_loss: 4.5051e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3102 - main_output_accuracy: 0.8987 - main_output_loss: 1.1562 - tof_gate_loss: 2.7827e-04 - val_loss: 1.3647 - val_main_output_accuracy: 0.7765 - val_main_output_loss: 1.2098 - val_tof_gate_loss: 4.5018e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 122/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4441 - main_output_accuracy: 0.8637 - main_output_loss: 1.2920 - tof_gate_loss: 2.9093e-04 - val_loss: 1.3646 - val_main_output_accuracy: 0.7739 - val_main_output_loss: 1.2108 - val_tof_gate_loss: 4.4827e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 123/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3457 - main_output_accuracy: 0.8805 - main_output_loss: 1.1851 - tof_gate_loss: 2.9808e-04 - val_loss: 1.3674 - val_main_output_accuracy: 0.7765 - val_main_output_loss: 1.2131 - val_tof_gate_loss: 4.4779e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 124/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3566 - main_output_accuracy: 0.8865 - main_output_loss: 1.2041 - tof_gate_loss: 2.6263e-04 - val_loss: 1.3668 - val_main_output_accuracy: 0.7712 - val_main_output_loss: 1.2125 - val_tof_gate_loss: 4.4388e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 125/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3953 - main_output_accuracy: 0.8773 - main_output_loss: 1.2408 - tof_gate_loss: 2.7256e-04 - val_loss: 1.3628 - val_main_output_accuracy: 0.7791 - val_main_output_loss: 1.2082 - val_tof_gate_loss: 4.4188e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 126/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4617 - main_output_accuracy: 0.8743 - main_output_loss: 1.3103 - tof_gate_loss: 2.8378e-04 - val_loss: 1.3684 - val_main_output_accuracy: 0.7752 - val_main_output_loss: 1.2148 - val_tof_gate_loss: 4.4089e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 127/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.2772 - main_output_accuracy: 0.9079 - main_output_loss: 1.1408 - tof_gate_loss: 2.5496e-04 - val_loss: 1.3670 - val_main_output_accuracy: 0.7765 - val_main_output_loss: 1.2122 - val_tof_gate_loss: 4.3907e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 128/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3324 - main_output_accuracy: 0.8940 - main_output_loss: 1.1729 - tof_gate_loss: 2.4381e-04 - val_loss: 1.3696 - val_main_output_accuracy: 0.7778 - val_main_output_loss: 1.2149 - val_tof_gate_loss: 4.3744e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 128: early stopping\n",
      "Restoring model weights from the end of the best epoch: 88.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 11:10:08.445442: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step\n",
      "\n",
      "===== FOLD 5/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 111ms/step - loss: 10.4265 - main_output_accuracy: 0.1535 - main_output_loss: 2.8532 - tof_gate_loss: 0.6866 - val_loss: 8.0781 - val_main_output_accuracy: 0.3995 - val_main_output_loss: 2.4113 - val_tof_gate_loss: 0.5635 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 7.4799 - main_output_accuracy: 0.3599 - main_output_loss: 2.2372 - tof_gate_loss: 0.5235 - val_loss: 6.1191 - val_main_output_accuracy: 0.5392 - val_main_output_loss: 1.9115 - val_tof_gate_loss: 0.4437 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 5.9981 - main_output_accuracy: 0.4443 - main_output_loss: 2.0378 - tof_gate_loss: 0.4128 - val_loss: 5.0306 - val_main_output_accuracy: 0.5686 - val_main_output_loss: 1.7127 - val_tof_gate_loss: 0.3466 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 5.0578 - main_output_accuracy: 0.4968 - main_output_loss: 1.9108 - tof_gate_loss: 0.3161 - val_loss: 4.3421 - val_main_output_accuracy: 0.5551 - val_main_output_loss: 1.6536 - val_tof_gate_loss: 0.2607 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 4.5077 - main_output_accuracy: 0.5184 - main_output_loss: 1.9410 - tof_gate_loss: 0.2445 - val_loss: 3.8179 - val_main_output_accuracy: 0.5858 - val_main_output_loss: 1.6011 - val_tof_gate_loss: 0.1905 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 3.9552 - main_output_accuracy: 0.5649 - main_output_loss: 1.8369 - tof_gate_loss: 0.1798 - val_loss: 3.3398 - val_main_output_accuracy: 0.6422 - val_main_output_loss: 1.4927 - val_tof_gate_loss: 0.1363 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 3.5553 - main_output_accuracy: 0.5862 - main_output_loss: 1.7837 - tof_gate_loss: 0.1297 - val_loss: 3.1233 - val_main_output_accuracy: 0.5944 - val_main_output_loss: 1.5704 - val_tof_gate_loss: 0.0987 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 3.3229 - main_output_accuracy: 0.5931 - main_output_loss: 1.8306 - tof_gate_loss: 0.0995 - val_loss: 2.8302 - val_main_output_accuracy: 0.6213 - val_main_output_loss: 1.5121 - val_tof_gate_loss: 0.0713 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 3.0703 - main_output_accuracy: 0.5935 - main_output_loss: 1.7997 - tof_gate_loss: 0.0729 - val_loss: 2.5884 - val_main_output_accuracy: 0.6691 - val_main_output_loss: 1.4548 - val_tof_gate_loss: 0.0535 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.9617 - main_output_accuracy: 0.5735 - main_output_loss: 1.8675 - tof_gate_loss: 0.0589 - val_loss: 2.3920 - val_main_output_accuracy: 0.6850 - val_main_output_loss: 1.4127 - val_tof_gate_loss: 0.0411 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.7651 - main_output_accuracy: 0.6001 - main_output_loss: 1.8140 - tof_gate_loss: 0.0445 - val_loss: 2.2777 - val_main_output_accuracy: 0.6703 - val_main_output_loss: 1.4223 - val_tof_gate_loss: 0.0320 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.5202 - main_output_accuracy: 0.6230 - main_output_loss: 1.6833 - tof_gate_loss: 0.0339 - val_loss: 2.1953 - val_main_output_accuracy: 0.6728 - val_main_output_loss: 1.4436 - val_tof_gate_loss: 0.0258 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 2.4675 - main_output_accuracy: 0.6210 - main_output_loss: 1.7269 - tof_gate_loss: 0.0281 - val_loss: 2.1870 - val_main_output_accuracy: 0.6262 - val_main_output_loss: 1.5144 - val_tof_gate_loss: 0.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 2.3125 - main_output_accuracy: 0.6546 - main_output_loss: 1.6591 - tof_gate_loss: 0.0230 - val_loss: 2.2933 - val_main_output_accuracy: 0.5502 - val_main_output_loss: 1.6872 - val_tof_gate_loss: 0.0172 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 2.3649 - main_output_accuracy: 0.6189 - main_output_loss: 1.7773 - tof_gate_loss: 0.0204 - val_loss: 1.9876 - val_main_output_accuracy: 0.6581 - val_main_output_loss: 1.4409 - val_tof_gate_loss: 0.0144 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.2133 - main_output_accuracy: 0.6422 - main_output_loss: 1.6820 - tof_gate_loss: 0.0161 - val_loss: 2.0056 - val_main_output_accuracy: 0.6299 - val_main_output_loss: 1.5103 - val_tof_gate_loss: 0.0122 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.1470 - main_output_accuracy: 0.6391 - main_output_loss: 1.6542 - tof_gate_loss: 0.0138 - val_loss: 1.9880 - val_main_output_accuracy: 0.6250 - val_main_output_loss: 1.5302 - val_tof_gate_loss: 0.0104 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.0864 - main_output_accuracy: 0.6502 - main_output_loss: 1.6341 - tof_gate_loss: 0.0118 - val_loss: 1.7973 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3689 - val_tof_gate_loss: 0.0090 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.9717 - main_output_accuracy: 0.6801 - main_output_loss: 1.5513 - tof_gate_loss: 0.0102 - val_loss: 1.9232 - val_main_output_accuracy: 0.5956 - val_main_output_loss: 1.5161 - val_tof_gate_loss: 0.0078 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.0185 - main_output_accuracy: 0.6726 - main_output_loss: 1.6201 - tof_gate_loss: 0.0092 - val_loss: 1.7221 - val_main_output_accuracy: 0.6924 - val_main_output_loss: 1.3384 - val_tof_gate_loss: 0.0069 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.8904 - main_output_accuracy: 0.6851 - main_output_loss: 1.5134 - tof_gate_loss: 0.0076 - val_loss: 1.8177 - val_main_output_accuracy: 0.6642 - val_main_output_loss: 1.4577 - val_tof_gate_loss: 0.0061 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.0162 - main_output_accuracy: 0.6564 - main_output_loss: 1.6613 - tof_gate_loss: 0.0074 - val_loss: 1.7526 - val_main_output_accuracy: 0.6691 - val_main_output_loss: 1.4124 - val_tof_gate_loss: 0.0053 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 2.0513 - main_output_accuracy: 0.6674 - main_output_loss: 1.7148 - tof_gate_loss: 0.0069 - val_loss: 1.7883 - val_main_output_accuracy: 0.6311 - val_main_output_loss: 1.4590 - val_tof_gate_loss: 0.0047 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.8480 - main_output_accuracy: 0.7024 - main_output_loss: 1.5238 - tof_gate_loss: 0.0053 - val_loss: 1.8181 - val_main_output_accuracy: 0.6618 - val_main_output_loss: 1.5024 - val_tof_gate_loss: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.9045 - main_output_accuracy: 0.6777 - main_output_loss: 1.5931 - tof_gate_loss: 0.0053 - val_loss: 1.7053 - val_main_output_accuracy: 0.6801 - val_main_output_loss: 1.4040 - val_tof_gate_loss: 0.0037 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 1.9781 - main_output_accuracy: 0.6886 - main_output_loss: 1.6734 - tof_gate_loss: 0.0049\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.9771 - main_output_accuracy: 0.6888 - main_output_loss: 1.6724 - tof_gate_loss: 0.0048 - val_loss: 1.6667 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3749 - val_tof_gate_loss: 0.0033 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.8608 - main_output_accuracy: 0.6973 - main_output_loss: 1.5726 - tof_gate_loss: 0.0042 - val_loss: 1.5883 - val_main_output_accuracy: 0.7255 - val_main_output_loss: 1.3100 - val_tof_gate_loss: 0.0031 - learning_rate: 2.5000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.7260 - main_output_accuracy: 0.7308 - main_output_loss: 1.4477 - tof_gate_loss: 0.0039 - val_loss: 1.5578 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2861 - val_tof_gate_loss: 0.0030 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7103 - main_output_accuracy: 0.7572 - main_output_loss: 1.4434 - tof_gate_loss: 0.0036 - val_loss: 1.5702 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.3082 - val_tof_gate_loss: 0.0028 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.8422 - main_output_accuracy: 0.7082 - main_output_loss: 1.5827 - tof_gate_loss: 0.0037 - val_loss: 1.6444 - val_main_output_accuracy: 0.6691 - val_main_output_loss: 1.3891 - val_tof_gate_loss: 0.0027 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.7036 - main_output_accuracy: 0.7580 - main_output_loss: 1.4506 - tof_gate_loss: 0.0034 - val_loss: 1.5319 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2826 - val_tof_gate_loss: 0.0025 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7272 - main_output_accuracy: 0.7565 - main_output_loss: 1.4788 - tof_gate_loss: 0.0031 - val_loss: 1.6642 - val_main_output_accuracy: 0.6838 - val_main_output_loss: 1.4188 - val_tof_gate_loss: 0.0024 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.7007 - main_output_accuracy: 0.7649 - main_output_loss: 1.4564 - tof_gate_loss: 0.0029 - val_loss: 1.5078 - val_main_output_accuracy: 0.7426 - val_main_output_loss: 1.2698 - val_tof_gate_loss: 0.0022 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.7876 - main_output_accuracy: 0.7215 - main_output_loss: 1.5480 - tof_gate_loss: 0.0030 - val_loss: 1.5757 - val_main_output_accuracy: 0.7206 - val_main_output_loss: 1.3420 - val_tof_gate_loss: 0.0021 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.7228 - main_output_accuracy: 0.7483 - main_output_loss: 1.4862 - tof_gate_loss: 0.0026 - val_loss: 1.5467 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3129 - val_tof_gate_loss: 0.0020 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.6937 - main_output_accuracy: 0.7575 - main_output_loss: 1.4614 - tof_gate_loss: 0.0025 - val_loss: 1.5396 - val_main_output_accuracy: 0.7206 - val_main_output_loss: 1.3124 - val_tof_gate_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.7350 - main_output_accuracy: 0.7428 - main_output_loss: 1.5081 - tof_gate_loss: 0.0024 - val_loss: 1.6839 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.4597 - val_tof_gate_loss: 0.0017 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.7359 - main_output_accuracy: 0.7368 - main_output_loss: 1.5160 - tof_gate_loss: 0.0023 - val_loss: 1.5598 - val_main_output_accuracy: 0.7120 - val_main_output_loss: 1.3368 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.7860 - main_output_accuracy: 0.7264 - main_output_loss: 1.5620 - tof_gate_loss: 0.0023 - val_loss: 1.6217 - val_main_output_accuracy: 0.7194 - val_main_output_loss: 1.4005 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5938 - main_output_accuracy: 0.8050 - main_output_loss: 1.3663 - tof_gate_loss: 0.0020 - val_loss: 1.5857 - val_main_output_accuracy: 0.7108 - val_main_output_loss: 1.3695 - val_tof_gate_loss: 0.0015 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.7049 - main_output_accuracy: 0.7449 - main_output_loss: 1.4872 - tof_gate_loss: 0.0020\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.7047 - main_output_accuracy: 0.7450 - main_output_loss: 1.4870 - tof_gate_loss: 0.0020 - val_loss: 1.5397 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3214 - val_tof_gate_loss: 0.0014 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4732 - main_output_accuracy: 0.8254 - main_output_loss: 1.2551 - tof_gate_loss: 0.0016 - val_loss: 1.4708 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2613 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5458 - main_output_accuracy: 0.7968 - main_output_loss: 1.3342 - tof_gate_loss: 0.0016 - val_loss: 1.4344 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.2271 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4949 - main_output_accuracy: 0.8114 - main_output_loss: 1.2851 - tof_gate_loss: 0.0015 - val_loss: 1.4447 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.2370 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.5865 - main_output_accuracy: 0.7973 - main_output_loss: 1.3830 - tof_gate_loss: 0.0016 - val_loss: 1.4312 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2297 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5625 - main_output_accuracy: 0.8065 - main_output_loss: 1.3606 - tof_gate_loss: 0.0015 - val_loss: 1.4332 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.2359 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5750 - main_output_accuracy: 0.7935 - main_output_loss: 1.3739 - tof_gate_loss: 0.0015 - val_loss: 1.4467 - val_main_output_accuracy: 0.7525 - val_main_output_loss: 1.2458 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5554 - main_output_accuracy: 0.8052 - main_output_loss: 1.3565 - tof_gate_loss: 0.0014 - val_loss: 1.3992 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1997 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5383 - main_output_accuracy: 0.8112 - main_output_loss: 1.3421 - tof_gate_loss: 0.0014 - val_loss: 1.4795 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2847 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.5468 - main_output_accuracy: 0.8114 - main_output_loss: 1.3501 - tof_gate_loss: 0.0013 - val_loss: 1.4681 - val_main_output_accuracy: 0.7304 - val_main_output_loss: 1.2742 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6374 - main_output_accuracy: 0.7908 - main_output_loss: 1.4403 - tof_gate_loss: 0.0014 - val_loss: 1.4299 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.2400 - val_tof_gate_loss: 9.7438e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.6264 - main_output_accuracy: 0.8052 - main_output_loss: 1.4342 - tof_gate_loss: 0.0013 - val_loss: 1.4489 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2613 - val_tof_gate_loss: 9.3044e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5713 - main_output_accuracy: 0.8032 - main_output_loss: 1.3813 - tof_gate_loss: 0.0012 - val_loss: 1.4517 - val_main_output_accuracy: 0.7414 - val_main_output_loss: 1.2636 - val_tof_gate_loss: 8.9408e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4799 - main_output_accuracy: 0.8225 - main_output_loss: 1.2873 - tof_gate_loss: 0.0011 - val_loss: 1.4723 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2815 - val_tof_gate_loss: 8.6523e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5741 - main_output_accuracy: 0.7935 - main_output_loss: 1.3851 - tof_gate_loss: 0.0011 - val_loss: 1.4460 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.2573 - val_tof_gate_loss: 8.2838e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.5648 - main_output_accuracy: 0.8200 - main_output_loss: 1.3795 - tof_gate_loss: 0.0010\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5650 - main_output_accuracy: 0.8199 - main_output_loss: 1.3796 - tof_gate_loss: 0.0010 - val_loss: 1.5161 - val_main_output_accuracy: 0.7194 - val_main_output_loss: 1.3305 - val_tof_gate_loss: 7.9741e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.5853 - main_output_accuracy: 0.7871 - main_output_loss: 1.3878 - tof_gate_loss: 0.0011 - val_loss: 1.3695 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1852 - val_tof_gate_loss: 7.7872e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 58/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4496 - main_output_accuracy: 0.8468 - main_output_loss: 1.2701 - tof_gate_loss: 9.1640e-04 - val_loss: 1.3919 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.2100 - val_tof_gate_loss: 7.6285e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 59/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4229 - main_output_accuracy: 0.8553 - main_output_loss: 1.2427 - tof_gate_loss: 9.4048e-04 - val_loss: 1.3684 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.1877 - val_tof_gate_loss: 7.4883e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 60/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - loss: 1.4850 - main_output_accuracy: 0.8318 - main_output_loss: 1.3034 - tof_gate_loss: 9.8306e-04 - val_loss: 1.3688 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1855 - val_tof_gate_loss: 7.2841e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 61/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5463 - main_output_accuracy: 0.8172 - main_output_loss: 1.3565 - tof_gate_loss: 9.5253e-04 - val_loss: 1.3860 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.2103 - val_tof_gate_loss: 7.0701e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 62/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.5379 - main_output_accuracy: 0.8184 - main_output_loss: 1.3611 - tof_gate_loss: 9.3546e-04 - val_loss: 1.3892 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.2153 - val_tof_gate_loss: 6.9570e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 63/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5380 - main_output_accuracy: 0.8178 - main_output_loss: 1.3653 - tof_gate_loss: 9.2449e-04 - val_loss: 1.4186 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.2393 - val_tof_gate_loss: 6.7303e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 64/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4681 - main_output_accuracy: 0.8410 - main_output_loss: 1.2925 - tof_gate_loss: 8.3358e-04 - val_loss: 1.3721 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1958 - val_tof_gate_loss: 6.5529e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 65/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.4769 - main_output_accuracy: 0.8262 - main_output_loss: 1.3018 - tof_gate_loss: 8.0417e-04\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4768 - main_output_accuracy: 0.8262 - main_output_loss: 1.3017 - tof_gate_loss: 8.0436e-04 - val_loss: 1.3684 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1941 - val_tof_gate_loss: 6.3890e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4940 - main_output_accuracy: 0.8439 - main_output_loss: 1.3171 - tof_gate_loss: 8.4207e-04 - val_loss: 1.3576 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1854 - val_tof_gate_loss: 6.2482e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5129 - main_output_accuracy: 0.8398 - main_output_loss: 1.3390 - tof_gate_loss: 8.2987e-04 - val_loss: 1.3510 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1752 - val_tof_gate_loss: 6.1996e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4361 - main_output_accuracy: 0.8533 - main_output_loss: 1.2628 - tof_gate_loss: 7.4445e-04 - val_loss: 1.3392 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1638 - val_tof_gate_loss: 6.1225e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4538 - main_output_accuracy: 0.8601 - main_output_loss: 1.2808 - tof_gate_loss: 7.8006e-04 - val_loss: 1.3340 - val_main_output_accuracy: 0.7745 - val_main_output_loss: 1.1576 - val_tof_gate_loss: 6.0481e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4141 - main_output_accuracy: 0.8846 - main_output_loss: 1.2447 - tof_gate_loss: 7.3455e-04 - val_loss: 1.3563 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1864 - val_tof_gate_loss: 5.9030e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.5522 - main_output_accuracy: 0.8116 - main_output_loss: 1.3774 - tof_gate_loss: 8.0877e-04 - val_loss: 1.3522 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1827 - val_tof_gate_loss: 5.8067e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4835 - main_output_accuracy: 0.8610 - main_output_loss: 1.3134 - tof_gate_loss: 7.8878e-04 - val_loss: 1.3490 - val_main_output_accuracy: 0.7855 - val_main_output_loss: 1.1762 - val_tof_gate_loss: 5.6971e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5445 - main_output_accuracy: 0.8127 - main_output_loss: 1.3714 - tof_gate_loss: 8.0836e-04 - val_loss: 1.3508 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1775 - val_tof_gate_loss: 5.6011e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4782 - main_output_accuracy: 0.8340 - main_output_loss: 1.3034 - tof_gate_loss: 7.8682e-04 - val_loss: 1.3544 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.1908 - val_tof_gate_loss: 5.4825e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5413 - main_output_accuracy: 0.8429 - main_output_loss: 1.3724 - tof_gate_loss: 7.3632e-04 - val_loss: 1.3698 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.2026 - val_tof_gate_loss: 5.4095e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3728 - main_output_accuracy: 0.8701 - main_output_loss: 1.2042 - tof_gate_loss: 7.0440e-04 - val_loss: 1.3632 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.1952 - val_tof_gate_loss: 5.2793e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3569 - main_output_accuracy: 0.8756 - main_output_loss: 1.1888 - tof_gate_loss: 6.4220e-04 - val_loss: 1.3272 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1587 - val_tof_gate_loss: 5.2057e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5506 - main_output_accuracy: 0.8250 - main_output_loss: 1.3830 - tof_gate_loss: 7.0820e-04 - val_loss: 1.3504 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1806 - val_tof_gate_loss: 5.1243e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4562 - main_output_accuracy: 0.8603 - main_output_loss: 1.2873 - tof_gate_loss: 6.9036e-04 - val_loss: 1.3852 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.2176 - val_tof_gate_loss: 4.9604e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.4940 - main_output_accuracy: 0.8272 - main_output_loss: 1.3215 - tof_gate_loss: 6.7928e-04\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.4928 - main_output_accuracy: 0.8275 - main_output_loss: 1.3204 - tof_gate_loss: 6.7864e-04 - val_loss: 1.3352 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1689 - val_tof_gate_loss: 4.9131e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4874 - main_output_accuracy: 0.8479 - main_output_loss: 1.3243 - tof_gate_loss: 6.4394e-04 - val_loss: 1.3527 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1837 - val_tof_gate_loss: 4.8108e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.2804 - main_output_accuracy: 0.9058 - main_output_loss: 1.1131 - tof_gate_loss: 5.5640e-04 - val_loss: 1.3325 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1656 - val_tof_gate_loss: 4.8089e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4295 - main_output_accuracy: 0.8634 - main_output_loss: 1.2616 - tof_gate_loss: 6.0040e-04 - val_loss: 1.3559 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.1928 - val_tof_gate_loss: 4.7291e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4380 - main_output_accuracy: 0.8694 - main_output_loss: 1.2715 - tof_gate_loss: 6.3518e-04 - val_loss: 1.3380 - val_main_output_accuracy: 0.7806 - val_main_output_loss: 1.1719 - val_tof_gate_loss: 4.6943e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3476 - main_output_accuracy: 0.8822 - main_output_loss: 1.1823 - tof_gate_loss: 5.5448e-04 - val_loss: 1.3454 - val_main_output_accuracy: 0.7598 - val_main_output_loss: 1.1802 - val_tof_gate_loss: 4.6266e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4240 - main_output_accuracy: 0.8657 - main_output_loss: 1.2592 - tof_gate_loss: 5.8284e-04 - val_loss: 1.3368 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1718 - val_tof_gate_loss: 4.5455e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3195 - main_output_accuracy: 0.9042 - main_output_loss: 1.1531 - tof_gate_loss: 5.4849e-04 - val_loss: 1.3490 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1866 - val_tof_gate_loss: 4.5385e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4767 - main_output_accuracy: 0.8709 - main_output_loss: 1.3180 - tof_gate_loss: 5.7893e-04 - val_loss: 1.3263 - val_main_output_accuracy: 0.7806 - val_main_output_loss: 1.1629 - val_tof_gate_loss: 4.4259e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.4843 - main_output_accuracy: 0.8483 - main_output_loss: 1.3264 - tof_gate_loss: 6.1746e-04\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4835 - main_output_accuracy: 0.8486 - main_output_loss: 1.3256 - tof_gate_loss: 6.1709e-04 - val_loss: 1.3430 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1774 - val_tof_gate_loss: 4.3935e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4071 - main_output_accuracy: 0.8604 - main_output_loss: 1.2394 - tof_gate_loss: 5.9152e-04 - val_loss: 1.3283 - val_main_output_accuracy: 0.7745 - val_main_output_loss: 1.1617 - val_tof_gate_loss: 4.3552e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 91/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3676 - main_output_accuracy: 0.8779 - main_output_loss: 1.2037 - tof_gate_loss: 5.5836e-04 - val_loss: 1.3321 - val_main_output_accuracy: 0.7782 - val_main_output_loss: 1.1730 - val_tof_gate_loss: 4.3451e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 92/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4036 - main_output_accuracy: 0.8424 - main_output_loss: 1.2344 - tof_gate_loss: 5.5748e-04 - val_loss: 1.3391 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1738 - val_tof_gate_loss: 4.2965e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 93/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.3472 - main_output_accuracy: 0.8866 - main_output_loss: 1.1813 - tof_gate_loss: 5.3615e-04 - val_loss: 1.3370 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1754 - val_tof_gate_loss: 4.2371e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 94/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3206 - main_output_accuracy: 0.8977 - main_output_loss: 1.1577 - tof_gate_loss: 5.0498e-04 - val_loss: 1.3403 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1759 - val_tof_gate_loss: 4.2394e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 95/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3912 - main_output_accuracy: 0.8751 - main_output_loss: 1.2266 - tof_gate_loss: 5.2750e-04 - val_loss: 1.3298 - val_main_output_accuracy: 0.7794 - val_main_output_loss: 1.1663 - val_tof_gate_loss: 4.2496e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 96/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4557 - main_output_accuracy: 0.8638 - main_output_loss: 1.2935 - tof_gate_loss: 5.7118e-04 - val_loss: 1.3289 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1640 - val_tof_gate_loss: 4.1891e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 97/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3297 - main_output_accuracy: 0.8899 - main_output_loss: 1.1680 - tof_gate_loss: 4.8873e-04 - val_loss: 1.3314 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1648 - val_tof_gate_loss: 4.1382e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 98/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.3443 - main_output_accuracy: 0.8908 - main_output_loss: 1.1813 - tof_gate_loss: 5.0566e-04\n",
      "Epoch 98: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3445 - main_output_accuracy: 0.8906 - main_output_loss: 1.1815 - tof_gate_loss: 5.0587e-04 - val_loss: 1.3279 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1642 - val_tof_gate_loss: 4.1116e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4076 - main_output_accuracy: 0.8550 - main_output_loss: 1.2454 - tof_gate_loss: 5.1486e-04 - val_loss: 1.3280 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1671 - val_tof_gate_loss: 4.0919e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3901 - main_output_accuracy: 0.8951 - main_output_loss: 1.2290 - tof_gate_loss: 5.5333e-04 - val_loss: 1.3401 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1778 - val_tof_gate_loss: 4.0477e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3328 - main_output_accuracy: 0.8965 - main_output_loss: 1.1707 - tof_gate_loss: 4.9030e-04 - val_loss: 1.3356 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1729 - val_tof_gate_loss: 4.0358e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3883 - main_output_accuracy: 0.8965 - main_output_loss: 1.2167 - tof_gate_loss: 5.0057e-04 - val_loss: 1.3327 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1687 - val_tof_gate_loss: 4.0326e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3540 - main_output_accuracy: 0.8685 - main_output_loss: 1.1909 - tof_gate_loss: 5.1110e-04 - val_loss: 1.3343 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1745 - val_tof_gate_loss: 4.0021e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4979 - main_output_accuracy: 0.8577 - main_output_loss: 1.3348 - tof_gate_loss: 5.4772e-04 - val_loss: 1.3327 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1680 - val_tof_gate_loss: 3.9884e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4667 - main_output_accuracy: 0.8455 - main_output_loss: 1.3022 - tof_gate_loss: 5.4522e-04 - val_loss: 1.3346 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1748 - val_tof_gate_loss: 4.0208e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4577 - main_output_accuracy: 0.8312 - main_output_loss: 1.2957 - tof_gate_loss: 5.5331e-04 - val_loss: 1.3350 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1750 - val_tof_gate_loss: 3.9687e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.4576 - main_output_accuracy: 0.8634 - main_output_loss: 1.2949 - tof_gate_loss: 5.2091e-04\n",
      "Epoch 107: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4575 - main_output_accuracy: 0.8634 - main_output_loss: 1.2948 - tof_gate_loss: 5.2089e-04 - val_loss: 1.3353 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1736 - val_tof_gate_loss: 3.9944e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3664 - main_output_accuracy: 0.8799 - main_output_loss: 1.2038 - tof_gate_loss: 4.6944e-04 - val_loss: 1.3406 - val_main_output_accuracy: 0.7745 - val_main_output_loss: 1.1812 - val_tof_gate_loss: 3.9151e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4617 - main_output_accuracy: 0.8530 - main_output_loss: 1.3008 - tof_gate_loss: 5.4575e-04 - val_loss: 1.3367 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1695 - val_tof_gate_loss: 3.9799e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3940 - main_output_accuracy: 0.8531 - main_output_loss: 1.2325 - tof_gate_loss: 5.2869e-04 - val_loss: 1.3355 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1724 - val_tof_gate_loss: 3.9257e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4277 - main_output_accuracy: 0.8552 - main_output_loss: 1.2626 - tof_gate_loss: 4.9650e-04 - val_loss: 1.3378 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1746 - val_tof_gate_loss: 3.8911e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3973 - main_output_accuracy: 0.8909 - main_output_loss: 1.2394 - tof_gate_loss: 5.0715e-04 - val_loss: 1.3348 - val_main_output_accuracy: 0.7757 - val_main_output_loss: 1.1689 - val_tof_gate_loss: 3.9280e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 112: early stopping\n",
      "Restoring model weights from the end of the best epoch: 72.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 11:32:48.765440: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\n",
      "===== FOLD 6/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 117ms/step - loss: 10.5064 - main_output_accuracy: 0.1591 - main_output_loss: 2.9122 - tof_gate_loss: 0.7187 - val_loss: 8.1449 - val_main_output_accuracy: 0.4436 - val_main_output_loss: 2.4527 - val_tof_gate_loss: 0.5291 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 7.5386 - main_output_accuracy: 0.3489 - main_output_loss: 2.2649 - tof_gate_loss: 0.5035 - val_loss: 6.1689 - val_main_output_accuracy: 0.5441 - val_main_output_loss: 1.9367 - val_tof_gate_loss: 0.3679 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 6.0504 - main_output_accuracy: 0.4285 - main_output_loss: 2.0609 - tof_gate_loss: 0.3509 - val_loss: 5.0505 - val_main_output_accuracy: 0.5760 - val_main_output_loss: 1.7083 - val_tof_gate_loss: 0.2561 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 5.1715 - main_output_accuracy: 0.4789 - main_output_loss: 1.9966 - tof_gate_loss: 0.2467 - val_loss: 4.2574 - val_main_output_accuracy: 0.6152 - val_main_output_loss: 1.5422 - val_tof_gate_loss: 0.1792 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 4.4549 - main_output_accuracy: 0.5423 - main_output_loss: 1.8657 - tof_gate_loss: 0.1732 - val_loss: 3.7290 - val_main_output_accuracy: 0.6287 - val_main_output_loss: 1.4796 - val_tof_gate_loss: 0.1288 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 4.0309 - main_output_accuracy: 0.5403 - main_output_loss: 1.8816 - tof_gate_loss: 0.1273 - val_loss: 3.3147 - val_main_output_accuracy: 0.6409 - val_main_output_loss: 1.4423 - val_tof_gate_loss: 0.0944 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 3.6897 - main_output_accuracy: 0.5466 - main_output_loss: 1.8922 - tof_gate_loss: 0.0974 - val_loss: 3.0813 - val_main_output_accuracy: 0.6483 - val_main_output_loss: 1.5009 - val_tof_gate_loss: 0.0714 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 3.3630 - main_output_accuracy: 0.5781 - main_output_loss: 1.8432 - tof_gate_loss: 0.0726 - val_loss: 2.7435 - val_main_output_accuracy: 0.6801 - val_main_output_loss: 1.3969 - val_tof_gate_loss: 0.0552 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 3.0137 - main_output_accuracy: 0.5943 - main_output_loss: 1.7207 - tof_gate_loss: 0.0553 - val_loss: 2.6741 - val_main_output_accuracy: 0.6152 - val_main_output_loss: 1.5189 - val_tof_gate_loss: 0.0438 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.8408 - main_output_accuracy: 0.6335 - main_output_loss: 1.7257 - tof_gate_loss: 0.0445 - val_loss: 2.4754 - val_main_output_accuracy: 0.6311 - val_main_output_loss: 1.4740 - val_tof_gate_loss: 0.0355 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.6860 - main_output_accuracy: 0.6328 - main_output_loss: 1.7178 - tof_gate_loss: 0.0368 - val_loss: 2.3818 - val_main_output_accuracy: 0.6176 - val_main_output_loss: 1.5049 - val_tof_gate_loss: 0.0295 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 2.5931 - main_output_accuracy: 0.6297 - main_output_loss: 1.7443 - tof_gate_loss: 0.0306 - val_loss: 2.2338 - val_main_output_accuracy: 0.6569 - val_main_output_loss: 1.4595 - val_tof_gate_loss: 0.0244 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.4321 - main_output_accuracy: 0.6458 - main_output_loss: 1.6805 - tof_gate_loss: 0.0249 - val_loss: 2.0728 - val_main_output_accuracy: 0.6838 - val_main_output_loss: 1.3880 - val_tof_gate_loss: 0.0206 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.2658 - main_output_accuracy: 0.6615 - main_output_loss: 1.5992 - tof_gate_loss: 0.0204 - val_loss: 2.1027 - val_main_output_accuracy: 0.6324 - val_main_output_loss: 1.4839 - val_tof_gate_loss: 0.0178 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.2308 - main_output_accuracy: 0.6541 - main_output_loss: 1.6277 - tof_gate_loss: 0.0183 - val_loss: 1.8917 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3337 - val_tof_gate_loss: 0.0152 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 2.1945 - main_output_accuracy: 0.6542 - main_output_loss: 1.6467 - tof_gate_loss: 0.0160 - val_loss: 1.9285 - val_main_output_accuracy: 0.6716 - val_main_output_loss: 1.4194 - val_tof_gate_loss: 0.0133 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 2.1153 - main_output_accuracy: 0.6514 - main_output_loss: 1.6163 - tof_gate_loss: 0.0127 - val_loss: 1.9629 - val_main_output_accuracy: 0.6225 - val_main_output_loss: 1.4905 - val_tof_gate_loss: 0.0115 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 2.0955 - main_output_accuracy: 0.6678 - main_output_loss: 1.6309 - tof_gate_loss: 0.0122 - val_loss: 1.8741 - val_main_output_accuracy: 0.6471 - val_main_output_loss: 1.4394 - val_tof_gate_loss: 0.0102 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 2.1495 - main_output_accuracy: 0.6567 - main_output_loss: 1.7141 - tof_gate_loss: 0.0112 - val_loss: 1.7324 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3230 - val_tof_gate_loss: 0.0090 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.9896 - main_output_accuracy: 0.6923 - main_output_loss: 1.5997 - tof_gate_loss: 0.0092 - val_loss: 1.8051 - val_main_output_accuracy: 0.6801 - val_main_output_loss: 1.4230 - val_tof_gate_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.9598 - main_output_accuracy: 0.6772 - main_output_loss: 1.5846 - tof_gate_loss: 0.0083 - val_loss: 1.7178 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3543 - val_tof_gate_loss: 0.0070 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.9042 - main_output_accuracy: 0.7051 - main_output_loss: 1.5378 - tof_gate_loss: 0.0074 - val_loss: 1.7672 - val_main_output_accuracy: 0.6446 - val_main_output_loss: 1.4184 - val_tof_gate_loss: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.8779 - main_output_accuracy: 0.6985 - main_output_loss: 1.5335 - tof_gate_loss: 0.0067 - val_loss: 1.8724 - val_main_output_accuracy: 0.6250 - val_main_output_loss: 1.5388 - val_tof_gate_loss: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.8206 - main_output_accuracy: 0.7166 - main_output_loss: 1.4954 - tof_gate_loss: 0.0059 - val_loss: 1.8176 - val_main_output_accuracy: 0.6311 - val_main_output_loss: 1.4992 - val_tof_gate_loss: 0.0051 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.0174 - main_output_accuracy: 0.6681 - main_output_loss: 1.7018 - tof_gate_loss: 0.0060 - val_loss: 1.8312 - val_main_output_accuracy: 0.6262 - val_main_output_loss: 1.5209 - val_tof_gate_loss: 0.0045 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.9039 - main_output_accuracy: 0.6898 - main_output_loss: 1.5993 - tof_gate_loss: 0.0050 - val_loss: 1.7771 - val_main_output_accuracy: 0.6397 - val_main_output_loss: 1.4748 - val_tof_gate_loss: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.9195 - main_output_accuracy: 0.6923 - main_output_loss: 1.6254 - tof_gate_loss: 0.0047\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.9195 - main_output_accuracy: 0.6922 - main_output_loss: 1.6254 - tof_gate_loss: 0.0047 - val_loss: 1.7354 - val_main_output_accuracy: 0.6740 - val_main_output_loss: 1.4450 - val_tof_gate_loss: 0.0037 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.9479 - main_output_accuracy: 0.6810 - main_output_loss: 1.6567 - tof_gate_loss: 0.0044 - val_loss: 1.5403 - val_main_output_accuracy: 0.7230 - val_main_output_loss: 1.2629 - val_tof_gate_loss: 0.0035 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.8361 - main_output_accuracy: 0.7361 - main_output_loss: 1.5589 - tof_gate_loss: 0.0037 - val_loss: 1.5442 - val_main_output_accuracy: 0.7206 - val_main_output_loss: 1.2767 - val_tof_gate_loss: 0.0033 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.7330 - main_output_accuracy: 0.7639 - main_output_loss: 1.4652 - tof_gate_loss: 0.0033 - val_loss: 1.5825 - val_main_output_accuracy: 0.6936 - val_main_output_loss: 1.3227 - val_tof_gate_loss: 0.0032 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.7780 - main_output_accuracy: 0.7531 - main_output_loss: 1.5203 - tof_gate_loss: 0.0035 - val_loss: 1.5200 - val_main_output_accuracy: 0.7206 - val_main_output_loss: 1.2652 - val_tof_gate_loss: 0.0030 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.6183 - main_output_accuracy: 0.7747 - main_output_loss: 1.3723 - tof_gate_loss: 0.0030 - val_loss: 1.6542 - val_main_output_accuracy: 0.6593 - val_main_output_loss: 1.4065 - val_tof_gate_loss: 0.0029 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.7268 - main_output_accuracy: 0.7644 - main_output_loss: 1.4802 - tof_gate_loss: 0.0032 - val_loss: 1.5121 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.2687 - val_tof_gate_loss: 0.0027 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.6420 - main_output_accuracy: 0.7674 - main_output_loss: 1.4049 - tof_gate_loss: 0.0028 - val_loss: 1.5319 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.2961 - val_tof_gate_loss: 0.0026 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.7418 - main_output_accuracy: 0.7542 - main_output_loss: 1.5048 - tof_gate_loss: 0.0029 - val_loss: 1.5087 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2745 - val_tof_gate_loss: 0.0024 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.7351 - main_output_accuracy: 0.7559 - main_output_loss: 1.5005 - tof_gate_loss: 0.0026 - val_loss: 1.5168 - val_main_output_accuracy: 0.7267 - val_main_output_loss: 1.2897 - val_tof_gate_loss: 0.0023 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.6054 - main_output_accuracy: 0.7639 - main_output_loss: 1.3740 - tof_gate_loss: 0.0025 - val_loss: 1.4610 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.2334 - val_tof_gate_loss: 0.0022 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.7090 - main_output_accuracy: 0.7614 - main_output_loss: 1.4834 - tof_gate_loss: 0.0026 - val_loss: 1.5277 - val_main_output_accuracy: 0.7206 - val_main_output_loss: 1.2979 - val_tof_gate_loss: 0.0021 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.7615 - main_output_accuracy: 0.7360 - main_output_loss: 1.5360 - tof_gate_loss: 0.0026 - val_loss: 1.7141 - val_main_output_accuracy: 0.6360 - val_main_output_loss: 1.4907 - val_tof_gate_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.6490 - main_output_accuracy: 0.7700 - main_output_loss: 1.4287 - tof_gate_loss: 0.0019 - val_loss: 1.5057 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2867 - val_tof_gate_loss: 0.0018 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.6764 - main_output_accuracy: 0.7740 - main_output_loss: 1.4540 - tof_gate_loss: 0.0020 - val_loss: 1.5396 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.3218 - val_tof_gate_loss: 0.0017 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5682 - main_output_accuracy: 0.8030 - main_output_loss: 1.3522 - tof_gate_loss: 0.0018 - val_loss: 1.5524 - val_main_output_accuracy: 0.7206 - val_main_output_loss: 1.3336 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.7290 - main_output_accuracy: 0.7488 - main_output_loss: 1.5149 - tof_gate_loss: 0.0019 - val_loss: 1.5113 - val_main_output_accuracy: 0.7304 - val_main_output_loss: 1.2968 - val_tof_gate_loss: 0.0015 - learning_rate: 2.5000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6706 - main_output_accuracy: 0.7648 - main_output_loss: 1.4598 - tof_gate_loss: 0.0017 - val_loss: 1.5563 - val_main_output_accuracy: 0.7255 - val_main_output_loss: 1.3443 - val_tof_gate_loss: 0.0014 - learning_rate: 2.5000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.5742 - main_output_accuracy: 0.7928 - main_output_loss: 1.3634 - tof_gate_loss: 0.0016\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5746 - main_output_accuracy: 0.7927 - main_output_loss: 1.3638 - tof_gate_loss: 0.0016 - val_loss: 1.5853 - val_main_output_accuracy: 0.7047 - val_main_output_loss: 1.3740 - val_tof_gate_loss: 0.0014 - learning_rate: 2.5000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.5534 - main_output_accuracy: 0.8053 - main_output_loss: 1.3445 - tof_gate_loss: 0.0014 - val_loss: 1.4215 - val_main_output_accuracy: 0.7512 - val_main_output_loss: 1.2142 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5215 - main_output_accuracy: 0.8231 - main_output_loss: 1.3166 - tof_gate_loss: 0.0014 - val_loss: 1.4402 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2397 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4823 - main_output_accuracy: 0.8212 - main_output_loss: 1.2772 - tof_gate_loss: 0.0013 - val_loss: 1.4040 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.2041 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.6298 - main_output_accuracy: 0.7907 - main_output_loss: 1.4304 - tof_gate_loss: 0.0015 - val_loss: 1.4103 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.2140 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5908 - main_output_accuracy: 0.8173 - main_output_loss: 1.3927 - tof_gate_loss: 0.0013 - val_loss: 1.4572 - val_main_output_accuracy: 0.7304 - val_main_output_loss: 1.2649 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.5368 - main_output_accuracy: 0.8177 - main_output_loss: 1.3408 - tof_gate_loss: 0.0012 - val_loss: 1.4555 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2605 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6061 - main_output_accuracy: 0.8167 - main_output_loss: 1.4109 - tof_gate_loss: 0.0013 - val_loss: 1.5098 - val_main_output_accuracy: 0.7230 - val_main_output_loss: 1.3180 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.5178 - main_output_accuracy: 0.8255 - main_output_loss: 1.3287 - tof_gate_loss: 0.0011 - val_loss: 1.4270 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.2358 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5063 - main_output_accuracy: 0.8094 - main_output_loss: 1.3169 - tof_gate_loss: 0.0011 - val_loss: 1.4232 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.2397 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5463 - main_output_accuracy: 0.8081 - main_output_loss: 1.3575 - tof_gate_loss: 0.0011 - val_loss: 1.4064 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.2187 - val_tof_gate_loss: 9.7312e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.5655 - main_output_accuracy: 0.8124 - main_output_loss: 1.3785 - tof_gate_loss: 0.0011 - val_loss: 1.4041 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.2182 - val_tof_gate_loss: 9.2736e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5651 - main_output_accuracy: 0.8005 - main_output_loss: 1.3797 - tof_gate_loss: 0.0011 - val_loss: 1.4904 - val_main_output_accuracy: 0.7279 - val_main_output_loss: 1.3049 - val_tof_gate_loss: 8.9874e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.6056 - main_output_accuracy: 0.8001 - main_output_loss: 1.4223 - tof_gate_loss: 9.9217e-04 - val_loss: 1.4945 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.3156 - val_tof_gate_loss: 8.6553e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4877 - main_output_accuracy: 0.8392 - main_output_loss: 1.2981 - tof_gate_loss: 9.3287e-04 - val_loss: 1.5088 - val_main_output_accuracy: 0.7328 - val_main_output_loss: 1.3259 - val_tof_gate_loss: 8.2353e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3947 - main_output_accuracy: 0.8498 - main_output_loss: 1.2130 - tof_gate_loss: 8.4416e-04 - val_loss: 1.4614 - val_main_output_accuracy: 0.7414 - val_main_output_loss: 1.2825 - val_tof_gate_loss: 8.0013e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4514 - main_output_accuracy: 0.8393 - main_output_loss: 1.2705 - tof_gate_loss: 8.5180e-04 - val_loss: 1.4193 - val_main_output_accuracy: 0.7451 - val_main_output_loss: 1.2444 - val_tof_gate_loss: 7.5798e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4727 - main_output_accuracy: 0.8449 - main_output_loss: 1.2871 - tof_gate_loss: 8.2993e-04 - val_loss: 1.4033 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.2247 - val_tof_gate_loss: 7.2402e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4582 - main_output_accuracy: 0.8102 - main_output_loss: 1.2802 - tof_gate_loss: 7.6119e-04 - val_loss: 1.4793 - val_main_output_accuracy: 0.7328 - val_main_output_loss: 1.3031 - val_tof_gate_loss: 7.0011e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.5234 - main_output_accuracy: 0.8131 - main_output_loss: 1.3461 - tof_gate_loss: 7.6605e-04\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5231 - main_output_accuracy: 0.8132 - main_output_loss: 1.3458 - tof_gate_loss: 7.6594e-04 - val_loss: 1.4613 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2866 - val_tof_gate_loss: 6.6348e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5153 - main_output_accuracy: 0.8353 - main_output_loss: 1.3385 - tof_gate_loss: 7.4786e-04 - val_loss: 1.3625 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1873 - val_tof_gate_loss: 6.5378e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 112ms/step - loss: 1.3403 - main_output_accuracy: 0.8803 - main_output_loss: 1.1655 - tof_gate_loss: 6.5268e-04 - val_loss: 1.3492 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1775 - val_tof_gate_loss: 6.3774e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3978 - main_output_accuracy: 0.8575 - main_output_loss: 1.2233 - tof_gate_loss: 6.5106e-04 - val_loss: 1.3663 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1947 - val_tof_gate_loss: 6.2010e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4892 - main_output_accuracy: 0.8236 - main_output_loss: 1.3157 - tof_gate_loss: 6.7168e-04 - val_loss: 1.3880 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.2162 - val_tof_gate_loss: 6.0907e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3687 - main_output_accuracy: 0.8562 - main_output_loss: 1.1973 - tof_gate_loss: 5.9822e-04 - val_loss: 1.3680 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1993 - val_tof_gate_loss: 5.9581e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5800 - main_output_accuracy: 0.8155 - main_output_loss: 1.4004 - tof_gate_loss: 7.0387e-04 - val_loss: 1.3743 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.2041 - val_tof_gate_loss: 5.8419e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3617 - main_output_accuracy: 0.8624 - main_output_loss: 1.1926 - tof_gate_loss: 5.8863e-04 - val_loss: 1.3899 - val_main_output_accuracy: 0.7475 - val_main_output_loss: 1.2175 - val_tof_gate_loss: 5.6777e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.4027 - main_output_accuracy: 0.8619 - main_output_loss: 1.2335 - tof_gate_loss: 5.8962e-04 - val_loss: 1.3889 - val_main_output_accuracy: 0.7537 - val_main_output_loss: 1.2187 - val_tof_gate_loss: 5.4582e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.3667 - main_output_accuracy: 0.8721 - main_output_loss: 1.1967 - tof_gate_loss: 5.8286e-04\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.3679 - main_output_accuracy: 0.8718 - main_output_loss: 1.1978 - tof_gate_loss: 5.8305e-04 - val_loss: 1.3962 - val_main_output_accuracy: 0.7574 - val_main_output_loss: 1.2321 - val_tof_gate_loss: 5.2973e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.5028 - main_output_accuracy: 0.8402 - main_output_loss: 1.3344 - tof_gate_loss: 6.4564e-04 - val_loss: 1.3610 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1972 - val_tof_gate_loss: 5.2180e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.4363 - main_output_accuracy: 0.8554 - main_output_loss: 1.2683 - tof_gate_loss: 5.8649e-04 - val_loss: 1.3194 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1516 - val_tof_gate_loss: 5.1387e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.5043 - main_output_accuracy: 0.8168 - main_output_loss: 1.3410 - tof_gate_loss: 5.9884e-04 - val_loss: 1.3600 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.1918 - val_tof_gate_loss: 5.1195e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.5376 - main_output_accuracy: 0.8527 - main_output_loss: 1.3719 - tof_gate_loss: 6.7178e-04 - val_loss: 1.3463 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.1839 - val_tof_gate_loss: 5.0301e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.4790 - main_output_accuracy: 0.8450 - main_output_loss: 1.3130 - tof_gate_loss: 5.6823e-04 - val_loss: 1.3620 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.1983 - val_tof_gate_loss: 4.9577e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.5814 - main_output_accuracy: 0.8093 - main_output_loss: 1.4170 - tof_gate_loss: 6.2046e-04 - val_loss: 1.3558 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1953 - val_tof_gate_loss: 4.8728e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.4437 - main_output_accuracy: 0.8288 - main_output_loss: 1.2816 - tof_gate_loss: 5.6016e-04 - val_loss: 1.3706 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.2054 - val_tof_gate_loss: 4.7514e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.4712 - main_output_accuracy: 0.8607 - main_output_loss: 1.3086 - tof_gate_loss: 5.0325e-04 - val_loss: 1.3684 - val_main_output_accuracy: 0.7598 - val_main_output_loss: 1.2070 - val_tof_gate_loss: 4.6531e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.4716 - main_output_accuracy: 0.8534 - main_output_loss: 1.3076 - tof_gate_loss: 5.4394e-04\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4711 - main_output_accuracy: 0.8535 - main_output_loss: 1.3070 - tof_gate_loss: 5.4369e-04 - val_loss: 1.3604 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.1969 - val_tof_gate_loss: 4.5747e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.4290 - main_output_accuracy: 0.8519 - main_output_loss: 1.2662 - tof_gate_loss: 5.3476e-04 - val_loss: 1.3508 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1889 - val_tof_gate_loss: 4.5591e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4206 - main_output_accuracy: 0.8538 - main_output_loss: 1.2585 - tof_gate_loss: 4.7473e-04 - val_loss: 1.3457 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1872 - val_tof_gate_loss: 4.5162e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.4431 - main_output_accuracy: 0.8554 - main_output_loss: 1.2864 - tof_gate_loss: 4.8270e-04 - val_loss: 1.3369 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1742 - val_tof_gate_loss: 4.4442e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4291 - main_output_accuracy: 0.8799 - main_output_loss: 1.2679 - tof_gate_loss: 4.6429e-04 - val_loss: 1.3468 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.1849 - val_tof_gate_loss: 4.3953e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4824 - main_output_accuracy: 0.8268 - main_output_loss: 1.3220 - tof_gate_loss: 4.9055e-04 - val_loss: 1.3421 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.1804 - val_tof_gate_loss: 4.4002e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4025 - main_output_accuracy: 0.8652 - main_output_loss: 1.2419 - tof_gate_loss: 4.7571e-04 - val_loss: 1.3390 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1782 - val_tof_gate_loss: 4.3085e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.4520 - main_output_accuracy: 0.8707 - main_output_loss: 1.2931 - tof_gate_loss: 4.4915e-04 - val_loss: 1.3398 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1820 - val_tof_gate_loss: 4.2455e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.3329 - main_output_accuracy: 0.8884 - main_output_loss: 1.1748 - tof_gate_loss: 4.6607e-04 - val_loss: 1.3302 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1688 - val_tof_gate_loss: 4.2510e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4696 - main_output_accuracy: 0.8544 - main_output_loss: 1.3076 - tof_gate_loss: 4.6966e-04 - val_loss: 1.3540 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1961 - val_tof_gate_loss: 4.1641e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.4003 - main_output_accuracy: 0.8822 - main_output_loss: 1.2413 - tof_gate_loss: 4.5180e-04 - val_loss: 1.3405 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1800 - val_tof_gate_loss: 4.1036e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.3779 - main_output_accuracy: 0.8734 - main_output_loss: 1.2167 - tof_gate_loss: 4.5671e-04 - val_loss: 1.3466 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1848 - val_tof_gate_loss: 4.0732e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 94/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.3335 - main_output_accuracy: 0.8982 - main_output_loss: 1.1852 - tof_gate_loss: 4.2543e-04 - val_loss: 1.3442 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1840 - val_tof_gate_loss: 3.9891e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 95/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4705 - main_output_accuracy: 0.8483 - main_output_loss: 1.3061 - tof_gate_loss: 4.5328e-04 - val_loss: 1.3448 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.1869 - val_tof_gate_loss: 3.9861e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 96/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.4407 - main_output_accuracy: 0.8663 - main_output_loss: 1.2820 - tof_gate_loss: 4.6591e-04 - val_loss: 1.3418 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1832 - val_tof_gate_loss: 3.8757e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 97/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 1.4716 - main_output_accuracy: 0.8499 - main_output_loss: 1.3122 - tof_gate_loss: 4.0746e-04\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4713 - main_output_accuracy: 0.8501 - main_output_loss: 1.3118 - tof_gate_loss: 4.0753e-04 - val_loss: 1.3445 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1816 - val_tof_gate_loss: 3.8560e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 98/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.4082 - main_output_accuracy: 0.8747 - main_output_loss: 1.2553 - tof_gate_loss: 4.4467e-04 - val_loss: 1.3287 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1718 - val_tof_gate_loss: 3.7917e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.4521 - main_output_accuracy: 0.8468 - main_output_loss: 1.2948 - tof_gate_loss: 4.2268e-04 - val_loss: 1.3296 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1691 - val_tof_gate_loss: 3.7677e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4348 - main_output_accuracy: 0.8553 - main_output_loss: 1.2758 - tof_gate_loss: 4.3795e-04 - val_loss: 1.3237 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1677 - val_tof_gate_loss: 3.7723e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.3708 - main_output_accuracy: 0.8958 - main_output_loss: 1.2125 - tof_gate_loss: 4.0955e-04 - val_loss: 1.3325 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1733 - val_tof_gate_loss: 3.7505e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3836 - main_output_accuracy: 0.8661 - main_output_loss: 1.2235 - tof_gate_loss: 4.0810e-04 - val_loss: 1.3388 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1809 - val_tof_gate_loss: 3.7095e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3969 - main_output_accuracy: 0.8773 - main_output_loss: 1.2386 - tof_gate_loss: 4.4068e-04 - val_loss: 1.3310 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1753 - val_tof_gate_loss: 3.6791e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.3013 - main_output_accuracy: 0.8952 - main_output_loss: 1.1456 - tof_gate_loss: 3.7227e-04 - val_loss: 1.3300 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1736 - val_tof_gate_loss: 3.6433e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3807 - main_output_accuracy: 0.8753 - main_output_loss: 1.2234 - tof_gate_loss: 4.0814e-04 - val_loss: 1.3293 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1708 - val_tof_gate_loss: 3.6161e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.3376 - main_output_accuracy: 0.9039 - main_output_loss: 1.1801 - tof_gate_loss: 3.8789e-04\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3376 - main_output_accuracy: 0.9037 - main_output_loss: 1.1801 - tof_gate_loss: 3.8786e-04 - val_loss: 1.3256 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1721 - val_tof_gate_loss: 3.5857e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3613 - main_output_accuracy: 0.8929 - main_output_loss: 1.2101 - tof_gate_loss: 3.5198e-04 - val_loss: 1.3265 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1646 - val_tof_gate_loss: 3.6024e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3397 - main_output_accuracy: 0.8996 - main_output_loss: 1.1832 - tof_gate_loss: 3.7511e-04 - val_loss: 1.3287 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1690 - val_tof_gate_loss: 3.5644e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.4207 - main_output_accuracy: 0.8788 - main_output_loss: 1.2629 - tof_gate_loss: 4.0406e-04 - val_loss: 1.3273 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1688 - val_tof_gate_loss: 3.5437e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4093 - main_output_accuracy: 0.8800 - main_output_loss: 1.2495 - tof_gate_loss: 4.1301e-04 - val_loss: 1.3286 - val_main_output_accuracy: 0.7598 - val_main_output_loss: 1.1729 - val_tof_gate_loss: 3.5738e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4604 - main_output_accuracy: 0.8470 - main_output_loss: 1.3036 - tof_gate_loss: 3.9348e-04 - val_loss: 1.3289 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1739 - val_tof_gate_loss: 3.5180e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3152 - main_output_accuracy: 0.8884 - main_output_loss: 1.1749 - tof_gate_loss: 3.9308e-04 - val_loss: 1.3222 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1631 - val_tof_gate_loss: 3.5516e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4189 - main_output_accuracy: 0.8621 - main_output_loss: 1.2620 - tof_gate_loss: 4.1079e-04 - val_loss: 1.3315 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1771 - val_tof_gate_loss: 3.5071e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4462 - main_output_accuracy: 0.8710 - main_output_loss: 1.2945 - tof_gate_loss: 4.0622e-04 - val_loss: 1.3281 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1665 - val_tof_gate_loss: 3.4648e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.4404 - main_output_accuracy: 0.8750 - main_output_loss: 1.2836 - tof_gate_loss: 3.8512e-04\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4404 - main_output_accuracy: 0.8750 - main_output_loss: 1.2837 - tof_gate_loss: 3.8523e-04 - val_loss: 1.3331 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1796 - val_tof_gate_loss: 3.4809e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3346 - main_output_accuracy: 0.8902 - main_output_loss: 1.1798 - tof_gate_loss: 3.6865e-04 - val_loss: 1.3222 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1664 - val_tof_gate_loss: 3.4762e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4415 - main_output_accuracy: 0.8609 - main_output_loss: 1.2828 - tof_gate_loss: 3.7632e-04 - val_loss: 1.3226 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1654 - val_tof_gate_loss: 3.4179e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.5129 - main_output_accuracy: 0.8644 - main_output_loss: 1.3564 - tof_gate_loss: 4.0189e-04 - val_loss: 1.3286 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1733 - val_tof_gate_loss: 3.4398e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.2894 - main_output_accuracy: 0.9033 - main_output_loss: 1.1328 - tof_gate_loss: 3.7271e-04 - val_loss: 1.3272 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1681 - val_tof_gate_loss: 3.3997e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4119 - main_output_accuracy: 0.8599 - main_output_loss: 1.2551 - tof_gate_loss: 3.7523e-04 - val_loss: 1.3220 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1647 - val_tof_gate_loss: 3.3844e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 121/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3775 - main_output_accuracy: 0.8711 - main_output_loss: 1.2218 - tof_gate_loss: 3.7248e-04 - val_loss: 1.3256 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1673 - val_tof_gate_loss: 3.3872e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 122/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3834 - main_output_accuracy: 0.8700 - main_output_loss: 1.2250 - tof_gate_loss: 3.7883e-04 - val_loss: 1.3302 - val_main_output_accuracy: 0.7684 - val_main_output_loss: 1.1751 - val_tof_gate_loss: 3.3780e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 123/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3054 - main_output_accuracy: 0.8978 - main_output_loss: 1.1502 - tof_gate_loss: 3.3243e-04 - val_loss: 1.3282 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1680 - val_tof_gate_loss: 3.3427e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 124/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.3678 - main_output_accuracy: 0.8744 - main_output_loss: 1.2113 - tof_gate_loss: 3.5993e-04 - val_loss: 1.3282 - val_main_output_accuracy: 0.7672 - val_main_output_loss: 1.1701 - val_tof_gate_loss: 3.3799e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 125/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3847 - main_output_accuracy: 0.8897 - main_output_loss: 1.2286 - tof_gate_loss: 3.7008e-04 - val_loss: 1.3257 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1647 - val_tof_gate_loss: 3.3586e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 126/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3985 - main_output_accuracy: 0.8836 - main_output_loss: 1.2434 - tof_gate_loss: 3.7688e-04 - val_loss: 1.3253 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1651 - val_tof_gate_loss: 3.3163e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 127/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3907 - main_output_accuracy: 0.8843 - main_output_loss: 1.2354 - tof_gate_loss: 3.6430e-04 - val_loss: 1.3215 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1650 - val_tof_gate_loss: 3.2930e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 128/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3304 - main_output_accuracy: 0.9002 - main_output_loss: 1.1747 - tof_gate_loss: 3.4087e-04 - val_loss: 1.3237 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1673 - val_tof_gate_loss: 3.3326e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 129/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4103 - main_output_accuracy: 0.8648 - main_output_loss: 1.2516 - tof_gate_loss: 3.6797e-04 - val_loss: 1.3241 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1662 - val_tof_gate_loss: 3.2777e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 129: early stopping\n",
      "Restoring model weights from the end of the best epoch: 89.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 11:59:49.434118: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step\n",
      "\n",
      "===== FOLD 7/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 111ms/step - loss: 10.5819 - main_output_accuracy: 0.1356 - main_output_loss: 2.9565 - tof_gate_loss: 1.1214 - val_loss: 8.0824 - val_main_output_accuracy: 0.4044 - val_main_output_loss: 2.4689 - val_tof_gate_loss: 0.8786 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 7.4450 - main_output_accuracy: 0.3661 - main_output_loss: 2.2631 - tof_gate_loss: 0.7989 - val_loss: 6.0875 - val_main_output_accuracy: 0.5355 - val_main_output_loss: 1.9181 - val_tof_gate_loss: 0.7138 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 6.0065 - main_output_accuracy: 0.4505 - main_output_loss: 2.0846 - tof_gate_loss: 0.6747 - val_loss: 5.0264 - val_main_output_accuracy: 0.5576 - val_main_output_loss: 1.7330 - val_tof_gate_loss: 0.6141 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 5.1158 - main_output_accuracy: 0.5088 - main_output_loss: 1.9863 - tof_gate_loss: 0.5992 - val_loss: 4.3251 - val_main_output_accuracy: 0.5453 - val_main_output_loss: 1.6421 - val_tof_gate_loss: 0.5322 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 4.4558 - main_output_accuracy: 0.5325 - main_output_loss: 1.9012 - tof_gate_loss: 0.5074 - val_loss: 3.7866 - val_main_output_accuracy: 0.5772 - val_main_output_loss: 1.5753 - val_tof_gate_loss: 0.4435 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 3.9564 - main_output_accuracy: 0.5609 - main_output_loss: 1.8464 - tof_gate_loss: 0.4064 - val_loss: 3.3394 - val_main_output_accuracy: 0.6152 - val_main_output_loss: 1.4965 - val_tof_gate_loss: 0.3497 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 3.5929 - main_output_accuracy: 0.5733 - main_output_loss: 1.8298 - tof_gate_loss: 0.3193 - val_loss: 3.0886 - val_main_output_accuracy: 0.6238 - val_main_output_loss: 1.5401 - val_tof_gate_loss: 0.2515 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 3.3207 - main_output_accuracy: 0.5810 - main_output_loss: 1.8339 - tof_gate_loss: 0.2287 - val_loss: 2.8799 - val_main_output_accuracy: 0.6054 - val_main_output_loss: 1.5756 - val_tof_gate_loss: 0.1716 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 3.1026 - main_output_accuracy: 0.5871 - main_output_loss: 1.8396 - tof_gate_loss: 0.1620 - val_loss: 2.6770 - val_main_output_accuracy: 0.6054 - val_main_output_loss: 1.5481 - val_tof_gate_loss: 0.1181 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 2.7782 - main_output_accuracy: 0.6063 - main_output_loss: 1.6917 - tof_gate_loss: 0.1101 - val_loss: 2.4947 - val_main_output_accuracy: 0.6201 - val_main_output_loss: 1.5159 - val_tof_gate_loss: 0.0844 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.5763 - main_output_accuracy: 0.6394 - main_output_loss: 1.6349 - tof_gate_loss: 0.0803 - val_loss: 2.4417 - val_main_output_accuracy: 0.5993 - val_main_output_loss: 1.5872 - val_tof_gate_loss: 0.0634 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 2.5551 - main_output_accuracy: 0.6297 - main_output_loss: 1.7368 - tof_gate_loss: 0.0634 - val_loss: 2.1398 - val_main_output_accuracy: 0.6752 - val_main_output_loss: 1.3913 - val_tof_gate_loss: 0.0485 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 2.4250 - main_output_accuracy: 0.6282 - main_output_loss: 1.6957 - tof_gate_loss: 0.0500 - val_loss: 2.2046 - val_main_output_accuracy: 0.5956 - val_main_output_loss: 1.5401 - val_tof_gate_loss: 0.0392 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 2.2924 - main_output_accuracy: 0.6496 - main_output_loss: 1.6411 - tof_gate_loss: 0.0395 - val_loss: 2.1307 - val_main_output_accuracy: 0.5993 - val_main_output_loss: 1.5306 - val_tof_gate_loss: 0.0323 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 2.2969 - main_output_accuracy: 0.6413 - main_output_loss: 1.7077 - tof_gate_loss: 0.0344 - val_loss: 1.9762 - val_main_output_accuracy: 0.6507 - val_main_output_loss: 1.4301 - val_tof_gate_loss: 0.0266 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.1523 - main_output_accuracy: 0.6589 - main_output_loss: 1.6212 - tof_gate_loss: 0.0260 - val_loss: 2.0198 - val_main_output_accuracy: 0.6581 - val_main_output_loss: 1.5194 - val_tof_gate_loss: 0.0225 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.1562 - main_output_accuracy: 0.6572 - main_output_loss: 1.6648 - tof_gate_loss: 0.0234 - val_loss: 1.9229 - val_main_output_accuracy: 0.6630 - val_main_output_loss: 1.4621 - val_tof_gate_loss: 0.0191 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.0722 - main_output_accuracy: 0.6625 - main_output_loss: 1.6246 - tof_gate_loss: 0.0192 - val_loss: 1.9705 - val_main_output_accuracy: 0.5919 - val_main_output_loss: 1.5462 - val_tof_gate_loss: 0.0165 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 2.1205 - main_output_accuracy: 0.6462 - main_output_loss: 1.6995 - tof_gate_loss: 0.0173 - val_loss: 1.9073 - val_main_output_accuracy: 0.6471 - val_main_output_loss: 1.5084 - val_tof_gate_loss: 0.0142 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 2.1185 - main_output_accuracy: 0.6505 - main_output_loss: 1.7209 - tof_gate_loss: 0.0150\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.1179 - main_output_accuracy: 0.6506 - main_output_loss: 1.7204 - tof_gate_loss: 0.0150 - val_loss: 1.8749 - val_main_output_accuracy: 0.6483 - val_main_output_loss: 1.5009 - val_tof_gate_loss: 0.0123 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.0122 - main_output_accuracy: 0.6690 - main_output_loss: 1.6419 - tof_gate_loss: 0.0135 - val_loss: 1.7579 - val_main_output_accuracy: 0.6801 - val_main_output_loss: 1.4014 - val_tof_gate_loss: 0.0115 - learning_rate: 2.5000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.8713 - main_output_accuracy: 0.7079 - main_output_loss: 1.5204 - tof_gate_loss: 0.0116 - val_loss: 1.6928 - val_main_output_accuracy: 0.6801 - val_main_output_loss: 1.3549 - val_tof_gate_loss: 0.0108 - learning_rate: 2.5000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.9606 - main_output_accuracy: 0.6936 - main_output_loss: 1.6227 - tof_gate_loss: 0.0119 - val_loss: 1.7109 - val_main_output_accuracy: 0.6642 - val_main_output_loss: 1.3830 - val_tof_gate_loss: 0.0101 - learning_rate: 2.5000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.8241 - main_output_accuracy: 0.7144 - main_output_loss: 1.4893 - tof_gate_loss: 0.0099 - val_loss: 1.6812 - val_main_output_accuracy: 0.6900 - val_main_output_loss: 1.3629 - val_tof_gate_loss: 0.0095 - learning_rate: 2.5000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.8049 - main_output_accuracy: 0.7471 - main_output_loss: 1.4926 - tof_gate_loss: 0.0096 - val_loss: 1.7114 - val_main_output_accuracy: 0.6642 - val_main_output_loss: 1.4061 - val_tof_gate_loss: 0.0088 - learning_rate: 2.5000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.8772 - main_output_accuracy: 0.7268 - main_output_loss: 1.5724 - tof_gate_loss: 0.0094 - val_loss: 1.6608 - val_main_output_accuracy: 0.6716 - val_main_output_loss: 1.3642 - val_tof_gate_loss: 0.0082 - learning_rate: 2.5000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.8256 - main_output_accuracy: 0.7343 - main_output_loss: 1.5256 - tof_gate_loss: 0.0088 - val_loss: 1.7084 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.4152 - val_tof_gate_loss: 0.0077 - learning_rate: 2.5000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.7205 - main_output_accuracy: 0.7514 - main_output_loss: 1.4313 - tof_gate_loss: 0.0079 - val_loss: 1.6126 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3280 - val_tof_gate_loss: 0.0071 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.7682 - main_output_accuracy: 0.7152 - main_output_loss: 1.4865 - tof_gate_loss: 0.0073 - val_loss: 1.8115 - val_main_output_accuracy: 0.6409 - val_main_output_loss: 1.5364 - val_tof_gate_loss: 0.0067 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.8131 - main_output_accuracy: 0.7320 - main_output_loss: 1.5347 - tof_gate_loss: 0.0072 - val_loss: 1.6614 - val_main_output_accuracy: 0.6667 - val_main_output_loss: 1.3916 - val_tof_gate_loss: 0.0062 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.7537 - main_output_accuracy: 0.7298 - main_output_loss: 1.4829 - tof_gate_loss: 0.0063 - val_loss: 1.6767 - val_main_output_accuracy: 0.6728 - val_main_output_loss: 1.4091 - val_tof_gate_loss: 0.0058 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.8035 - main_output_accuracy: 0.7500 - main_output_loss: 1.5391 - tof_gate_loss: 0.0061 - val_loss: 1.5944 - val_main_output_accuracy: 0.6912 - val_main_output_loss: 1.3367 - val_tof_gate_loss: 0.0054 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.8155 - main_output_accuracy: 0.7345 - main_output_loss: 1.5514 - tof_gate_loss: 0.0058 - val_loss: 1.6880 - val_main_output_accuracy: 0.6667 - val_main_output_loss: 1.4326 - val_tof_gate_loss: 0.0051 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.6811 - main_output_accuracy: 0.7686 - main_output_loss: 1.4260 - tof_gate_loss: 0.0050 - val_loss: 1.6801 - val_main_output_accuracy: 0.6703 - val_main_output_loss: 1.4289 - val_tof_gate_loss: 0.0048 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6853 - main_output_accuracy: 0.7543 - main_output_loss: 1.4359 - tof_gate_loss: 0.0049 - val_loss: 1.6226 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3713 - val_tof_gate_loss: 0.0045 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.7016 - main_output_accuracy: 0.7659 - main_output_loss: 1.4548 - tof_gate_loss: 0.0045\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.7017 - main_output_accuracy: 0.7658 - main_output_loss: 1.4549 - tof_gate_loss: 0.0045 - val_loss: 1.6168 - val_main_output_accuracy: 0.6826 - val_main_output_loss: 1.3719 - val_tof_gate_loss: 0.0042 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.6314 - main_output_accuracy: 0.7954 - main_output_loss: 1.3878 - tof_gate_loss: 0.0040 - val_loss: 1.5049 - val_main_output_accuracy: 0.7279 - val_main_output_loss: 1.2646 - val_tof_gate_loss: 0.0041 - learning_rate: 1.2500e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.5598 - main_output_accuracy: 0.8034 - main_output_loss: 1.3213 - tof_gate_loss: 0.0039 - val_loss: 1.5602 - val_main_output_accuracy: 0.7181 - val_main_output_loss: 1.3248 - val_tof_gate_loss: 0.0039 - learning_rate: 1.2500e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6697 - main_output_accuracy: 0.7788 - main_output_loss: 1.4377 - tof_gate_loss: 0.0040 - val_loss: 1.5208 - val_main_output_accuracy: 0.7230 - val_main_output_loss: 1.2882 - val_tof_gate_loss: 0.0038 - learning_rate: 1.2500e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.6542 - main_output_accuracy: 0.7888 - main_output_loss: 1.4210 - tof_gate_loss: 0.0037 - val_loss: 1.5397 - val_main_output_accuracy: 0.7022 - val_main_output_loss: 1.3092 - val_tof_gate_loss: 0.0036 - learning_rate: 1.2500e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.7848 - main_output_accuracy: 0.7589 - main_output_loss: 1.5568 - tof_gate_loss: 0.0041 - val_loss: 1.4888 - val_main_output_accuracy: 0.7279 - val_main_output_loss: 1.2636 - val_tof_gate_loss: 0.0035 - learning_rate: 1.2500e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.7173 - main_output_accuracy: 0.7745 - main_output_loss: 1.4889 - tof_gate_loss: 0.0036 - val_loss: 1.5394 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.3200 - val_tof_gate_loss: 0.0034 - learning_rate: 1.2500e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6038 - main_output_accuracy: 0.7941 - main_output_loss: 1.3815 - tof_gate_loss: 0.0035 - val_loss: 1.5076 - val_main_output_accuracy: 0.7304 - val_main_output_loss: 1.2875 - val_tof_gate_loss: 0.0032 - learning_rate: 1.2500e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5885 - main_output_accuracy: 0.8043 - main_output_loss: 1.3694 - tof_gate_loss: 0.0031 - val_loss: 1.5455 - val_main_output_accuracy: 0.7120 - val_main_output_loss: 1.3292 - val_tof_gate_loss: 0.0031 - learning_rate: 1.2500e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.6121 - main_output_accuracy: 0.7924 - main_output_loss: 1.3874 - tof_gate_loss: 0.0032 - val_loss: 1.4830 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2697 - val_tof_gate_loss: 0.0030 - learning_rate: 1.2500e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6742 - main_output_accuracy: 0.7733 - main_output_loss: 1.4677 - tof_gate_loss: 0.0032 - val_loss: 1.5206 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3030 - val_tof_gate_loss: 0.0029 - learning_rate: 1.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5927 - main_output_accuracy: 0.8094 - main_output_loss: 1.3779 - tof_gate_loss: 0.0030 - val_loss: 1.5354 - val_main_output_accuracy: 0.7279 - val_main_output_loss: 1.3274 - val_tof_gate_loss: 0.0028 - learning_rate: 1.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.5859 - main_output_accuracy: 0.7991 - main_output_loss: 1.3753 - tof_gate_loss: 0.0028 - val_loss: 1.5939 - val_main_output_accuracy: 0.6949 - val_main_output_loss: 1.3819 - val_tof_gate_loss: 0.0026 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5334 - main_output_accuracy: 0.8289 - main_output_loss: 1.3249 - tof_gate_loss: 0.0024 - val_loss: 1.5139 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.3019 - val_tof_gate_loss: 0.0025 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4973 - main_output_accuracy: 0.8331 - main_output_loss: 1.2874 - tof_gate_loss: 0.0024 - val_loss: 1.5431 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.3361 - val_tof_gate_loss: 0.0024 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5961 - main_output_accuracy: 0.7898 - main_output_loss: 1.3942 - tof_gate_loss: 0.0025 - val_loss: 1.5494 - val_main_output_accuracy: 0.6998 - val_main_output_loss: 1.3447 - val_tof_gate_loss: 0.0023 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4688 - main_output_accuracy: 0.8358 - main_output_loss: 1.2621 - tof_gate_loss: 0.0022 - val_loss: 1.5218 - val_main_output_accuracy: 0.7243 - val_main_output_loss: 1.3199 - val_tof_gate_loss: 0.0022 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.5077 - main_output_accuracy: 0.8344 - main_output_loss: 1.3087 - tof_gate_loss: 0.0022\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5081 - main_output_accuracy: 0.8343 - main_output_loss: 1.3092 - tof_gate_loss: 0.0022 - val_loss: 1.4990 - val_main_output_accuracy: 0.7255 - val_main_output_loss: 1.2981 - val_tof_gate_loss: 0.0021 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6158 - main_output_accuracy: 0.8107 - main_output_loss: 1.4146 - tof_gate_loss: 0.0022 - val_loss: 1.4949 - val_main_output_accuracy: 0.7108 - val_main_output_loss: 1.2981 - val_tof_gate_loss: 0.0021 - learning_rate: 6.2500e-05\n",
      "Epoch 55/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5634 - main_output_accuracy: 0.8299 - main_output_loss: 1.3626 - tof_gate_loss: 0.0022 - val_loss: 1.4637 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2647 - val_tof_gate_loss: 0.0020 - learning_rate: 6.2500e-05\n",
      "Epoch 56/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4747 - main_output_accuracy: 0.8406 - main_output_loss: 1.2779 - tof_gate_loss: 0.0020 - val_loss: 1.4667 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2679 - val_tof_gate_loss: 0.0020 - learning_rate: 6.2500e-05\n",
      "Epoch 57/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.5460 - main_output_accuracy: 0.8273 - main_output_loss: 1.3542 - tof_gate_loss: 0.0021 - val_loss: 1.5121 - val_main_output_accuracy: 0.7157 - val_main_output_loss: 1.3162 - val_tof_gate_loss: 0.0019 - learning_rate: 6.2500e-05\n",
      "Epoch 58/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4210 - main_output_accuracy: 0.8642 - main_output_loss: 1.2286 - tof_gate_loss: 0.0019 - val_loss: 1.4616 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.2652 - val_tof_gate_loss: 0.0019 - learning_rate: 6.2500e-05\n",
      "Epoch 59/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4067 - main_output_accuracy: 0.8590 - main_output_loss: 1.2103 - tof_gate_loss: 0.0018 - val_loss: 1.4759 - val_main_output_accuracy: 0.7279 - val_main_output_loss: 1.2819 - val_tof_gate_loss: 0.0018 - learning_rate: 6.2500e-05\n",
      "Epoch 60/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.5892 - main_output_accuracy: 0.8091 - main_output_loss: 1.3924 - tof_gate_loss: 0.0020 - val_loss: 1.4711 - val_main_output_accuracy: 0.7292 - val_main_output_loss: 1.2792 - val_tof_gate_loss: 0.0018 - learning_rate: 6.2500e-05\n",
      "Epoch 61/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4371 - main_output_accuracy: 0.8514 - main_output_loss: 1.2423 - tof_gate_loss: 0.0017 - val_loss: 1.4927 - val_main_output_accuracy: 0.7157 - val_main_output_loss: 1.3068 - val_tof_gate_loss: 0.0018 - learning_rate: 6.2500e-05\n",
      "Epoch 62/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3604 - main_output_accuracy: 0.8668 - main_output_loss: 1.1694 - tof_gate_loss: 0.0016 - val_loss: 1.4573 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2660 - val_tof_gate_loss: 0.0017 - learning_rate: 6.2500e-05\n",
      "Epoch 63/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.5227 - main_output_accuracy: 0.8231 - main_output_loss: 1.3330 - tof_gate_loss: 0.0017\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5224 - main_output_accuracy: 0.8232 - main_output_loss: 1.3327 - tof_gate_loss: 0.0017 - val_loss: 1.4673 - val_main_output_accuracy: 0.7230 - val_main_output_loss: 1.2753 - val_tof_gate_loss: 0.0016 - learning_rate: 6.2500e-05\n",
      "Epoch 64/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4742 - main_output_accuracy: 0.8521 - main_output_loss: 1.2852 - tof_gate_loss: 0.0016 - val_loss: 1.4590 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2687 - val_tof_gate_loss: 0.0016 - learning_rate: 3.1250e-05\n",
      "Epoch 65/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4495 - main_output_accuracy: 0.8650 - main_output_loss: 1.2656 - tof_gate_loss: 0.0017 - val_loss: 1.4484 - val_main_output_accuracy: 0.7304 - val_main_output_loss: 1.2626 - val_tof_gate_loss: 0.0016 - learning_rate: 3.1250e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4458 - main_output_accuracy: 0.8479 - main_output_loss: 1.2568 - tof_gate_loss: 0.0015 - val_loss: 1.4389 - val_main_output_accuracy: 0.7255 - val_main_output_loss: 1.2526 - val_tof_gate_loss: 0.0016 - learning_rate: 3.1250e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4170 - main_output_accuracy: 0.8651 - main_output_loss: 1.2294 - tof_gate_loss: 0.0015 - val_loss: 1.4606 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2740 - val_tof_gate_loss: 0.0016 - learning_rate: 3.1250e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3409 - main_output_accuracy: 0.8843 - main_output_loss: 1.1570 - tof_gate_loss: 0.0014 - val_loss: 1.4253 - val_main_output_accuracy: 0.7463 - val_main_output_loss: 1.2382 - val_tof_gate_loss: 0.0015 - learning_rate: 3.1250e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4317 - main_output_accuracy: 0.8594 - main_output_loss: 1.2462 - tof_gate_loss: 0.0015 - val_loss: 1.4370 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2495 - val_tof_gate_loss: 0.0015 - learning_rate: 3.1250e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5039 - main_output_accuracy: 0.8346 - main_output_loss: 1.3128 - tof_gate_loss: 0.0016 - val_loss: 1.4464 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2611 - val_tof_gate_loss: 0.0015 - learning_rate: 3.1250e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4645 - main_output_accuracy: 0.8764 - main_output_loss: 1.2801 - tof_gate_loss: 0.0014 - val_loss: 1.4341 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2503 - val_tof_gate_loss: 0.0014 - learning_rate: 3.1250e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.4101 - main_output_accuracy: 0.8764 - main_output_loss: 1.2282 - tof_gate_loss: 0.0014 - val_loss: 1.4432 - val_main_output_accuracy: 0.7292 - val_main_output_loss: 1.2597 - val_tof_gate_loss: 0.0014 - learning_rate: 3.1250e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.4147 - main_output_accuracy: 0.8581 - main_output_loss: 1.2358 - tof_gate_loss: 0.0014 - val_loss: 1.4180 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2356 - val_tof_gate_loss: 0.0014 - learning_rate: 3.1250e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4954 - main_output_accuracy: 0.8347 - main_output_loss: 1.3149 - tof_gate_loss: 0.0014 - val_loss: 1.4468 - val_main_output_accuracy: 0.7292 - val_main_output_loss: 1.2611 - val_tof_gate_loss: 0.0014 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5712 - main_output_accuracy: 0.8168 - main_output_loss: 1.3898 - tof_gate_loss: 0.0015 - val_loss: 1.4257 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2467 - val_tof_gate_loss: 0.0013 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.5128 - main_output_accuracy: 0.8386 - main_output_loss: 1.3312 - tof_gate_loss: 0.0014\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5122 - main_output_accuracy: 0.8387 - main_output_loss: 1.3307 - tof_gate_loss: 0.0014 - val_loss: 1.4613 - val_main_output_accuracy: 0.7194 - val_main_output_loss: 1.2795 - val_tof_gate_loss: 0.0013 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.4860 - main_output_accuracy: 0.8459 - main_output_loss: 1.3054 - tof_gate_loss: 0.0013 - val_loss: 1.4247 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2432 - val_tof_gate_loss: 0.0013 - learning_rate: 1.5625e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4698 - main_output_accuracy: 0.8744 - main_output_loss: 1.2898 - tof_gate_loss: 0.0014 - val_loss: 1.4234 - val_main_output_accuracy: 0.7341 - val_main_output_loss: 1.2432 - val_tof_gate_loss: 0.0013 - learning_rate: 1.5625e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.3602 - main_output_accuracy: 0.8950 - main_output_loss: 1.1794 - tof_gate_loss: 0.0013 - val_loss: 1.4199 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2400 - val_tof_gate_loss: 0.0013 - learning_rate: 1.5625e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4929 - main_output_accuracy: 0.8429 - main_output_loss: 1.3097 - tof_gate_loss: 0.0013 - val_loss: 1.4106 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.2312 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4545 - main_output_accuracy: 0.8438 - main_output_loss: 1.2706 - tof_gate_loss: 0.0013 - val_loss: 1.4250 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2452 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4140 - main_output_accuracy: 0.8814 - main_output_loss: 1.2435 - tof_gate_loss: 0.0012 - val_loss: 1.4283 - val_main_output_accuracy: 0.7328 - val_main_output_loss: 1.2464 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4473 - main_output_accuracy: 0.8569 - main_output_loss: 1.2682 - tof_gate_loss: 0.0013 - val_loss: 1.4222 - val_main_output_accuracy: 0.7414 - val_main_output_loss: 1.2449 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4053 - main_output_accuracy: 0.8814 - main_output_loss: 1.2242 - tof_gate_loss: 0.0012 - val_loss: 1.4316 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2562 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3622 - main_output_accuracy: 0.8810 - main_output_loss: 1.1830 - tof_gate_loss: 0.0012 - val_loss: 1.4098 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2357 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.3784 - main_output_accuracy: 0.8817 - main_output_loss: 1.1983 - tof_gate_loss: 0.0012 - val_loss: 1.4112 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.2343 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4519 - main_output_accuracy: 0.8461 - main_output_loss: 1.2740 - tof_gate_loss: 0.0012 - val_loss: 1.4236 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2434 - val_tof_gate_loss: 0.0012 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.4703 - main_output_accuracy: 0.8462 - main_output_loss: 1.2910 - tof_gate_loss: 0.0012\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4706 - main_output_accuracy: 0.8461 - main_output_loss: 1.2913 - tof_gate_loss: 0.0012 - val_loss: 1.4191 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2423 - val_tof_gate_loss: 0.0011 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4353 - main_output_accuracy: 0.8534 - main_output_loss: 1.2582 - tof_gate_loss: 0.0011 - val_loss: 1.4254 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2498 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 90/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4014 - main_output_accuracy: 0.8690 - main_output_loss: 1.2231 - tof_gate_loss: 0.0011 - val_loss: 1.4186 - val_main_output_accuracy: 0.7426 - val_main_output_loss: 1.2438 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 91/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4133 - main_output_accuracy: 0.8626 - main_output_loss: 1.2346 - tof_gate_loss: 0.0012 - val_loss: 1.4183 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.2427 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 92/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.3911 - main_output_accuracy: 0.8767 - main_output_loss: 1.2144 - tof_gate_loss: 0.0011 - val_loss: 1.4229 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2419 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 93/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4673 - main_output_accuracy: 0.8501 - main_output_loss: 1.2903 - tof_gate_loss: 0.0012 - val_loss: 1.4124 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2340 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 94/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4091 - main_output_accuracy: 0.8711 - main_output_loss: 1.2325 - tof_gate_loss: 0.0011 - val_loss: 1.4163 - val_main_output_accuracy: 0.7414 - val_main_output_loss: 1.2409 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 95/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4703 - main_output_accuracy: 0.8526 - main_output_loss: 1.2921 - tof_gate_loss: 0.0012 - val_loss: 1.4242 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2497 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 96/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.3603 - main_output_accuracy: 0.8688 - main_output_loss: 1.1819 - tof_gate_loss: 0.0011 - val_loss: 1.4229 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2514 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 97/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 1.4790 - main_output_accuracy: 0.8509 - main_output_loss: 1.3026 - tof_gate_loss: 0.0012\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4792 - main_output_accuracy: 0.8508 - main_output_loss: 1.3028 - tof_gate_loss: 0.0012 - val_loss: 1.4320 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2504 - val_tof_gate_loss: 0.0011 - learning_rate: 7.8125e-06\n",
      "Epoch 98/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4746 - main_output_accuracy: 0.8607 - main_output_loss: 1.3014 - tof_gate_loss: 0.0011 - val_loss: 1.4312 - val_main_output_accuracy: 0.7292 - val_main_output_loss: 1.2520 - val_tof_gate_loss: 0.0011 - learning_rate: 3.9063e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4187 - main_output_accuracy: 0.8705 - main_output_loss: 1.2421 - tof_gate_loss: 0.0010 - val_loss: 1.4192 - val_main_output_accuracy: 0.7414 - val_main_output_loss: 1.2513 - val_tof_gate_loss: 0.0011 - learning_rate: 3.9063e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3432 - main_output_accuracy: 0.8899 - main_output_loss: 1.1669 - tof_gate_loss: 0.0011 - val_loss: 1.4173 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2386 - val_tof_gate_loss: 0.0010 - learning_rate: 3.9063e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3758 - main_output_accuracy: 0.8780 - main_output_loss: 1.2000 - tof_gate_loss: 9.8415e-04 - val_loss: 1.4213 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2443 - val_tof_gate_loss: 0.0010 - learning_rate: 3.9063e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5882 - main_output_accuracy: 0.8200 - main_output_loss: 1.4119 - tof_gate_loss: 0.0011 - val_loss: 1.4196 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.2453 - val_tof_gate_loss: 0.0010 - learning_rate: 3.9063e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4604 - main_output_accuracy: 0.8677 - main_output_loss: 1.2832 - tof_gate_loss: 0.0010 - val_loss: 1.4155 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2387 - val_tof_gate_loss: 0.0010 - learning_rate: 3.9063e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4788 - main_output_accuracy: 0.8455 - main_output_loss: 1.3040 - tof_gate_loss: 0.0011 - val_loss: 1.4183 - val_main_output_accuracy: 0.7328 - val_main_output_loss: 1.2415 - val_tof_gate_loss: 0.0010 - learning_rate: 3.9063e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4689 - main_output_accuracy: 0.8599 - main_output_loss: 1.2858 - tof_gate_loss: 0.0010 - val_loss: 1.4209 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2449 - val_tof_gate_loss: 0.0010 - learning_rate: 3.9063e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 1.4161 - main_output_accuracy: 0.8504 - main_output_loss: 1.2405 - tof_gate_loss: 0.0011\n",
      "Epoch 106: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.4162 - main_output_accuracy: 0.8505 - main_output_loss: 1.2406 - tof_gate_loss: 0.0011 - val_loss: 1.4259 - val_main_output_accuracy: 0.7426 - val_main_output_loss: 1.2526 - val_tof_gate_loss: 0.0010 - learning_rate: 3.9063e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3887 - main_output_accuracy: 0.8890 - main_output_loss: 1.2352 - tof_gate_loss: 0.0010 - val_loss: 1.4219 - val_main_output_accuracy: 0.7426 - val_main_output_loss: 1.2454 - val_tof_gate_loss: 0.0010 - learning_rate: 3.0000e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3892 - main_output_accuracy: 0.8897 - main_output_loss: 1.2141 - tof_gate_loss: 0.0010 - val_loss: 1.4248 - val_main_output_accuracy: 0.7475 - val_main_output_loss: 1.2500 - val_tof_gate_loss: 0.0010 - learning_rate: 3.0000e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.2928 - main_output_accuracy: 0.9033 - main_output_loss: 1.1158 - tof_gate_loss: 9.7057e-04 - val_loss: 1.4194 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2423 - val_tof_gate_loss: 0.0010 - learning_rate: 3.0000e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3825 - main_output_accuracy: 0.8775 - main_output_loss: 1.2071 - tof_gate_loss: 9.7449e-04 - val_loss: 1.4182 - val_main_output_accuracy: 0.7475 - val_main_output_loss: 1.2430 - val_tof_gate_loss: 0.0010 - learning_rate: 3.0000e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4308 - main_output_accuracy: 0.8639 - main_output_loss: 1.2530 - tof_gate_loss: 0.0010 - val_loss: 1.4243 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2533 - val_tof_gate_loss: 0.0010 - learning_rate: 3.0000e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3963 - main_output_accuracy: 0.8803 - main_output_loss: 1.2310 - tof_gate_loss: 0.0010 - val_loss: 1.4298 - val_main_output_accuracy: 0.7328 - val_main_output_loss: 1.2539 - val_tof_gate_loss: 0.0010 - learning_rate: 3.0000e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4572 - main_output_accuracy: 0.8631 - main_output_loss: 1.2839 - tof_gate_loss: 0.0010 - val_loss: 1.4199 - val_main_output_accuracy: 0.7377 - val_main_output_loss: 1.2457 - val_tof_gate_loss: 0.0010 - learning_rate: 3.0000e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3238 - main_output_accuracy: 0.9016 - main_output_loss: 1.1503 - tof_gate_loss: 9.4678e-04 - val_loss: 1.4172 - val_main_output_accuracy: 0.7328 - val_main_output_loss: 1.2460 - val_tof_gate_loss: 9.9494e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3759 - main_output_accuracy: 0.8837 - main_output_loss: 1.2014 - tof_gate_loss: 0.0010 - val_loss: 1.4206 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2532 - val_tof_gate_loss: 9.8881e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 116/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4419 - main_output_accuracy: 0.8656 - main_output_loss: 1.2637 - tof_gate_loss: 0.0011 - val_loss: 1.4189 - val_main_output_accuracy: 0.7402 - val_main_output_loss: 1.2409 - val_tof_gate_loss: 9.9416e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 117/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4777 - main_output_accuracy: 0.8745 - main_output_loss: 1.2998 - tof_gate_loss: 9.7095e-04 - val_loss: 1.4149 - val_main_output_accuracy: 0.7414 - val_main_output_loss: 1.2415 - val_tof_gate_loss: 9.8048e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 118/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3750 - main_output_accuracy: 0.8825 - main_output_loss: 1.1999 - tof_gate_loss: 9.6661e-04 - val_loss: 1.4133 - val_main_output_accuracy: 0.7390 - val_main_output_loss: 1.2415 - val_tof_gate_loss: 9.8132e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 119/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4613 - main_output_accuracy: 0.8658 - main_output_loss: 1.2861 - tof_gate_loss: 0.0010 - val_loss: 1.4179 - val_main_output_accuracy: 0.7365 - val_main_output_loss: 1.2396 - val_tof_gate_loss: 9.7556e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 120/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4150 - main_output_accuracy: 0.8825 - main_output_loss: 1.2394 - tof_gate_loss: 9.9919e-04 - val_loss: 1.4170 - val_main_output_accuracy: 0.7353 - val_main_output_loss: 1.2396 - val_tof_gate_loss: 9.7568e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 120: early stopping\n",
      "Restoring model weights from the end of the best epoch: 80.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 12:23:34.166079: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\n",
      "===== FOLD 8/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 115ms/step - loss: 10.4182 - main_output_accuracy: 0.1662 - main_output_loss: 2.8366 - tof_gate_loss: 0.6225 - val_loss: 8.0847 - val_main_output_accuracy: 0.4126 - val_main_output_loss: 2.3987 - val_tof_gate_loss: 0.5072 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 7.5160 - main_output_accuracy: 0.3595 - main_output_loss: 2.2651 - tof_gate_loss: 0.4126 - val_loss: 6.1203 - val_main_output_accuracy: 0.5453 - val_main_output_loss: 1.9142 - val_tof_gate_loss: 0.3360 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 5.9683 - main_output_accuracy: 0.4668 - main_output_loss: 2.0192 - tof_gate_loss: 0.2706 - val_loss: 4.9878 - val_main_output_accuracy: 0.5848 - val_main_output_loss: 1.6777 - val_tof_gate_loss: 0.2158 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 5.1009 - main_output_accuracy: 0.4918 - main_output_loss: 1.9587 - tof_gate_loss: 0.1880 - val_loss: 4.3267 - val_main_output_accuracy: 0.6097 - val_main_output_loss: 1.6385 - val_tof_gate_loss: 0.1427 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 4.4860 - main_output_accuracy: 0.5327 - main_output_loss: 1.9231 - tof_gate_loss: 0.1386 - val_loss: 3.7746 - val_main_output_accuracy: 0.6189 - val_main_output_loss: 1.5538 - val_tof_gate_loss: 0.1008 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 3.9507 - main_output_accuracy: 0.5467 - main_output_loss: 1.8254 - tof_gate_loss: 0.1010 - val_loss: 3.5009 - val_main_output_accuracy: 0.5821 - val_main_output_loss: 1.6461 - val_tof_gate_loss: 0.0726 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 3.5194 - main_output_accuracy: 0.5859 - main_output_loss: 1.7364 - tof_gate_loss: 0.0754 - val_loss: 3.1461 - val_main_output_accuracy: 0.6071 - val_main_output_loss: 1.5822 - val_tof_gate_loss: 0.0534 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 3.3732 - main_output_accuracy: 0.5565 - main_output_loss: 1.8683 - tof_gate_loss: 0.0642 - val_loss: 2.9100 - val_main_output_accuracy: 0.6531 - val_main_output_loss: 1.5805 - val_tof_gate_loss: 0.0405 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 3.0002 - main_output_accuracy: 0.6263 - main_output_loss: 1.7183 - tof_gate_loss: 0.0467 - val_loss: 2.7233 - val_main_output_accuracy: 0.6557 - val_main_output_loss: 1.5818 - val_tof_gate_loss: 0.0324 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.8129 - main_output_accuracy: 0.6267 - main_output_loss: 1.7200 - tof_gate_loss: 0.0401 - val_loss: 2.5507 - val_main_output_accuracy: 0.6242 - val_main_output_loss: 1.5634 - val_tof_gate_loss: 0.0258 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.7550 - main_output_accuracy: 0.6054 - main_output_loss: 1.8011 - tof_gate_loss: 0.0343 - val_loss: 2.5145 - val_main_output_accuracy: 0.6058 - val_main_output_loss: 1.6521 - val_tof_gate_loss: 0.0211 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 2.5676 - main_output_accuracy: 0.6129 - main_output_loss: 1.7295 - tof_gate_loss: 0.0268 - val_loss: 2.2628 - val_main_output_accuracy: 0.6426 - val_main_output_loss: 1.5014 - val_tof_gate_loss: 0.0174 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 2.4406 - main_output_accuracy: 0.6416 - main_output_loss: 1.6996 - tof_gate_loss: 0.0217 - val_loss: 2.3521 - val_main_output_accuracy: 0.5887 - val_main_output_loss: 1.6738 - val_tof_gate_loss: 0.0147 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 122ms/step - loss: 2.3977 - main_output_accuracy: 0.6270 - main_output_loss: 1.7216 - tof_gate_loss: 0.0206 - val_loss: 2.2477 - val_main_output_accuracy: 0.6084 - val_main_output_loss: 1.6396 - val_tof_gate_loss: 0.0123 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 2.2079 - main_output_accuracy: 0.6491 - main_output_loss: 1.6160 - tof_gate_loss: 0.0165 - val_loss: 2.1224 - val_main_output_accuracy: 0.6386 - val_main_output_loss: 1.5733 - val_tof_gate_loss: 0.0106 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.2069 - main_output_accuracy: 0.6553 - main_output_loss: 1.6701 - tof_gate_loss: 0.0149 - val_loss: 2.1827 - val_main_output_accuracy: 0.5940 - val_main_output_loss: 1.6833 - val_tof_gate_loss: 0.0091 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 2.1924 - main_output_accuracy: 0.6418 - main_output_loss: 1.6995 - tof_gate_loss: 0.0129\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 2.1922 - main_output_accuracy: 0.6418 - main_output_loss: 1.6993 - tof_gate_loss: 0.0128 - val_loss: 1.9796 - val_main_output_accuracy: 0.6452 - val_main_output_loss: 1.5177 - val_tof_gate_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 2.0858 - main_output_accuracy: 0.6966 - main_output_loss: 1.6290 - tof_gate_loss: 0.0113 - val_loss: 1.8829 - val_main_output_accuracy: 0.6781 - val_main_output_loss: 1.4461 - val_tof_gate_loss: 0.0073 - learning_rate: 2.5000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.9391 - main_output_accuracy: 0.7202 - main_output_loss: 1.5101 - tof_gate_loss: 0.0098 - val_loss: 1.8964 - val_main_output_accuracy: 0.6557 - val_main_output_loss: 1.4841 - val_tof_gate_loss: 0.0068 - learning_rate: 2.5000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - loss: 2.0536 - main_output_accuracy: 0.6880 - main_output_loss: 1.6420 - tof_gate_loss: 0.0101 - val_loss: 1.8445 - val_main_output_accuracy: 0.6741 - val_main_output_loss: 1.4512 - val_tof_gate_loss: 0.0063 - learning_rate: 2.5000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.8990 - main_output_accuracy: 0.7256 - main_output_loss: 1.5149 - tof_gate_loss: 0.0088 - val_loss: 1.9631 - val_main_output_accuracy: 0.6084 - val_main_output_loss: 1.5850 - val_tof_gate_loss: 0.0059 - learning_rate: 2.5000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.9845 - main_output_accuracy: 0.7031 - main_output_loss: 1.6085 - tof_gate_loss: 0.0084 - val_loss: 1.8838 - val_main_output_accuracy: 0.6610 - val_main_output_loss: 1.5208 - val_tof_gate_loss: 0.0055 - learning_rate: 2.5000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.9039 - main_output_accuracy: 0.7252 - main_output_loss: 1.5455 - tof_gate_loss: 0.0080 - val_loss: 1.8187 - val_main_output_accuracy: 0.6794 - val_main_output_loss: 1.4683 - val_tof_gate_loss: 0.0050 - learning_rate: 2.5000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.8942 - main_output_accuracy: 0.7229 - main_output_loss: 1.5411 - tof_gate_loss: 0.0076 - val_loss: 1.8410 - val_main_output_accuracy: 0.6544 - val_main_output_loss: 1.5054 - val_tof_gate_loss: 0.0046 - learning_rate: 2.5000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 1.7532 - main_output_accuracy: 0.7400 - main_output_loss: 1.4314 - tof_gate_loss: 0.0065 - val_loss: 1.8894 - val_main_output_accuracy: 0.6505 - val_main_output_loss: 1.5591 - val_tof_gate_loss: 0.0043 - learning_rate: 2.5000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.9012 - main_output_accuracy: 0.7298 - main_output_loss: 1.5760 - tof_gate_loss: 0.0065 - val_loss: 1.8513 - val_main_output_accuracy: 0.6255 - val_main_output_loss: 1.5329 - val_tof_gate_loss: 0.0040 - learning_rate: 2.5000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 121ms/step - loss: 1.7537 - main_output_accuracy: 0.7362 - main_output_loss: 1.4356 - tof_gate_loss: 0.0055 - val_loss: 1.8248 - val_main_output_accuracy: 0.6518 - val_main_output_loss: 1.5142 - val_tof_gate_loss: 0.0037 - learning_rate: 2.5000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 120ms/step - loss: 1.8451 - main_output_accuracy: 0.7340 - main_output_loss: 1.5368 - tof_gate_loss: 0.0056 - val_loss: 1.7921 - val_main_output_accuracy: 0.6465 - val_main_output_loss: 1.4876 - val_tof_gate_loss: 0.0034 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.9741 - main_output_accuracy: 0.7021 - main_output_loss: 1.6750 - tof_gate_loss: 0.0058 - val_loss: 1.7909 - val_main_output_accuracy: 0.6833 - val_main_output_loss: 1.4973 - val_tof_gate_loss: 0.0031 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.7636 - main_output_accuracy: 0.7319 - main_output_loss: 1.4707 - tof_gate_loss: 0.0049 - val_loss: 1.7259 - val_main_output_accuracy: 0.6965 - val_main_output_loss: 1.4386 - val_tof_gate_loss: 0.0029 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.7836 - main_output_accuracy: 0.7425 - main_output_loss: 1.4974 - tof_gate_loss: 0.0045 - val_loss: 1.7964 - val_main_output_accuracy: 0.6570 - val_main_output_loss: 1.5140 - val_tof_gate_loss: 0.0027 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.6608 - main_output_accuracy: 0.7651 - main_output_loss: 1.3835 - tof_gate_loss: 0.0040 - val_loss: 1.7761 - val_main_output_accuracy: 0.6544 - val_main_output_loss: 1.5016 - val_tof_gate_loss: 0.0025 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.8080 - main_output_accuracy: 0.7308 - main_output_loss: 1.5338 - tof_gate_loss: 0.0039 - val_loss: 1.6654 - val_main_output_accuracy: 0.6859 - val_main_output_loss: 1.3946 - val_tof_gate_loss: 0.0023 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.6762 - main_output_accuracy: 0.7707 - main_output_loss: 1.4069 - tof_gate_loss: 0.0035 - val_loss: 1.8200 - val_main_output_accuracy: 0.6491 - val_main_output_loss: 1.5549 - val_tof_gate_loss: 0.0021 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.6626 - main_output_accuracy: 0.7590 - main_output_loss: 1.3979 - tof_gate_loss: 0.0032 - val_loss: 1.7389 - val_main_output_accuracy: 0.6702 - val_main_output_loss: 1.4783 - val_tof_gate_loss: 0.0020 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 1.7126 - main_output_accuracy: 0.7658 - main_output_loss: 1.4580 - tof_gate_loss: 0.0031 - val_loss: 1.7383 - val_main_output_accuracy: 0.6386 - val_main_output_loss: 1.4849 - val_tof_gate_loss: 0.0018 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6405 - main_output_accuracy: 0.7783 - main_output_loss: 1.3877 - tof_gate_loss: 0.0029 - val_loss: 1.7327 - val_main_output_accuracy: 0.6623 - val_main_output_loss: 1.4813 - val_tof_gate_loss: 0.0017 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.7527 - main_output_accuracy: 0.7634 - main_output_loss: 1.5190 - tof_gate_loss: 0.0029\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.7519 - main_output_accuracy: 0.7635 - main_output_loss: 1.5181 - tof_gate_loss: 0.0029 - val_loss: 1.7947 - val_main_output_accuracy: 0.6557 - val_main_output_loss: 1.5459 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.7553 - main_output_accuracy: 0.7516 - main_output_loss: 1.5206 - tof_gate_loss: 0.0027 - val_loss: 1.6380 - val_main_output_accuracy: 0.6899 - val_main_output_loss: 1.3950 - val_tof_gate_loss: 0.0015 - learning_rate: 1.2500e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6145 - main_output_accuracy: 0.8072 - main_output_loss: 1.3779 - tof_gate_loss: 0.0024 - val_loss: 1.6614 - val_main_output_accuracy: 0.6846 - val_main_output_loss: 1.4245 - val_tof_gate_loss: 0.0015 - learning_rate: 1.2500e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.6198 - main_output_accuracy: 0.7923 - main_output_loss: 1.3822 - tof_gate_loss: 0.0023 - val_loss: 1.6839 - val_main_output_accuracy: 0.6649 - val_main_output_loss: 1.4496 - val_tof_gate_loss: 0.0014 - learning_rate: 1.2500e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6572 - main_output_accuracy: 0.7752 - main_output_loss: 1.4345 - tof_gate_loss: 0.0023 - val_loss: 1.6495 - val_main_output_accuracy: 0.6991 - val_main_output_loss: 1.4180 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6141 - main_output_accuracy: 0.7963 - main_output_loss: 1.3835 - tof_gate_loss: 0.0022 - val_loss: 1.6363 - val_main_output_accuracy: 0.7004 - val_main_output_loss: 1.4052 - val_tof_gate_loss: 0.0013 - learning_rate: 1.2500e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6086 - main_output_accuracy: 0.7889 - main_output_loss: 1.3815 - tof_gate_loss: 0.0020 - val_loss: 1.6639 - val_main_output_accuracy: 0.6767 - val_main_output_loss: 1.4368 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6055 - main_output_accuracy: 0.8103 - main_output_loss: 1.3792 - tof_gate_loss: 0.0019 - val_loss: 1.6538 - val_main_output_accuracy: 0.7043 - val_main_output_loss: 1.4303 - val_tof_gate_loss: 0.0012 - learning_rate: 1.2500e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6246 - main_output_accuracy: 0.7863 - main_output_loss: 1.4001 - tof_gate_loss: 0.0019 - val_loss: 1.7111 - val_main_output_accuracy: 0.6623 - val_main_output_loss: 1.4896 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.7020 - main_output_accuracy: 0.7712 - main_output_loss: 1.4792 - tof_gate_loss: 0.0019 - val_loss: 1.6878 - val_main_output_accuracy: 0.6754 - val_main_output_loss: 1.4670 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.6530 - main_output_accuracy: 0.7996 - main_output_loss: 1.4332 - tof_gate_loss: 0.0019 - val_loss: 1.6360 - val_main_output_accuracy: 0.6859 - val_main_output_loss: 1.4205 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - loss: 1.5073 - main_output_accuracy: 0.8075 - main_output_loss: 1.2948 - tof_gate_loss: 0.0016 - val_loss: 1.6743 - val_main_output_accuracy: 0.6715 - val_main_output_loss: 1.4613 - val_tof_gate_loss: 9.8686e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.6084 - main_output_accuracy: 0.7923 - main_output_loss: 1.3950 - tof_gate_loss: 0.0016 - val_loss: 1.6221 - val_main_output_accuracy: 0.6912 - val_main_output_loss: 1.4072 - val_tof_gate_loss: 9.4195e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6080 - main_output_accuracy: 0.7889 - main_output_loss: 1.4003 - tof_gate_loss: 0.0016 - val_loss: 1.6429 - val_main_output_accuracy: 0.7004 - val_main_output_loss: 1.4305 - val_tof_gate_loss: 8.9885e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6818 - main_output_accuracy: 0.7750 - main_output_loss: 1.4826 - tof_gate_loss: 0.0015 - val_loss: 1.6673 - val_main_output_accuracy: 0.6715 - val_main_output_loss: 1.4572 - val_tof_gate_loss: 8.5487e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.5513 - main_output_accuracy: 0.8157 - main_output_loss: 1.3452 - tof_gate_loss: 0.0014 - val_loss: 1.5959 - val_main_output_accuracy: 0.7214 - val_main_output_loss: 1.3866 - val_tof_gate_loss: 8.1182e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.6078 - main_output_accuracy: 0.8104 - main_output_loss: 1.3979 - tof_gate_loss: 0.0014 - val_loss: 1.6553 - val_main_output_accuracy: 0.6833 - val_main_output_loss: 1.4499 - val_tof_gate_loss: 7.7034e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.5605 - main_output_accuracy: 0.8046 - main_output_loss: 1.3564 - tof_gate_loss: 0.0013 - val_loss: 1.6402 - val_main_output_accuracy: 0.6925 - val_main_output_loss: 1.4340 - val_tof_gate_loss: 7.3244e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.4878 - main_output_accuracy: 0.8244 - main_output_loss: 1.2839 - tof_gate_loss: 0.0012 - val_loss: 1.6936 - val_main_output_accuracy: 0.6702 - val_main_output_loss: 1.4895 - val_tof_gate_loss: 6.9328e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.5447 - main_output_accuracy: 0.8147 - main_output_loss: 1.3410 - tof_gate_loss: 0.0012 - val_loss: 1.6377 - val_main_output_accuracy: 0.6886 - val_main_output_loss: 1.4341 - val_tof_gate_loss: 6.6099e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5596 - main_output_accuracy: 0.8175 - main_output_loss: 1.3567 - tof_gate_loss: 0.0011 - val_loss: 1.7330 - val_main_output_accuracy: 0.6505 - val_main_output_loss: 1.5326 - val_tof_gate_loss: 6.3021e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5489 - main_output_accuracy: 0.8185 - main_output_loss: 1.3496 - tof_gate_loss: 0.0011 - val_loss: 1.6330 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.4347 - val_tof_gate_loss: 5.9800e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.6287 - main_output_accuracy: 0.7865 - main_output_loss: 1.4286 - tof_gate_loss: 0.0010 - val_loss: 1.6461 - val_main_output_accuracy: 0.6912 - val_main_output_loss: 1.4474 - val_tof_gate_loss: 5.6898e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.6050 - main_output_accuracy: 0.7855 - main_output_loss: 1.4103 - tof_gate_loss: 0.0010\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.6045 - main_output_accuracy: 0.7856 - main_output_loss: 1.4098 - tof_gate_loss: 0.0010 - val_loss: 1.6418 - val_main_output_accuracy: 0.6938 - val_main_output_loss: 1.4441 - val_tof_gate_loss: 5.3892e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4045 - main_output_accuracy: 0.8550 - main_output_loss: 1.2085 - tof_gate_loss: 8.6229e-04 - val_loss: 1.5979 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.4016 - val_tof_gate_loss: 5.2122e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 63/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4923 - main_output_accuracy: 0.8472 - main_output_loss: 1.2968 - tof_gate_loss: 8.9450e-04 - val_loss: 1.6225 - val_main_output_accuracy: 0.6886 - val_main_output_loss: 1.4274 - val_tof_gate_loss: 5.1058e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 64/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.4574 - main_output_accuracy: 0.8489 - main_output_loss: 1.2629 - tof_gate_loss: 8.4094e-04 - val_loss: 1.5672 - val_main_output_accuracy: 0.7188 - val_main_output_loss: 1.3733 - val_tof_gate_loss: 4.9612e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 65/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4630 - main_output_accuracy: 0.8553 - main_output_loss: 1.2725 - tof_gate_loss: 8.2027e-04 - val_loss: 1.5893 - val_main_output_accuracy: 0.7004 - val_main_output_loss: 1.3979 - val_tof_gate_loss: 4.8361e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4772 - main_output_accuracy: 0.8252 - main_output_loss: 1.2849 - tof_gate_loss: 7.9842e-04 - val_loss: 1.5885 - val_main_output_accuracy: 0.7004 - val_main_output_loss: 1.3965 - val_tof_gate_loss: 4.6846e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.5436 - main_output_accuracy: 0.8300 - main_output_loss: 1.3531 - tof_gate_loss: 8.4656e-04 - val_loss: 1.5765 - val_main_output_accuracy: 0.7043 - val_main_output_loss: 1.3898 - val_tof_gate_loss: 4.5324e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.3713 - main_output_accuracy: 0.8570 - main_output_loss: 1.1786 - tof_gate_loss: 7.1918e-04 - val_loss: 1.5869 - val_main_output_accuracy: 0.6951 - val_main_output_loss: 1.3979 - val_tof_gate_loss: 4.4176e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.4949 - main_output_accuracy: 0.8235 - main_output_loss: 1.3054 - tof_gate_loss: 7.7462e-04 - val_loss: 1.5646 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3752 - val_tof_gate_loss: 4.2930e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.4686 - main_output_accuracy: 0.8378 - main_output_loss: 1.2805 - tof_gate_loss: 7.0933e-04\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4684 - main_output_accuracy: 0.8379 - main_output_loss: 1.2803 - tof_gate_loss: 7.0927e-04 - val_loss: 1.5855 - val_main_output_accuracy: 0.6978 - val_main_output_loss: 1.4000 - val_tof_gate_loss: 4.1364e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4018 - main_output_accuracy: 0.8645 - main_output_loss: 1.2127 - tof_gate_loss: 6.7149e-04 - val_loss: 1.5609 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3730 - val_tof_gate_loss: 4.0927e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5495 - main_output_accuracy: 0.8372 - main_output_loss: 1.3704 - tof_gate_loss: 7.4734e-04 - val_loss: 1.5518 - val_main_output_accuracy: 0.7175 - val_main_output_loss: 1.3674 - val_tof_gate_loss: 4.0496e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4767 - main_output_accuracy: 0.8365 - main_output_loss: 1.2918 - tof_gate_loss: 6.6602e-04 - val_loss: 1.5712 - val_main_output_accuracy: 0.7122 - val_main_output_loss: 1.3851 - val_tof_gate_loss: 3.9500e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4368 - main_output_accuracy: 0.8667 - main_output_loss: 1.2503 - tof_gate_loss: 7.0937e-04 - val_loss: 1.5560 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.3720 - val_tof_gate_loss: 3.8687e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.3394 - main_output_accuracy: 0.8789 - main_output_loss: 1.1656 - tof_gate_loss: 6.0158e-04 - val_loss: 1.5317 - val_main_output_accuracy: 0.7135 - val_main_output_loss: 1.3488 - val_tof_gate_loss: 3.8419e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4728 - main_output_accuracy: 0.8609 - main_output_loss: 1.2892 - tof_gate_loss: 7.0906e-04 - val_loss: 1.5718 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3879 - val_tof_gate_loss: 3.7174e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5130 - main_output_accuracy: 0.8453 - main_output_loss: 1.3284 - tof_gate_loss: 6.3825e-04 - val_loss: 1.5501 - val_main_output_accuracy: 0.7070 - val_main_output_loss: 1.3674 - val_tof_gate_loss: 3.6465e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3470 - main_output_accuracy: 0.8763 - main_output_loss: 1.1635 - tof_gate_loss: 6.1693e-04 - val_loss: 1.5655 - val_main_output_accuracy: 0.7057 - val_main_output_loss: 1.3831 - val_tof_gate_loss: 3.5747e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.3417 - main_output_accuracy: 0.8895 - main_output_loss: 1.1571 - tof_gate_loss: 5.9591e-04\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3422 - main_output_accuracy: 0.8893 - main_output_loss: 1.1577 - tof_gate_loss: 5.9614e-04 - val_loss: 1.5490 - val_main_output_accuracy: 0.7004 - val_main_output_loss: 1.3673 - val_tof_gate_loss: 3.5069e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4502 - main_output_accuracy: 0.8529 - main_output_loss: 1.2676 - tof_gate_loss: 6.7780e-04 - val_loss: 1.5702 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.3902 - val_tof_gate_loss: 3.4597e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3811 - main_output_accuracy: 0.8711 - main_output_loss: 1.1960 - tof_gate_loss: 5.6136e-04 - val_loss: 1.5429 - val_main_output_accuracy: 0.7109 - val_main_output_loss: 1.3615 - val_tof_gate_loss: 3.4283e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5116 - main_output_accuracy: 0.8218 - main_output_loss: 1.3493 - tof_gate_loss: 5.9614e-04 - val_loss: 1.5474 - val_main_output_accuracy: 0.7148 - val_main_output_loss: 1.3673 - val_tof_gate_loss: 3.4031e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3431 - main_output_accuracy: 0.8721 - main_output_loss: 1.1615 - tof_gate_loss: 5.4193e-04 - val_loss: 1.5360 - val_main_output_accuracy: 0.7148 - val_main_output_loss: 1.3552 - val_tof_gate_loss: 3.3423e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5691 - main_output_accuracy: 0.8252 - main_output_loss: 1.3838 - tof_gate_loss: 6.1703e-04 - val_loss: 1.5381 - val_main_output_accuracy: 0.7083 - val_main_output_loss: 1.3572 - val_tof_gate_loss: 3.3156e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.4233 - main_output_accuracy: 0.8568 - main_output_loss: 1.2443 - tof_gate_loss: 5.6165e-04 - val_loss: 1.5489 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.3699 - val_tof_gate_loss: 3.2589e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3981 - main_output_accuracy: 0.8770 - main_output_loss: 1.2204 - tof_gate_loss: 5.6531e-04 - val_loss: 1.5513 - val_main_output_accuracy: 0.7070 - val_main_output_loss: 1.3711 - val_tof_gate_loss: 3.2302e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5025 - main_output_accuracy: 0.8319 - main_output_loss: 1.3228 - tof_gate_loss: 5.8735e-04 - val_loss: 1.5425 - val_main_output_accuracy: 0.7135 - val_main_output_loss: 1.3633 - val_tof_gate_loss: 3.1770e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 1.3308 - main_output_accuracy: 0.8787 - main_output_loss: 1.1522 - tof_gate_loss: 5.0065e-04\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3312 - main_output_accuracy: 0.8785 - main_output_loss: 1.1526 - tof_gate_loss: 5.0086e-04 - val_loss: 1.5526 - val_main_output_accuracy: 0.7057 - val_main_output_loss: 1.3722 - val_tof_gate_loss: 3.1454e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4927 - main_output_accuracy: 0.8588 - main_output_loss: 1.3115 - tof_gate_loss: 6.0279e-04 - val_loss: 1.5533 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.3748 - val_tof_gate_loss: 3.1142e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 90/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3507 - main_output_accuracy: 0.8845 - main_output_loss: 1.1728 - tof_gate_loss: 4.8542e-04 - val_loss: 1.5369 - val_main_output_accuracy: 0.7109 - val_main_output_loss: 1.3561 - val_tof_gate_loss: 3.0947e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 91/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3801 - main_output_accuracy: 0.8923 - main_output_loss: 1.2023 - tof_gate_loss: 4.9519e-04 - val_loss: 1.5407 - val_main_output_accuracy: 0.7096 - val_main_output_loss: 1.3610 - val_tof_gate_loss: 3.0720e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 92/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.4575 - main_output_accuracy: 0.8711 - main_output_loss: 1.2784 - tof_gate_loss: 5.3042e-04 - val_loss: 1.5454 - val_main_output_accuracy: 0.7122 - val_main_output_loss: 1.3670 - val_tof_gate_loss: 3.0475e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 93/160\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 102ms/step - loss: 1.4198 - main_output_accuracy: 0.8734 - main_output_loss: 1.2401 - tof_gate_loss: 5.3259e-04 - val_loss: 1.5398 - val_main_output_accuracy: 0.7148 - val_main_output_loss: 1.3604 - val_tof_gate_loss: 3.0274e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 93: early stopping\n",
      "Restoring model weights from the end of the best epoch: 53.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 12:43:03.900882: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step\n",
      "\n",
      "===== FOLD 9/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 116ms/step - loss: 10.4623 - main_output_accuracy: 0.1461 - main_output_loss: 2.8599 - tof_gate_loss: 0.7753 - val_loss: 8.0606 - val_main_output_accuracy: 0.4289 - val_main_output_loss: 2.3730 - val_tof_gate_loss: 0.6072 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 7.5026 - main_output_accuracy: 0.3639 - main_output_loss: 2.2451 - tof_gate_loss: 0.5233 - val_loss: 6.1211 - val_main_output_accuracy: 0.5600 - val_main_output_loss: 1.8838 - val_tof_gate_loss: 0.4280 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 6.0696 - main_output_accuracy: 0.4567 - main_output_loss: 2.0858 - tof_gate_loss: 0.3702 - val_loss: 4.9728 - val_main_output_accuracy: 0.6091 - val_main_output_loss: 1.6231 - val_tof_gate_loss: 0.2990 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 5.1053 - main_output_accuracy: 0.4963 - main_output_loss: 1.9345 - tof_gate_loss: 0.2511 - val_loss: 4.2823 - val_main_output_accuracy: 0.5919 - val_main_output_loss: 1.5586 - val_tof_gate_loss: 0.2134 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 4.4394 - main_output_accuracy: 0.5444 - main_output_loss: 1.8508 - tof_gate_loss: 0.1764 - val_loss: 3.7483 - val_main_output_accuracy: 0.6373 - val_main_output_loss: 1.5055 - val_tof_gate_loss: 0.1549 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 4.0543 - main_output_accuracy: 0.5408 - main_output_loss: 1.9131 - tof_gate_loss: 0.1300 - val_loss: 3.3231 - val_main_output_accuracy: 0.6434 - val_main_output_loss: 1.4515 - val_tof_gate_loss: 0.1160 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 3.6723 - main_output_accuracy: 0.5536 - main_output_loss: 1.8798 - tof_gate_loss: 0.0984 - val_loss: 3.0019 - val_main_output_accuracy: 0.6409 - val_main_output_loss: 1.4244 - val_tof_gate_loss: 0.0884 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 3.3350 - main_output_accuracy: 0.5836 - main_output_loss: 1.8213 - tof_gate_loss: 0.0729 - val_loss: 2.7740 - val_main_output_accuracy: 0.6544 - val_main_output_loss: 1.4315 - val_tof_gate_loss: 0.0682 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 3.1165 - main_output_accuracy: 0.5775 - main_output_loss: 1.8281 - tof_gate_loss: 0.0561 - val_loss: 2.5936 - val_main_output_accuracy: 0.6581 - val_main_output_loss: 1.4413 - val_tof_gate_loss: 0.0546 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 2.8025 - main_output_accuracy: 0.6128 - main_output_loss: 1.7004 - tof_gate_loss: 0.0431 - val_loss: 2.5084 - val_main_output_accuracy: 0.6458 - val_main_output_loss: 1.5113 - val_tof_gate_loss: 0.0453 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 2.6585 - main_output_accuracy: 0.6252 - main_output_loss: 1.6922 - tof_gate_loss: 0.0361 - val_loss: 2.3318 - val_main_output_accuracy: 0.6397 - val_main_output_loss: 1.4614 - val_tof_gate_loss: 0.0375 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 2.4617 - main_output_accuracy: 0.6495 - main_output_loss: 1.6188 - tof_gate_loss: 0.0282 - val_loss: 2.2262 - val_main_output_accuracy: 0.6507 - val_main_output_loss: 1.4581 - val_tof_gate_loss: 0.0315 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 2.4591 - main_output_accuracy: 0.6484 - main_output_loss: 1.7192 - tof_gate_loss: 0.0270 - val_loss: 2.0695 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.3908 - val_tof_gate_loss: 0.0266 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.4145 - main_output_accuracy: 0.6400 - main_output_loss: 1.7501 - tof_gate_loss: 0.0222 - val_loss: 2.1067 - val_main_output_accuracy: 0.6385 - val_main_output_loss: 1.4971 - val_tof_gate_loss: 0.0225 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.2359 - main_output_accuracy: 0.6622 - main_output_loss: 1.6398 - tof_gate_loss: 0.0180 - val_loss: 1.9447 - val_main_output_accuracy: 0.6654 - val_main_output_loss: 1.3882 - val_tof_gate_loss: 0.0194 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 2.2353 - main_output_accuracy: 0.6597 - main_output_loss: 1.6961 - tof_gate_loss: 0.0156 - val_loss: 1.9206 - val_main_output_accuracy: 0.6507 - val_main_output_loss: 1.4152 - val_tof_gate_loss: 0.0167 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 2.2273 - main_output_accuracy: 0.6366 - main_output_loss: 1.7333 - tof_gate_loss: 0.0149 - val_loss: 1.8513 - val_main_output_accuracy: 0.6900 - val_main_output_loss: 1.3854 - val_tof_gate_loss: 0.0143 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 2.0594 - main_output_accuracy: 0.6648 - main_output_loss: 1.6030 - tof_gate_loss: 0.0118 - val_loss: 1.8466 - val_main_output_accuracy: 0.6716 - val_main_output_loss: 1.4136 - val_tof_gate_loss: 0.0127 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 2.0526 - main_output_accuracy: 0.6824 - main_output_loss: 1.6234 - tof_gate_loss: 0.0104 - val_loss: 1.7725 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3710 - val_tof_gate_loss: 0.0112 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.9684 - main_output_accuracy: 0.6818 - main_output_loss: 1.5695 - tof_gate_loss: 0.0088 - val_loss: 1.7864 - val_main_output_accuracy: 0.6667 - val_main_output_loss: 1.4046 - val_tof_gate_loss: 0.0098 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.9037 - main_output_accuracy: 0.7035 - main_output_loss: 1.5277 - tof_gate_loss: 0.0073 - val_loss: 1.6597 - val_main_output_accuracy: 0.7132 - val_main_output_loss: 1.2983 - val_tof_gate_loss: 0.0088 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.8869 - main_output_accuracy: 0.6885 - main_output_loss: 1.5307 - tof_gate_loss: 0.0067 - val_loss: 1.7721 - val_main_output_accuracy: 0.6752 - val_main_output_loss: 1.4246 - val_tof_gate_loss: 0.0079 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.9078 - main_output_accuracy: 0.6925 - main_output_loss: 1.5677 - tof_gate_loss: 0.0068 - val_loss: 1.7545 - val_main_output_accuracy: 0.6789 - val_main_output_loss: 1.4249 - val_tof_gate_loss: 0.0070 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.9571 - main_output_accuracy: 0.6760 - main_output_loss: 1.6272 - tof_gate_loss: 0.0057 - val_loss: 1.6299 - val_main_output_accuracy: 0.7218 - val_main_output_loss: 1.3150 - val_tof_gate_loss: 0.0063 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.8344 - main_output_accuracy: 0.7290 - main_output_loss: 1.5254 - tof_gate_loss: 0.0049 - val_loss: 1.6590 - val_main_output_accuracy: 0.6814 - val_main_output_loss: 1.3549 - val_tof_gate_loss: 0.0056 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.8429 - main_output_accuracy: 0.7100 - main_output_loss: 1.5405 - tof_gate_loss: 0.0047 - val_loss: 1.6745 - val_main_output_accuracy: 0.6740 - val_main_output_loss: 1.3798 - val_tof_gate_loss: 0.0050 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.8590 - main_output_accuracy: 0.6819 - main_output_loss: 1.5695 - tof_gate_loss: 0.0041 - val_loss: 1.7131 - val_main_output_accuracy: 0.6752 - val_main_output_loss: 1.4273 - val_tof_gate_loss: 0.0046 - learning_rate: 5.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.9813 - main_output_accuracy: 0.6571 - main_output_loss: 1.6938 - tof_gate_loss: 0.0041 - val_loss: 1.5670 - val_main_output_accuracy: 0.7255 - val_main_output_loss: 1.2887 - val_tof_gate_loss: 0.0041 - learning_rate: 5.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.9708 - main_output_accuracy: 0.6827 - main_output_loss: 1.6910 - tof_gate_loss: 0.0036 - val_loss: 1.5471 - val_main_output_accuracy: 0.7255 - val_main_output_loss: 1.2741 - val_tof_gate_loss: 0.0037 - learning_rate: 5.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.8339 - main_output_accuracy: 0.7195 - main_output_loss: 1.5640 - tof_gate_loss: 0.0032 - val_loss: 1.6520 - val_main_output_accuracy: 0.7071 - val_main_output_loss: 1.3849 - val_tof_gate_loss: 0.0033 - learning_rate: 5.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.7874 - main_output_accuracy: 0.7201 - main_output_loss: 1.5222 - tof_gate_loss: 0.0028 - val_loss: 1.6728 - val_main_output_accuracy: 0.6740 - val_main_output_loss: 1.4107 - val_tof_gate_loss: 0.0031 - learning_rate: 5.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.8243 - main_output_accuracy: 0.7005 - main_output_loss: 1.5621 - tof_gate_loss: 0.0026 - val_loss: 1.6117 - val_main_output_accuracy: 0.6838 - val_main_output_loss: 1.3479 - val_tof_gate_loss: 0.0028 - learning_rate: 5.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7764 - main_output_accuracy: 0.7287 - main_output_loss: 1.5178 - tof_gate_loss: 0.0024 - val_loss: 1.6795 - val_main_output_accuracy: 0.6409 - val_main_output_loss: 1.4238 - val_tof_gate_loss: 0.0026 - learning_rate: 5.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.8528 - main_output_accuracy: 0.6885 - main_output_loss: 1.5988 - tof_gate_loss: 0.0022 - val_loss: 1.5657 - val_main_output_accuracy: 0.7010 - val_main_output_loss: 1.3143 - val_tof_gate_loss: 0.0023 - learning_rate: 5.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.7542 - main_output_accuracy: 0.7191 - main_output_loss: 1.5030 - tof_gate_loss: 0.0020 - val_loss: 1.5580 - val_main_output_accuracy: 0.7120 - val_main_output_loss: 1.3073 - val_tof_gate_loss: 0.0022 - learning_rate: 5.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.6935 - main_output_accuracy: 0.7399 - main_output_loss: 1.4468 - tof_gate_loss: 0.0017\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.6941 - main_output_accuracy: 0.7397 - main_output_loss: 1.4474 - tof_gate_loss: 0.0017 - val_loss: 1.6232 - val_main_output_accuracy: 0.7108 - val_main_output_loss: 1.3804 - val_tof_gate_loss: 0.0020 - learning_rate: 5.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.7167 - main_output_accuracy: 0.7479 - main_output_loss: 1.4724 - tof_gate_loss: 0.0017 - val_loss: 1.4359 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.2020 - val_tof_gate_loss: 0.0019 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.6856 - main_output_accuracy: 0.7620 - main_output_loss: 1.4517 - tof_gate_loss: 0.0016 - val_loss: 1.4846 - val_main_output_accuracy: 0.7120 - val_main_output_loss: 1.2553 - val_tof_gate_loss: 0.0018 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6919 - main_output_accuracy: 0.7679 - main_output_loss: 1.4714 - tof_gate_loss: 0.0016 - val_loss: 1.4044 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1814 - val_tof_gate_loss: 0.0017 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6906 - main_output_accuracy: 0.7560 - main_output_loss: 1.4686 - tof_gate_loss: 0.0015 - val_loss: 1.4740 - val_main_output_accuracy: 0.7255 - val_main_output_loss: 1.2568 - val_tof_gate_loss: 0.0016 - learning_rate: 2.5000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5789 - main_output_accuracy: 0.7739 - main_output_loss: 1.3638 - tof_gate_loss: 0.0014 - val_loss: 1.5342 - val_main_output_accuracy: 0.6973 - val_main_output_loss: 1.3218 - val_tof_gate_loss: 0.0015 - learning_rate: 2.5000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 111ms/step - loss: 1.7391 - main_output_accuracy: 0.7589 - main_output_loss: 1.5237 - tof_gate_loss: 0.0015 - val_loss: 1.4378 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.2266 - val_tof_gate_loss: 0.0015 - learning_rate: 2.5000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.5739 - main_output_accuracy: 0.7701 - main_output_loss: 1.3608 - tof_gate_loss: 0.0012 - val_loss: 1.4524 - val_main_output_accuracy: 0.7316 - val_main_output_loss: 1.2441 - val_tof_gate_loss: 0.0014 - learning_rate: 2.5000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.5719 - main_output_accuracy: 0.7845 - main_output_loss: 1.3655 - tof_gate_loss: 0.0012 - val_loss: 1.4135 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.2083 - val_tof_gate_loss: 0.0013 - learning_rate: 2.5000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6572 - main_output_accuracy: 0.7714 - main_output_loss: 1.4632 - tof_gate_loss: 0.0013 - val_loss: 1.4490 - val_main_output_accuracy: 0.7292 - val_main_output_loss: 1.2461 - val_tof_gate_loss: 0.0013 - learning_rate: 2.5000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6344 - main_output_accuracy: 0.7611 - main_output_loss: 1.4318 - tof_gate_loss: 0.0011 - val_loss: 1.3967 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.1962 - val_tof_gate_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 1.7032 - main_output_accuracy: 0.7530 - main_output_loss: 1.5050 - tof_gate_loss: 0.0011\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.7025 - main_output_accuracy: 0.7532 - main_output_loss: 1.5043 - tof_gate_loss: 0.0011 - val_loss: 1.3872 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.1879 - val_tof_gate_loss: 0.0012 - learning_rate: 2.5000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.5091 - main_output_accuracy: 0.8159 - main_output_loss: 1.3081 - tof_gate_loss: 0.0010 - val_loss: 1.3669 - val_main_output_accuracy: 0.7561 - val_main_output_loss: 1.1740 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.5877 - main_output_accuracy: 0.8096 - main_output_loss: 1.3912 - tof_gate_loss: 0.0010 - val_loss: 1.3499 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1578 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.5136 - main_output_accuracy: 0.8129 - main_output_loss: 1.3334 - tof_gate_loss: 9.9882e-04 - val_loss: 1.3353 - val_main_output_accuracy: 0.7745 - val_main_output_loss: 1.1426 - val_tof_gate_loss: 0.0011 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 120ms/step - loss: 1.6026 - main_output_accuracy: 0.8133 - main_output_loss: 1.4134 - tof_gate_loss: 9.7783e-04 - val_loss: 1.3437 - val_main_output_accuracy: 0.7623 - val_main_output_loss: 1.1558 - val_tof_gate_loss: 0.0010 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.6058 - main_output_accuracy: 0.7893 - main_output_loss: 1.4070 - tof_gate_loss: 0.0010 - val_loss: 1.3847 - val_main_output_accuracy: 0.7439 - val_main_output_loss: 1.2007 - val_tof_gate_loss: 9.9919e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.5725 - main_output_accuracy: 0.8119 - main_output_loss: 1.3880 - tof_gate_loss: 9.1255e-04 - val_loss: 1.3367 - val_main_output_accuracy: 0.7806 - val_main_output_loss: 1.1552 - val_tof_gate_loss: 9.6405e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.4260 - main_output_accuracy: 0.8394 - main_output_loss: 1.2452 - tof_gate_loss: 7.8997e-04 - val_loss: 1.3567 - val_main_output_accuracy: 0.7549 - val_main_output_loss: 1.1743 - val_tof_gate_loss: 9.3498e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 112ms/step - loss: 1.4644 - main_output_accuracy: 0.8164 - main_output_loss: 1.2874 - tof_gate_loss: 7.6379e-04 - val_loss: 1.3490 - val_main_output_accuracy: 0.7500 - val_main_output_loss: 1.1712 - val_tof_gate_loss: 9.0800e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6063 - main_output_accuracy: 0.7928 - main_output_loss: 1.4269 - tof_gate_loss: 8.5810e-04 - val_loss: 1.4038 - val_main_output_accuracy: 0.7426 - val_main_output_loss: 1.2234 - val_tof_gate_loss: 8.7879e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5385 - main_output_accuracy: 0.8251 - main_output_loss: 1.3597 - tof_gate_loss: 8.1378e-04 - val_loss: 1.3500 - val_main_output_accuracy: 0.7745 - val_main_output_loss: 1.1717 - val_tof_gate_loss: 8.4520e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4709 - main_output_accuracy: 0.8218 - main_output_loss: 1.2948 - tof_gate_loss: 7.7624e-04 - val_loss: 1.3688 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1928 - val_tof_gate_loss: 8.1482e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4888 - main_output_accuracy: 0.8348 - main_output_loss: 1.3140 - tof_gate_loss: 7.1331e-04 - val_loss: 1.3315 - val_main_output_accuracy: 0.7782 - val_main_output_loss: 1.1558 - val_tof_gate_loss: 7.9711e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 111ms/step - loss: 1.5574 - main_output_accuracy: 0.7930 - main_output_loss: 1.3811 - tof_gate_loss: 7.1335e-04 - val_loss: 1.3351 - val_main_output_accuracy: 0.7610 - val_main_output_loss: 1.1606 - val_tof_gate_loss: 7.6536e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.5654 - main_output_accuracy: 0.7885 - main_output_loss: 1.3945 - tof_gate_loss: 7.2223e-04\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.5653 - main_output_accuracy: 0.7886 - main_output_loss: 1.3943 - tof_gate_loss: 7.2206e-04 - val_loss: 1.3351 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1612 - val_tof_gate_loss: 7.3263e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5244 - main_output_accuracy: 0.8111 - main_output_loss: 1.3493 - tof_gate_loss: 6.8705e-04 - val_loss: 1.3167 - val_main_output_accuracy: 0.7647 - val_main_output_loss: 1.1493 - val_tof_gate_loss: 7.0823e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 63/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4725 - main_output_accuracy: 0.8425 - main_output_loss: 1.3038 - tof_gate_loss: 6.5664e-04 - val_loss: 1.3208 - val_main_output_accuracy: 0.7586 - val_main_output_loss: 1.1562 - val_tof_gate_loss: 6.9353e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 64/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4680 - main_output_accuracy: 0.8343 - main_output_loss: 1.2994 - tof_gate_loss: 6.4999e-04 - val_loss: 1.3224 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1541 - val_tof_gate_loss: 6.8265e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 65/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.4830 - main_output_accuracy: 0.8322 - main_output_loss: 1.3142 - tof_gate_loss: 6.0373e-04 - val_loss: 1.3150 - val_main_output_accuracy: 0.7880 - val_main_output_loss: 1.1480 - val_tof_gate_loss: 6.7110e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 115ms/step - loss: 1.4483 - main_output_accuracy: 0.8225 - main_output_loss: 1.2775 - tof_gate_loss: 5.9732e-04 - val_loss: 1.3245 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1604 - val_tof_gate_loss: 6.6661e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.5704 - main_output_accuracy: 0.8101 - main_output_loss: 1.4157 - tof_gate_loss: 6.0508e-04 - val_loss: 1.3143 - val_main_output_accuracy: 0.7757 - val_main_output_loss: 1.1475 - val_tof_gate_loss: 6.4491e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.3802 - main_output_accuracy: 0.8516 - main_output_loss: 1.2167 - tof_gate_loss: 5.3875e-04 - val_loss: 1.3011 - val_main_output_accuracy: 0.7659 - val_main_output_loss: 1.1384 - val_tof_gate_loss: 6.2615e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 118ms/step - loss: 1.3989 - main_output_accuracy: 0.8571 - main_output_loss: 1.2344 - tof_gate_loss: 5.7458e-04 - val_loss: 1.3143 - val_main_output_accuracy: 0.7696 - val_main_output_loss: 1.1501 - val_tof_gate_loss: 6.0554e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 119ms/step - loss: 1.4027 - main_output_accuracy: 0.8506 - main_output_loss: 1.2387 - tof_gate_loss: 5.3876e-04 - val_loss: 1.3035 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1408 - val_tof_gate_loss: 5.9487e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.3561 - main_output_accuracy: 0.8492 - main_output_loss: 1.1906 - tof_gate_loss: 5.0911e-04 - val_loss: 1.3296 - val_main_output_accuracy: 0.7708 - val_main_output_loss: 1.1678 - val_tof_gate_loss: 5.7671e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.3317 - main_output_accuracy: 0.8881 - main_output_loss: 1.1791 - tof_gate_loss: 4.7323e-04 - val_loss: 1.3124 - val_main_output_accuracy: 0.7598 - val_main_output_loss: 1.1518 - val_tof_gate_loss: 5.6211e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 1.4037 - main_output_accuracy: 0.8618 - main_output_loss: 1.2474 - tof_gate_loss: 4.9901e-04\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 99ms/step - loss: 1.4035 - main_output_accuracy: 0.8617 - main_output_loss: 1.2472 - tof_gate_loss: 4.9902e-04 - val_loss: 1.3118 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1542 - val_tof_gate_loss: 5.4881e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 94ms/step - loss: 1.4565 - main_output_accuracy: 0.8385 - main_output_loss: 1.2921 - tof_gate_loss: 4.8206e-04 - val_loss: 1.2844 - val_main_output_accuracy: 0.7782 - val_main_output_loss: 1.1238 - val_tof_gate_loss: 5.4143e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 92ms/step - loss: 1.5138 - main_output_accuracy: 0.8321 - main_output_loss: 1.3569 - tof_gate_loss: 5.3402e-04 - val_loss: 1.2873 - val_main_output_accuracy: 0.7929 - val_main_output_loss: 1.1310 - val_tof_gate_loss: 5.3311e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4774 - main_output_accuracy: 0.8323 - main_output_loss: 1.3172 - tof_gate_loss: 5.3684e-04 - val_loss: 1.2997 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1392 - val_tof_gate_loss: 5.2707e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.4442 - main_output_accuracy: 0.8477 - main_output_loss: 1.2869 - tof_gate_loss: 4.9551e-04 - val_loss: 1.2806 - val_main_output_accuracy: 0.7855 - val_main_output_loss: 1.1228 - val_tof_gate_loss: 5.1146e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.4077 - main_output_accuracy: 0.8590 - main_output_loss: 1.2483 - tof_gate_loss: 5.0617e-04 - val_loss: 1.2939 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1354 - val_tof_gate_loss: 5.1097e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.3828 - main_output_accuracy: 0.8600 - main_output_loss: 1.2245 - tof_gate_loss: 4.6001e-04 - val_loss: 1.3003 - val_main_output_accuracy: 0.7782 - val_main_output_loss: 1.1446 - val_tof_gate_loss: 4.9506e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.3172 - main_output_accuracy: 0.8923 - main_output_loss: 1.1572 - tof_gate_loss: 4.3761e-04 - val_loss: 1.3017 - val_main_output_accuracy: 0.7721 - val_main_output_loss: 1.1438 - val_tof_gate_loss: 4.8612e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.4047 - main_output_accuracy: 0.8670 - main_output_loss: 1.2484 - tof_gate_loss: 4.3475e-04 - val_loss: 1.3096 - val_main_output_accuracy: 0.7635 - val_main_output_loss: 1.1571 - val_tof_gate_loss: 4.8317e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 88ms/step - loss: 1.3424 - main_output_accuracy: 0.8770 - main_output_loss: 1.1863 - tof_gate_loss: 4.3842e-04 - val_loss: 1.2820 - val_main_output_accuracy: 0.7782 - val_main_output_loss: 1.1259 - val_tof_gate_loss: 4.7296e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 1.4745 - main_output_accuracy: 0.8287 - main_output_loss: 1.3179 - tof_gate_loss: 4.7857e-04\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4742 - main_output_accuracy: 0.8289 - main_output_loss: 1.3176 - tof_gate_loss: 4.7828e-04 - val_loss: 1.3071 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1489 - val_tof_gate_loss: 4.6341e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.5452 - main_output_accuracy: 0.8311 - main_output_loss: 1.3888 - tof_gate_loss: 4.5683e-04 - val_loss: 1.2860 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1372 - val_tof_gate_loss: 4.5645e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.3623 - main_output_accuracy: 0.8671 - main_output_loss: 1.2077 - tof_gate_loss: 4.1865e-04 - val_loss: 1.2893 - val_main_output_accuracy: 0.7819 - val_main_output_loss: 1.1359 - val_tof_gate_loss: 4.5255e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.2607 - main_output_accuracy: 0.8972 - main_output_loss: 1.1061 - tof_gate_loss: 3.8046e-04 - val_loss: 1.2718 - val_main_output_accuracy: 0.7855 - val_main_output_loss: 1.1166 - val_tof_gate_loss: 4.4692e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.4680 - main_output_accuracy: 0.8545 - main_output_loss: 1.3143 - tof_gate_loss: 4.2803e-04 - val_loss: 1.2810 - val_main_output_accuracy: 0.7794 - val_main_output_loss: 1.1301 - val_tof_gate_loss: 4.4288e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4024 - main_output_accuracy: 0.8702 - main_output_loss: 1.2432 - tof_gate_loss: 4.2462e-04 - val_loss: 1.2758 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1274 - val_tof_gate_loss: 4.3912e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4766 - main_output_accuracy: 0.8433 - main_output_loss: 1.3230 - tof_gate_loss: 4.1066e-04 - val_loss: 1.2850 - val_main_output_accuracy: 0.7733 - val_main_output_loss: 1.1338 - val_tof_gate_loss: 4.3725e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 90/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.4736 - main_output_accuracy: 0.8435 - main_output_loss: 1.3175 - tof_gate_loss: 4.2098e-04 - val_loss: 1.2840 - val_main_output_accuracy: 0.7806 - val_main_output_loss: 1.1305 - val_tof_gate_loss: 4.3059e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 91/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4347 - main_output_accuracy: 0.8564 - main_output_loss: 1.2810 - tof_gate_loss: 4.2560e-04 - val_loss: 1.2727 - val_main_output_accuracy: 0.7892 - val_main_output_loss: 1.1191 - val_tof_gate_loss: 4.2926e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 92/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.3250 - main_output_accuracy: 0.8847 - main_output_loss: 1.1766 - tof_gate_loss: 3.7052e-04\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.3251 - main_output_accuracy: 0.8847 - main_output_loss: 1.1767 - tof_gate_loss: 3.7057e-04 - val_loss: 1.2846 - val_main_output_accuracy: 0.7745 - val_main_output_loss: 1.1300 - val_tof_gate_loss: 4.1744e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 93/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.4869 - main_output_accuracy: 0.8503 - main_output_loss: 1.3337 - tof_gate_loss: 4.1238e-04 - val_loss: 1.2817 - val_main_output_accuracy: 0.7757 - val_main_output_loss: 1.1264 - val_tof_gate_loss: 4.1512e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 94/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.4150 - main_output_accuracy: 0.8456 - main_output_loss: 1.2626 - tof_gate_loss: 4.3599e-04 - val_loss: 1.2789 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1254 - val_tof_gate_loss: 4.1435e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 95/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4040 - main_output_accuracy: 0.8881 - main_output_loss: 1.2547 - tof_gate_loss: 3.6564e-04 - val_loss: 1.2819 - val_main_output_accuracy: 0.7892 - val_main_output_loss: 1.1287 - val_tof_gate_loss: 4.1355e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 96/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4090 - main_output_accuracy: 0.8863 - main_output_loss: 1.2552 - tof_gate_loss: 3.7778e-04 - val_loss: 1.2826 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1281 - val_tof_gate_loss: 4.0651e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 97/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.4206 - main_output_accuracy: 0.8885 - main_output_loss: 1.2724 - tof_gate_loss: 3.6805e-04 - val_loss: 1.2795 - val_main_output_accuracy: 0.7855 - val_main_output_loss: 1.1295 - val_tof_gate_loss: 4.0866e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 98/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.4297 - main_output_accuracy: 0.8575 - main_output_loss: 1.2778 - tof_gate_loss: 3.7159e-04 - val_loss: 1.2876 - val_main_output_accuracy: 0.7843 - val_main_output_loss: 1.1329 - val_tof_gate_loss: 4.0010e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.3807 - main_output_accuracy: 0.8735 - main_output_loss: 1.2329 - tof_gate_loss: 3.4500e-04 - val_loss: 1.2826 - val_main_output_accuracy: 0.7794 - val_main_output_loss: 1.1313 - val_tof_gate_loss: 3.9837e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 90ms/step - loss: 1.3196 - main_output_accuracy: 0.8898 - main_output_loss: 1.1674 - tof_gate_loss: 3.6899e-04 - val_loss: 1.2747 - val_main_output_accuracy: 0.7843 - val_main_output_loss: 1.1218 - val_tof_gate_loss: 3.9325e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 1.3038 - main_output_accuracy: 0.8966 - main_output_loss: 1.1518 - tof_gate_loss: 3.3721e-04\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - loss: 1.3041 - main_output_accuracy: 0.8965 - main_output_loss: 1.1521 - tof_gate_loss: 3.3729e-04 - val_loss: 1.2817 - val_main_output_accuracy: 0.7880 - val_main_output_loss: 1.1327 - val_tof_gate_loss: 3.9554e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 91ms/step - loss: 1.3762 - main_output_accuracy: 0.8805 - main_output_loss: 1.2237 - tof_gate_loss: 3.4056e-04 - val_loss: 1.2764 - val_main_output_accuracy: 0.7892 - val_main_output_loss: 1.1261 - val_tof_gate_loss: 3.8757e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 103/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 92ms/step - loss: 1.3310 - main_output_accuracy: 0.8967 - main_output_loss: 1.1788 - tof_gate_loss: 3.2698e-04 - val_loss: 1.2734 - val_main_output_accuracy: 0.7843 - val_main_output_loss: 1.1213 - val_tof_gate_loss: 3.9150e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 104/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3822 - main_output_accuracy: 0.8724 - main_output_loss: 1.2307 - tof_gate_loss: 3.4342e-04 - val_loss: 1.2796 - val_main_output_accuracy: 0.7868 - val_main_output_loss: 1.1265 - val_tof_gate_loss: 3.9082e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 105/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3658 - main_output_accuracy: 0.8863 - main_output_loss: 1.2142 - tof_gate_loss: 3.5936e-04 - val_loss: 1.2759 - val_main_output_accuracy: 0.7904 - val_main_output_loss: 1.1234 - val_tof_gate_loss: 3.8260e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 106/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.2898 - main_output_accuracy: 0.8756 - main_output_loss: 1.1388 - tof_gate_loss: 3.2103e-04 - val_loss: 1.2817 - val_main_output_accuracy: 0.7855 - val_main_output_loss: 1.1289 - val_tof_gate_loss: 3.8310e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 107/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4162 - main_output_accuracy: 0.8683 - main_output_loss: 1.2632 - tof_gate_loss: 3.7039e-04 - val_loss: 1.2822 - val_main_output_accuracy: 0.7770 - val_main_output_loss: 1.1296 - val_tof_gate_loss: 3.8239e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 108/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4329 - main_output_accuracy: 0.8648 - main_output_loss: 1.2805 - tof_gate_loss: 3.6687e-04 - val_loss: 1.2836 - val_main_output_accuracy: 0.7843 - val_main_output_loss: 1.1334 - val_tof_gate_loss: 3.8097e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 109/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3260 - main_output_accuracy: 0.8847 - main_output_loss: 1.1671 - tof_gate_loss: 3.4640e-04 - val_loss: 1.2812 - val_main_output_accuracy: 0.7831 - val_main_output_loss: 1.1262 - val_tof_gate_loss: 3.8083e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 110/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 1.3134 - main_output_accuracy: 0.8914 - main_output_loss: 1.1619 - tof_gate_loss: 3.2600e-04\n",
      "Epoch 110: ReduceLROnPlateau reducing learning rate to 3e-06.\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.3139 - main_output_accuracy: 0.8913 - main_output_loss: 1.1624 - tof_gate_loss: 3.2612e-04 - val_loss: 1.2807 - val_main_output_accuracy: 0.7819 - val_main_output_loss: 1.1288 - val_tof_gate_loss: 3.7827e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 111/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3802 - main_output_accuracy: 0.8726 - main_output_loss: 1.2392 - tof_gate_loss: 3.6266e-04 - val_loss: 1.2806 - val_main_output_accuracy: 0.7843 - val_main_output_loss: 1.1288 - val_tof_gate_loss: 3.7434e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 112/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3976 - main_output_accuracy: 0.8700 - main_output_loss: 1.2464 - tof_gate_loss: 3.4921e-04 - val_loss: 1.2749 - val_main_output_accuracy: 0.7819 - val_main_output_loss: 1.1222 - val_tof_gate_loss: 3.7361e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 113/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3746 - main_output_accuracy: 0.8926 - main_output_loss: 1.2184 - tof_gate_loss: 3.4721e-04 - val_loss: 1.2738 - val_main_output_accuracy: 0.7868 - val_main_output_loss: 1.1231 - val_tof_gate_loss: 3.7489e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 114/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4009 - main_output_accuracy: 0.8750 - main_output_loss: 1.2505 - tof_gate_loss: 3.6295e-04 - val_loss: 1.2791 - val_main_output_accuracy: 0.7843 - val_main_output_loss: 1.1269 - val_tof_gate_loss: 3.7412e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 115/160\n",
      "\u001b[1m112/112\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4246 - main_output_accuracy: 0.8598 - main_output_loss: 1.2793 - tof_gate_loss: 3.4805e-04 - val_loss: 1.2814 - val_main_output_accuracy: 0.7806 - val_main_output_loss: 1.1277 - val_tof_gate_loss: 3.7354e-04 - learning_rate: 3.0000e-06\n",
      "Epoch 115: early stopping\n",
      "Restoring model weights from the end of the best epoch: 75.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 13:06:13.239014: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\n",
      "===== FOLD 10/10 =====\n",
      "Epoch 1/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 113ms/step - loss: 10.5137 - main_output_accuracy: 0.1599 - main_output_loss: 2.9014 - tof_gate_loss: 0.4140 - val_loss: 8.2134 - val_main_output_accuracy: 0.3669 - val_main_output_loss: 2.4378 - val_tof_gate_loss: 0.2548 - learning_rate: 5.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 7.5766 - main_output_accuracy: 0.3669 - main_output_loss: 2.2201 - tof_gate_loss: 0.2727 - val_loss: 6.3438 - val_main_output_accuracy: 0.4300 - val_main_output_loss: 2.0488 - val_tof_gate_loss: 0.1573 - learning_rate: 5.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 6.1138 - main_output_accuracy: 0.4381 - main_output_loss: 2.0655 - tof_gate_loss: 0.1823 - val_loss: 5.2199 - val_main_output_accuracy: 0.4790 - val_main_output_loss: 1.8380 - val_tof_gate_loss: 0.0980 - learning_rate: 5.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 5.1684 - main_output_accuracy: 0.4970 - main_output_loss: 1.9541 - tof_gate_loss: 0.1197 - val_loss: 4.4485 - val_main_output_accuracy: 0.5476 - val_main_output_loss: 1.6936 - val_tof_gate_loss: 0.0626 - learning_rate: 5.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 110ms/step - loss: 4.5733 - main_output_accuracy: 0.4984 - main_output_loss: 1.9591 - tof_gate_loss: 0.0798 - val_loss: 3.9824 - val_main_output_accuracy: 0.5252 - val_main_output_loss: 1.7215 - val_tof_gate_loss: 0.0416 - learning_rate: 5.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 3.9978 - main_output_accuracy: 0.5475 - main_output_loss: 1.8842 - tof_gate_loss: 0.0532 - val_loss: 3.4965 - val_main_output_accuracy: 0.5630 - val_main_output_loss: 1.6223 - val_tof_gate_loss: 0.0291 - learning_rate: 5.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 3.6078 - main_output_accuracy: 0.5778 - main_output_loss: 1.8072 - tof_gate_loss: 0.0411 - val_loss: 3.2071 - val_main_output_accuracy: 0.5560 - val_main_output_loss: 1.5969 - val_tof_gate_loss: 0.0217 - learning_rate: 5.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 3.3886 - main_output_accuracy: 0.5528 - main_output_loss: 1.8626 - tof_gate_loss: 0.0317 - val_loss: 2.9158 - val_main_output_accuracy: 0.5770 - val_main_output_loss: 1.5509 - val_tof_gate_loss: 0.0164 - learning_rate: 5.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 3.0479 - main_output_accuracy: 0.6028 - main_output_loss: 1.7480 - tof_gate_loss: 0.0222 - val_loss: 2.7612 - val_main_output_accuracy: 0.5756 - val_main_output_loss: 1.6439 - val_tof_gate_loss: 0.0121 - learning_rate: 5.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 2.9307 - main_output_accuracy: 0.5891 - main_output_loss: 1.8144 - tof_gate_loss: 0.0193 - val_loss: 2.6020 - val_main_output_accuracy: 0.5826 - val_main_output_loss: 1.6036 - val_tof_gate_loss: 0.0099 - learning_rate: 5.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.5899 - main_output_accuracy: 0.6530 - main_output_loss: 1.6238 - tof_gate_loss: 0.0134 - val_loss: 2.5000 - val_main_output_accuracy: 0.5644 - val_main_output_loss: 1.6057 - val_tof_gate_loss: 0.0083 - learning_rate: 5.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 2.6543 - main_output_accuracy: 0.6005 - main_output_loss: 1.8369 - tof_gate_loss: 0.0124 - val_loss: 2.3602 - val_main_output_accuracy: 0.5826 - val_main_output_loss: 1.6054 - val_tof_gate_loss: 0.0066 - learning_rate: 5.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 2.4767 - main_output_accuracy: 0.6317 - main_output_loss: 1.7346 - tof_gate_loss: 0.0100 - val_loss: 2.2603 - val_main_output_accuracy: 0.6092 - val_main_output_loss: 1.6030 - val_tof_gate_loss: 0.0052 - learning_rate: 5.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 103ms/step - loss: 2.3687 - main_output_accuracy: 0.6427 - main_output_loss: 1.7093 - tof_gate_loss: 0.0088 - val_loss: 2.1976 - val_main_output_accuracy: 0.5756 - val_main_output_loss: 1.5968 - val_tof_gate_loss: 0.0042 - learning_rate: 5.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 2.2915 - main_output_accuracy: 0.6571 - main_output_loss: 1.7001 - tof_gate_loss: 0.0077 - val_loss: 2.1484 - val_main_output_accuracy: 0.5910 - val_main_output_loss: 1.5913 - val_tof_gate_loss: 0.0035 - learning_rate: 5.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 2.2130 - main_output_accuracy: 0.6518 - main_output_loss: 1.6802 - tof_gate_loss: 0.0062 - val_loss: 2.1224 - val_main_output_accuracy: 0.5784 - val_main_output_loss: 1.6537 - val_tof_gate_loss: 0.0033 - learning_rate: 5.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 2.1125 - main_output_accuracy: 0.6726 - main_output_loss: 1.6252 - tof_gate_loss: 0.0050 - val_loss: 1.9757 - val_main_output_accuracy: 0.6218 - val_main_output_loss: 1.5551 - val_tof_gate_loss: 0.0026 - learning_rate: 5.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 2.0934 - main_output_accuracy: 0.6738 - main_output_loss: 1.6535 - tof_gate_loss: 0.0044 - val_loss: 1.8930 - val_main_output_accuracy: 0.6653 - val_main_output_loss: 1.4487 - val_tof_gate_loss: 0.0023 - learning_rate: 5.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 2.0508 - main_output_accuracy: 0.6797 - main_output_loss: 1.6422 - tof_gate_loss: 0.0038 - val_loss: 1.8999 - val_main_output_accuracy: 0.6204 - val_main_output_loss: 1.4971 - val_tof_gate_loss: 0.0021 - learning_rate: 5.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 2.0198 - main_output_accuracy: 0.6709 - main_output_loss: 1.6489 - tof_gate_loss: 0.0037 - val_loss: 1.9206 - val_main_output_accuracy: 0.6008 - val_main_output_loss: 1.5057 - val_tof_gate_loss: 0.0018 - learning_rate: 5.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 2.0555 - main_output_accuracy: 0.6571 - main_output_loss: 1.6853 - tof_gate_loss: 0.0033 - val_loss: 1.9950 - val_main_output_accuracy: 0.5504 - val_main_output_loss: 1.6567 - val_tof_gate_loss: 0.0016 - learning_rate: 5.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.9751 - main_output_accuracy: 0.6932 - main_output_loss: 1.6997 - tof_gate_loss: 0.0026 - val_loss: 1.9080 - val_main_output_accuracy: 0.6176 - val_main_output_loss: 1.5812 - val_tof_gate_loss: 0.0014 - learning_rate: 5.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.9596 - main_output_accuracy: 0.6989 - main_output_loss: 1.6304 - tof_gate_loss: 0.0025 - val_loss: 1.7987 - val_main_output_accuracy: 0.6555 - val_main_output_loss: 1.4679 - val_tof_gate_loss: 0.0012 - learning_rate: 5.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.8771 - main_output_accuracy: 0.7006 - main_output_loss: 1.5627 - tof_gate_loss: 0.0021 - val_loss: 1.8925 - val_main_output_accuracy: 0.5812 - val_main_output_loss: 1.5582 - val_tof_gate_loss: 0.0011 - learning_rate: 5.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.9551 - main_output_accuracy: 0.6804 - main_output_loss: 1.6519 - tof_gate_loss: 0.0020 - val_loss: 1.9065 - val_main_output_accuracy: 0.5826 - val_main_output_loss: 1.6026 - val_tof_gate_loss: 9.7667e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.8349 - main_output_accuracy: 0.7151 - main_output_loss: 1.5425 - tof_gate_loss: 0.0016\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.8352 - main_output_accuracy: 0.7150 - main_output_loss: 1.5427 - tof_gate_loss: 0.0016 - val_loss: 1.9508 - val_main_output_accuracy: 0.5686 - val_main_output_loss: 1.6704 - val_tof_gate_loss: 8.8730e-04 - learning_rate: 5.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.8069 - main_output_accuracy: 0.7143 - main_output_loss: 1.5206 - tof_gate_loss: 0.0015 - val_loss: 1.7026 - val_main_output_accuracy: 0.6555 - val_main_output_loss: 1.4138 - val_tof_gate_loss: 7.9733e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 1.7653 - main_output_accuracy: 0.7471 - main_output_loss: 1.4919 - tof_gate_loss: 0.0015 - val_loss: 1.6615 - val_main_output_accuracy: 0.6639 - val_main_output_loss: 1.3754 - val_tof_gate_loss: 8.1347e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.7479 - main_output_accuracy: 0.7512 - main_output_loss: 1.4893 - tof_gate_loss: 0.0014 - val_loss: 1.7050 - val_main_output_accuracy: 0.6471 - val_main_output_loss: 1.4390 - val_tof_gate_loss: 7.5658e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.7539 - main_output_accuracy: 0.7407 - main_output_loss: 1.4980 - tof_gate_loss: 0.0013 - val_loss: 1.6937 - val_main_output_accuracy: 0.6485 - val_main_output_loss: 1.4349 - val_tof_gate_loss: 6.7849e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 1.8000 - main_output_accuracy: 0.7236 - main_output_loss: 1.7319 - tof_gate_loss: 0.0013 - val_loss: 1.6205 - val_main_output_accuracy: 0.6737 - val_main_output_loss: 1.3633 - val_tof_gate_loss: 6.6920e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 110ms/step - loss: 1.6616 - main_output_accuracy: 0.7709 - main_output_loss: 1.4179 - tof_gate_loss: 0.0012 - val_loss: 1.7292 - val_main_output_accuracy: 0.6359 - val_main_output_loss: 1.4797 - val_tof_gate_loss: 6.3702e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - loss: 1.6736 - main_output_accuracy: 0.7421 - main_output_loss: 1.4390 - tof_gate_loss: 0.0011 - val_loss: 1.6466 - val_main_output_accuracy: 0.6723 - val_main_output_loss: 1.4260 - val_tof_gate_loss: 6.0499e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6765 - main_output_accuracy: 0.7575 - main_output_loss: 1.4409 - tof_gate_loss: 0.0011 - val_loss: 1.7172 - val_main_output_accuracy: 0.6485 - val_main_output_loss: 1.4833 - val_tof_gate_loss: 5.9210e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6472 - main_output_accuracy: 0.7676 - main_output_loss: 1.4202 - tof_gate_loss: 9.9424e-04 - val_loss: 1.6371 - val_main_output_accuracy: 0.6625 - val_main_output_loss: 1.4308 - val_tof_gate_loss: 5.3492e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.6095 - main_output_accuracy: 0.7830 - main_output_loss: 1.4070 - tof_gate_loss: 9.0851e-04 - val_loss: 1.6802 - val_main_output_accuracy: 0.6457 - val_main_output_loss: 1.4599 - val_tof_gate_loss: 5.1291e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 114ms/step - loss: 1.7638 - main_output_accuracy: 0.7500 - main_output_loss: 1.5382 - tof_gate_loss: 9.7305e-04 - val_loss: 1.6714 - val_main_output_accuracy: 0.6569 - val_main_output_loss: 1.4185 - val_tof_gate_loss: 4.5959e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6555 - main_output_accuracy: 0.7728 - main_output_loss: 1.4324 - tof_gate_loss: 8.5031e-04 - val_loss: 1.6499 - val_main_output_accuracy: 0.6695 - val_main_output_loss: 1.4460 - val_tof_gate_loss: 4.2478e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 1.7014 - main_output_accuracy: 0.7478 - main_output_loss: 1.4810 - tof_gate_loss: 8.8524e-04\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 101ms/step - loss: 1.7014 - main_output_accuracy: 0.7479 - main_output_loss: 1.4810 - tof_gate_loss: 8.8490e-04 - val_loss: 1.7072 - val_main_output_accuracy: 0.6527 - val_main_output_loss: 1.5236 - val_tof_gate_loss: 4.0868e-04 - learning_rate: 2.5000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.5269 - main_output_accuracy: 0.8015 - main_output_loss: 1.3168 - tof_gate_loss: 7.1089e-04 - val_loss: 1.5506 - val_main_output_accuracy: 0.6947 - val_main_output_loss: 1.3128 - val_tof_gate_loss: 4.5646e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.6115 - main_output_accuracy: 0.7932 - main_output_loss: 1.5236 - tof_gate_loss: 7.8915e-04 - val_loss: 1.5153 - val_main_output_accuracy: 0.7031 - val_main_output_loss: 1.2995 - val_tof_gate_loss: 3.7360e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6790 - main_output_accuracy: 0.7747 - main_output_loss: 1.4695 - tof_gate_loss: 7.7820e-04 - val_loss: 1.5874 - val_main_output_accuracy: 0.7003 - val_main_output_loss: 1.3517 - val_tof_gate_loss: 3.8356e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.6485 - main_output_accuracy: 0.7903 - main_output_loss: 1.4469 - tof_gate_loss: 7.3175e-04 - val_loss: 1.5228 - val_main_output_accuracy: 0.7171 - val_main_output_loss: 1.3133 - val_tof_gate_loss: 3.8470e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5497 - main_output_accuracy: 0.8020 - main_output_loss: 1.3492 - tof_gate_loss: 6.5338e-04 - val_loss: 1.5660 - val_main_output_accuracy: 0.6891 - val_main_output_loss: 1.4023 - val_tof_gate_loss: 3.6320e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.5007 - main_output_accuracy: 0.8324 - main_output_loss: 1.3160 - tof_gate_loss: 6.2163e-04 - val_loss: 1.5650 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.3758 - val_tof_gate_loss: 3.4112e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5940 - main_output_accuracy: 0.8066 - main_output_loss: 1.4013 - tof_gate_loss: 6.5333e-04 - val_loss: 1.5584 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.3575 - val_tof_gate_loss: 3.2508e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5461 - main_output_accuracy: 0.8040 - main_output_loss: 1.3592 - tof_gate_loss: 5.9654e-04 - val_loss: 1.5549 - val_main_output_accuracy: 0.6835 - val_main_output_loss: 1.3489 - val_tof_gate_loss: 3.1847e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.5394 - main_output_accuracy: 0.8146 - main_output_loss: 1.3703 - tof_gate_loss: 5.5851e-04 - val_loss: 1.5826 - val_main_output_accuracy: 0.6597 - val_main_output_loss: 1.3695 - val_tof_gate_loss: 2.9822e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.6090 - main_output_accuracy: 0.8201 - main_output_loss: 1.4173 - tof_gate_loss: 6.0181e-04 - val_loss: 1.5037 - val_main_output_accuracy: 0.7227 - val_main_output_loss: 1.3016 - val_tof_gate_loss: 2.9652e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4591 - main_output_accuracy: 0.8290 - main_output_loss: 1.2744 - tof_gate_loss: 4.9980e-04 - val_loss: 1.5762 - val_main_output_accuracy: 0.6891 - val_main_output_loss: 1.4037 - val_tof_gate_loss: 2.7754e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5036 - main_output_accuracy: 0.8353 - main_output_loss: 1.4179 - tof_gate_loss: 5.1346e-04 - val_loss: 1.5678 - val_main_output_accuracy: 0.6611 - val_main_output_loss: 1.3571 - val_tof_gate_loss: 3.0845e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.5803 - main_output_accuracy: 0.7961 - main_output_loss: 1.4050 - tof_gate_loss: 5.4898e-04 - val_loss: 1.6059 - val_main_output_accuracy: 0.6653 - val_main_output_loss: 1.4011 - val_tof_gate_loss: 2.8772e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4484 - main_output_accuracy: 0.8288 - main_output_loss: 1.2733 - tof_gate_loss: 4.8671e-04 - val_loss: 1.5396 - val_main_output_accuracy: 0.6933 - val_main_output_loss: 1.3371 - val_tof_gate_loss: 2.7833e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 110ms/step - loss: 1.5540 - main_output_accuracy: 0.8044 - main_output_loss: 1.3741 - tof_gate_loss: 4.7925e-04 - val_loss: 1.5633 - val_main_output_accuracy: 0.6765 - val_main_output_loss: 1.3640 - val_tof_gate_loss: 2.3173e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4977 - main_output_accuracy: 0.8268 - main_output_loss: 1.5114 - tof_gate_loss: 4.6483e-04 - val_loss: 1.5166 - val_main_output_accuracy: 0.7143 - val_main_output_loss: 1.3204 - val_tof_gate_loss: 2.2018e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4591 - main_output_accuracy: 0.8333 - main_output_loss: 1.4668 - tof_gate_loss: 4.2625e-04 - val_loss: 1.5565 - val_main_output_accuracy: 0.7073 - val_main_output_loss: 1.4051 - val_tof_gate_loss: 2.2470e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 1.4943 - main_output_accuracy: 0.8447 - main_output_loss: 1.3182 - tof_gate_loss: 4.1296e-04\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4945 - main_output_accuracy: 0.8446 - main_output_loss: 1.3184 - tof_gate_loss: 4.1284e-04 - val_loss: 1.5217 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3224 - val_tof_gate_loss: 1.9969e-04 - learning_rate: 1.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4188 - main_output_accuracy: 0.8470 - main_output_loss: 1.2427 - tof_gate_loss: 3.4245e-04 - val_loss: 1.4917 - val_main_output_accuracy: 0.7087 - val_main_output_loss: 1.3311 - val_tof_gate_loss: 2.0858e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 59/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4909 - main_output_accuracy: 0.8317 - main_output_loss: 1.3107 - tof_gate_loss: 3.8373e-04 - val_loss: 1.4800 - val_main_output_accuracy: 0.7143 - val_main_output_loss: 1.2920 - val_tof_gate_loss: 1.9274e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 60/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3712 - main_output_accuracy: 0.8662 - main_output_loss: 1.2058 - tof_gate_loss: 3.5217e-04 - val_loss: 1.5155 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3401 - val_tof_gate_loss: 1.9548e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 61/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5160 - main_output_accuracy: 0.8163 - main_output_loss: 1.3545 - tof_gate_loss: 3.9019e-04 - val_loss: 1.5013 - val_main_output_accuracy: 0.6975 - val_main_output_loss: 1.3576 - val_tof_gate_loss: 2.0886e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 62/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 110ms/step - loss: 1.4412 - main_output_accuracy: 0.8505 - main_output_loss: 1.2777 - tof_gate_loss: 3.4223e-04 - val_loss: 1.4805 - val_main_output_accuracy: 0.7241 - val_main_output_loss: 1.3275 - val_tof_gate_loss: 1.8072e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 63/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.5173 - main_output_accuracy: 0.8335 - main_output_loss: 1.3865 - tof_gate_loss: 3.4739e-04 - val_loss: 1.4675 - val_main_output_accuracy: 0.6989 - val_main_output_loss: 1.2954 - val_tof_gate_loss: 1.7315e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 64/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 110ms/step - loss: 1.4254 - main_output_accuracy: 0.8524 - main_output_loss: 1.2703 - tof_gate_loss: 3.3792e-04 - val_loss: 1.4879 - val_main_output_accuracy: 0.6919 - val_main_output_loss: 1.3657 - val_tof_gate_loss: 1.7564e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 65/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3975 - main_output_accuracy: 0.8721 - main_output_loss: 1.2278 - tof_gate_loss: 3.1125e-04 - val_loss: 1.5338 - val_main_output_accuracy: 0.6905 - val_main_output_loss: 1.3553 - val_tof_gate_loss: 1.6704e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 66/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4403 - main_output_accuracy: 0.8500 - main_output_loss: 1.2703 - tof_gate_loss: 3.2068e-04 - val_loss: 1.5000 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.2919 - val_tof_gate_loss: 1.6011e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 67/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4378 - main_output_accuracy: 0.8451 - main_output_loss: 1.2653 - tof_gate_loss: 3.1286e-04 - val_loss: 1.4961 - val_main_output_accuracy: 0.6989 - val_main_output_loss: 1.3200 - val_tof_gate_loss: 1.6120e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 68/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 102ms/step - loss: 1.4793 - main_output_accuracy: 0.8351 - main_output_loss: 1.3401 - tof_gate_loss: 3.1172e-04 - val_loss: 1.4932 - val_main_output_accuracy: 0.7031 - val_main_output_loss: 1.3500 - val_tof_gate_loss: 1.5698e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 69/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4341 - main_output_accuracy: 0.8580 - main_output_loss: 1.2687 - tof_gate_loss: 2.9394e-04 - val_loss: 1.4752 - val_main_output_accuracy: 0.7129 - val_main_output_loss: 1.3264 - val_tof_gate_loss: 1.5130e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 70/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 1.3830 - main_output_accuracy: 0.8688 - main_output_loss: 1.2153 - tof_gate_loss: 2.7144e-04\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3829 - main_output_accuracy: 0.8688 - main_output_loss: 1.2153 - tof_gate_loss: 2.7146e-04 - val_loss: 1.4959 - val_main_output_accuracy: 0.6919 - val_main_output_loss: 1.3243 - val_tof_gate_loss: 1.4780e-04 - learning_rate: 6.2500e-05\n",
      "Epoch 71/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3999 - main_output_accuracy: 0.8560 - main_output_loss: 1.2323 - tof_gate_loss: 2.8099e-04 - val_loss: 1.4559 - val_main_output_accuracy: 0.7157 - val_main_output_loss: 1.2552 - val_tof_gate_loss: 1.4258e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 72/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.4894 - main_output_accuracy: 0.8445 - main_output_loss: 1.3249 - tof_gate_loss: 2.9189e-04 - val_loss: 1.4659 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3233 - val_tof_gate_loss: 1.5197e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 73/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4019 - main_output_accuracy: 0.8665 - main_output_loss: 1.2433 - tof_gate_loss: 2.5504e-04 - val_loss: 1.4586 - val_main_output_accuracy: 0.6989 - val_main_output_loss: 1.2766 - val_tof_gate_loss: 1.3367e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 74/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.4096 - main_output_accuracy: 0.8612 - main_output_loss: 1.2535 - tof_gate_loss: 2.6474e-04 - val_loss: 1.4830 - val_main_output_accuracy: 0.6919 - val_main_output_loss: 1.3373 - val_tof_gate_loss: 1.3377e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 75/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4550 - main_output_accuracy: 0.8593 - main_output_loss: 1.3151 - tof_gate_loss: 2.6500e-04 - val_loss: 1.4927 - val_main_output_accuracy: 0.6905 - val_main_output_loss: 1.3406 - val_tof_gate_loss: 1.2948e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 76/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.3887 - main_output_accuracy: 0.8676 - main_output_loss: 1.2393 - tof_gate_loss: 2.6599e-04 - val_loss: 1.4772 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.3669 - val_tof_gate_loss: 1.2613e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 77/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4452 - main_output_accuracy: 0.8619 - main_output_loss: 1.3050 - tof_gate_loss: 2.5740e-04 - val_loss: 1.4693 - val_main_output_accuracy: 0.6989 - val_main_output_loss: 1.3444 - val_tof_gate_loss: 1.2875e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 78/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5129 - main_output_accuracy: 0.8389 - main_output_loss: 1.3768 - tof_gate_loss: 2.5079e-04 - val_loss: 1.5012 - val_main_output_accuracy: 0.6933 - val_main_output_loss: 1.3141 - val_tof_gate_loss: 1.2430e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 79/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.4041 - main_output_accuracy: 0.8619 - main_output_loss: 1.2794 - tof_gate_loss: 2.3750e-04\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4041 - main_output_accuracy: 0.8619 - main_output_loss: 1.2793 - tof_gate_loss: 2.3749e-04 - val_loss: 1.4608 - val_main_output_accuracy: 0.7171 - val_main_output_loss: 1.2960 - val_tof_gate_loss: 1.1914e-04 - learning_rate: 3.1250e-05\n",
      "Epoch 80/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.3524 - main_output_accuracy: 0.8799 - main_output_loss: 1.1948 - tof_gate_loss: 2.2877e-04 - val_loss: 1.4737 - val_main_output_accuracy: 0.7101 - val_main_output_loss: 1.3252 - val_tof_gate_loss: 1.2532e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 81/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4793 - main_output_accuracy: 0.8276 - main_output_loss: 1.3220 - tof_gate_loss: 2.7100e-04 - val_loss: 1.4654 - val_main_output_accuracy: 0.7073 - val_main_output_loss: 1.2703 - val_tof_gate_loss: 1.1349e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 82/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.4718 - main_output_accuracy: 0.8582 - main_output_loss: 1.3233 - tof_gate_loss: 2.4407e-04 - val_loss: 1.4761 - val_main_output_accuracy: 0.7101 - val_main_output_loss: 1.3016 - val_tof_gate_loss: 1.2335e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 83/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3230 - main_output_accuracy: 0.8925 - main_output_loss: 1.1700 - tof_gate_loss: 2.1941e-04 - val_loss: 1.4609 - val_main_output_accuracy: 0.7143 - val_main_output_loss: 1.2552 - val_tof_gate_loss: 1.1779e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 84/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3840 - main_output_accuracy: 0.8949 - main_output_loss: 1.2236 - tof_gate_loss: 2.1394e-04 - val_loss: 1.4649 - val_main_output_accuracy: 0.7115 - val_main_output_loss: 1.3116 - val_tof_gate_loss: 1.1068e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 85/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4464 - main_output_accuracy: 0.8761 - main_output_loss: 1.3091 - tof_gate_loss: 2.1564e-04 - val_loss: 1.4648 - val_main_output_accuracy: 0.7115 - val_main_output_loss: 1.3018 - val_tof_gate_loss: 1.1275e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 86/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3865 - main_output_accuracy: 0.8834 - main_output_loss: 1.2244 - tof_gate_loss: 2.1329e-04 - val_loss: 1.4524 - val_main_output_accuracy: 0.7129 - val_main_output_loss: 1.2947 - val_tof_gate_loss: 1.0624e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 87/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.5088 - main_output_accuracy: 0.8479 - main_output_loss: 1.3504 - tof_gate_loss: 2.2927e-04 - val_loss: 1.4567 - val_main_output_accuracy: 0.7101 - val_main_output_loss: 1.2926 - val_tof_gate_loss: 1.1419e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 88/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 1.4420 - main_output_accuracy: 0.8670 - main_output_loss: 1.2850 - tof_gate_loss: 2.2913e-04\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4416 - main_output_accuracy: 0.8670 - main_output_loss: 1.2847 - tof_gate_loss: 2.2900e-04 - val_loss: 1.4730 - val_main_output_accuracy: 0.6961 - val_main_output_loss: 1.3055 - val_tof_gate_loss: 1.1542e-04 - learning_rate: 1.5625e-05\n",
      "Epoch 89/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3007 - main_output_accuracy: 0.8898 - main_output_loss: 1.1409 - tof_gate_loss: 1.9862e-04 - val_loss: 1.4583 - val_main_output_accuracy: 0.7059 - val_main_output_loss: 1.2695 - val_tof_gate_loss: 1.0629e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 90/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 113ms/step - loss: 1.3987 - main_output_accuracy: 0.8800 - main_output_loss: 1.2365 - tof_gate_loss: 2.2011e-04 - val_loss: 1.4614 - val_main_output_accuracy: 0.7073 - val_main_output_loss: 1.2959 - val_tof_gate_loss: 1.0240e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 91/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3313 - main_output_accuracy: 0.9018 - main_output_loss: 1.1713 - tof_gate_loss: 1.9338e-04 - val_loss: 1.4602 - val_main_output_accuracy: 0.7157 - val_main_output_loss: 1.3083 - val_tof_gate_loss: 1.0598e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 92/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 104ms/step - loss: 1.3634 - main_output_accuracy: 0.8716 - main_output_loss: 1.2190 - tof_gate_loss: 1.9160e-04 - val_loss: 1.4624 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.2951 - val_tof_gate_loss: 1.0229e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 93/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4684 - main_output_accuracy: 0.8644 - main_output_loss: 1.3109 - tof_gate_loss: 2.1811e-04 - val_loss: 1.4556 - val_main_output_accuracy: 0.7087 - val_main_output_loss: 1.3220 - val_tof_gate_loss: 1.0429e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 94/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3597 - main_output_accuracy: 0.8926 - main_output_loss: 1.2095 - tof_gate_loss: 1.9814e-04 - val_loss: 1.4582 - val_main_output_accuracy: 0.7059 - val_main_output_loss: 1.3098 - val_tof_gate_loss: 1.0310e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 95/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.3741 - main_output_accuracy: 0.8928 - main_output_loss: 1.2124 - tof_gate_loss: 1.9166e-04 - val_loss: 1.4745 - val_main_output_accuracy: 0.7017 - val_main_output_loss: 1.2988 - val_tof_gate_loss: 9.8443e-05 - learning_rate: 7.8125e-06\n",
      "Epoch 96/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 108ms/step - loss: 1.4049 - main_output_accuracy: 0.8761 - main_output_loss: 1.2490 - tof_gate_loss: 2.0369e-04 - val_loss: 1.4577 - val_main_output_accuracy: 0.7157 - val_main_output_loss: 1.3188 - val_tof_gate_loss: 1.0288e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 97/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 1.5040 - main_output_accuracy: 0.8504 - main_output_loss: 1.3527 - tof_gate_loss: 2.0846e-04\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.5034 - main_output_accuracy: 0.8505 - main_output_loss: 1.3521 - tof_gate_loss: 2.0842e-04 - val_loss: 1.4665 - val_main_output_accuracy: 0.7031 - val_main_output_loss: 1.3076 - val_tof_gate_loss: 1.0254e-04 - learning_rate: 7.8125e-06\n",
      "Epoch 98/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 109ms/step - loss: 1.3614 - main_output_accuracy: 0.9031 - main_output_loss: 1.2183 - tof_gate_loss: 1.8185e-04 - val_loss: 1.4566 - val_main_output_accuracy: 0.7087 - val_main_output_loss: 1.2790 - val_tof_gate_loss: 1.0685e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 99/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.3292 - main_output_accuracy: 0.8910 - main_output_loss: 1.1725 - tof_gate_loss: 1.8660e-04 - val_loss: 1.4557 - val_main_output_accuracy: 0.7073 - val_main_output_loss: 1.2975 - val_tof_gate_loss: 9.6927e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 100/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 107ms/step - loss: 1.4001 - main_output_accuracy: 0.8710 - main_output_loss: 1.2505 - tof_gate_loss: 1.9021e-04 - val_loss: 1.4577 - val_main_output_accuracy: 0.7087 - val_main_output_loss: 1.3113 - val_tof_gate_loss: 1.0655e-04 - learning_rate: 3.9063e-06\n",
      "Epoch 101/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 111ms/step - loss: 1.3871 - main_output_accuracy: 0.8943 - main_output_loss: 1.2434 - tof_gate_loss: 1.8099e-04 - val_loss: 1.4583 - val_main_output_accuracy: 0.7087 - val_main_output_loss: 1.3168 - val_tof_gate_loss: 9.6587e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 102/160\n",
      "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.3875 - main_output_accuracy: 0.8733 - main_output_loss: 1.2760 - tof_gate_loss: 1.9695e-04 - val_loss: 1.4606 - val_main_output_accuracy: 0.7087 - val_main_output_loss: 1.3025 - val_tof_gate_loss: 9.4127e-05 - learning_rate: 3.9063e-06\n",
      "Epoch 102: early stopping\n",
      "Restoring model weights from the end of the best epoch: 62.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2025-09-02 13:27:19.785784: E tensorflow/core/framework/node_def_util.cc:676] NodeDef mentions attribute use_unbounded_threadpool which is not in the op definition: Op<name=MapDataset; signature=input_dataset:variant, other_arguments: -> handle:variant; attr=f:func; attr=Targuments:list(type),min=0; attr=output_types:list(type),min=1; attr=output_shapes:list(shape),min=1; attr=use_inter_op_parallelism:bool,default=true; attr=preserve_cardinality:bool,default=false; attr=force_synchronous:bool,default=false; attr=metadata:string,default=\"\"> This may be expected if your graph generating binary is newer  than this binary. Unknown attributes will be ignored. NodeDef: {{node ParallelMapDatasetV2/_14}}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step\n",
      "\n",
      "✔ Training done.\n",
      "Overall OOF H‑F1 Score = 0.8428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "if TRAIN:\n",
    "    print(\"▶ TRAIN MODE – loading dataset ...\")\n",
    "    df = pd.read_csv(RAW_DIR / \"train.csv\")\n",
    "    \n",
    "    train_dem_df = pd.read_csv(RAW_DIR / \"train_demographics.csv\")\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df['gesture_int'] = le.fit_transform(df['gesture'])\n",
    "    np.save(EXPORT_DIR / \"gesture_classes.npy\", le.classes_)\n",
    "    \n",
    "    acc_y_neg_subjects = (\n",
    "        df.groupby('subject')['acc_y']\n",
    "        .mean()\n",
    "        .loc[lambda x: x < 0]\n",
    "        .index\n",
    "        .tolist()\n",
    "    )\n",
    "    \n",
    "    # Bu subject'leri tamamen drop et\n",
    "    df = df[~df['subject'].isin(acc_y_neg_subjects)].reset_index(drop=True)\n",
    "    \n",
    "    # --- [Önemli Değişiklik] Gelişmiş Fiziksel ve İstatistiksel Özellikler ---\n",
    "    print(\"  Removing gravity and calculating linear acceleration features...\")\n",
    "    linear_accel_list = [pd.DataFrame(remove_gravity_from_acc(group[['acc_x', 'acc_y', 'acc_z']], group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['linear_acc_x', 'linear_acc_y', 'linear_acc_z'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "    df = pd.concat([df, pd.concat(linear_accel_list)], axis=1)\n",
    "    \n",
    "    # Lineer İvme Özellikleri\n",
    "    df['linear_acc_mag'] = np.sqrt(df['linear_acc_x']**2 + df['linear_acc_y']**2 + df['linear_acc_z']**2)\n",
    "    # df['linear_acc_mag_jerk'] already exists, but consider a smoother derivative or higher order jerks if needed\n",
    "    df['linear_acc_mag_jerk'] = df.groupby('sequence_id')['linear_acc_mag'].diff().fillna(0) # Keep current for now\n",
    "    \n",
    "   \n",
    "    \n",
    "    print(\"  Calculating angular velocity and distance from quaternions...\")\n",
    "    angular_vel_list = [pd.DataFrame(calculate_angular_velocity_from_quat(group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['angular_vel_x', 'angular_vel_y', 'angular_vel_z'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "    df = pd.concat([df, pd.concat(angular_vel_list)], axis=1)\n",
    "    angular_dist_list = [pd.DataFrame(calculate_angular_distance(group[['rot_x', 'rot_y', 'rot_z', 'rot_w']]), columns=['angular_distance'], index=group.index) for _, group in df.groupby('sequence_id')]\n",
    "    df = pd.concat([df, pd.concat(angular_dist_list)], axis=1)\n",
    "\n",
    "  \n",
    "    #- HUSEYİN GUR (GMN) 1.FE 80>81\n",
    "    # Hız ve İvme için Anlık İstatistiksel Özellikler (Mevcut sensör okumalarına ek olarak) \n",
    "    for col in ['acc_x', 'acc_y', 'acc_z',  'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z']:  # 'rot_w', 'rot_x', 'rot_y', 'rot_z' eksik\n",
    "        if col in df.columns:\n",
    "            df[f'{col}_diff'] = df.groupby('sequence_id')[col].diff().fillna(0)\n",
    "            df[f'{col}_abs_diff'] = np.abs(df.groupby('sequence_id')[col].diff()).fillna(0) # Mutlak fark\n",
    "    #- HUSEYİN GUR (GMN) 1.FE 80>81\n",
    "\n",
    "    # --- [Önemli Değişiklik] Fiziksel ve Yeni İstatistiksel FE'yi Yansıtan Özellik Listesi ---\n",
    "    imu_cols_base = ['acc_x', 'acc_y', 'acc_z'] + [c for c in df.columns if c.startswith('rot_')]  #+ ['handedness', 'height_cm']\n",
    "    # , 'acc_x_spectral_energy','acc_y_spectral_energy','acc_z_spectral_energy', 'linear_acc_mag_spectral_energy'\n",
    "    imu_engineered = [\n",
    "    'linear_acc_mag', 'linear_acc_mag_jerk',\n",
    "    'angular_vel_x', 'angular_vel_y', 'angular_vel_z', 'angular_distance',\n",
    "    #'jerk_mad_25'\n",
    "    #'damj_linear_acc_mag_jerk_mean', 'damj_linear_acc_mag_jerk_std', 'damj_linear_acc_mag_jerk_skew',\n",
    "    #'damj_jerk_mad_25_mean','damj_jerk_mad_25_std'\n",
    "   \n",
    "    ] \n",
    "    #- HUSEYİN GUR (GMN) 1.FE 80>81\n",
    "    # Yeni eklenen differansiyel ve mutlak fark özellikleri\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z']:\n",
    "        if col in df.columns:\n",
    "            imu_engineered.append(f'{col}_diff')\n",
    "            imu_engineered.append(f'{col}_abs_diff')\n",
    "     #- HUSEYİN GUR (GMN) 1.FE 80>81\n",
    "\n",
    "    imu_cols = list(dict.fromkeys(imu_cols_base + imu_engineered))\n",
    "    \n",
    "    # HUSEYIN GUR - THM - CGPT 3.FE ÇOK AZ BAŞARISIZ 81>81 FAKAT CV 83\n",
    "    #df = extract_temporal_thm_features(df)\n",
    "    #df = extract_spatial_thm_features(df)\n",
    "    # HUSEYIN GUR - THM - CGPT 3.FE\n",
    "    \n",
    "    thm_cols_original = [c for c in df.columns if c.startswith('thm_')]\n",
    "    \n",
    "    tof_aggregated_cols_template = []\n",
    "    for i in range(1, 6): tof_aggregated_cols_template.extend([f'tof_{i}_mean', f'tof_{i}_std', f'tof_{i}_min', f'tof_{i}_max'])\n",
    "\n",
    "    # Spatial Gradient ToF - HUSEYİN GUR - cgpt 2.FE 81>better 81\n",
    "    for i in range(1, 6):\n",
    "        tof_aggregated_cols_template.extend([\n",
    "            f'tof_{i}_grad_mean', f'tof_{i}_grad_std', f'tof_{i}_grad_max'\n",
    "        ])\n",
    "    # Spatial Gradient ToF - HUSEYİN GUR - cgpt 2.FE 81>better 81\n",
    "    \n",
    "    final_feature_cols = imu_cols  + tof_aggregated_cols_template + thm_cols_original\n",
    "\n",
    "    imu_dim_final = len(imu_cols)\n",
    "    #tof_thm_aggregated_dim_final = len(thm_cols_original) + len(tof_aggregated_cols_template)\n",
    "    tof_dim = len(tof_aggregated_cols_template)\n",
    "    thm_dim = len(thm_cols_original)\n",
    "\n",
    "    print(f\"  IMU (phys-based + enhanced) {imu_dim_final} | THM + Aggregated TOF {tof_dim + thm_dim} | total {len(final_feature_cols)} features\")\n",
    "    np.save(EXPORT_DIR / \"feature_cols.npy\", np.array(final_feature_cols))\n",
    "    \n",
    "    print(\"  Building sequences...\")\n",
    "    seq_gp = df.groupby('sequence_id') \n",
    "    X_list_unscaled, y_list_int, groups_list, lens = [], [], [], [] \n",
    "    for seq_id, seq_df in seq_gp:\n",
    "        seq_df_copy = seq_df.copy()\n",
    "        for i in range(1, 6):\n",
    "            pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]; tof_data = seq_df_copy[pixel_cols].replace(-1, np.nan)\n",
    "            seq_df_copy[f'tof_{i}_mean'], seq_df_copy[f'tof_{i}_std'], seq_df_copy[f'tof_{i}_min'], seq_df_copy[f'tof_{i}_max'] = tof_data.mean(axis=1), tof_data.std(axis=1), tof_data.min(axis=1), tof_data.max(axis=1)\n",
    "            \n",
    "            # Spatial Gradient ToF - HUSEYİN GUR - cgpt 2.FE 81>better 81\n",
    "            spatial_feats = calculate_spatial_tof_features(seq_df_copy, i)\n",
    "            seq_df_copy = pd.concat([seq_df_copy, spatial_feats], axis=1)\n",
    "            # Spatial Gradient ToF - HUSEYİN GUR - cgpt 2.FE 81>better 81\n",
    "        \n",
    "        # Sadece belirlenen nihai özellik sütunlarını kullan\n",
    "        X_list_unscaled.append(seq_df_copy[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32'))\n",
    "        y_list_int.append(seq_df_copy['gesture_int'].iloc[0])\n",
    "        groups_list.append(seq_df_copy['subject'].iloc[0])\n",
    "        lens.append(len(seq_df_copy))\n",
    "\n",
    "    print(\"  Fitting StandardScaler...\")\n",
    "    all_steps_concatenated = np.concatenate(X_list_unscaled, axis=0)\n",
    "    scaler = StandardScaler().fit(all_steps_concatenated)\n",
    "    joblib.dump(scaler, EXPORT_DIR / \"scaler.pkl\")\n",
    "    \n",
    "    print(\"  Scaling and padding sequences...\")\n",
    "    X_scaled_list = [scaler.transform(x_seq) for x_seq in X_list_unscaled]\n",
    "    pad_len = int(np.percentile(lens, PAD_PERCENTILE)); np.save(EXPORT_DIR / \"sequence_maxlen.npy\", pad_len)\n",
    "    X = pad_sequences(X_scaled_list, maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "    #y_stratify = np.array(y_list_int)\n",
    "\n",
    "       # --- DEĞİŞİKLİK BAŞLANGICI --- SOL ELLERİ HER FOLD'A EŞİT DAĞIT!\n",
    "    subject_acc_x_mean_global = df.groupby('subject')['acc_x'].mean()\n",
    "    subject_is_acc_x_mean_negative = (subject_acc_x_mean_global < 0).astype(str) # '0' veya '1' string olarak\n",
    "    \n",
    "    y_stratify = np.array([f\"{gesture_label}_{subject_is_acc_x_mean_negative.loc[sub_id]}\"\n",
    "                           for gesture_label, sub_id in zip(y_list_int, groups_list)])\n",
    "    # --- DEĞİŞİKLİK SONU ---\n",
    "    \n",
    "    groups, y = np.array(groups_list), to_categorical(y_list_int, num_classes=len(le.classes_))\n",
    "    print(\"  Starting training with Stratified Group K-Fold CV...\")\n",
    "    sgkf = StratifiedGroupKFold(n_splits=N_SPLITS, shuffle=True, random_state=state_num)\n",
    "    oof_preds = np.zeros_like(y, dtype='float32')\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y_stratify, groups)):\n",
    "        print(f\"\\n===== FOLD {fold+1}/{N_SPLITS} =====\")\n",
    "        X_tr, X_val, y_tr, y_val = X[train_idx], X[val_idx], y[train_idx], y[val_idx]\n",
    "       \n",
    "        # --- [Önemli Değişiklik] Model Derlemesi ve Geri Çağırmalar ---\n",
    "        #model = build_gated_two_branch_model(pad_len, imu_dim_final, tof_dim, thm_dim, len(le.classes_), wd=WD)\n",
    "        model = build_gated_two_branch_model(pad_len, imu_dim_final, tof_dim+thm_dim, len(le.classes_), wd=WD)\n",
    "        \n",
    "        # Learning Rate Scheduler ekleme - TEK BAŞINA 80>81\n",
    "        # Bu scheduler, belirli bir metrik iyileşmediğinde öğrenme oranını azaltır.\n",
    "        lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_main_output_accuracy',\n",
    "            mode='max',\n",
    "            factor=0.5,\n",
    "            patience=8,\n",
    "            cooldown=2,\n",
    "            min_lr=3e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        model.compile(optimizer=Adam(LR_INIT),\n",
    "                      loss={'main_output': tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "                             'tof_gate': tf.keras.losses.BinaryCrossentropy()\n",
    "                             },\n",
    "                      loss_weights={'main_output': 1.0,\n",
    "                                     'tof_gate': GATE_LOSS_WEIGHT,\n",
    "                                     },\n",
    "                      metrics={'main_output': 'accuracy'})\n",
    "        \n",
    "        class_weight_dict = dict(enumerate(compute_class_weight('balanced', classes=np.arange(len(le.classes_)), y=y_tr.argmax(1))))\n",
    "        \n",
    "        # GatedMixupGenerator'ın imu_dim parametresini güncelledik\n",
    "        train_gen = GatedMixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, imu_dim=imu_dim_final, class_weight=class_weight_dict, alpha=MIXUP_ALPHA)\n",
    "        val_gen = GatedMixupGenerator(X_val, y_val, batch_size=BATCH_SIZE, imu_dim=imu_dim_final,class_weight=None, alpha=0.0) # İmu_dim burada da doğru olmalı\n",
    "\n",
    "        #train_gen = GatedMixupGenerator(X_tr, y_tr, batch_size=BATCH_SIZE, imu_dim=imu_dim_final, class_weight=class_weight_dict, alpha=MIXUP_ALPHA, masking_prob=MASKING_PROB)\n",
    "        #val_gen = GatedMixupGenerator(X_val, y_val, batch_size=BATCH_SIZE, imu_dim=imu_dim_final,class_weight=None, alpha=0.2, masking_prob=0.0) # İmu_dim burada da doğru olmalı\n",
    "\n",
    "        # EarlyStopping ve LearningRateScheduler'ı birlikte kullan\n",
    "        cb = [\n",
    "            EarlyStopping(patience=PATIENCE, restore_best_weights=True, verbose=1, monitor='val_main_output_accuracy', mode='max'),\n",
    "            lr_scheduler\n",
    "        ]\n",
    "        \n",
    "        model.fit(train_gen, epochs=EPOCHS, validation_data=val_gen, callbacks=cb, verbose=1)\n",
    "        model.save(EXPORT_DIR / f\"gesture_model_fold_{fold}.h5\")\n",
    "        preds_val,_ = model.predict(X_val) # Gate çıktısını ayır\n",
    "        oof_preds[val_idx] = preds_val\n",
    "\n",
    "    print(\"\\n✔ Training done.\")\n",
    "    \n",
    "    # --- [OOF Skoru Hesaplama] ---\n",
    "    from metric import CompetitionMetric\n",
    "    true_oof_int = y.argmax(1)\n",
    "    pred_oof_int = oof_preds.argmax(1)\n",
    "    \n",
    "    h_f1_oof = CompetitionMetric().calculate_hierarchical_f1(\n",
    "        pd.DataFrame({'gesture': le.classes_[true_oof_int]}),\n",
    "        pd.DataFrame({'gesture': le.classes_[pred_oof_int]}))\n",
    "    print(f\"Overall OOF H‑F1 Score = {h_f1_oof:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T19:54:16.507523Z",
     "iopub.status.busy": "2025-07-03T19:54:16.507315Z",
     "iopub.status.idle": "2025-07-03T19:54:16.518619Z",
     "shell.execute_reply": "2025-07-03T19:54:16.517884Z",
     "shell.execute_reply.started": "2025-07-03T19:54:16.507508Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(sequence: pl.DataFrame, demographics: pl.DataFrame) -> str:\n",
    "    df_seq = sequence.to_pandas()\n",
    "    seq_df_copy = df_seq.copy() \n",
    "\n",
    "\n",
    "    linear_accel = remove_gravity_from_acc(df_seq, df_seq)\n",
    "    df_seq['linear_acc_x'], df_seq['linear_acc_y'], df_seq['linear_acc_z'] = linear_accel[:, 0], linear_accel[:, 1], linear_accel[:, 2]\n",
    "    df_seq['linear_acc_mag'] = np.sqrt(df_seq['linear_acc_x']**2 + df_seq['linear_acc_y']**2 + df_seq['linear_acc_z']**2)\n",
    "    df_seq['linear_acc_mag_jerk'] = df_seq['linear_acc_mag'].diff().fillna(0)\n",
    "    angular_vel = calculate_angular_velocity_from_quat(df_seq)\n",
    "    df_seq['angular_vel_x'], df_seq['angular_vel_y'], df_seq['angular_vel_z'] = angular_vel[:, 0], angular_vel[:, 1], angular_vel[:, 2]\n",
    "    df_seq['angular_distance'] = calculate_angular_distance(df_seq)\n",
    "\n",
    "    for col in ['acc_x', 'acc_y', 'acc_z', 'linear_acc_x', 'linear_acc_y', 'linear_acc_z', 'angular_vel_x', 'angular_vel_y', 'angular_vel_z']:\n",
    "        if col in df_seq.columns:\n",
    "            df_seq[f'{col}_diff'] = df_seq.groupby('sequence_id')[col].diff().fillna(0)\n",
    "            df_seq[f'{col}_abs_diff'] = np.abs(df_seq.groupby('sequence_id')[col].diff()).fillna(0) # Mutlak fark\n",
    "\n",
    "    for i in range(1, 6):\n",
    "        pixel_cols = [f\"tof_{i}_v{p}\" for p in range(64)]; tof_data = df_seq[pixel_cols].replace(-1, np.nan)\n",
    "        df_seq[f'tof_{i}_mean'], df_seq[f'tof_{i}_std'], df_seq[f'tof_{i}_min'], df_seq[f'tof_{i}_max'] = tof_data.mean(axis=1), tof_data.std(axis=1), tof_data.min(axis=1), tof_data.max(axis=1)\n",
    "        spatial_feats = calculate_spatial_tof_features(seq_df_copy, i)\n",
    "        df_seq = pd.concat([df_seq, spatial_feats], axis=1)\n",
    "        \n",
    "        \n",
    "    mat_unscaled = df_seq[final_feature_cols].ffill().bfill().fillna(0).values.astype('float32')\n",
    "    mat_scaled = scaler.transform(mat_unscaled)\n",
    "    pad_input = pad_sequences([mat_scaled], maxlen=pad_len, padding='post', truncating='post', dtype='float32')\n",
    "\n",
    "   \n",
    "    all_preds = [model.predict(pad_input, verbose=0)[0] for model in models] # 主出力のみ取得\n",
    "    avg_pred = np.mean(all_preds, axis=0)\n",
    "    print(str(gesture_classes[avg_pred.argmax()]))\n",
    "    return str(gesture_classes[avg_pred.argmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-03T19:54:16.519668Z",
     "iopub.status.busy": "2025-07-03T19:54:16.519431Z",
     "iopub.status.idle": "2025-07-03T19:54:30.810934Z",
     "shell.execute_reply": "2025-07-03T19:54:30.810174Z",
     "shell.execute_reply.started": "2025-07-03T19:54:16.519652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if not TRAIN:\n",
    "    import kaggle_evaluation.cmi_inference_server\n",
    "    inference_server = kaggle_evaluation.cmi_inference_server.CMIInferenceServer(predict)\n",
    "\n",
    "    if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "        inference_server.serve()\n",
    "    else:\n",
    "        inference_server.run_local_gateway(\n",
    "            data_paths=(\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test.csv',\n",
    "                '/kaggle/input/cmi-detect-behavior-with-sensor-data/test_demographics.csv',\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 12518947,
     "sourceId": 102335,
     "sourceType": "competition"
    },
    {
     "datasetId": 7713851,
     "sourceId": 12274546,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7782242,
     "sourceId": 12344631,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 242954653,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "kaggle-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
